Directory Structure:

└── ./
    ├── optimizer
    │   ├── metal
    │   │   ├── __init__.py
    │   │   ├── jit.py
    │   │   ├── manifold_physics.metal
    │   │   ├── manifold_physics.py
    │   │   └── ops.mm
    │   ├── triton
    │   │   ├── __init__.py
    │   │   ├── manifold_grid_kernels.py
    │   │   ├── manifold_physics_kernels.py
    │   │   ├── manifold_physics.py
    │   │   ├── smoke_test.py
    │   │   └── spatial_hash_kernels.py
    │   ├── __init__.py
    │   ├── kernel_registry.py
    │   ├── kernels.py
    │   ├── manifold_physics.py
    │   └── runtime.py
    ├── sensorium
    │   ├── experiments
    │   │   ├── __init__.py
    │   │   ├── ablations.py
    │   │   ├── audio_gen.py
    │   │   ├── base.py
    │   │   ├── harness.py
    │   │   ├── image_gen.py
    │   │   ├── kernel_ablations.py
    │   │   ├── kernel_audio_gen.py
    │   │   ├── kernel_cocktail_party.py
    │   │   ├── kernel_continuous.py
    │   │   ├── kernel_engine.py
    │   │   ├── kernel_image_gen.py
    │   │   ├── kernel_mnist_bytes.py
    │   │   ├── kernel_next_token.py
    │   │   ├── kernel_rule_shift.py
    │   │   ├── kernel_text_diffusion.py
    │   │   ├── kernel_timeseries.py
    │   │   ├── mnist_bytes.py
    │   │   ├── next_token.py
    │   │   ├── result.py
    │   │   ├── rule_shift.py
    │   │   ├── text_diffusion.py
    │   │   └── timeseries.py
    │   └── manifold
    │       ├── carriers.py
    │       ├── config.py
    │       ├── generator.py
    │       ├── profiler.py
    │       ├── simulator.py
    │       └── visualizer.py
    └── run.py



---
File: /optimizer/metal/__init__.py
---

"""Metal (MPS) fused kernels for Apple Silicon.

This submodule provides a serious, real implementation of a fused DBA (decoupled)
attention *decode* path for MPS, backed by a custom Metal Shading Language kernel
and an Objective-C++ PyTorch extension.

The kernel is intended for autoregressive decode (single-token query) where the
primary cost is repeatedly materializing score tensors and performing unfused
softmax/value matmuls. The Metal kernel performs a numerically-stable, two-pass
softmax (max + exp-sum) fused with the V-weighted reduction, without materializing
the full score matrix.
"""

from __future__ import annotations

from .manifold_physics import ManifoldPhysics, ManifoldPhysicsConfig, manifold_physics_available

__all__ = [
    "ManifoldPhysics",
    "ManifoldPhysicsConfig",
    "manifold_physics_available",
]




---
File: /optimizer/metal/jit.py
---

"""JIT build + load the Metal extension.

We intentionally keep this separate from the main import path so `caramba` can
import/type-check on non-mac platforms without requiring Xcode toolchains.
"""

from __future__ import annotations

from pathlib import Path
import subprocess
from typing import Any

from optimizer.runtime import metal_build_tools_available, metal_supported


def _this_dir() -> Path:
    return Path(__file__).resolve().parent


_CACHED_MOD: Any | None = None
_CACHED_ERR: Exception | None = None


def _xcrun_find(tool: str) -> str:
    """Resolve a tool path from the active Xcode toolchain via xcrun."""
    try:
        out = subprocess.check_output(
            ["xcrun", "-sdk", "macosx", "--find", str(tool)],
            stderr=subprocess.STDOUT,
        )
        p = out.decode("utf-8", errors="replace").strip()
        if not p:
            raise RuntimeError(f"xcrun returned empty path for tool {tool!r}")
        return p
    except Exception as e:
        # Make this actionable: most failures are missing SDK/toolchain selection.
        try:
            devdir = subprocess.check_output(["xcode-select", "-p"], stderr=subprocess.STDOUT).decode(
                "utf-8", errors="replace"
            ).strip()
        except Exception:
            devdir = "<unknown>"
        raise RuntimeError(
            f"Unable to locate required Xcode tool {tool!r} via xcrun.\n"
            f"Active developer dir: {devdir}\n\n"
            "Fix:\n"
            "  - Install Xcode Command Line Tools: `xcode-select --install`\n"
            "  - OR select Xcode.app:\n"
            "      `sudo xcode-select -s /Applications/Xcode.app/Contents/Developer`\n"
            "      `sudo xcodebuild -license accept`\n\n"
            "Verify:\n"
            "  `xcrun -sdk macosx --find metal`\n"
            "  `xcrun -sdk macosx --find metallib`\n"
        ) from e


def _compile_metallib(*, out_dir: Path, verbose: bool) -> Path:
    """Compile Metal shaders -> `caramba_ops.metallib` in `out_dir`."""

    sources = [
        _this_dir() / "manifold_physics.metal",
    ]
    airs = [out_dir / f"{src.stem}.air" for src in sources]
    metallib = out_dir / "caramba_ops.metallib"

    metal = _xcrun_find("metal")
    metallib_tool = _xcrun_find("metallib")

    # Rebuild only when missing or any source is newer.
    if metallib.exists():
        mt = metallib.stat().st_mtime
        if all(mt >= src.stat().st_mtime for src in sources):
            return metallib

    out_dir.mkdir(parents=True, exist_ok=True)

    # Compile each .metal source to .air.
    for src, air in zip(sources, airs, strict=True):
        cmd = [
            metal,
            "-c",
            str(src),
            "-o",
            str(air),
        ]
        if verbose:
            print("[caramba] compiling Metal shader:", " ".join(cmd))
        proc = subprocess.run(cmd, capture_output=True, text=True)
        if proc.returncode != 0:
            raise RuntimeError(
                "Failed to compile Metal shaders with the active toolchain.\n\n"
                f"Command:\n  {' '.join(cmd)}\n\n"
                f"stdout:\n{proc.stdout}\n\n"
                f"stderr:\n{proc.stderr}\n\n"
                "If the error mentions SDKs, verify:\n"
                "  `xcrun --sdk macosx --show-sdk-path`\n"
                "If the error mentions missing tools, verify:\n"
                "  `xcrun -sdk macosx --find metallib`\n"
            )

    # Link all .air files into a single metallib.
    cmd2 = [
        metallib_tool,
        *[str(air) for air in airs],
        "-o",
        str(metallib),
    ]
    if verbose:
        print("[caramba] linking Metal metallib:", " ".join(cmd2))
    proc2 = subprocess.run(cmd2, capture_output=True, text=True)
    if proc2.returncode != 0:
        raise RuntimeError(
            "Failed to link Metal metallib (`metallib`).\n\n"
            f"Command:\n  {' '.join(cmd2)}\n\n"
            f"stdout:\n{proc2.stdout}\n\n"
            f"stderr:\n{proc2.stderr}\n"
        )
    return metallib


def load_caramba_metal_ops(*, verbose: bool = False) -> Any:
    """Build (if needed) and import the `caramba_metal_ops` extension.

    Returns the imported extension module. Raises on build/import failures.
    """
    global _CACHED_MOD, _CACHED_ERR
    if _CACHED_MOD is not None:
        return _CACHED_MOD
    if _CACHED_ERR is not None:
        raise _CACHED_ERR

    if not metal_supported():
        err = RuntimeError("Metal/MPS is not supported on this runtime")
        _CACHED_ERR = err
        raise err
    if not metal_build_tools_available():
        err = RuntimeError(
            "Metal build tools unavailable.\n\n"
            "caramba's fused Metal kernels require Xcode's Metal toolchain (`metal`, `metallib`).\n"
            "Install/select it:\n"
            "  - `xcode-select --install`\n"
            "  - or install Xcode.app then:\n"
            "      `sudo xcode-select -s /Applications/Xcode.app/Contents/Developer`\n"
            "      `sudo xcodebuild -license accept`\n\n"
            "Verify:\n"
            "  `xcrun -sdk macosx --find metal`\n"
            "  `xcrun -sdk macosx --find metallib`\n"
        )
        _CACHED_ERR = err
        raise err

    import torch.utils.cpp_extension as ce

    try:
        name = "caramba_metal_ops"
        build_dir = Path(ce._get_build_directory(name, verbose=verbose))

        _compile_metallib(out_dir=build_dir, verbose=verbose)

        # Build/load the ObjC++ extension. We intentionally place the metallib in the
        # same directory as the built .so so the extension can locate it via dladdr.
        src_ops = str(_this_dir() / "ops.mm")
        extra_cflags = [
            "-O3",
            "-std=c++17",
            "-fobjc-arc",
            "-fblocks",
        ]
        extra_ldflags = [
            "-framework",
            "Metal",
            "-framework",
            "Foundation",
        ]
        mod = ce.load(
            name=name,
            sources=[src_ops],
            extra_cflags=extra_cflags,
            extra_ldflags=extra_ldflags,
            with_cuda=False,
            is_python_module=True,
            build_directory=str(build_dir),
            verbose=verbose,
        )
    except Exception as e:
        _CACHED_ERR = e
        raise

    _CACHED_MOD = mod
    return mod




---
File: /optimizer/metal/manifold_physics.metal
---

#include <metal_stdlib>
using namespace metal;

// =============================================================================
// Manifold Physics Kernels
// =============================================================================
// Implements the core physics simulation for the thermo-manifold:
// - Particle-to-field scatter (gravity, heat)
// - Field-to-particle gather + integrated state update
// - Carrier-oscillator coupling
//
// Design principles:
// - Fused operations to minimize memory bandwidth
// - Hardware-accelerated trilinear interpolation via texture3d
// - All physics in one gather-update pass
// =============================================================================

// =============================================================================
// TEXTURE3D SAMPLER CONFIGURATION
// =============================================================================
// Metal's texture sampling hardware provides:
// - Free trilinear interpolation (in TMU, not ALU)
// - Automatic boundary clamping
// - Cache-optimized memory access patterns
//
// For field sampling, this gives ~2x speedup over manual interpolation.

constexpr sampler trilinear_sampler(
    coord::normalized,           // Use [0,1] normalized coordinates
    address::clamp_to_edge,      // Clamp at boundaries
    filter::linear,              // Trilinear interpolation
    mip_filter::none             // No mipmapping
);

// Alternative sampler for nearest-neighbor (for debugging or exact cell access)
constexpr sampler nearest_sampler(
    coord::normalized,
    address::clamp_to_edge,
    filter::nearest
);

// -----------------------------------------------------------------------------
// Parameter Structs (must match ops.mm)
// -----------------------------------------------------------------------------

struct ManifoldFieldParams {
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;
    float grid_spacing;     // Physical size of each grid cell
    float inv_grid_spacing; // 1.0 / grid_spacing
};

struct ManifoldPhysicsParams {
    // Grid parameters
    uint32_t num_particles;
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;
    float grid_spacing;
    float inv_grid_spacing;
    float dt;                    // Time step
    
    // Fundamental physical constants (simulation units)
    float G;                     // Gravitational constant
    float k_B;                   // Boltzmann constant
    float sigma_SB;              // Stefan-Boltzmann constant
    
    // Material properties
    float particle_radius;       // Radius of particles
    float thermal_conductivity;  // k: heat transfer rate
    float specific_heat;         // c_v: heat capacity per unit mass  
    float dynamic_viscosity;     // η: resistance to flow
    float emissivity;            // ε: radiation efficiency (0-1)
    float young_modulus;         // E: collision stiffness
};

// =============================================================================
// Adaptive Thermodynamics: Fast reduction for global energy statistics
// =============================================================================
// We use a 2-pass reduction to compute:
//   mean_abs = mean(|x|), mean = mean(x), std = std(x)
// entirely on-GPU, so downstream kernels can do adaptive renormalization without
// CPU sync or "magic number" damping.
//
// Output format (single float4 in `out_stats`):
//   x: mean_abs
//   y: mean
//   z: std
//   w: count (as float)
//
// NOTE: Host must dispatch pass1 with exactly 256 threads/threadgroup and
//       num_threadgroups = ceil(N / 256).
// -----------------------------------------------------------------------------

// NOTE: Program-scope variables must reside in the constant address space in Metal.
constant uint kReduceThreads = 256;

kernel void reduce_float_stats_pass1(
    device const float* x           [[buffer(0)]],  // (N,)
    device float* group_stats       [[buffer(1)]],  // (num_groups * 4,) [sum_abs, sum, sum_sq, count]
    constant uint& N                [[buffer(2)]],
    uint tid                        [[thread_index_in_threadgroup]],
    uint tg_id                      [[threadgroup_position_in_grid]]
) {
    uint idx = tg_id * kReduceThreads + tid;
    float v = (idx < N) ? x[idx] : 0.0f;
    float4 acc = float4(fabs(v), v, v * v, (idx < N) ? 1.0f : 0.0f);

    threadgroup float4 scratch[kReduceThreads];
    scratch[tid] = acc;
    threadgroup_barrier(mem_flags::mem_threadgroup);

    // Parallel reduction in shared memory.
    for (uint offset = kReduceThreads / 2; offset > 0; offset >>= 1) {
        if (tid < offset) {
            scratch[tid] += scratch[tid + offset];
        }
        threadgroup_barrier(mem_flags::mem_threadgroup);
    }

    if (tid == 0) {
        group_stats[tg_id * 4 + 0] = scratch[0].x;
        group_stats[tg_id * 4 + 1] = scratch[0].y;
        group_stats[tg_id * 4 + 2] = scratch[0].z;
        group_stats[tg_id * 4 + 3] = scratch[0].w;
    }
}

kernel void reduce_float_stats_finalize(
    device const float* group_stats [[buffer(0)]],  // (num_groups * 4,)
    device float* out_stats         [[buffer(1)]],  // (4,) [mean_abs, mean, std, count]
    constant uint& num_groups        [[buffer(2)]],
    uint tid                         [[thread_index_in_threadgroup]]
) {
    // One threadgroup (kReduceThreads) reduces all group_stats.
    float4 acc = float4(0.0f);
    for (uint i = tid; i < num_groups; i += kReduceThreads) {
        float sum_abs = group_stats[i * 4 + 0];
        float sum = group_stats[i * 4 + 1];
        float sum_sq = group_stats[i * 4 + 2];
        float count = group_stats[i * 4 + 3];
        acc += float4(sum_abs, sum, sum_sq, count);
    }

    threadgroup float4 scratch[kReduceThreads];
    scratch[tid] = acc;
    threadgroup_barrier(mem_flags::mem_threadgroup);

    for (uint offset = kReduceThreads / 2; offset > 0; offset >>= 1) {
        if (tid < offset) {
            scratch[tid] += scratch[tid + offset];
        }
        threadgroup_barrier(mem_flags::mem_threadgroup);
    }

    if (tid == 0) {
        float sum_abs = scratch[0].x;
        float sum = scratch[0].y;
        float sum_sq = scratch[0].z;
        float count = max(scratch[0].w, 1.0f);

        float mean_abs = sum_abs / count;
        float mean = sum / count;
        float var = max((sum_sq / count) - mean * mean, 0.0f);
        float std = sqrt(var);

        out_stats[0] = mean_abs;
        out_stats[1] = mean;
        out_stats[2] = std;
        out_stats[3] = count;
    }
}

// =============================================================================
// Stochastic helpers (hash + Box-Muller for N(0,1))
// =============================================================================
inline uint hash_u32(uint x) {
    // PCG-inspired mix (fast, decent avalanche)
    x ^= x >> 16;
    x *= 0x7feb352du;
    x ^= x >> 15;
    x *= 0x846ca68bu;
    x ^= x >> 16;
    return x;
}

inline float u01_from_u32(uint x) {
    // Map to (0,1): avoid exact 0 which breaks log() in Box-Muller.
    // Use 24-bit mantissa-like range for stability.
    float u = (float)(x & 0x00FFFFFFu) * (1.0f / 16777216.0f);
    return max(u, 1e-7f);
}

inline float2 box_muller(float u1, float u2) {
    float r = sqrt(-2.0f * log(u1));
    float t = 2.0f * M_PI_F * u2;
    return float2(r * cos(t), r * sin(t));
}

inline float3 randn3(uint seed, uint idx) {
    // Deterministic per-(seed, idx) 3D standard normal.
    // Uses 6 uniforms derived from a hashed stream.
    uint s0 = hash_u32(seed ^ (idx * 0x9e3779b9u));
    uint s1 = hash_u32(s0 + 1u);
    uint s2 = hash_u32(s0 + 2u);
    uint s3 = hash_u32(s0 + 3u);
    float2 z0 = box_muller(u01_from_u32(s0), u01_from_u32(s1));
    float2 z1 = box_muller(u01_from_u32(s2), u01_from_u32(s3));
    // We only need 3 independent N(0,1) samples here.
    return float3(z0.x, z0.y, z1.x);
}

inline float2 randn2(uint seed, uint idx) {
    uint s0 = hash_u32(seed ^ (idx * 0x9e3779b9u));
    uint s1 = hash_u32(s0 + 1u);
    return box_muller(u01_from_u32(s0), u01_from_u32(s1));
}

inline float randn1(uint seed, uint idx) {
    return randn2(seed, idx).x;
}

// =============================================================================
// Spatial Hash Grid Structures (for O(N) collision detection)
// =============================================================================
// The spatial hash divides the simulation domain into cells. Each particle is
// assigned to a cell based on its position. Collision detection only checks
// particles in the same cell and 26 neighboring cells (3x3x3 neighborhood).
//
// Cell size should be >= 2 * particle_radius for correctness.
// For optimal performance, cell_size ≈ 2-4 * particle_radius.

struct SpatialHashParams {
    uint32_t num_particles;
    uint32_t grid_x;         // Number of cells in X
    uint32_t grid_y;         // Number of cells in Y
    uint32_t grid_z;         // Number of cells in Z
    float cell_size;         // Size of each cell
    float inv_cell_size;     // 1.0 / cell_size
    float domain_min_x;      // Domain minimum X
    float domain_min_y;      // Domain minimum Y
    float domain_min_z;      // Domain minimum Z
};

struct SpatialCollisionParams {
    uint32_t num_particles;
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;
    float cell_size;
    float inv_cell_size;
    float domain_min_x;
    float domain_min_y;
    float domain_min_z;
    float dt;
    float particle_radius;
    float young_modulus;
    float thermal_conductivity;
    float restitution;
};

// Tiled scatter parameters for reduced atomic contention
struct TiledScatterParams {
    uint32_t num_particles;
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;
    float grid_spacing;
    float inv_grid_spacing;
    uint32_t tile_size;      // Particles per threadgroup tile
};

// -----------------------------------------------------------------------------
// Utility: Trilinear Interpolation
// -----------------------------------------------------------------------------

// Compute trilinear weights and grid indices for a position
inline void trilinear_coords(
    float3 pos,
    float inv_spacing,
    uint3 grid_dims,
    thread uint3& base_idx,
    thread float3& frac
) {
    // Convert world position to grid coordinates
    float3 grid_pos = pos * inv_spacing;
    
    // Clamp to valid range (leaving room for +1 neighbor)
    grid_pos = clamp(grid_pos, float3(0.0f), float3(grid_dims) - 1.001f);
    
    // Integer base index and fractional part
    base_idx = uint3(floor(grid_pos));
    frac = grid_pos - float3(base_idx);
}

// Sample a 3D field with trilinear interpolation
inline float sample_field_trilinear(
    device const float* field,
    uint3 base_idx,
    float3 frac,
    uint3 grid_dims
) {
    // Compute strides
    uint stride_z = 1;
    uint stride_y = grid_dims.z;
    uint stride_x = grid_dims.y * grid_dims.z;
    
    // Base linear index
    uint base = base_idx.x * stride_x + base_idx.y * stride_y + base_idx.z * stride_z;
    
    // Sample all 8 corners
    float c000 = field[base];
    float c001 = field[base + stride_z];
    float c010 = field[base + stride_y];
    float c011 = field[base + stride_y + stride_z];
    float c100 = field[base + stride_x];
    float c101 = field[base + stride_x + stride_z];
    float c110 = field[base + stride_x + stride_y];
    float c111 = field[base + stride_x + stride_y + stride_z];
    
    // Trilinear interpolation
    float fx = frac.x;
    float fy = frac.y;
    float fz = frac.z;
    
    float c00 = c000 * (1.0f - fz) + c001 * fz;
    float c01 = c010 * (1.0f - fz) + c011 * fz;
    float c10 = c100 * (1.0f - fz) + c101 * fz;
    float c11 = c110 * (1.0f - fz) + c111 * fz;
    
    float c0 = c00 * (1.0f - fy) + c01 * fy;
    float c1 = c10 * (1.0f - fy) + c11 * fy;
    
    return c0 * (1.0f - fx) + c1 * fx;
}

// Compute gradient of a 3D field at a position (central differences)
inline float3 sample_gradient_trilinear(
    device const float* field,
    uint3 base_idx,
    float3 frac,
    uint3 grid_dims,
    float inv_spacing
) {
    uint stride_z = 1;
    uint stride_y = grid_dims.z;
    uint stride_x = grid_dims.y * grid_dims.z;
    
    // Sample at offset positions for gradient
    // We approximate gradient using the interpolated values at slightly offset positions
    // For efficiency, we use the corner values to estimate gradient
    
    uint base = base_idx.x * stride_x + base_idx.y * stride_y + base_idx.z * stride_z;
    
    float c000 = field[base];
    float c001 = field[base + stride_z];
    float c010 = field[base + stride_y];
    float c011 = field[base + stride_y + stride_z];
    float c100 = field[base + stride_x];
    float c101 = field[base + stride_x + stride_z];
    float c110 = field[base + stride_x + stride_y];
    float c111 = field[base + stride_x + stride_y + stride_z];
    
    // Gradient in each direction (using trilinear interpolation of face values)
    float fy = frac.y;
    float fz = frac.z;
    
    // dF/dx: difference between x=1 and x=0 faces
    float face_x0 = c000 * (1-fy) * (1-fz) + c010 * fy * (1-fz) + c001 * (1-fy) * fz + c011 * fy * fz;
    float face_x1 = c100 * (1-fy) * (1-fz) + c110 * fy * (1-fz) + c101 * (1-fy) * fz + c111 * fy * fz;
    float grad_x = (face_x1 - face_x0) * inv_spacing;
    
    float fx = frac.x;
    // dF/dy
    float face_y0 = c000 * (1-fx) * (1-fz) + c100 * fx * (1-fz) + c001 * (1-fx) * fz + c101 * fx * fz;
    float face_y1 = c010 * (1-fx) * (1-fz) + c110 * fx * (1-fz) + c011 * (1-fx) * fz + c111 * fx * fz;
    float grad_y = (face_y1 - face_y0) * inv_spacing;
    
    // dF/dz
    float face_z0 = c000 * (1-fx) * (1-fy) + c100 * fx * (1-fy) + c010 * (1-fx) * fy + c110 * fx * fy;
    float face_z1 = c001 * (1-fx) * (1-fy) + c101 * fx * (1-fy) + c011 * (1-fx) * fy + c111 * fx * fy;
    float grad_z = (face_z1 - face_z0) * inv_spacing;
    
    return float3(grad_x, grad_y, grad_z);
}

// -----------------------------------------------------------------------------
// Kernel: Scatter particles to fields (gravity + heat)
// -----------------------------------------------------------------------------
// Each particle contributes its mass to the gravity field and its heat to the
// temperature field using trilinear interpolation weights.

kernel void scatter_particles_to_fields(
    device const float* particle_pos      [[buffer(0)]],  // N * 3
    device const float* particle_mass     [[buffer(1)]],  // N
    device const float* particle_heat     [[buffer(2)]],  // N
    device atomic_float* gravity_field    [[buffer(3)]],  // X * Y * Z
    device atomic_float* heat_field       [[buffer(4)]],  // X * Y * Z
    constant ManifoldFieldParams& params  [[buffer(5)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= params.grid_x * params.grid_y * params.grid_z) return;
    
    // This version: each thread handles one particle
    // For large particle counts, consider tiling or hierarchical approaches
}

// Per-particle scatter (one thread per particle)
kernel void scatter_particle(
    device const float* particle_pos      [[buffer(0)]],  // N * 3
    device const float* particle_mass     [[buffer(1)]],  // N
    device const float* particle_heat     [[buffer(2)]],  // N
    device atomic_float* gravity_field    [[buffer(3)]],  // X * Y * Z
    device atomic_float* heat_field       [[buffer(4)]],  // X * Y * Z
    constant ManifoldPhysicsParams& p     [[buffer(5)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    // Read particle position
    float3 pos = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    float mass = particle_mass[gid];
    float heat = particle_heat[gid];
    
    // Get trilinear coordinates
    uint3 base_idx;
    float3 frac;
    uint3 grid_dims = uint3(p.grid_x, p.grid_y, p.grid_z);
    trilinear_coords(pos, p.inv_grid_spacing, grid_dims, base_idx, frac);
    
    // Compute 8 trilinear weights
    float wx0 = 1.0f - frac.x, wx1 = frac.x;
    float wy0 = 1.0f - frac.y, wy1 = frac.y;
    float wz0 = 1.0f - frac.z, wz1 = frac.z;
    
    float weights[8] = {
        wx0 * wy0 * wz0,  // 000
        wx0 * wy0 * wz1,  // 001
        wx0 * wy1 * wz0,  // 010
        wx0 * wy1 * wz1,  // 011
        wx1 * wy0 * wz0,  // 100
        wx1 * wy0 * wz1,  // 101
        wx1 * wy1 * wz0,  // 110
        wx1 * wy1 * wz1   // 111
    };
    
    // Grid strides
    uint stride_z = 1;
    uint stride_y = p.grid_z;
    uint stride_x = p.grid_y * p.grid_z;
    uint base = base_idx.x * stride_x + base_idx.y * stride_y + base_idx.z * stride_z;
    
    // Offsets for 8 corners
    uint offsets[8] = {
        0,
        stride_z,
        stride_y,
        stride_y + stride_z,
        stride_x,
        stride_x + stride_z,
        stride_x + stride_y,
        stride_x + stride_y + stride_z
    };
    
    // Atomic scatter to both fields
    for (int i = 0; i < 8; i++) {
        uint idx = base + offsets[i];
        atomic_fetch_add_explicit(&gravity_field[idx], mass * weights[i], memory_order_relaxed);
        atomic_fetch_add_explicit(&heat_field[idx], heat * weights[i], memory_order_relaxed);
    }
}

// -----------------------------------------------------------------------------
// Kernel: Gather from fields + update particle state (FUSED)
// -----------------------------------------------------------------------------
// This is the main physics kernel. For each particle:
// 1. Sample gravity potential → compute force
// 2. Sample temperature → compute heat exchange
// 3. Update velocity from force (with viscosity)
// 4. Update position from velocity
// 5. Update energy, heat, excitation from thermodynamic rules
// All in one kernel, one read per field, minimal memory traffic.

kernel void gather_update_particles(
    // Fields (read-only)
    device const float* gravity_potential [[buffer(0)]],  // X * Y * Z
    device const float* temperature_field [[buffer(1)]],  // X * Y * Z
    // Particle state (read-write)
    device float* particle_pos            [[buffer(2)]],  // N * 3
    device float* particle_vel            [[buffer(3)]],  // N * 3
    device float* particle_energy         [[buffer(4)]],  // N
    device float* particle_heat           [[buffer(5)]],  // N
    device float* particle_excitation     [[buffer(6)]],  // N
    device const float* particle_mass     [[buffer(7)]],  // N (read-only, doesn't change)
    // Parameters
    constant ManifoldPhysicsParams& p     [[buffer(8)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    // -------------------------------------------------------------------------
    // 1. Read current particle state
    // -------------------------------------------------------------------------
    float3 pos = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    float3 vel = float3(
        particle_vel[gid * 3 + 0],
        particle_vel[gid * 3 + 1],
        particle_vel[gid * 3 + 2]
    );
    float energy = particle_energy[gid];
    float heat = particle_heat[gid];
    float excitation = particle_excitation[gid];
    float mass = particle_mass[gid];
    
    // -------------------------------------------------------------------------
    // 2. Gather from fields (trilinear interpolation)
    // -------------------------------------------------------------------------
    uint3 base_idx;
    float3 frac;
    uint3 grid_dims = uint3(p.grid_x, p.grid_y, p.grid_z);
    trilinear_coords(pos, p.inv_grid_spacing, grid_dims, base_idx, frac);
    
    // =========================================================================
    // GRAVITATIONAL FORCE: F = -m * ∇φ where φ is gravitational potential
    // =========================================================================
    float3 gravity_grad = sample_gradient_trilinear(
        gravity_potential, base_idx, frac, grid_dims, p.inv_grid_spacing
    );
    // Newton's law of gravitation: F = -G * m * ∇φ
    float3 gravity_force = -gravity_grad * mass * p.G;
    
    // =========================================================================
    // TEMPERATURE AND PRESSURE
    // =========================================================================
    // Sample local temperature field (this is T from heat diffusion on grid)
    float local_temp = sample_field_trilinear(
        temperature_field, base_idx, frac, grid_dims
    );
    
    // Particle temperature from its internal heat: T = Q / (m * c_v)
    float particle_temp = heat / (max(mass, 1e-6f) * p.specific_heat);
    
    // Pressure gradient from ideal gas law: P = ρ * k_B * T
    // Force per unit mass: a = -(1/ρ) * ∇P = -k_B * ∇T (for uniform composition)
    float3 temp_grad = sample_gradient_trilinear(
        temperature_field, base_idx, frac, grid_dims, p.inv_grid_spacing
    );
    float3 pressure_force = -temp_grad * p.k_B * mass;
    
    // =========================================================================
    // HEAT TRANSFER: Newton's law of cooling + Stefan-Boltzmann radiation
    // =========================================================================
    // Newton's law: dQ/dt = h * A * (T_env - T)
    // For sphere: A = 4πr², and h ~ k/r (thermal conductivity / length scale)
    // Combined: dQ/dt ~ k * r * (T_env - T)
    float r = p.particle_radius;
    float heat_transfer_coef = p.thermal_conductivity * r;
    float dQ_conduction = heat_transfer_coef * (local_temp - particle_temp) * p.dt;
    heat += dQ_conduction;
    
    // Stefan-Boltzmann radiation: P = ε * σ * A * T^4
    // Surface area A = 4πr² (we absorb 4π into σ_SB)
    float surface_area = r * r;
    float T4 = particle_temp * particle_temp * particle_temp * particle_temp;
    float dQ_radiation = p.emissivity * p.sigma_SB * surface_area * T4 * p.dt;
    heat = max(heat - dQ_radiation, 0.0f);
    
    // Update temperature after heat exchange
    particle_temp = heat / (max(mass, 1e-6f) * p.specific_heat);
    
    // =========================================================================
    // EXCITATION DYNAMICS (oscillator frequency)
    // =========================================================================
    // Excitation represents the oscillator's INTRINSIC natural frequency.
    // This is a conserved property that does NOT change during simulation.
    // 
    // The frequency is set at particle creation and remains fixed.
    // This ensures spectral diversity is preserved throughout the simulation.
    //
    // Note: We do NOT modify excitation here - it's an intrinsic property.
    // The spectral carrier layer reads excitation as oscillator frequency (ω).
    //
    // Energy thermalization happens at a fixed rate (not frequency-dependent):
    float tau_thermalization = 10.0f;  // Slower thermalization time scale
    float dQ_thermalization = (energy / tau_thermalization) * p.dt;
    dQ_thermalization = min(dQ_thermalization, energy);
    energy -= dQ_thermalization;
    heat += dQ_thermalization;
    
    // Physical constraints (numerical safety only)
    energy = max(energy, 0.0f);
    heat = max(heat, 0.0f);
    
    // =========================================================================
    // VISCOUS DRAG: Stokes' law F = -6πηrv
    // =========================================================================
    // For a sphere moving through viscous medium at low Reynolds number
    // γ = 6πηr is the drag coefficient
    float gamma = 6.0f * 3.14159f * p.dynamic_viscosity * r;
    
    // Total force = gravity + pressure (hydrostatic equilibrium when balanced)
    float3 total_force = gravity_force + pressure_force;
    
    // Apply forces: F = ma → a = F/m
    float3 acceleration = total_force / max(mass, 1e-6f);
    
    // Clamp acceleration to prevent explosions
    float acc_mag = length(acceleration);
    float max_acc = 10.0f;  // Maximum acceleration per step
    if (acc_mag > max_acc) {
        acceleration = acceleration * (max_acc / acc_mag);
    }
    
    // Compute kinetic energy before damping (for energy conservation)
    float ke_before = 0.5f * mass * dot(vel, vel);
    
    // Apply drag force as a damping term
    // Use exact exponential for accuracy: v' = v * exp(-gamma * dt)
    float damping_factor = exp(-gamma * p.dt);
    vel = vel * damping_factor + acceleration * p.dt;
    
    // Compute kinetic energy after damping
    float ke_after = 0.5f * mass * dot(vel, vel);
    
    // Lost kinetic energy becomes heat (first law of thermodynamics)
    // dE_total/dt = 0, so dE_kinetic + dQ = 0  →  dQ = -dE_kinetic
    // All dissipated kinetic energy becomes internal energy (heat)
    float ke_lost = max(ke_before - ke_after, 0.0f);
    heat += ke_lost;  // 100% energy conservation
    
    // Clamp velocity magnitude to prevent runaway
    float vel_mag = length(vel);
    float max_vel = 2.0f;  // Maximum velocity (aligned with collision kernel)
    if (vel_mag > max_vel) {
        vel = vel * (max_vel / vel_mag);
    }
    
    // -------------------------------------------------------------------------
    // 5. Position update
    // -------------------------------------------------------------------------
    pos += vel * p.dt;
    
    // Clamp to grid bounds with soft boundary (reflect velocity at walls)
    float3 grid_max = float3(p.grid_x, p.grid_y, p.grid_z) * p.grid_spacing * 0.95f;
    float3 grid_min = float3(0.5f);
    
    // Reflect velocity at boundaries
    if (pos.x < grid_min.x) { pos.x = grid_min.x; vel.x = abs(vel.x) * 0.5f; }
    if (pos.y < grid_min.y) { pos.y = grid_min.y; vel.y = abs(vel.y) * 0.5f; }
    if (pos.z < grid_min.z) { pos.z = grid_min.z; vel.z = abs(vel.z) * 0.5f; }
    if (pos.x > grid_max.x) { pos.x = grid_max.x; vel.x = -abs(vel.x) * 0.5f; }
    if (pos.y > grid_max.y) { pos.y = grid_max.y; vel.y = -abs(vel.y) * 0.5f; }
    if (pos.z > grid_max.z) { pos.z = grid_max.z; vel.z = -abs(vel.z) * 0.5f; }
    
    // -------------------------------------------------------------------------
    // 6. Write back updated state
    // -------------------------------------------------------------------------
    particle_pos[gid * 3 + 0] = pos.x;
    particle_pos[gid * 3 + 1] = pos.y;
    particle_pos[gid * 3 + 2] = pos.z;
    
    particle_vel[gid * 3 + 0] = vel.x;
    particle_vel[gid * 3 + 1] = vel.y;
    particle_vel[gid * 3 + 2] = vel.z;
    
    particle_energy[gid] = energy;
    particle_heat[gid] = heat;
    particle_excitation[gid] = excitation;
}

// -----------------------------------------------------------------------------
// Kernel: Gather + BAOAB Langevin update + Kuramoto mean-field "entanglement"
// -----------------------------------------------------------------------------
// Goal:
// - Replace clamp-heavy semi-Euler update with a stable Langevin integrator.
// - Add a non-local coupling signal via carrier mean-field alignment.
//
// Notes:
// - This does NOT require backprop. The "loss" is the effective energy landscape
//   implied by forces + thermostat.
// - We keep the legacy kernel intact; this is opt-in from the host.
//
// BAOAB splitting (one step):
//   v <- v + (dt/2m) F(x)                          (B)
//   v <- a v + b N(0,1)  with a=exp(-γdt), b=...   (A/O)
//   x <- x + dt v                                  (O)
//   v <- v + (dt/2m) F(x_new)                      (B)
//
// Kuramoto mean-field:
// - g_i = Σ_k T(ω_i, ω_k, σ_k) * c_k
// - alignment = Re(e^{-iφ_i} g_i) / (|g_i|+eps) ∈ [-1,1]
// - entangle_force ∥ ∇φ_gravity, scaled by alignment (global, non-local signal)
//
// -----------------------------------------------------------------------------
// Kernel: Gather from fields using TEXTURE3D (hardware-accelerated)
// -----------------------------------------------------------------------------
// This version uses Metal's texture sampling hardware for:
// - Free trilinear interpolation in texture unit (TMU)
// - Cache-optimized memory access patterns
// - ~2x faster than manual buffer interpolation
//
// To use this kernel, the host must:
// 1. Create MTLTexture objects with MTLPixelFormatR32Float
// 2. Copy field data into textures before each frame
// 3. Use MTLSamplerDescriptor with linear filtering

struct ManifoldPhysicsTextureParams {
    uint32_t num_particles;
    uint32_t grid_x;
    uint32_t grid_y;
    uint32_t grid_z;
    float grid_spacing;
    float inv_grid_spacing;
    float dt;
    float G;
    float k_B;
    float sigma_SB;
    float particle_radius;
    float thermal_conductivity;
    float specific_heat;
    float dynamic_viscosity;
    float emissivity;
    float young_modulus;
};

kernel void gather_update_particles_textured(
    // Fields as 3D textures (read-only, hardware trilinear)
    texture3d<float, access::sample> gravity_potential [[texture(0)]],
    texture3d<float, access::sample> temperature_field [[texture(1)]],
    // Particle state (read-write)
    device float* particle_pos            [[buffer(0)]],  // N * 3
    device float* particle_vel            [[buffer(1)]],  // N * 3
    device float* particle_energy         [[buffer(2)]],  // N
    device float* particle_heat           [[buffer(3)]],  // N
    device float* particle_excitation     [[buffer(4)]],  // N
    device const float* particle_mass     [[buffer(5)]],  // N
    // Parameters
    constant ManifoldPhysicsTextureParams& p [[buffer(6)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    // Read current particle state
    float3 pos = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    float3 vel = float3(
        particle_vel[gid * 3 + 0],
        particle_vel[gid * 3 + 1],
        particle_vel[gid * 3 + 2]
    );
    float energy = particle_energy[gid];
    float heat = particle_heat[gid];
    float excitation = particle_excitation[gid];
    float mass = particle_mass[gid];
    
    // Convert position to normalized texture coordinates [0, 1]
    float3 grid_dims = float3(p.grid_x, p.grid_y, p.grid_z);
    float3 tex_coord = pos * p.inv_grid_spacing / grid_dims;
    
    // Sample temperature field using hardware trilinear interpolation
    // Note: texture.sample() returns float4, we use .x for single-channel
    // (gravity potential is only used for gradient, not the value itself)
    float local_temp = temperature_field.sample(trilinear_sampler, tex_coord).x;
    
    // Compute gradients using finite differences on texture samples
    float3 texel_size = 1.0f / grid_dims;
    float3 gravity_grad = float3(
        gravity_potential.sample(trilinear_sampler, tex_coord + float3(texel_size.x, 0, 0)).x -
        gravity_potential.sample(trilinear_sampler, tex_coord - float3(texel_size.x, 0, 0)).x,
        gravity_potential.sample(trilinear_sampler, tex_coord + float3(0, texel_size.y, 0)).x -
        gravity_potential.sample(trilinear_sampler, tex_coord - float3(0, texel_size.y, 0)).x,
        gravity_potential.sample(trilinear_sampler, tex_coord + float3(0, 0, texel_size.z)).x -
        gravity_potential.sample(trilinear_sampler, tex_coord - float3(0, 0, texel_size.z)).x
    ) * (0.5f * p.inv_grid_spacing);
    
    float3 temp_grad = float3(
        temperature_field.sample(trilinear_sampler, tex_coord + float3(texel_size.x, 0, 0)).x -
        temperature_field.sample(trilinear_sampler, tex_coord - float3(texel_size.x, 0, 0)).x,
        temperature_field.sample(trilinear_sampler, tex_coord + float3(0, texel_size.y, 0)).x -
        temperature_field.sample(trilinear_sampler, tex_coord - float3(0, texel_size.y, 0)).x,
        temperature_field.sample(trilinear_sampler, tex_coord + float3(0, 0, texel_size.z)).x -
        temperature_field.sample(trilinear_sampler, tex_coord - float3(0, 0, texel_size.z)).x
    ) * (0.5f * p.inv_grid_spacing);
    
    // Physics calculations (same as buffer version)
    float3 gravity_force = -gravity_grad * mass * p.G;
    float particle_temp = heat / (max(mass, 1e-6f) * p.specific_heat);
    float3 pressure_force = -temp_grad * p.k_B * mass;
    
    // Heat transfer
    float r = p.particle_radius;
    float heat_transfer_coef = p.thermal_conductivity * r;
    float dQ_conduction = heat_transfer_coef * (local_temp - particle_temp) * p.dt;
    heat += dQ_conduction;
    
    float surface_area = r * r;
    float T4 = particle_temp * particle_temp * particle_temp * particle_temp;
    float dQ_radiation = p.emissivity * p.sigma_SB * surface_area * T4 * p.dt;
    heat = max(heat - dQ_radiation, 0.0f);
    
    particle_temp = heat / (max(mass, 1e-6f) * p.specific_heat);
    
    // Excitation is an intrinsic property - do NOT modify it.
    // See gather_update_particles for documentation.
    
    // Energy thermalization (fixed rate, not frequency-dependent)
    float tau_thermalization = 10.0f;
    float dQ_thermalization = (energy / tau_thermalization) * p.dt;
    dQ_thermalization = min(dQ_thermalization, energy);
    energy -= dQ_thermalization;
    heat += dQ_thermalization;
    
    energy = max(energy, 0.0f);
    heat = max(heat, 0.0f);
    
    // Viscous drag
    float gamma = 6.0f * 3.14159f * p.dynamic_viscosity * r;
    float3 total_force = gravity_force + pressure_force;
    float3 acceleration = total_force / max(mass, 1e-6f);
    
    float acc_mag = length(acceleration);
    float max_acc = 10.0f;
    if (acc_mag > max_acc) {
        acceleration = acceleration * (max_acc / acc_mag);
    }
    
    float ke_before = 0.5f * mass * dot(vel, vel);
    float damping_factor = exp(-gamma * p.dt);
    vel = vel * damping_factor + acceleration * p.dt;
    float ke_after = 0.5f * mass * dot(vel, vel);
    float ke_lost = max(ke_before - ke_after, 0.0f);
    heat += ke_lost;
    
    float vel_mag = length(vel);
    float max_vel = 2.0f;
    if (vel_mag > max_vel) {
        vel = vel * (max_vel / vel_mag);
    }
    
    // Position update
    pos += vel * p.dt;
    
    float3 grid_max = float3(p.grid_x, p.grid_y, p.grid_z) * p.grid_spacing * 0.95f;
    float3 grid_min = float3(0.5f);
    
    if (pos.x < grid_min.x) { pos.x = grid_min.x; vel.x = abs(vel.x) * 0.5f; }
    if (pos.y < grid_min.y) { pos.y = grid_min.y; vel.y = abs(vel.y) * 0.5f; }
    if (pos.z < grid_min.z) { pos.z = grid_min.z; vel.z = abs(vel.z) * 0.5f; }
    if (pos.x > grid_max.x) { pos.x = grid_max.x; vel.x = -abs(vel.x) * 0.5f; }
    if (pos.y > grid_max.y) { pos.y = grid_max.y; vel.y = -abs(vel.y) * 0.5f; }
    if (pos.z > grid_max.z) { pos.z = grid_max.z; vel.z = -abs(vel.z) * 0.5f; }
    
    // Write back
    particle_pos[gid * 3 + 0] = pos.x;
    particle_pos[gid * 3 + 1] = pos.y;
    particle_pos[gid * 3 + 2] = pos.z;
    
    particle_vel[gid * 3 + 0] = vel.x;
    particle_vel[gid * 3 + 1] = vel.y;
    particle_vel[gid * 3 + 2] = vel.z;
    
    particle_energy[gid] = energy;
    particle_heat[gid] = heat;
    particle_excitation[gid] = excitation;
}

// -----------------------------------------------------------------------------
// Kernel: Heat diffusion on the field (Laplacian stencil)
// -----------------------------------------------------------------------------
// Evolves the temperature field via diffusion: dT/dt = α ∇²T

kernel void diffuse_heat_field(
    device const float* temp_in           [[buffer(0)]],  // X * Y * Z
    device float* temp_out                [[buffer(1)]],  // X * Y * Z
    constant ManifoldFieldParams& p       [[buffer(2)]],
    constant float& diffusion_coef        [[buffer(3)]],
    constant float& dt                    [[buffer(4)]],
    uint3 gid [[thread_position_in_grid]]
) {
    if (gid.x >= p.grid_x || gid.y >= p.grid_y || gid.z >= p.grid_z) return;
    
    uint stride_z = 1;
    uint stride_y = p.grid_z;
    uint stride_x = p.grid_y * p.grid_z;
    uint idx = gid.x * stride_x + gid.y * stride_y + gid.z * stride_z;
    
    float center = temp_in[idx];
    
    // 6-point Laplacian stencil with boundary handling
    float xm = (gid.x > 0) ? temp_in[idx - stride_x] : center;
    float xp = (gid.x < p.grid_x - 1) ? temp_in[idx + stride_x] : center;
    float ym = (gid.y > 0) ? temp_in[idx - stride_y] : center;
    float yp = (gid.y < p.grid_y - 1) ? temp_in[idx + stride_y] : center;
    float zm = (gid.z > 0) ? temp_in[idx - stride_z] : center;
    float zp = (gid.z < p.grid_z - 1) ? temp_in[idx + stride_z] : center;
    
    float laplacian = (xm + xp + ym + yp + zm + zp - 6.0f * center) 
                      * (p.inv_grid_spacing * p.inv_grid_spacing);
    
    temp_out[idx] = center + diffusion_coef * laplacian * dt;
}

// -----------------------------------------------------------------------------
// Kernel: Solve Poisson equation for gravity (Jacobi iteration step)
// -----------------------------------------------------------------------------
// ∇²φ = 4πG ρ  →  One Jacobi iteration step
// For production, consider FFT-based solver or multigrid

kernel void poisson_jacobi_step(
    device const float* phi_in            [[buffer(0)]],  // X * Y * Z (potential)
    device const float* rho               [[buffer(1)]],  // X * Y * Z (density/mass)
    device float* phi_out                 [[buffer(2)]],  // X * Y * Z
    constant ManifoldFieldParams& p       [[buffer(3)]],
    constant float& gravity_4pi           [[buffer(4)]],  // 4 * pi * G
    uint3 gid [[thread_position_in_grid]]
) {
    if (gid.x >= p.grid_x || gid.y >= p.grid_y || gid.z >= p.grid_z) return;
    
    uint stride_z = 1;
    uint stride_y = p.grid_z;
    uint stride_x = p.grid_y * p.grid_z;
    uint idx = gid.x * stride_x + gid.y * stride_y + gid.z * stride_z;
    
    // Boundary handling (Dirichlet: φ = 0 at boundary)
    float xm = (gid.x > 0) ? phi_in[idx - stride_x] : 0.0f;
    float xp = (gid.x < p.grid_x - 1) ? phi_in[idx + stride_x] : 0.0f;
    float ym = (gid.y > 0) ? phi_in[idx - stride_y] : 0.0f;
    float yp = (gid.y < p.grid_y - 1) ? phi_in[idx + stride_y] : 0.0f;
    float zm = (gid.z > 0) ? phi_in[idx - stride_z] : 0.0f;
    float zp = (gid.z < p.grid_z - 1) ? phi_in[idx + stride_z] : 0.0f;
    
    float h2 = p.grid_spacing * p.grid_spacing;
    
    // Jacobi iteration: φ_new = (sum of neighbors - h² * 4πGρ) / 6
    phi_out[idx] = (xm + xp + ym + yp + zm + zp - h2 * gravity_4pi * rho[idx]) / 6.0f;
}

// -----------------------------------------------------------------------------
// Kernel: Clear field (set to zero)
// -----------------------------------------------------------------------------

kernel void clear_field(
    device float* field [[buffer(0)]],
    constant uint& num_elements [[buffer(1)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= num_elements) return;
    field[gid] = 0.0f;
}

// =============================================================================
// Particle-Particle Interaction Kernel (Collision + Excitation Transfer)
// =============================================================================
// This kernel computes short-range forces between particles:
// 1. Soft-sphere repulsion: prevents overlap, stronger for excited particles
// 2. Excitation transfer: when particles "bump", excitation equilibrates
//
// NOTE: This is O(N²) which is fine for N < 1000. For larger systems,
// use spatial hashing or neighbor lists.

struct ParticleInteractionParams {
    uint32_t num_particles;
    float dt;
    float particle_radius;       // r: particle radius for collision detection
    float young_modulus;         // E: Young's modulus for Hertzian contact (spring stiffness)
    float thermal_conductivity;  // k: heat transfer on contact
    float restitution;           // e: coefficient of restitution (0-1)
};

kernel void particle_interactions(
    device float* particle_pos            [[buffer(0)]],  // N * 3 (read-only for positions)
    device float* particle_vel            [[buffer(1)]],  // N * 3 (read-write for velocity)
    device float* particle_excitation     [[buffer(2)]],  // N (read-write for excitation)
    device const float* particle_mass     [[buffer(3)]],  // N (read-only)
    device float* particle_heat           [[buffer(4)]],  // N (read-write for heat)
    constant ParticleInteractionParams& p [[buffer(5)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    // Read this particle's state
    float3 pos_i = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    float3 vel_i = float3(
        particle_vel[gid * 3 + 0],
        particle_vel[gid * 3 + 1],
        particle_vel[gid * 3 + 2]
    );
    float mass_i = particle_mass[gid];
    float heat_i = particle_heat[gid];
    // Note: particle_excitation is read-only intrinsic property, not needed for collisions
    
    // Particle radius (from material property)
    float r_i = p.particle_radius;
    
    // Accumulate impulses and heat changes
    float3 impulse_total = float3(0.0f);
    float heat_delta = 0.0f;
    
    // Loop over all other particles
    for (uint j = 0; j < p.num_particles; j++) {
        if (j == gid) continue;
        
        float3 pos_j = float3(
            particle_pos[j * 3 + 0],
            particle_pos[j * 3 + 1],
            particle_pos[j * 3 + 2]
        );
        float3 vel_j = float3(
            particle_vel[j * 3 + 0],
            particle_vel[j * 3 + 1],
            particle_vel[j * 3 + 2]
        );
        float mass_j = particle_mass[j];
        float heat_j = particle_heat[j];
        
        float r_j = p.particle_radius;
        float combined_radius = r_i + r_j;
        
        // Distance vector from j to i
        float3 delta = pos_i - pos_j;
        float dist = length(delta);
        
        if (dist < combined_radius && dist > 1e-6f) {
            // =====================================================
            // COLLISION DETECTED
            // =====================================================
            float3 n = delta / dist;  // Normal from j to i
            float overlap = combined_radius - dist;
            
            // Relative velocity (i relative to j)
            float3 v_rel = vel_i - vel_j;
            float v_n = dot(v_rel, n);  // Normal component
            
            // -------------------------------------------------
            // IMPULSE-BASED COLLISION (momentum conservation)
            // -------------------------------------------------
            if (v_n < 0.0f) {  // Only if approaching
                // Coefficient of restitution e: v'_rel = -e * v_rel
                float e = p.restitution;
                
                // Reduced mass: m_eff = m_i * m_j / (m_i + m_j)
                float m_eff = (mass_i * mass_j) / (mass_i + mass_j);
                
                // Impulse magnitude: J = (1 + e) * m_eff * |v_n|
                float J = (1.0f + e) * m_eff * (-v_n);
                
                // Impulse on particle i: Δv_i = J/m_i * n
                // We divide by 2 because we process each pair twice (once for i, once for j)
                impulse_total += (n * J / mass_i) * 0.5f;
                
                // -------------------------------------------------
                // ENERGY CONSERVATION: KE_lost becomes heat
                // -------------------------------------------------
                // KE_before = 0.5 * m_eff * v_n^2
                // KE_after  = 0.5 * m_eff * (e * v_n)^2
                // ΔKE = 0.5 * m_eff * v_n^2 * (1 - e^2)
                float ke_lost = 0.5f * m_eff * v_n * v_n * (1.0f - e * e);
                heat_delta += ke_lost * 0.5f;  // Half to each particle
            }
            
            // -------------------------------------------------
            // HERTZIAN CONTACT FORCE (prevents interpenetration)
            // -------------------------------------------------
            // F = (4/3) * E* * sqrt(R*) * δ^(3/2) for Hertzian contact
            // Simplified: F ≈ E * δ for small overlaps (linear spring)
            float contact_force = p.young_modulus * overlap;
            impulse_total += n * contact_force * p.dt / mass_i;
            
            // -------------------------------------------------
            // HEAT CONDUCTION ON CONTACT (Fourier's law)
            // -------------------------------------------------
            // Q = k * A * (T_j - T_i) / d, where d ≈ overlap
            // Approximate: dQ/dt ∝ k * (T_j - T_i) * contact_area
            float T_i = heat_i / max(mass_i, 1e-6f);
            float T_j = heat_j / max(mass_j, 1e-6f);
            float contact_area = overlap * overlap;  // Approximate circular contact
            float dQ_conduction = p.thermal_conductivity * contact_area * (T_j - T_i) * p.dt;
            heat_delta += dQ_conduction;
            
            // Note: Excitation (oscillator frequency) is an INTRINSIC property
            // and does NOT equilibrate on contact. Each particle maintains its
            // unique frequency throughout the simulation.
        }
    }
    
    // Apply accumulated changes
    vel_i += impulse_total;
    heat_i += heat_delta;
    
    // Physical constraints (non-negative)
    heat_i = max(heat_i, 0.0f);
    
    // Write back
    particle_vel[gid * 3 + 0] = vel_i.x;
    particle_vel[gid * 3 + 1] = vel_i.y;
    particle_vel[gid * 3 + 2] = vel_i.z;
    // Note: particle_excitation is NOT written - it's an intrinsic property
    particle_heat[gid] = heat_i;
}

// =============================================================================
// SPATIAL HASH GRID ACCELERATION
// =============================================================================
// Three-phase approach for O(N) collision detection:
//   Phase 1: Assign each particle to a cell (compute cell index)
//   Phase 2: Count particles per cell, compute prefix sum → cell start indices
//   Phase 3: Collision detection using cell-based neighbor lookup
//
// This reduces O(N²) to O(N * k) where k = avg particles in 27 neighbor cells.
// For uniform distributions, k ~ 27 * (N / num_cells) which is constant for
// fixed density, giving O(N) total complexity.
// =============================================================================

// -----------------------------------------------------------------------------
// Utility: Compute cell index from position
// -----------------------------------------------------------------------------
inline uint3 position_to_cell(
    float3 pos,
    float inv_cell_size,
    float3 domain_min,
    uint3 grid_dims
) {
    float3 local = (pos - domain_min) * inv_cell_size;
    uint3 cell = uint3(clamp(local, float3(0.0f), float3(grid_dims) - 1.0f));
    return cell;
}

inline uint cell_to_linear(uint3 cell, uint3 grid_dims) {
    return cell.x * grid_dims.y * grid_dims.z + cell.y * grid_dims.z + cell.z;
}

inline uint3 linear_to_cell(uint linear_idx, uint3 grid_dims) {
    uint x = linear_idx / (grid_dims.y * grid_dims.z);
    uint rem = linear_idx % (grid_dims.y * grid_dims.z);
    uint y = rem / grid_dims.z;
    uint z = rem % grid_dims.z;
    return uint3(x, y, z);
}

// -----------------------------------------------------------------------------
// Kernel: Assign particles to cells (Phase 1)
// -----------------------------------------------------------------------------
// Each particle computes its cell index and stores it.
// Also atomically increments the cell's particle count.

kernel void spatial_hash_assign(
    device const float* particle_pos       [[buffer(0)]],  // N * 3
    device uint* particle_cell_idx         [[buffer(1)]],  // N (output: linear cell index)
    device atomic_uint* cell_counts        [[buffer(2)]],  // num_cells (output: count per cell)
    constant SpatialHashParams& p          [[buffer(3)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    float3 pos = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    
    float3 domain_min = float3(p.domain_min_x, p.domain_min_y, p.domain_min_z);
    uint3 grid_dims = uint3(p.grid_x, p.grid_y, p.grid_z);
    
    uint3 cell = position_to_cell(pos, p.inv_cell_size, domain_min, grid_dims);
    uint linear_idx = cell_to_linear(cell, grid_dims);
    
    particle_cell_idx[gid] = linear_idx;
    atomic_fetch_add_explicit(&cell_counts[linear_idx], 1, memory_order_relaxed);
}

// -----------------------------------------------------------------------------
// Kernel: Exclusive prefix sum on cell counts (Phase 2a)
// -----------------------------------------------------------------------------
// Computes cell_starts[i] = sum(cell_counts[0..i-1])
// This gives the starting index in the sorted particle array for each cell.
//
// For small grids (< 64³ = 262k cells), single-thread scan is acceptable.
// For larger grids, use parallel Blelloch scan.

kernel void spatial_hash_prefix_sum(
    device const uint* cell_counts         [[buffer(0)]],  // num_cells
    device uint* cell_starts               [[buffer(1)]],  // num_cells + 1
    constant uint& num_cells               [[buffer(2)]],
    uint gid [[thread_position_in_grid]]
) {
    // Single-thread sequential scan (for num_cells up to ~256k)
    if (gid != 0) return;
    
    uint running_sum = 0;
    for (uint i = 0; i < num_cells; i++) {
        cell_starts[i] = running_sum;
        running_sum += cell_counts[i];
    }
    cell_starts[num_cells] = running_sum;  // Total particle count
}

// Parallel Blelloch-style prefix sum for larger grids
// This uses threadgroup-local reductions for better scaling
kernel void spatial_hash_prefix_sum_parallel(
    device uint* cell_counts               [[buffer(0)]],  // num_cells (in/out: becomes cell_starts)
    device uint* block_sums                [[buffer(1)]],  // (num_cells / BLOCK_SIZE) intermediate sums
    constant uint& num_cells               [[buffer(2)]],
    uint gid [[thread_position_in_grid]],
    uint tid [[thread_position_in_threadgroup]],
    uint tg_size [[threads_per_threadgroup]],
    threadgroup uint* shared [[threadgroup(0)]]
) {
    // Load into shared memory
    uint idx = gid;
    shared[tid] = (idx < num_cells) ? cell_counts[idx] : 0;
    threadgroup_barrier(mem_flags::mem_threadgroup);
    
    // Up-sweep (reduce) phase
    for (uint stride = 1; stride < tg_size; stride *= 2) {
        uint ai = (tid + 1) * stride * 2 - 1;
        if (ai < tg_size) {
            shared[ai] += shared[ai - stride];
        }
        threadgroup_barrier(mem_flags::mem_threadgroup);
    }
    
    // Store block sum and clear last element
    if (tid == tg_size - 1) {
        uint block_idx = gid / tg_size;
        block_sums[block_idx] = shared[tid];
        shared[tid] = 0;
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);
    
    // Down-sweep phase
    for (uint stride = tg_size / 2; stride > 0; stride /= 2) {
        uint ai = (tid + 1) * stride * 2 - 1;
        if (ai < tg_size) {
            uint t = shared[ai - stride];
            shared[ai - stride] = shared[ai];
            shared[ai] += t;
        }
        threadgroup_barrier(mem_flags::mem_threadgroup);
    }
    
    // Write back exclusive prefix sum
    if (idx < num_cells) {
        cell_counts[idx] = shared[tid];
    }
}

// -----------------------------------------------------------------------------
// Kernel: Scatter particles to sorted array (Phase 2b)
// -----------------------------------------------------------------------------
// Places particle indices into a sorted array based on their cell.
// Uses atomic counters per cell to handle collisions within cells.

kernel void spatial_hash_scatter(
    device const uint* particle_cell_idx   [[buffer(0)]],  // N (cell index per particle)
    device uint* sorted_particle_idx       [[buffer(1)]],  // N (output: sorted indices)
    device atomic_uint* cell_offsets       [[buffer(2)]],  // num_cells (working offsets)
    constant uint& num_particles           [[buffer(3)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= num_particles) return;
    
    uint cell_idx = particle_cell_idx[gid];
    uint slot = atomic_fetch_add_explicit(&cell_offsets[cell_idx], 1, memory_order_relaxed);
    sorted_particle_idx[slot] = gid;
}

// -----------------------------------------------------------------------------
// Kernel: Spatial hash collision detection (Phase 3)
// -----------------------------------------------------------------------------
// For each particle, check only particles in the same cell and 26 neighbors.
// This is O(N * k) where k = avg particles per 27-cell neighborhood.

kernel void spatial_hash_collisions(
    // Particle state
    device const float* particle_pos       [[buffer(0)]],  // N * 3
    device float* particle_vel             [[buffer(1)]],  // N * 3
    device float* particle_excitation      [[buffer(2)]],  // N
    device const float* particle_mass      [[buffer(3)]],  // N
    device float* particle_heat            [[buffer(4)]],  // N
    // Spatial hash data
    device const uint* sorted_particle_idx [[buffer(5)]],  // N (sorted by cell)
    device const uint* cell_starts         [[buffer(6)]],  // num_cells + 1
    device const uint* particle_cell_idx   [[buffer(7)]],  // N (cell index per particle)
    // Parameters
    constant SpatialCollisionParams& p     [[buffer(8)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    // Read this particle's state
    float3 pos_i = float3(
        particle_pos[gid * 3 + 0],
        particle_pos[gid * 3 + 1],
        particle_pos[gid * 3 + 2]
    );
    float3 vel_i = float3(
        particle_vel[gid * 3 + 0],
        particle_vel[gid * 3 + 1],
        particle_vel[gid * 3 + 2]
    );
    float mass_i = particle_mass[gid];
    float heat_i = particle_heat[gid];
    // Note: particle_excitation is read-only intrinsic property, not needed for collisions
    
    float r_i = p.particle_radius;
    uint3 grid_dims = uint3(p.grid_x, p.grid_y, p.grid_z);
    
    // Get this particle's cell
    float3 domain_min = float3(p.domain_min_x, p.domain_min_y, p.domain_min_z);
    uint3 cell_i = position_to_cell(pos_i, p.inv_cell_size, domain_min, grid_dims);
    
    // Accumulate impulses and changes
    float3 impulse_total = float3(0.0f);
    float heat_delta = 0.0f;
    
    // Iterate over 3x3x3 neighborhood (27 cells)
    for (int dx = -1; dx <= 1; dx++) {
        for (int dy = -1; dy <= 1; dy++) {
            for (int dz = -1; dz <= 1; dz++) {
                int3 neighbor = int3(cell_i) + int3(dx, dy, dz);
                
                // Boundary check
                if (neighbor.x < 0 || neighbor.x >= (int)p.grid_x ||
                    neighbor.y < 0 || neighbor.y >= (int)p.grid_y ||
                    neighbor.z < 0 || neighbor.z >= (int)p.grid_z) {
                    continue;
                }
                
                uint neighbor_linear = cell_to_linear(uint3(neighbor), grid_dims);
                uint start = cell_starts[neighbor_linear];
                uint end = cell_starts[neighbor_linear + 1];
                
                // Iterate over particles in this cell
                for (uint slot = start; slot < end; slot++) {
                    uint j = sorted_particle_idx[slot];
                    if (j == gid) continue;  // Skip self
                    
                    float3 pos_j = float3(
                        particle_pos[j * 3 + 0],
                        particle_pos[j * 3 + 1],
                        particle_pos[j * 3 + 2]
                    );
                    
                    float3 delta = pos_i - pos_j;
                    float dist_sq = dot(delta, delta);
                    float r_j = p.particle_radius;
                    float combined_radius = r_i + r_j;
                    
                    // Early exit with squared distance check (avoid sqrt)
                    if (dist_sq >= combined_radius * combined_radius || dist_sq < 1e-12f) {
                        continue;
                    }
                    
                    float dist = sqrt(dist_sq);
                    
                    // =====================================================
                    // COLLISION DETECTED
                    // =====================================================
                    float3 n = delta / dist;
                    float overlap = combined_radius - dist;
                    
                    float3 vel_j = float3(
                        particle_vel[j * 3 + 0],
                        particle_vel[j * 3 + 1],
                        particle_vel[j * 3 + 2]
                    );
                    float mass_j = particle_mass[j];
                    float heat_j = particle_heat[j];
                    
                    float3 v_rel = vel_i - vel_j;
                    float v_n = dot(v_rel, n);
                    
                    // IMPULSE-BASED COLLISION
                    if (v_n < 0.0f) {
                        float e = p.restitution;
                        float m_eff = (mass_i * mass_j) / (mass_i + mass_j);
                        float J = (1.0f + e) * m_eff * (-v_n);
                        impulse_total += (n * J / mass_i) * 0.5f;
                        
                        // Energy conservation
                        float ke_lost = 0.5f * m_eff * v_n * v_n * (1.0f - e * e);
                        heat_delta += ke_lost * 0.5f;
                    }
                    
                    // HERTZIAN CONTACT FORCE
                    float contact_force = p.young_modulus * overlap;
                    impulse_total += n * contact_force * p.dt / mass_i;
                    
                    // HEAT CONDUCTION
                    float T_i = heat_i / max(mass_i, 1e-6f);
                    float T_j = heat_j / max(mass_j, 1e-6f);
                    float contact_area = overlap * overlap;
                    float dQ_conduction = p.thermal_conductivity * contact_area * (T_j - T_i) * p.dt;
                    heat_delta += dQ_conduction;
                    
                    // Note: Excitation (oscillator frequency) is INTRINSIC - no equilibration
                }
            }
        }
    }
    
    // Apply accumulated changes
    vel_i += impulse_total;
    heat_i += heat_delta;
    
    // Physical constraints
    heat_i = max(heat_i, 0.0f);
    
    // Write back
    particle_vel[gid * 3 + 0] = vel_i.x;
    particle_vel[gid * 3 + 1] = vel_i.y;
    particle_vel[gid * 3 + 2] = vel_i.z;
    // Note: particle_excitation NOT written - intrinsic property
    particle_heat[gid] = heat_i;
}

// -----------------------------------------------------------------------------
// Helper: Atomic Float Add for Threadgroup Memory (CAS Loop)
// -----------------------------------------------------------------------------
// Metal doesn't have native atomic float in threadgroup memory on all hardware.
// We emulate it using compare-and-swap on uint, interpreting the bits as float.

inline void atomic_add_float_threadgroup(threadgroup atomic_uint* address, float val) {
    uint old_val = atomic_load_explicit(address, memory_order_relaxed);
    uint new_val;
    
    while (true) {
        // Convert bits to float to do the math
        float old_f = as_type<float>(old_val);
        float new_f = old_f + val;
        
        // Convert result back to bits
        new_val = as_type<uint>(new_f);
        
        // Try to swap: if *address == old_val, set *address = new_val and return true
        // If *address != old_val, update old_val to current value and return false
        if (atomic_compare_exchange_weak_explicit(
                address, 
                &old_val, 
                new_val, 
                memory_order_relaxed, 
                memory_order_relaxed)) {
            break;
        }
    }
}

// -----------------------------------------------------------------------------
// Kernel: Tiled scatter with threadgroup reduction (CAS-based atomics)
// -----------------------------------------------------------------------------
// Reduces atomic contention by having each threadgroup accumulate contributions
// locally before performing a single atomic add per grid cell per threadgroup.
// This is especially effective when particles cluster spatially.
//
// Uses CAS loop for threadgroup float atomics (portable across all Metal GPUs).

kernel void scatter_particle_tiled(
    device const float* particle_pos       [[buffer(0)]],  // N * 3
    device const float* particle_mass      [[buffer(1)]],  // N
    device const float* particle_heat      [[buffer(2)]],  // N
    device atomic_float* gravity_field     [[buffer(3)]],  // X * Y * Z
    device atomic_float* heat_field        [[buffer(4)]],  // X * Y * Z
    constant TiledScatterParams& p         [[buffer(5)]],
    uint gid [[thread_position_in_grid]],
    uint tid [[thread_position_in_threadgroup]],
    uint tg_size [[threads_per_threadgroup]],
    threadgroup atomic_uint* local_gravity [[threadgroup(0)]],  // grid_size uints (as float bits)
    threadgroup atomic_uint* local_heat [[threadgroup(1)]]      // grid_size uints (as float bits)
) {
    uint num_cells = p.grid_x * p.grid_y * p.grid_z;
    
    // Initialize local accumulators to 0.0f (stored as uint bits)
    uint zero_bits = as_type<uint>(0.0f);
    for (uint i = tid; i < num_cells; i += tg_size) {
        atomic_store_explicit(&local_gravity[i], zero_bits, memory_order_relaxed);
        atomic_store_explicit(&local_heat[i], zero_bits, memory_order_relaxed);
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);
    
    // Scatter to local accumulators using CAS-based atomic add
    if (gid < p.num_particles) {
        float3 pos = float3(
            particle_pos[gid * 3 + 0],
            particle_pos[gid * 3 + 1],
            particle_pos[gid * 3 + 2]
        );
        float mass = particle_mass[gid];
        float heat = particle_heat[gid];
        
        // Get trilinear coordinates
        uint3 grid_dims = uint3(p.grid_x, p.grid_y, p.grid_z);
        float3 grid_pos = pos * p.inv_grid_spacing;
        grid_pos = clamp(grid_pos, float3(0.0f), float3(grid_dims) - 1.001f);
        uint3 base_idx = uint3(floor(grid_pos));
        float3 frac = grid_pos - float3(base_idx);
        
        // Compute 8 trilinear weights
        float wx0 = 1.0f - frac.x, wx1 = frac.x;
        float wy0 = 1.0f - frac.y, wy1 = frac.y;
        float wz0 = 1.0f - frac.z, wz1 = frac.z;
        
        float weights[8] = {
            wx0 * wy0 * wz0, wx0 * wy0 * wz1,
            wx0 * wy1 * wz0, wx0 * wy1 * wz1,
            wx1 * wy0 * wz0, wx1 * wy0 * wz1,
            wx1 * wy1 * wz0, wx1 * wy1 * wz1
        };
        
        uint stride_z = 1;
        uint stride_y = p.grid_z;
        uint stride_x = p.grid_y * p.grid_z;
        uint base = base_idx.x * stride_x + base_idx.y * stride_y + base_idx.z * stride_z;
        
        uint offsets[8] = {
            0, stride_z, stride_y, stride_y + stride_z,
            stride_x, stride_x + stride_z, stride_x + stride_y,
            stride_x + stride_y + stride_z
        };
        
        // Accumulate to threadgroup memory using CAS-based atomic add
        for (int i = 0; i < 8; i++) {
            uint idx = base + offsets[i];
            atomic_add_float_threadgroup(&local_gravity[idx], mass * weights[i]);
            atomic_add_float_threadgroup(&local_heat[idx], heat * weights[i]);
        }
    }
    
    threadgroup_barrier(mem_flags::mem_threadgroup);
    
    // Flush local accumulators to global memory (one atomic per cell per threadgroup)
    for (uint i = tid; i < num_cells; i += tg_size) {
        float gval = as_type<float>(atomic_load_explicit(&local_gravity[i], memory_order_relaxed));
        float hval = as_type<float>(atomic_load_explicit(&local_heat[i], memory_order_relaxed));
        
        if (gval != 0.0f) {
            atomic_fetch_add_explicit(&gravity_field[i], gval, memory_order_relaxed);
        }
        if (hval != 0.0f) {
            atomic_fetch_add_explicit(&heat_field[i], hval, memory_order_relaxed);
        }
    }
}

// =============================================================================
// Spectral Carrier Coupling (Resonance Potential, Langevin Flow)
// =============================================================================
// This implements a conservative "resonance potential" view of the spectral layer.
//
// Definitions:
// - Oscillator (particle in wave-space): z_i = A_i e^{iθ_i}
// - Carrier (global mode):              C_k = R_k e^{iψ_k}
//
// Potential (conceptual):
//   U = - Σ_{i,k} T_{ik}(ω_i, ω_k, σ_k) * Re(z_i C_k*)
//       + (λ/2) Σ_k |C_k|^2
//
// where T_{ik} is a Gaussian tuning kernel in frequency space.
//
// Gradients:
// - Carrier "force":   ∂(-U)/∂C_k*  = Σ_i T_{ik} z_i  - λ C_k
// - Phase "torque":    θ̇_i += Σ_k T_{ik} (A_i R_k) sin(ψ_k - θ_i)
//
// Langevin flow:
// - Add isotropic noise with temperature T to both carrier updates and phase updates.

// -----------------------------------------------------------------------------
// Carrier memory (anchored + crystallized)
// -----------------------------------------------------------------------------
// We model "chunks" as long-lived spectral modes (carriers) that store a small
// set of anchored oscillators and their relative phase offsets.
//
// This yields:
// - Storage: crystallized carriers stop decaying and stop drifting in ω.
// - Top-down bias: crystallized carriers pull anchored oscillators toward stored
//   phase offsets and can inject energy into anchored oscillators.
// - Idle compute: same kernels with a mode knob (consolidate/disambiguate/explore).
//
#define CARRIER_ANCHORS 8u
#define CARRIER_STATE_VOLATILE 0u
#define CARRIER_STATE_STABLE 1u
#define CARRIER_STATE_CRYSTALLIZED 2u

struct SpectralCarrierParams {
    uint32_t num_osc;              // N
    uint32_t max_carriers;         // capacity of carrier arrays
    uint32_t num_carriers;         // current active carriers (<= max_carriers)
    float dt;
    float coupling_scale;          // phase torque scale
    float carrier_reg;             // λ (L2 regularization on |C| to prevent blow-up)
    float temperature;             // Langevin temperature (noise strength)
    uint32_t rng_seed;             // updated each tick by host
    float conflict_threshold;      // coherence threshold to trigger split (high = stricter)
    float offender_weight_floor;   // ignore tiny weights
    float gate_width_min;
    float gate_width_max;
    float ema_alpha;               // smoothing for conflict
    float recenter_alpha;          // smoothing for ω_k recentering
    // --- Memory / modes ---
    uint32_t mode;                 // 0=online, 1=consolidate, 2=disambiguate, 3=explore
    float anchor_random_eps;       // ε-greedy anchor refresh probability
    float stable_amp_threshold;    // promote volatile->stable when |C| exceeds this
    float crystallize_amp_threshold;       // stable->crystallized when |C| exceeds this...
    float crystallize_conflict_threshold;  // ...and conflict below this for long enough
    uint32_t crystallize_age;      // consecutive stable frames required
    float crystallized_coupling_boost;     // extra coupling for crystallized carriers
    float volatile_decay_mul;      // extra decay factor for volatile carriers
    float stable_decay_mul;        // extra decay factor for stable carriers
    float crystallized_decay_mul;  // extra decay factor for crystallized carriers
    float topdown_phase_scale;     // extra phase pull for anchored oscillators
    float topdown_energy_scale;    // energy injection scale for crystallized carriers
    float topdown_random_energy_eps; // random energy nudge probability (exploration)
    float repulsion_scale;         // carrier ω repulsion (disambiguation)
};

inline float tuning_from_freq(float omega_i, float omega_k, float gate_width) {
    float d = omega_i - omega_k;
    float sigma = max(gate_width, 1e-4f);
    return exp(-(d * d) / (sigma * sigma));
}

kernel void spectral_carrier_update_and_split(
    // Oscillator state (particles-as-oscillators)
    device const float* osc_phase           [[buffer(0)]],  // N
    device const float* osc_omega           [[buffer(1)]],  // N
    device const float* osc_amp             [[buffer(2)]],  // N
    // Carrier state (in/out)
    device float* carrier_real              [[buffer(3)]],  // maxM
    device float* carrier_imag              [[buffer(4)]],  // maxM
    device float* carrier_omega             [[buffer(5)]],  // maxM
    device float* carrier_gate_width        [[buffer(6)]],  // maxM
    device float* carrier_conflict          [[buffer(7)]],  // maxM (out: spectral variance proxy)
    // Memory state (in/out)
    device uint* carrier_state              [[buffer(8)]],  // maxM (0=volatile,1=stable,2=crystallized)
    device uint* carrier_age                [[buffer(9)]],  // maxM (consecutive stable frames)
    device uint* carrier_anchor_idx         [[buffer(10)]], // maxM * CARRIER_ANCHORS (osc indices, UINT_MAX=empty)
    device float* carrier_anchor_phase      [[buffer(11)]], // maxM * CARRIER_ANCHORS (phase offsets)
    device float* carrier_anchor_weight     [[buffer(12)]], // maxM * CARRIER_ANCHORS (anchor strengths)
    // Split output
    device atomic_uint* out_num_carriers    [[buffer(13)]], // single counter (in/out)
    device uint* out_spawned_from_osc       [[buffer(14)]], // maxM (optional: osc index for spawned carrier)
    // Random phases for spawned carriers (pre-generated on device)
    device const float* random_phases       [[buffer(15)]], // maxM (uniform [0,1])
    // Global system energy statistics (computed via reduction pass)
    device const float* energy_stats        [[buffer(16)]], // (4,) [mean_abs, mean, std, count]
    constant SpectralCarrierParams& p       [[buffer(17)]],
    uint gid [[thread_position_in_grid]]
) {
    // One thread per *existing* carrier.
    if (gid >= p.num_carriers) return;

    float cr = carrier_real[gid];
    float ci = carrier_imag[gid];
    float omega_k = carrier_omega[gid];
    float gate_w = clamp(carrier_gate_width[gid], p.gate_width_min, p.gate_width_max);
    uint state = carrier_state[gid];
    uint age = carrier_age[gid];

    // -------------------------------------------------------------------------
    // Adaptive renormalization (global, thermodynamic)
    // -------------------------------------------------------------------------
    // Use system energy scale to set a decay that self-tunes:
    //   e_scale = mean(|E|) + eps
    //   decay  = exp(-dt / e_scale)
    float mean_abs_e = energy_stats[0];
    float e_scale = max(mean_abs_e, 1e-8f);
    float adaptive_decay = exp(-p.dt / e_scale);
    float decay_mul = 1.0f;
    if (state == CARRIER_STATE_VOLATILE) decay_mul = max(p.volatile_decay_mul, 0.0f);
    else if (state == CARRIER_STATE_STABLE) decay_mul = max(p.stable_decay_mul, 0.0f);
    else decay_mul = max(p.crystallized_decay_mul, 0.0f);
    cr *= (adaptive_decay * decay_mul);
    ci *= (adaptive_decay * decay_mul);

    // Accumulate complex force F_k = Σ_i w_ik z_i, and stats for coherence + recentering.
    float force_r_raw = 0.0f;
    float force_i_raw = 0.0f;
    float w_sum = 0.0f;         // Σ w
    float w_omega_sum = 0.0f;   // Σ w ω
    float w_amp_sum = 0.0f;     // Σ w A

    // Track offender (largest weighted deviation from mean)
    uint offender_idx = 0;
    float offender_score = 0.0f;

    for (uint i = 0; i < p.num_osc; i++) {
        float omega_i = osc_omega[i];
        float amp_i = osc_amp[i];
        float phi_i = osc_phase[i];

        float t = tuning_from_freq(omega_i, omega_k, gate_w);
        // Weight includes oscillator amplitude (strong oscillators couple more).
        float w = t * amp_i;
        if (w <= p.offender_weight_floor) continue;

        // z_i = A_i e^{iθ_i}
        float zr = amp_i * cos(phi_i);
        float zi = amp_i * sin(phi_i);

        force_r_raw += w * zr;
        force_i_raw += w * zi;

        w_sum += w;
        w_omega_sum += w * omega_i;
        w_amp_sum += w * amp_i;
    }

    float mean_omega = (w_sum > 1e-8f) ? (w_omega_sum / w_sum) : omega_k;

    // Coherence / conflict:
    // - R = |Σ w z| measures phase coherence among coupled oscillators.
    // - Normalize by Σ w A to get [0,1] scale-ish.
    float R = sqrt(force_r_raw * force_r_raw + force_i_raw * force_i_raw);
    float denom = max(w_amp_sum, 1e-8f);
    float coherence = clamp(R / denom, 0.0f, 1.0f);
    float inst_conflict = 1.0f - coherence;

    // Persistent conflict (EMA) to avoid thrashing/spawn storms.
    float prev_conflict = carrier_conflict[gid];
    float a = clamp(p.ema_alpha, 0.0f, 1.0f);
    float conflict = prev_conflict * (1.0f - a) + inst_conflict * a;
    carrier_conflict[gid] = conflict;

    // Re-center ω_k toward what it's actually binding (unless crystallized).
    if (state != CARRIER_STATE_CRYSTALLIZED) {
        float rc = clamp(p.recenter_alpha, 0.0f, 1.0f);
        omega_k = omega_k * (1.0f - rc) + mean_omega * rc;
    }

    // Offender selection (phase stress): maximize weighted (1 - cos Δθ) relative to the
    // target direction (arg of the force vector).
    float psi_target = atan2(force_i_raw, force_r_raw);
    if (w_sum > 1e-8f && conflict > p.conflict_threshold) {
        for (uint i = 0; i < p.num_osc; i++) {
            float omega_i = osc_omega[i];
            float amp_i = osc_amp[i];
            float phi_i = osc_phase[i];
            float t = tuning_from_freq(omega_i, omega_k, gate_w);
            float w = t * amp_i;
            if (w <= p.offender_weight_floor) continue;
            float d = phi_i - psi_target;
            // wrap to [-pi, pi]
            d = d - 2.0f * M_PI_F * floor((d + M_PI_F) / (2.0f * M_PI_F));
            float stress = 1.0f - cos(d); // 0..2
            float score = w * stress;
            if (score > offender_score) {
                offender_score = score;
                offender_idx = i;
            }
        }
    }

    // Mean-field normalization:
    // Use the *average* tuned phasor so carrier scale doesn't explode with N.
    float inv_w = 1.0f / max(w_sum, 1e-8f);
    float force_r = force_r_raw * inv_w;
    float force_i = force_i_raw * inv_w;

    // -------------------------------------------------------------------------
    // Metabolic homeostasis for carriers (income vs expense)
    // -------------------------------------------------------------------------
    // Income: how much coherent drive the carrier receives this tick.
    // Expense: global energy scale (cost-of-living proxy).
    // If income < expense, shrink carrier amplitude; this prunes unused modes.
    float income = sqrt(force_r * force_r + force_i * force_i);
    float expense = e_scale;
    if (state != CARRIER_STATE_CRYSTALLIZED && income < expense) {
        float deficit = expense - income;
        float shrink = exp(-p.dt * deficit / (expense + 1e-8f));
        cr *= shrink;
        ci *= shrink;
    }

    // Langevin carrier update:
    //   dC = (F - λC) dt + sqrt(2T dt) * η
    float2 n = randn2(p.rng_seed ^ 0xA5A5A5A5u, gid);
    // Scale temperature gently with system energy (hotter system -> more stochasticity).
    float temp_factor = e_scale / (e_scale + 1.0f);
    float noise_scale = sqrt(max(2.0f * (p.temperature * temp_factor) * p.dt, 0.0f));
    float reg = (state == CARRIER_STATE_CRYSTALLIZED) ? 0.0f : p.carrier_reg;
    float dcr = (force_r - reg * cr) * p.dt + noise_scale * n.x;
    float dci = (force_i - reg * ci) * p.dt + noise_scale * n.y;
    cr += dcr;
    ci += dci;

    // Optional carrier-frequency repulsion (idle disambiguation mode).
    if (p.mode == 2u && p.repulsion_scale > 0.0f && p.num_carriers > 1u && state != CARRIER_STATE_CRYSTALLIZED) {
        float repel = 0.0f;
        for (uint k2 = 0; k2 < p.num_carriers; k2++) {
            if (k2 == gid) continue;
            float d = omega_k - carrier_omega[k2];
            float s = gate_w + clamp(carrier_gate_width[k2], p.gate_width_min, p.gate_width_max);
            s = max(s, 1e-3f);
            repel += d * exp(-(d * d) / (s * s));
        }
        omega_k += p.dt * p.repulsion_scale * repel;
    }

    // Crystallization state machine (volatile -> stable -> crystallized).
    float ampC = sqrt(cr * cr + ci * ci);
    if (state == CARRIER_STATE_VOLATILE) {
        if (ampC >= max(p.stable_amp_threshold, 0.0f)) {
            state = CARRIER_STATE_STABLE;
            age = 0u;
        }
    }
    if (state == CARRIER_STATE_STABLE) {
        bool ok_amp = ampC >= max(p.crystallize_amp_threshold, 0.0f);
        bool ok_conf = conflict <= clamp(p.crystallize_conflict_threshold, 0.0f, 1.0f);
        if (ok_amp && ok_conf) {
            age += 1u;
            if (age >= max(p.crystallize_age, 1u)) {
                state = CARRIER_STATE_CRYSTALLIZED;
                age = p.crystallize_age;
            }
        } else {
            age = 0u;
        }
    }

    // Anchor refresh (ε-greedy; disabled once crystallized).
    if (state != CARRIER_STATE_CRYSTALLIZED && p.num_osc > 0u) {
        uint h = hash_u32(p.rng_seed ^ (gid * 0xB4B82E39u) ^ 0x1C3A5F7Du);
        float u = u01_from_u32(h);
        uint slot = hash_u32(h + 0x3C6EF372u) % CARRIER_ANCHORS;
        uint base = gid * CARRIER_ANCHORS + slot;
        float eps_anchor = clamp(p.anchor_random_eps, 0.0f, 1.0f);
        // In exploration mode, allow weaker bonds to contribute by lowering the floor implicitly.
        if (u <= eps_anchor) {
            uint cand = hash_u32(h + 0x9E3779B9u) % p.num_osc;
            carrier_anchor_idx[base] = cand;
            float psi = atan2(ci, cr);
            float d = osc_phase[cand] - psi;
            d = d - 2.0f * M_PI_F * floor((d + M_PI_F) / (2.0f * M_PI_F));
            carrier_anchor_phase[base] = d;
            float w = tuning_from_freq(osc_omega[cand], omega_k, gate_w) * osc_amp[cand];
            carrier_anchor_weight[base] = w;
        } else if (offender_score > 0.0f) {
            carrier_anchor_idx[base] = offender_idx;
            float psi = atan2(ci, cr);
            float d = osc_phase[offender_idx] - psi;
            d = d - 2.0f * M_PI_F * floor((d + M_PI_F) / (2.0f * M_PI_F));
            carrier_anchor_phase[base] = d;
            float w = tuning_from_freq(osc_omega[offender_idx], omega_k, gate_w) * osc_amp[offender_idx];
            carrier_anchor_weight[base] = w;
        }
    }

    carrier_real[gid] = cr;
    carrier_imag[gid] = ci;
    carrier_omega[gid] = omega_k;
    carrier_gate_width[gid] = gate_w;
    carrier_state[gid] = state;
    carrier_age[gid] = age;

    // Conflict-driven split: spawn a new carrier centered on offender omega.
    // Never split crystallized carriers (treat as long-term memory).
    if (state != CARRIER_STATE_CRYSTALLIZED && offender_score > 0.0f) {
        // Atomically claim a new carrier slot.
        uint slot = atomic_fetch_add_explicit(out_num_carriers, 1, memory_order_relaxed);
        if (slot < p.max_carriers) {
            float omega_new = osc_omega[offender_idx];
            float amp_new = osc_amp[offender_idx];
            float phi_new = osc_phase[offender_idx];
            // Initialize new carrier from offender phasor (small magnitude to avoid shocks).
            float init_scale = 0.5f;
            float nr = init_scale * amp_new * cos(phi_new);
            float ni = init_scale * amp_new * sin(phi_new);

            carrier_real[slot] = nr;
            carrier_imag[slot] = ni;
            carrier_omega[slot] = omega_new;

            // Start moderately wide; specialization can be implemented by shrinking over time.
            carrier_gate_width[slot] = gate_w;
            carrier_conflict[slot] = 0.0f;
            carrier_state[slot] = CARRIER_STATE_VOLATILE;
            carrier_age[slot] = 0u;

            // Initialize anchors: offender as first anchor, rest empty.
            for (uint j = 0; j < CARRIER_ANCHORS; j++) {
                uint b = slot * CARRIER_ANCHORS + j;
                carrier_anchor_idx[b] = 0xFFFFFFFFu;
                carrier_anchor_phase[b] = 0.0f;
                carrier_anchor_weight[b] = 0.0f;
            }
            {
                uint b0 = slot * CARRIER_ANCHORS;
                carrier_anchor_idx[b0] = offender_idx;
                float psi0 = atan2(ni, nr);
                float d0 = phi_new - psi0;
                d0 = d0 - 2.0f * M_PI_F * floor((d0 + M_PI_F) / (2.0f * M_PI_F));
                carrier_anchor_phase[b0] = d0;
                carrier_anchor_weight[b0] = amp_new;
            }

            // Optional: record which oscillator spawned this carrier
            if (out_spawned_from_osc != nullptr) {
                out_spawned_from_osc[slot] = offender_idx;
            }

            // Randomize phase slightly by rotating c (keeps magnitude, changes ψ)
            float r = random_phases[slot] * 2.0f * M_PI_F;
            float rot_r = cos(r);
            float rot_i = sin(r);
            float rr = carrier_real[slot];
            float ri = carrier_imag[slot];
            carrier_real[slot] = rr * rot_r - ri * rot_i;
            carrier_imag[slot] = rr * rot_i + ri * rot_r;
        }

        // Reset conflict on the parent carrier after a split so it doesn't
        // repeatedly spawn every step.
        carrier_conflict[gid] = 0.0f;
    }
}

kernel void spectral_update_oscillator_phases(
    device float* osc_phase               [[buffer(0)]],  // N (in/out)
    device const float* osc_omega         [[buffer(1)]],  // N
    device const float* osc_amp           [[buffer(2)]],  // N
    device const float* carrier_real      [[buffer(3)]],  // maxM
    device const float* carrier_imag      [[buffer(4)]],  // maxM
    device const float* carrier_omega     [[buffer(5)]],  // maxM
    device const float* carrier_gate_width[[buffer(6)]],  // maxM
    device const uint* carrier_state      [[buffer(7)]],  // maxM
    device const uint* carrier_anchor_idx [[buffer(8)]],  // maxM * CARRIER_ANCHORS
    device const float* carrier_anchor_phase [[buffer(9)]], // maxM * CARRIER_ANCHORS
    device const float* carrier_anchor_weight[[buffer(10)]], // maxM * CARRIER_ANCHORS
    // Global energy stats (same format as in carrier update)
    device const float* energy_stats      [[buffer(11)]],  // (4,) [mean_abs, mean, std, count]
    constant uint& num_carriers           [[buffer(12)]],
    constant SpectralCarrierParams& p     [[buffer(13)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_osc) return;

    float phi = osc_phase[gid];
    float omega_i = osc_omega[gid];
    float amp_i = osc_amp[gid];

    // Torque from resonance potential:
    //   θ̇_i += Σ_k T_ik (A_i R_k) sin(ψ_k - θ_i)
    float torque = 0.0f;
    for (uint k = 0; k < num_carriers; k++) {
        float omega_k = carrier_omega[k];
        float gate_w = clamp(carrier_gate_width[k], p.gate_width_min, p.gate_width_max);
        float t = tuning_from_freq(omega_i, omega_k, gate_w);
        float cr = carrier_real[k];
        float ci = carrier_imag[k];
        float psi = atan2(ci, cr);
        float R = sqrt(cr * cr + ci * ci);
        float boost = 1.0f;
        if (carrier_state[k] == CARRIER_STATE_CRYSTALLIZED) {
            boost += max(p.crystallized_coupling_boost, 0.0f);
        }
        torque += boost * t * (amp_i * R) * sin(psi - phi);

        // Extra top-down phase pull if this oscillator is anchored in a crystallized carrier.
        if (carrier_state[k] == CARRIER_STATE_CRYSTALLIZED && p.topdown_phase_scale > 0.0f) {
            uint base = k * CARRIER_ANCHORS;
            for (uint j = 0; j < CARRIER_ANCHORS; j++) {
                uint idx = carrier_anchor_idx[base + j];
                if (idx == gid) {
                    float off = carrier_anchor_phase[base + j];
                    float w = carrier_anchor_weight[base + j];
                    float target = psi + off;
                    float d = target - phi;
                    d = d - 2.0f * M_PI_F * floor((d + M_PI_F) / (2.0f * M_PI_F));
                    torque += p.topdown_phase_scale * w * sin(d);
                }
            }
        }
    }

    float mean_abs_e = energy_stats[0];
    float e_scale = max(mean_abs_e, 1e-8f);
    float temp_factor = e_scale / (e_scale + 1.0f);
    float noise_scale = sqrt(max(2.0f * (p.temperature * temp_factor) * p.dt, 0.0f));
    float n = randn1(p.rng_seed ^ 0xC3C3C3C3u, gid);
    float dphi = omega_i + p.coupling_scale * torque;
    phi += dphi * p.dt + noise_scale * n;

    // Wrap phase to [0, 2π)
    phi = phi - 2.0f * M_PI_F * floor(phi / (2.0f * M_PI_F));
    osc_phase[gid] = phi;
}

// -----------------------------------------------------------------------------
// Kernel: Top-down energy bias from crystallized carriers (anchored completion)
// -----------------------------------------------------------------------------
// One thread per carrier. Atomically injects small energy into anchored oscillators
// proportional to carrier activation and anchor weights.
kernel void spectral_topdown_bias_energies(
    device atomic_float* osc_energy        [[buffer(0)]],  // N (in/out, atomic adds)
    device const float* osc_amp            [[buffer(1)]],  // N
    device const uint* carrier_state       [[buffer(2)]],  // maxM
    device const uint* carrier_anchor_idx  [[buffer(3)]],  // maxM * CARRIER_ANCHORS
    device const float* carrier_anchor_weight [[buffer(4)]], // maxM * CARRIER_ANCHORS
    constant uint& num_carriers            [[buffer(5)]],
    constant SpectralCarrierParams& p      [[buffer(6)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= num_carriers) return;
    if (carrier_state[gid] != CARRIER_STATE_CRYSTALLIZED) return;
    if (p.topdown_energy_scale <= 0.0f || p.num_osc == 0u) return;

    uint base = gid * CARRIER_ANCHORS;
    float wsum = 0.0f;
    float act = 0.0f;
    for (uint j = 0; j < CARRIER_ANCHORS; j++) {
        uint idx = carrier_anchor_idx[base + j];
        if (idx == 0xFFFFFFFFu || idx >= p.num_osc) continue;
        float w = carrier_anchor_weight[base + j];
        wsum += w;
        act += w * osc_amp[idx];
    }
    if (wsum <= 1e-8f) return;
    act = act / wsum;

    // Inject energy into anchored oscillators, favoring low-amplitude ones.
    for (uint j = 0; j < CARRIER_ANCHORS; j++) {
        uint idx = carrier_anchor_idx[base + j];
        if (idx == 0xFFFFFFFFu || idx >= p.num_osc) continue;
        float w = carrier_anchor_weight[base + j] / wsum;
        float a = osc_amp[idx];
        float need = 1.0f / (1.0f + a); // higher when oscillator is quiet
        float dE = p.dt * p.topdown_energy_scale * act * w * need;
        if (dE != 0.0f) {
            atomic_fetch_add_explicit(&osc_energy[idx], dE, memory_order_relaxed);
        }
    }

    // Exploration: random nudge so weaker bonds can "get lucky".
    if (p.topdown_random_energy_eps > 0.0f) {
        uint h = hash_u32(p.rng_seed ^ (gid * 0x27D4EB2Du) ^ 0x85EBCA6Bu);
        float u = u01_from_u32(h);
        if (u <= clamp(p.topdown_random_energy_eps, 0.0f, 1.0f)) {
            uint idx = hash_u32(h + 0x165667B1u) % p.num_osc;
            float dE = p.dt * (0.25f * p.topdown_energy_scale) * act;
            atomic_fetch_add_explicit(&osc_energy[idx], dE, memory_order_relaxed);
        }
    }
}

// -----------------------------------------------------------------------------
// Kernel: Spawn carriers for uncoupled oscillators
// -----------------------------------------------------------------------------
// Any oscillator with total coupling weight below threshold spawns its own carrier.
// This ensures every oscillator is coupled to at least one carrier.

kernel void spectral_spawn_uncoupled(
    device const float* osc_phase           [[buffer(0)]],  // N
    device const float* osc_omega           [[buffer(1)]],  // N
    device const float* osc_amp             [[buffer(2)]],  // N
    device const float* carrier_omega       [[buffer(3)]],  // maxM
    device const float* carrier_gate_width  [[buffer(4)]],  // maxM
    device float* carrier_real              [[buffer(5)]],  // maxM (out for new carriers)
    device float* carrier_imag              [[buffer(6)]],  // maxM
    device float* carrier_omega_out         [[buffer(7)]],  // maxM
    device float* carrier_gate_width_out    [[buffer(8)]],  // maxM
    device float* carrier_conflict          [[buffer(9)]],  // maxM
    device uint* carrier_state              [[buffer(10)]], // maxM
    device uint* carrier_age                [[buffer(11)]], // maxM
    device uint* carrier_anchor_idx         [[buffer(12)]], // maxM * CARRIER_ANCHORS
    device float* carrier_anchor_phase      [[buffer(13)]], // maxM * CARRIER_ANCHORS
    device float* carrier_anchor_weight     [[buffer(14)]], // maxM * CARRIER_ANCHORS
    device atomic_uint* num_carriers_atomic [[buffer(15)]], // single counter (in/out)
    constant uint& num_carriers             [[buffer(16)]], // current count (read)
    constant uint& max_carriers             [[buffer(17)]],
    constant float& coupling_threshold      [[buffer(18)]], // min total coupling to be "coupled"
    constant float& gate_width_init         [[buffer(19)]],
    constant float& gate_width_min          [[buffer(20)]],
    constant float& gate_width_max          [[buffer(21)]],
    uint gid [[thread_position_in_grid]],
    constant uint& num_osc                  [[buffer(22)]]
) {
    if (gid >= num_osc) return;
    
    float omega_i = osc_omega[gid];
    float amp_i = osc_amp[gid];
    float phi_i = osc_phase[gid];
    
    // Compute total coupling weight to all existing carriers
    float total_coupling = 0.0f;
    for (uint k = 0; k < num_carriers; k++) {
        float omega_k = carrier_omega[k];
        float gate_w = clamp(carrier_gate_width[k], gate_width_min, gate_width_max);
        float t = tuning_from_freq(omega_i, omega_k, gate_w);
        total_coupling += t;
    }
    
    // If oscillator is not sufficiently coupled to any carrier, spawn its own
    if (total_coupling < coupling_threshold) {
        uint slot = atomic_fetch_add_explicit(num_carriers_atomic, 1, memory_order_relaxed);
        if (slot < max_carriers) {
            // Initialize carrier from oscillator's phasor
            carrier_real[slot] = amp_i * cos(phi_i);
            carrier_imag[slot] = amp_i * sin(phi_i);
            carrier_omega_out[slot] = omega_i;
            carrier_gate_width_out[slot] = gate_width_init;
            carrier_conflict[slot] = 0.0f;
            carrier_state[slot] = CARRIER_STATE_VOLATILE;
            carrier_age[slot] = 0u;
            for (uint j = 0; j < CARRIER_ANCHORS; j++) {
                uint b = slot * CARRIER_ANCHORS + j;
                carrier_anchor_idx[b] = 0xFFFFFFFFu;
                carrier_anchor_phase[b] = 0.0f;
                carrier_anchor_weight[b] = 0.0f;
            }
            // Self-anchor (helps recruitment)
            {
                uint b0 = slot * CARRIER_ANCHORS;
                carrier_anchor_idx[b0] = gid;
                carrier_anchor_phase[b0] = 0.0f;
                carrier_anchor_weight[b0] = amp_i;
            }
        }
    }
}

// =============================================================================
// Particle Generation Kernels
// =============================================================================
// Move synthetic data generation patterns to GPU for faster file injection.

struct ParticleGenParams {
    uint32_t num_particles;
    float grid_x;
    float grid_y;
    float grid_z;
    float energy_scale;
    uint32_t pattern;  // 0=cluster, 1=line, 2=sphere, 3=random, 4=grid
    float center_x;
    float center_y;
    float center_z;
    float spread;      // Cluster spread or sphere radius
    float dir_x;       // Line direction
    float dir_y;
    float dir_z;
};

// -----------------------------------------------------------------------------
// Kernel: Generate particle positions based on pattern
// -----------------------------------------------------------------------------

kernel void generate_particle_positions(
    device float* positions           [[buffer(0)]],  // N * 3
    device const float* random_vals   [[buffer(1)]],  // N * 3 (pre-generated uniform [0,1])
    constant ParticleGenParams& p     [[buffer(2)]],
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    float3 center = float3(p.center_x, p.center_y, p.center_z);
    float3 r = float3(
        random_vals[gid * 3 + 0],
        random_vals[gid * 3 + 1],
        random_vals[gid * 3 + 2]
    );
    
    float3 pos;
    
    if (p.pattern == 0) {
        // Cluster: Gaussian around center
        // Convert uniform to Gaussian using Box-Muller (approximate)
        float3 gauss = (r - 0.5f) * 2.0f * 2.0f;  // Rough approximation
        pos = center + gauss * p.spread;
    }
    else if (p.pattern == 1) {
        // Line: along direction from start
        float t = float(gid) / float(p.num_particles) * p.spread;
        float3 dir = float3(p.dir_x, p.dir_y, p.dir_z);
        pos = center + dir * t + (r - 0.5f) * 0.5f;
    }
    else if (p.pattern == 2) {
        // Sphere: points on shell
        float theta = r.x * 2.0f * M_PI_F;
        float phi = acos(2.0f * r.y - 1.0f);
        float x = sin(phi) * cos(theta);
        float y = sin(phi) * sin(theta);
        float z = cos(phi);
        pos = center + float3(x, y, z) * p.spread;
    }
    else if (p.pattern == 4) {
        // Grid: regular lattice
        uint side = uint(pow(float(p.num_particles), 1.0f / 3.0f)) + 1;
        uint ix = gid % side;
        uint iy = (gid / side) % side;
        uint iz = gid / (side * side);
        float spacing = min(p.grid_x, min(p.grid_y, p.grid_z)) * 0.8f / float(side);
        pos = float3(
            2.0f + float(ix) * spacing,
            2.0f + float(iy) * spacing,
            2.0f + float(iz) * spacing
        ) + (r - 0.5f) * 0.3f;
    }
    else {
        // Random
        pos = float3(
            r.x * (p.grid_x - 2.0f) + 1.0f,
            r.y * (p.grid_y - 2.0f) + 1.0f,
            r.z * (p.grid_z - 2.0f) + 1.0f
        );
    }
    
    // Clamp to valid range
    float grid_max = min(p.grid_x, min(p.grid_y, p.grid_z)) - 1.5f;
    pos = clamp(pos, float3(0.5f), float3(grid_max));
    
    positions[gid * 3 + 0] = pos.x;
    positions[gid * 3 + 1] = pos.y;
    positions[gid * 3 + 2] = pos.z;
}

// -----------------------------------------------------------------------------
// Kernel: Initialize particle properties (velocity, energy, etc.)
// -----------------------------------------------------------------------------

kernel void initialize_particle_properties(
    device const float* positions      [[buffer(0)]],  // N * 3
    device float* velocities           [[buffer(1)]],  // N * 3
    device float* energies             [[buffer(2)]],  // N
    device float* heats                [[buffer(3)]],  // N
    device float* excitations          [[buffer(4)]],  // N
    device float* masses               [[buffer(5)]],  // N
    device const float* random_vals    [[buffer(6)]],  // N * 4 (for vel_scale, energy, exc, unused)
    constant ParticleGenParams& p      [[buffer(7)]],
    constant float& center_x           [[buffer(8)]],  // Mean position x
    constant float& center_y           [[buffer(9)]],  // Mean position y  
    constant float& center_z           [[buffer(10)]], // Mean position z
    uint gid [[thread_position_in_grid]]
) {
    if (gid >= p.num_particles) return;
    
    float3 pos = float3(
        positions[gid * 3 + 0],
        positions[gid * 3 + 1],
        positions[gid * 3 + 2]
    );
    
    float3 center = float3(center_x, center_y, center_z);
    
    // Velocity: toward center with small random component
    float3 vel = (center - pos) * 0.01f;
    vel += (float3(random_vals[gid * 4 + 0], random_vals[gid * 4 + 1], random_vals[gid * 4 + 2]) - 0.5f) * 0.1f;
    
    // Energy: distance-based for cluster/sphere, random otherwise
    float energy;
    if (p.pattern == 0 || p.pattern == 2) {
        float dist = length(pos - center);
        float max_dist = p.spread + 1.0f;
        energy = (1.0f - dist / max_dist) * p.energy_scale + 0.1f;
    } else {
        energy = random_vals[gid * 4 + 3] * p.energy_scale * 0.5f + 0.5f;
    }
    energy = max(energy, 0.1f);
    
    // Heat: starts at zero
    float heat = 0.0f;
    
    // Excitation: small random
    float exc = random_vals[gid * 4 + 2] * 0.1f;
    
    // Mass: proportional to energy
    float mass = energy;
    
    velocities[gid * 3 + 0] = vel.x;
    velocities[gid * 3 + 1] = vel.y;
    velocities[gid * 3 + 2] = vel.z;
    energies[gid] = energy;
    heats[gid] = heat;
    excitations[gid] = exc;
    masses[gid] = mass;
}



---
File: /optimizer/metal/manifold_physics.py
---

"""Metal manifold physics kernels.

Single implementation using Metal acceleration. No fallbacks.
If Metal is not available or something fails, we raise an exception.
"""

from __future__ import annotations

import math
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Dict, Any, Optional

import torch

if TYPE_CHECKING:
    from torch import Tensor


def manifold_physics_available() -> bool:
    """Check if Metal manifold physics is available."""
    if not torch.backends.mps.is_available():
        return False
    try:
        from .jit import load_caramba_metal_ops
        load_caramba_metal_ops()
        return True
    except Exception:
        return False


@dataclass
class ManifoldPhysicsConfig:
    """Configuration for manifold physics simulation."""
    
    grid_size: tuple[int, int, int] = (64, 64, 64)
    # Simulation parameters
    grid_spacing: float = 1.0            # Length scale (defines unit of length)
    dt: float = 0.01                     # Time step (defines unit of time)
    poisson_iterations: int = 50         # Solver iterations (need 30-50 for 64³ grid)
    
    # Fundamental physical constants (in simulation units)
    # CRITICAL: These must have correct relative magnitudes!
    # 
    # Real-world hierarchy (weakest to strongest):
    #   Gravity << Radiation << Thermal << Elastic
    #
    # G:        Gravity is the WEAKEST force - should not dominate local dynamics
    # sigma_SB: Radiation is a slow heat leak, not instant freeze (real σ = 5.67e-8)
    # k_B:      Thermal fluctuations should be moderate, not explosive
    #
    G: float = 0.001                     # Gravitational constant (weak - long range)
    k_B: float = 0.1                     # Boltzmann constant (moderate thermal pressure)
    sigma_SB: float = 1e-5               # Stefan-Boltzmann constant (slow radiation leak)
    
    # Material properties (define what the "stuff" is made of)
    # 
    # particle_radius:      Defines collision geometry
    # thermal_conductivity: Heat diffusion rate (moderate)
    # specific_heat:        How much energy to change temperature (higher = more stable)
    # dynamic_viscosity:    Drag in medium (low for gas-like, high for liquid-like)
    # emissivity:           Fraction of blackbody radiation (0-1)
    # restitution:          Collision elasticity (0 = sticky, 1 = bouncy)
    # young_modulus:        Contact stiffness (HIGH to prevent interpenetration)
    #
    particle_radius: float = 0.5         # Radius of particles
    thermal_conductivity: float = 0.1    # Heat flow rate (reduced to prevent instability)
    specific_heat: float = 10.0          # Heat capacity (higher = more thermal inertia)
    dynamic_viscosity: float = 0.01      # Low viscosity (gas-like medium)
    emissivity: float = 0.5              # Radiation efficiency (0-1)
    restitution: float = 0.8             # Collision elasticity (0-1)
    young_modulus: float = 1000.0        # High stiffness to prevent overlap


@dataclass
class SpectralCarrierConfig:
    """Configuration for spectral carriers (resonance potential, Langevin flow).

    This layer is an energy-based, non-local coupling mechanism:
    - Oscillators: z_i = A_i e^{iθ_i}, with intrinsic frequency ω_i.
    - Carriers:    C_k = R_k e^{iψ_k}, global modes in frequency space.
    - Tuning:      T_ik = exp(-(ω_i - ω_k)^2 / σ_k^2).
    - Updates follow the gradient of a resonance potential + Langevin noise.
    """

    max_carriers: int = 64
    coupling_scale: float = 0.25
    carrier_reg: float = 0.15      # λ: L2 penalty on |C| (prevents runaway growth)
    temperature: float = 0.01      # Langevin temperature (noise strength)

    # Conflict → split (EMA of phase incoherence)
    conflict_threshold: float = 0.35
    offender_weight_floor: float = 1e-3
    ema_alpha: float = 0.10
    recenter_alpha: float = 0.10
    
    # Uncoupled oscillators spawn their own carrier if total coupling < this
    uncoupled_threshold: float = 0.1

    # Gate width (tolerance / specialization)
    gate_width_init: float = 0.35
    gate_width_min: float = 0.08
    gate_width_max: float = 1.25

    # ------------------------------------------------------------------
    # Memory + top-down bias (carrier-as-chunk store)
    # ------------------------------------------------------------------
    # NOTE: Must match CARRIER_ANCHORS in `manifold_physics.metal`.
    anchor_slots: int = 8

    # Crystallization lifecycle
    stable_amp_threshold: float = 0.25
    crystallize_amp_threshold: float = 0.75
    crystallize_conflict_threshold: float = 0.12
    crystallize_age: int = 120

    # Dynamics modifiers
    crystallized_coupling_boost: float = 1.0
    volatile_decay_mul: float = 0.90
    stable_decay_mul: float = 0.98
    crystallized_decay_mul: float = 1.00

    # Top-down effects
    topdown_phase_scale: float = 0.05
    topdown_energy_scale: float = 0.05
    topdown_random_energy_eps: float = 0.02

    # Anchor refresh ε (online); higher values are used in exploration modes
    anchor_random_eps: float = 0.05

    # Idle-time disambiguation: ω-space repulsion between nearby carriers
    repulsion_scale: float = 0.05

    # Genesis: first oscillator creates first carrier (seed_carriers is deprecated)
    seed_carriers: int = 1  # Unused - genesis always starts with exactly 1 carrier


class ManifoldPhysics:
    """Metal-accelerated manifold physics simulation.
    
    No fallbacks. Metal only. Exceptions on failure.
    """
    
    def __init__(
        self,
        config: ManifoldPhysicsConfig,
        device: str = "mps",
    ):
        if device != "mps":
            raise RuntimeError(f"ManifoldPhysics requires device='mps', got '{device}'")
        
        if not torch.backends.mps.is_available():
            raise RuntimeError("MPS backend not available")
        
        self.config = config
        self.device = torch.device(device)
        self.dtype = torch.float32
        
        gx, gy, gz = config.grid_size
        self.grid_dims = (gx, gy, gz)
        
        # Allocate fields
        self.gravity_field = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)
        self.gravity_potential = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)
        self.temperature_field = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)
        
        # Load Metal ops immediately (fail fast)
        from .jit import load_caramba_metal_ops
        self._ops = load_caramba_metal_ops()
    
    @property
    def ops(self):
        return self._ops
    
    def scatter_particles(
        self,
        positions: "Tensor",
        masses: "Tensor",
        heats: "Tensor",
    ) -> None:
        """Scatter particle mass and heat to fields."""
        self.ops.manifold_clear_field(self.gravity_field)
        self.ops.manifold_clear_field(self.temperature_field)
        self.ops.manifold_scatter_particles(
            positions.contiguous(),
            masses.contiguous(),
            heats.contiguous(),
            self.gravity_field,
            self.temperature_field,
            float(self.config.grid_spacing),
        )
    
    def solve_gravity(self) -> None:
        """Solve Poisson equation for gravitational potential.
        
        Poisson equation: ∇²φ = 4πGρ
        We use G from the config as the gravitational constant.
        """
        cfg = self.config
        # Poisson equation coefficient: 4πG
        gravity_4pi = 4.0 * 3.14159265359 * cfg.G
        
        phi_tmp = torch.zeros_like(self.gravity_potential)
        
        for i in range(cfg.poisson_iterations):
            if i % 2 == 0:
                self.ops.manifold_poisson_step(
                    self.gravity_potential, self.gravity_field, phi_tmp,
                    gravity_4pi, float(cfg.grid_spacing)
                )
            else:
                self.ops.manifold_poisson_step(
                    phi_tmp, self.gravity_field, self.gravity_potential,
                    gravity_4pi, float(cfg.grid_spacing)
                )
        
        if cfg.poisson_iterations % 2 == 1:
            self.gravity_potential.copy_(phi_tmp)
    
    def diffuse_heat(self) -> None:
        """Evolve temperature field via diffusion.
        
        Heat equation: ∂T/∂t = α∇²T where α = k/(ρ*c_v)
        We use thermal_conductivity from config as the diffusion coefficient.
        """
        cfg = self.config
        temp_out = torch.zeros_like(self.temperature_field)
        # Thermal diffusivity α = k (using k directly as we're in simulation units)
        self.ops.manifold_diffuse_heat(
            self.temperature_field, temp_out,
            float(cfg.thermal_conductivity), float(cfg.dt), float(cfg.grid_spacing)
        )
        self.temperature_field.copy_(temp_out)
    
    def gather_update_particles(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        energies: "Tensor",
        heats: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
    ) -> tuple["Tensor", "Tensor", "Tensor", "Tensor", "Tensor"]:
        """Gather from fields and update all particle state.
        
        Uses fundamental physics:
        - Gravity: F = -G * m * ∇φ
        - Pressure: F = -k_B * m * ∇T (ideal gas law)
        - Heat transfer: Newton's law + Stefan-Boltzmann radiation
        - Drag: Stokes' law F = -6πηrv
        """
        cfg = self.config
        
        positions = positions.contiguous()
        velocities = velocities.contiguous()
        energies = energies.contiguous()
        heats = heats.contiguous()
        excitations = excitations.contiguous()
        masses = masses.contiguous()
        
        self.ops.manifold_gather_update_particles(
            self.gravity_potential,
            self.temperature_field,
            positions,
            velocities,
            energies,
            heats,
            excitations,
            masses,
            float(cfg.dt),
            float(cfg.grid_spacing),
            # Fundamental constants
            float(cfg.G),
            float(cfg.k_B),
            float(cfg.sigma_SB),
            # Material properties
            float(cfg.particle_radius),
            float(cfg.thermal_conductivity),
            float(cfg.specific_heat),
            float(cfg.dynamic_viscosity),
            float(cfg.emissivity),
            float(cfg.young_modulus),
        )
        return positions, velocities, energies, heats, excitations

    
    def compute_interactions(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
        heats: "Tensor",
    ) -> tuple["Tensor", "Tensor", "Tensor"]:
        """Compute particle-particle interactions (collision + heat transfer).
        
        Implements proper physics:
        - Momentum-conserving impulse-based collisions
        - Energy conservation: KE_lost = 0.5 * m_eff * v_n² * (1 - e²) → heat
        - Hertzian contact force: F = E * δ (prevents interpenetration)
        - Fourier's law heat conduction on contact
        
        This is O(N²) so best for moderate particle counts (<1000).
        """
        cfg = self.config
        
        positions = positions.contiguous()
        velocities = velocities.contiguous()
        excitations = excitations.contiguous()
        masses = masses.contiguous()
        heats = heats.contiguous()
        
        self.ops.particle_interactions(
            positions,
            velocities,
            excitations,
            masses,
            heats,
            float(cfg.dt),
            float(cfg.particle_radius),
            float(cfg.young_modulus),
            float(cfg.thermal_conductivity),
            float(cfg.restitution),
        )
        return velocities, excitations, heats
    
    def compute_interactions_spatial_hash(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
        heats: "Tensor",
        cell_size: Optional[float] = None,
    ) -> tuple["Tensor", "Tensor", "Tensor"]:
        """Compute particle-particle interactions using spatial hashing.
        
        This is O(N) on average, much faster than O(N²) for large particle counts.
        Use this method when num_particles > 1000.
        
        The simulation domain is divided into cells of size `cell_size`.
        Particles only check for collisions with particles in the same or
        neighboring cells (27 cells total in 3D).
        
        Args:
            cell_size: Size of spatial hash cells. Should be >= 2 * particle_radius.
                       If None, defaults to 4 * particle_radius for optimal performance.
        """
        cfg = self.config
        n = positions.size(0)
        
        if n == 0:
            return velocities, excitations, heats
        
        # Use 4x particle radius if not specified (empirically optimal)
        if cell_size is None:
            cell_size = 4.0 * cfg.particle_radius
        
        # Compute grid dimensions for spatial hash
        gx, gy, gz = self.grid_dims
        domain_size = (
            gx * cfg.grid_spacing,
            gy * cfg.grid_spacing,
            gz * cfg.grid_spacing,
        )
        
        hash_grid_x = max(1, int(math.ceil(domain_size[0] / cell_size)))
        hash_grid_y = max(1, int(math.ceil(domain_size[1] / cell_size)))
        hash_grid_z = max(1, int(math.ceil(domain_size[2] / cell_size)))
        num_cells = hash_grid_x * hash_grid_y * hash_grid_z
        
        # Allocate working buffers (reuse if possible in hot path)
        particle_cell_idx = torch.empty(n, dtype=torch.int32, device=self.device)
        cell_counts = torch.zeros(num_cells, dtype=torch.int32, device=self.device)
        cell_starts = torch.empty(num_cells + 1, dtype=torch.int32, device=self.device)
        sorted_particle_idx = torch.empty(n, dtype=torch.int32, device=self.device)
        
        positions = positions.contiguous()
        velocities = velocities.contiguous()
        excitations = excitations.contiguous()
        masses = masses.contiguous()
        heats = heats.contiguous()
        
        # Phase 1: Assign particles to cells
        self.ops.spatial_hash_assign(
            positions,
            particle_cell_idx,
            cell_counts,
            hash_grid_x,
            hash_grid_y,
            hash_grid_z,
            cell_size,
            0.0,  # domain_min_x
            0.0,  # domain_min_y
            0.0,  # domain_min_z
        )
        
        # Phase 2: Compute prefix sum (cell_starts[i] = sum(counts[0:i]))
        self.ops.spatial_hash_prefix_sum(
            cell_counts,
            cell_starts,
            num_cells,
        )
        
        # Phase 3: Scatter particles to sorted array
        # First copy cell_starts to cell_offsets (working copy)
        cell_offsets = cell_starts[:num_cells].clone()
        self.ops.spatial_hash_scatter(
            particle_cell_idx,
            sorted_particle_idx,
            cell_offsets,
            n,
        )
        
        # Phase 4: Collision detection using spatial hash
        self.ops.spatial_hash_collisions(
            positions,
            velocities,
            excitations,
            masses,
            heats,
            sorted_particle_idx,
            cell_starts,
            particle_cell_idx,
            hash_grid_x,
            hash_grid_y,
            hash_grid_z,
            cell_size,
            0.0,  # domain_min_x
            0.0,  # domain_min_y
            0.0,  # domain_min_z
            float(cfg.dt),
            float(cfg.particle_radius),
            float(cfg.young_modulus),
            float(cfg.thermal_conductivity),
            float(cfg.restitution),
        )
        
        return velocities, excitations, heats
    
    def step(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        energies: "Tensor",
        heats: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
        use_spatial_hash: Optional[bool] = None,
    ) -> tuple["Tensor", "Tensor", "Tensor", "Tensor", "Tensor"]:
        """Execute one full physics timestep.
        
        Args:
            use_spatial_hash: If True, use O(N) spatial hash collisions.
                              If False, use O(N²) brute force.
                              If None (default), auto-select based on particle count:
                              - N < 1000: use brute force (lower overhead)
                              - N >= 1000: use spatial hash (better scaling)
        """
        # 1. Scatter particles to fields
        self.scatter_particles(positions, masses, heats)
        
        # 2. Solve field equations
        self.solve_gravity()
        self.diffuse_heat()
        
        # 3. Gather from fields and update particle state
        positions, velocities, energies, heats, excitations = self.gather_update_particles(
            positions, velocities, energies, heats, excitations, masses
        )
        
        # 4. Particle-particle interactions (collision + excitation transfer)
        # Auto-select collision algorithm based on particle count
        n = positions.size(0)
        if use_spatial_hash is None:
            use_spatial_hash = n >= 1000
        
        if use_spatial_hash:
            # O(N) spatial hash - better for large particle counts
            velocities, excitations, heats = self.compute_interactions_spatial_hash(
                positions, velocities, excitations, masses, heats
            )
        else:
            # O(N²) brute force - lower overhead for small counts
            velocities, excitations, heats = self.compute_interactions(
                positions, velocities, excitations, masses, heats
            )
        
        return positions, velocities, energies, heats, excitations


class SpectralCarrierPhysics:
    """Metal-accelerated spectral carriers (resonance potential, Langevin flow).

    This is the wave-space entanglement layer:
    - Oscillators are particles viewed as (phase θ, omega ω, amplitude A).
    - Carriers are global complex modes C_k with (omega_k, gate_width σ_k).
    - Updates are gradient flow on a resonance potential + Langevin noise.
    - Persistent *phase incoherence* triggers carrier splitting/spawning.
    """

    def __init__(
        self,
        config: SpectralCarrierConfig,
        grid_size: tuple[int, int, int],
        dt: float,
        device: str = "mps",
    ):
        if device != "mps":
            raise RuntimeError(f"SpectralCarrierPhysics requires device='mps', got '{device}'")
        if not torch.backends.mps.is_available():
            raise RuntimeError("MPS backend not available")

        self.config = config
        self.grid_size = grid_size
        self.dt = float(dt)
        self.device = torch.device(device)
        self.dtype = torch.float32

        self.max_carriers = int(config.max_carriers)
        if self.max_carriers <= 0:
            raise ValueError("SpectralCarrierConfig.max_carriers must be > 0")

        if int(config.anchor_slots) != 8:
            raise ValueError(
                "SpectralCarrierConfig.anchor_slots must be 8 "
                "(must match CARRIER_ANCHORS in optimizer/metal/manifold_physics.metal)"
            )

        # Carrier state buffers (fixed capacity; active count tracked separately)
        self.carrier_real = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_imag = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_omega = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_gate_width = torch.full(
            (self.max_carriers,), float(config.gate_width_init), device=self.device, dtype=self.dtype
        )
        self.carrier_conflict = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.spawned_from_osc = torch.full(
            (self.max_carriers,), -1, device=self.device, dtype=torch.int32
        )

        # Memory state (GPU-owned)
        # carrier_state: 0=volatile, 1=stable, 2=crystallized
        self.carrier_state = torch.zeros(self.max_carriers, device=self.device, dtype=torch.int32)
        self.carrier_age = torch.zeros(self.max_carriers, device=self.device, dtype=torch.int32)

        # Anchors (flattened: max_carriers * anchor_slots)
        anchors = int(config.anchor_slots)
        self.anchor_slots = anchors
        self.carrier_anchor_idx = torch.full(
            (self.max_carriers * anchors,), -1, device=self.device, dtype=torch.int32
        )
        self.carrier_anchor_phase = torch.zeros(
            (self.max_carriers * anchors,), device=self.device, dtype=self.dtype
        )
        self.carrier_anchor_weight = torch.zeros(
            (self.max_carriers * anchors,), device=self.device, dtype=self.dtype
        )

        # Atomic counter buffer used by the Metal kernel (int32 backing storage)
        self._num_carriers_buf = torch.zeros(1, device=self.device, dtype=torch.int32)
        self.num_carriers = 0

        # Random phases used when spawning carriers inside the kernel
        self._random_phases = torch.rand(self.max_carriers, device=self.device, dtype=self.dtype)

        # Global energy statistics buffer (GPU-written each step):
        # [mean_abs, mean, std, count]
        self._energy_stats = torch.zeros(4, device=self.device, dtype=self.dtype)

        # RNG seed for Langevin noise (host-controlled)
        self._rng_seed: int = 1

        # Load Metal ops
        from .jit import load_caramba_metal_ops
        self._ops = load_caramba_metal_ops()

    @property
    def ops(self):
        return self._ops

    def _ensure_seeded(self, osc_phase: "Tensor", osc_omega: "Tensor", osc_amp: "Tensor") -> None:
        """Genesis event: create the first carrier from the first oscillator.
        
        All other oscillators will couple to this carrier since it's the only one.
        Spectral conflict will build and trigger splits, creating new carriers
        that oscillators can then redistribute to based on frequency alignment.
        """
        if self.num_carriers > 0:
            return
        N = int(osc_phase.shape[0])
        if N == 0:
            return

        # Genesis: exactly ONE carrier from the first oscillator
        # (In a real system, this is the first particle that enters)
        idx = 0
        phi = osc_phase[idx].item()
        omega = osc_omega[idx].item()
        amp = osc_amp[idx].item()

        # Initialize carrier from the first oscillator phasor: C = z (no polarity hack)
        self.carrier_real[0] = amp * math.cos(phi)
        self.carrier_imag[0] = amp * math.sin(phi)
        self.carrier_omega[0] = omega
        # Gate width derived from wavelength: wider frequency = narrower pulse
        # For now, use initial value; this could be omega-dependent
        self.carrier_gate_width[0] = float(self.config.gate_width_init)
        self.carrier_conflict[0] = 0.0
        self.spawned_from_osc[0] = 0
        self.carrier_state[0] = 0
        self.carrier_age[0] = 0

        # Seed anchors: self-anchor the genesis oscillator.
        self.carrier_anchor_idx.fill_(-1)
        self.carrier_anchor_phase.zero_()
        self.carrier_anchor_weight.zero_()
        self.carrier_anchor_idx[0] = 0
        self.carrier_anchor_phase[0] = 0.0
        self.carrier_anchor_weight[0] = float(osc_amp[idx].item())

        self.num_carriers = 1
        self._num_carriers_buf[0] = 1

    def idle_compute(
        self,
        osc_phase: "Tensor",
        particle_excitations: "Tensor",
        particle_energies: "Tensor",
        *,
        steps: int = 1,
        mode: str = "explore",
    ) -> Dict[str, "Tensor"]:
        """Idle-time compute for spectral memory (runs on GPU).

        This is the Metal version of the old "idle pondering" ideas, renamed:
        - **consolidate**: stabilize and crystallize carriers (low noise)
        - **disambiguate**: reduce mode collisions (ω-space repulsion)
        - **explore**: counterfactual exploration with stochasticity + luck for weak links
        """
        mode_s = str(mode).lower().strip()
        if mode_s in ("consolidate", "consolidation", "stabilize"):
            m = 1
            temp = float(self.config.temperature) * 0.25
            anchor_eps = float(self.config.anchor_random_eps) * 0.25
            rand_energy_eps = float(self.config.topdown_random_energy_eps) * 0.25
            offender_floor = float(self.config.offender_weight_floor)
            repulsion = 0.0
        elif mode_s in ("disambiguate", "resolve", "separate"):
            m = 2
            temp = float(self.config.temperature) * 0.50
            anchor_eps = float(self.config.anchor_random_eps) * 0.50
            rand_energy_eps = float(self.config.topdown_random_energy_eps) * 0.50
            offender_floor = float(self.config.offender_weight_floor)
            repulsion = float(self.config.repulsion_scale)
        elif mode_s in ("explore", "counterfactual", "counterfactual_exploration"):
            m = 3
            temp = float(self.config.temperature) * 2.0
            # "weak bonds get lucky": raise ε and lower the weight floor
            anchor_eps = max(float(self.config.anchor_random_eps), 0.20)
            rand_energy_eps = max(float(self.config.topdown_random_energy_eps), 0.10)
            offender_floor = float(self.config.offender_weight_floor) * 0.10
            repulsion = 0.0
        else:
            raise ValueError(f"Unknown idle_compute mode: {mode!r}")

        out: Dict[str, "Tensor"] = {}
        for _ in range(int(steps)):
            osc_phase = osc_phase.contiguous()
            osc_omega = particle_excitations.to(dtype=self.dtype).contiguous()
            energy = particle_energies.to(dtype=self.dtype).contiguous()
            osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

            self.ops.thermo_reduce_energy_stats(energy, self._energy_stats)
            self._ensure_seeded(osc_phase, osc_omega, osc_amp)
            if self.num_carriers == 0:
                out = {
                    "frequencies": torch.empty(0, device=self.device, dtype=self.dtype),
                    "gate_widths": torch.empty(0, device=self.device, dtype=self.dtype),
                    "amplitudes": torch.empty(0, device=self.device, dtype=self.dtype),
                    "phases": torch.empty(0, device=self.device, dtype=self.dtype),
                    "conflict": torch.empty(0, device=self.device, dtype=self.dtype),
                    "osc_phase": osc_phase,
                    "osc_energy": energy,
                    "carrier_state": torch.empty(0, device=self.device, dtype=torch.int32),
                    "carrier_age": torch.empty(0, device=self.device, dtype=torch.int32),
                }
                break

            self._num_carriers_buf[0] = int(self.num_carriers)
            self._random_phases.uniform_()
            self._rng_seed = (self._rng_seed + 1) & 0xFFFFFFFF
            cfg = self.config

            self.ops.spectral_carrier_update_and_split(
                osc_phase,
                osc_omega,
                osc_amp,
                self.carrier_real,
                self.carrier_imag,
                self.carrier_omega,
                self.carrier_gate_width,
                self.carrier_conflict,
                self.carrier_state,
                self.carrier_age,
                self.carrier_anchor_idx,
                self.carrier_anchor_phase,
                self.carrier_anchor_weight,
                self._num_carriers_buf,
                self.spawned_from_osc,
                self._random_phases,
                self._energy_stats,
                int(self.num_carriers),
                int(self.max_carriers),
                float(self.dt),
                float(cfg.coupling_scale),
                float(cfg.carrier_reg),
                float(temp),
                int(self._rng_seed) & 0xFFFFFFFF,
                float(cfg.conflict_threshold),
                float(offender_floor),
                float(cfg.gate_width_min),
                float(cfg.gate_width_max),
                float(cfg.ema_alpha),
                float(cfg.recenter_alpha),
                int(m),
                float(anchor_eps),
                float(cfg.stable_amp_threshold),
                float(cfg.crystallize_amp_threshold),
                float(cfg.crystallize_conflict_threshold),
                int(cfg.crystallize_age),
                float(cfg.crystallized_coupling_boost),
                float(cfg.volatile_decay_mul),
                float(cfg.stable_decay_mul),
                float(cfg.crystallized_decay_mul),
                float(cfg.topdown_phase_scale),
                float(cfg.topdown_energy_scale),
                float(rand_energy_eps),
                float(repulsion),
            )

            new_count = int(self._num_carriers_buf.to("cpu").item())
            self.num_carriers = max(0, min(new_count, self.max_carriers))

            self.ops.spectral_topdown_bias_energies(
                energy,
                osc_amp,
                self.carrier_state,
                self.carrier_anchor_idx,
                self.carrier_anchor_weight,
                int(self.num_carriers),
                int(self.max_carriers),
                float(self.dt),
                int(self._rng_seed) & 0xFFFFFFFF,
                int(m),
                float(cfg.topdown_energy_scale),
                float(rand_energy_eps),
            )

            osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()
            self.ops.spectral_update_oscillator_phases(
                osc_phase,
                osc_omega,
                osc_amp,
                self.carrier_real,
                self.carrier_imag,
                self.carrier_omega,
                self.carrier_gate_width,
                self.carrier_state,
                self.carrier_anchor_idx,
                self.carrier_anchor_phase,
                self.carrier_anchor_weight,
                self._energy_stats,
                int(self.num_carriers),
                int(self.max_carriers),
                float(self.dt),
                float(cfg.coupling_scale),
                float(temp),
                int(self._rng_seed) & 0xFFFFFFFF,
                float(cfg.gate_width_min),
                float(cfg.gate_width_max),
                float(cfg.crystallized_coupling_boost),
                float(cfg.topdown_phase_scale),
            )

            self._num_carriers_buf[0] = int(self.num_carriers)
            new_count = self.ops.spectral_spawn_uncoupled(
                osc_phase,
                osc_omega,
                osc_amp,
                self.carrier_omega,
                self.carrier_gate_width,
                self.carrier_real,
                self.carrier_imag,
                self.carrier_omega,
                self.carrier_gate_width,
                self.carrier_conflict,
                self.carrier_state,
                self.carrier_age,
                self.carrier_anchor_idx,
                self.carrier_anchor_phase,
                self.carrier_anchor_weight,
                self._num_carriers_buf,
                int(self.num_carriers),
                int(self.max_carriers),
                float(cfg.uncoupled_threshold),
                float(cfg.gate_width_init),
                float(cfg.gate_width_min),
                float(cfg.gate_width_max),
            )
            self.num_carriers = int(new_count)

            cr = self.carrier_real[: self.num_carriers]
            ci = self.carrier_imag[: self.num_carriers]
            amp = torch.sqrt(cr * cr + ci * ci)
            phase = torch.atan2(ci, cr)
            out = {
                "frequencies": self.carrier_omega[: self.num_carriers],
                "gate_widths": self.carrier_gate_width[: self.num_carriers],
                "amplitudes": amp,
                "phases": phase,
                "conflict": self.carrier_conflict[: self.num_carriers],
                "osc_phase": osc_phase,
                "osc_energy": energy,
                "carrier_state": self.carrier_state[: self.num_carriers],
                "carrier_age": self.carrier_age[: self.num_carriers],
            }
            particle_energies = energy
        return out

    def step(
        self,
        osc_phase: "Tensor",           # (N,) fp32 MPS in/out
        particle_excitations: "Tensor",# (N,) fp32 MPS
        particle_energies: "Tensor",   # (N,) fp32 MPS
    ) -> Dict[str, "Tensor"]:
        """One spectral carrier tick (update + split + oscillator phase update)."""
        osc_phase = osc_phase.contiguous()
        osc_omega = particle_excitations.to(dtype=self.dtype).contiguous()
        energy = particle_energies.to(dtype=self.dtype).contiguous()
        osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

        # Adaptive renormalization: compute global energy statistics on-GPU.
        self.ops.thermo_reduce_energy_stats(energy, self._energy_stats)

        self._ensure_seeded(osc_phase, osc_omega, osc_amp)
        if self.num_carriers == 0:
            return {
                "frequencies": torch.empty(0, device=self.device, dtype=self.dtype),
                "gate_widths": torch.empty(0, device=self.device, dtype=self.dtype),
                "amplitudes": torch.empty(0, device=self.device, dtype=self.dtype),
                "phases": torch.empty(0, device=self.device, dtype=self.dtype),
                "conflict": torch.empty(0, device=self.device, dtype=self.dtype),
                "osc_phase": osc_phase,
            }

        # Ensure counter starts at current carrier count (kernel increments it on split)
        self._num_carriers_buf[0] = int(self.num_carriers)
        self._random_phases.uniform_()

        cfg = self.config
        # Advance RNG seed so noise changes each step deterministically
        self._rng_seed = (self._rng_seed + 1) & 0xFFFFFFFF
        self.ops.spectral_carrier_update_and_split(
            osc_phase,
            osc_omega,
            osc_amp,
            self.carrier_real,
            self.carrier_imag,
            self.carrier_omega,
            self.carrier_gate_width,
            self.carrier_conflict,
            self.carrier_state,
            self.carrier_age,
            self.carrier_anchor_idx,
            self.carrier_anchor_phase,
            self.carrier_anchor_weight,
            self._num_carriers_buf,
            self.spawned_from_osc,
            self._random_phases,
            self._energy_stats,
            int(self.num_carriers),
            int(self.max_carriers),
            float(self.dt),
            float(cfg.coupling_scale),
            float(cfg.carrier_reg),
            float(cfg.temperature),
            int(self._rng_seed) & 0xFFFFFFFF,
            float(cfg.conflict_threshold),
            float(cfg.offender_weight_floor),
            float(cfg.gate_width_min),
            float(cfg.gate_width_max),
            float(cfg.ema_alpha),
            float(cfg.recenter_alpha),
            0,  # mode (0=online)
            float(cfg.anchor_random_eps),
            float(cfg.stable_amp_threshold),
            float(cfg.crystallize_amp_threshold),
            float(cfg.crystallize_conflict_threshold),
            int(cfg.crystallize_age),
            float(cfg.crystallized_coupling_boost),
            float(cfg.volatile_decay_mul),
            float(cfg.stable_decay_mul),
            float(cfg.crystallized_decay_mul),
            float(cfg.topdown_phase_scale),
            float(cfg.topdown_energy_scale),
            float(cfg.topdown_random_energy_eps),
            float(cfg.repulsion_scale),
        )

        # Read updated carrier count (sync via CPU copy)
        new_count = int(self._num_carriers_buf.to("cpu").item())
        self.num_carriers = max(0, min(new_count, self.max_carriers))

        # Top-down energy bias (crystallized carriers act as priors/completions).
        # NOTE: This updates `energy` (a local fp32 view); callers can choose to
        # use the returned "osc_energy" for downstream inference.
        self.ops.spectral_topdown_bias_energies(
            energy,
            osc_amp,
            self.carrier_state,
            self.carrier_anchor_idx,
            self.carrier_anchor_weight,
            int(self.num_carriers),
            int(self.max_carriers),
            float(self.dt),
            int(self._rng_seed) & 0xFFFFFFFF,
            0,  # mode (0=online)
            float(cfg.topdown_energy_scale),
            float(cfg.topdown_random_energy_eps),
        )

        # Recompute amplitude after energy injection so phase update sees the bias.
        osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

        # Oscillator phase update from carriers
        self.ops.spectral_update_oscillator_phases(
            osc_phase,
            osc_omega,
            osc_amp,
            self.carrier_real,
            self.carrier_imag,
            self.carrier_omega,
            self.carrier_gate_width,
            self.carrier_state,
            self.carrier_anchor_idx,
            self.carrier_anchor_phase,
            self.carrier_anchor_weight,
            self._energy_stats,
            int(self.num_carriers),
            int(self.max_carriers),
            float(self.dt),
            float(cfg.coupling_scale),
            float(cfg.temperature),
            int(self._rng_seed) & 0xFFFFFFFF,
            float(cfg.gate_width_min),
            float(cfg.gate_width_max),
            float(cfg.crystallized_coupling_boost),
            float(cfg.topdown_phase_scale),
        )

        # Spawn carriers for any uncoupled oscillators
        # (ensures every oscillator is coupled to at least one carrier)
        self._num_carriers_buf[0] = int(self.num_carriers)
        new_count = self.ops.spectral_spawn_uncoupled(
            osc_phase,
            osc_omega,
            osc_amp,
            self.carrier_omega,
            self.carrier_gate_width,
            self.carrier_real,
            self.carrier_imag,
            self.carrier_omega,      # write to same buffer
            self.carrier_gate_width, # write to same buffer
            self.carrier_conflict,
            self.carrier_state,
            self.carrier_age,
            self.carrier_anchor_idx,
            self.carrier_anchor_phase,
            self.carrier_anchor_weight,
            self._num_carriers_buf,
            int(self.num_carriers),
            int(self.max_carriers),
            float(cfg.uncoupled_threshold),  # oscillators with total coupling < this spawn
            float(cfg.gate_width_init),
            float(cfg.gate_width_min),
            float(cfg.gate_width_max),
        )
        self.num_carriers = int(new_count)

        # Prepare state views for dashboard
        cr = self.carrier_real[: self.num_carriers]
        ci = self.carrier_imag[: self.num_carriers]
        amp = torch.sqrt(cr * cr + ci * ci)
        phase = torch.atan2(ci, cr)

        return {
            "frequencies": self.carrier_omega[: self.num_carriers],
            "gate_widths": self.carrier_gate_width[: self.num_carriers],
            "amplitudes": amp,
            "phases": phase,
            "conflict": self.carrier_conflict[: self.num_carriers],
            "osc_phase": osc_phase,
            "osc_energy": energy,
            "carrier_state": self.carrier_state[: self.num_carriers],
            "carrier_age": self.carrier_age[: self.num_carriers],
        }


class ParticleGenerator:
    """Metal-accelerated particle generation for file injection."""
    
    # Pattern constants
    PATTERN_CLUSTER = 0
    PATTERN_LINE = 1
    PATTERN_SPHERE = 2
    PATTERN_RANDOM = 3
    PATTERN_GRID = 4
    
    PATTERN_NAMES = ["cluster", "line", "sphere", "random", "grid"]
    
    def __init__(
        self,
        grid_size: tuple[int, int, int],
        device: str = "mps",
    ):
        if device != "mps":
            raise RuntimeError(f"ParticleGenerator requires device='mps', got '{device}'")
        
        self.grid_size = grid_size
        self.device = torch.device(device)
        self.dtype = torch.float32
        self.file_count = 0
        
        from .jit import load_caramba_metal_ops
        self._ops = load_caramba_metal_ops()
    
    @property
    def ops(self):
        return self._ops
    
    def generate_file(
        self,
        num_particles: int = 50,
        pattern: Optional[str] = None,
        energy_scale: float = 1.0,
    ) -> Dict[str, Any]:
        """Generate a synthetic 'file' - a burst of related particles.
        
        All computation happens on GPU via Metal kernels.
        """
        import random
        
        self.file_count += 1
        
        if pattern is None:
            pattern = random.choice(self.PATTERN_NAMES)
        
        pattern_id = self.PATTERN_NAMES.index(pattern) if pattern in self.PATTERN_NAMES else 3
        
        gx, gy, gz = self.grid_size
        
        # Random center for cluster/sphere patterns
        center_x = random.uniform(gx * 0.2, gx * 0.8)
        center_y = random.uniform(gy * 0.2, gy * 0.8)
        center_z = random.uniform(gz * 0.2, gz * 0.8)
        
        # Spread depends on pattern
        grid_min = min(gx, gy, gz)
        if pattern == "cluster":
            spread = grid_min * 0.15
        elif pattern == "sphere":
            spread = grid_min * 0.2 + random.uniform(0, 5)
        elif pattern == "line":
            spread = grid_min * 0.7
        else:
            spread = grid_min * 0.4
        
        # Direction for line pattern
        dir_vec = torch.randn(3)
        dir_vec = dir_vec / (dir_vec.norm() + 1e-8)
        
        # Allocate output tensors
        positions = torch.empty(num_particles, 3, device=self.device, dtype=self.dtype)
        velocities = torch.empty(num_particles, 3, device=self.device, dtype=self.dtype)
        energies = torch.empty(num_particles, device=self.device, dtype=self.dtype)
        heats = torch.empty(num_particles, device=self.device, dtype=self.dtype)
        excitations = torch.empty(num_particles, device=self.device, dtype=self.dtype)
        masses = torch.empty(num_particles, device=self.device, dtype=self.dtype)
        
        # Random values for generation
        random_pos = torch.rand(num_particles, 3, device=self.device, dtype=self.dtype)
        random_props = torch.rand(num_particles, 4, device=self.device, dtype=self.dtype)
        
        self.ops.generate_particles(
            positions,
            velocities,
            energies,
            heats,
            excitations,
            masses,
            random_pos,
            random_props,
            pattern_id,
            float(gx),
            float(gy),
            float(gz),
            energy_scale,
            center_x,
            center_y,
            center_z,
            spread,
            float(dir_vec[0]),
            float(dir_vec[1]),
            float(dir_vec[2]),
        )
        
        return {
            "positions": positions,
            "velocities": velocities,
            "energies": energies,
            "heats": heats,
            "excitations": excitations,
            "masses": masses,
            "pattern": pattern,
            "file_id": self.file_count,
        }



---
File: /optimizer/metal/ops.mm
---

#include <torch/extension.h>

#include <ATen/mps/MPSDevice.h>
#include <ATen/mps/MPSStream.h>

#include <dlfcn.h>
#include <filesystem>
#include <mutex>
#include <string>

#import <Foundation/Foundation.h>
#import <Metal/Metal.h>
#include <dispatch/dispatch.h>

namespace fs = std::filesystem;

namespace {

// Must match `ManifoldPhysicsParams` in `manifold_physics.metal`.
struct ManifoldPhysicsParams {
  // Grid parameters
  uint32_t num_particles;
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float grid_spacing;
  float inv_grid_spacing;
  float dt;
  
  // Fundamental physical constants
  float G;                     // Gravitational constant
  float k_B;                   // Boltzmann constant
  float sigma_SB;              // Stefan-Boltzmann constant
  
  // Material properties
  float particle_radius;
  float thermal_conductivity;
  float specific_heat;
  float dynamic_viscosity;
  float emissivity;
  float young_modulus;
};

// Must match `ManifoldFieldParams` in `manifold_physics.metal`.
struct ManifoldFieldParams {
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float grid_spacing;
  float inv_grid_spacing;
};

// Must match `ParticleGenParams` in `manifold_physics.metal`.
struct ParticleGenParams {
  uint32_t num_particles;
  float grid_x;
  float grid_y;
  float grid_z;
  float energy_scale;
  uint32_t pattern;
  float center_x;
  float center_y;
  float center_z;
  float spread;
  float dir_x;
  float dir_y;
  float dir_z;
};

// Must match `ParticleInteractionParams` in `manifold_physics.metal`.
struct ParticleInteractionParams {
  uint32_t num_particles;
  float dt;
  float particle_radius;        // r: particle radius for collision detection
  float young_modulus;          // E: Young's modulus for contact stiffness
  float thermal_conductivity;   // k: heat transfer on contact
  float restitution;            // e: coefficient of restitution (0-1)
};

// Must match `SpectralCarrierParams` in `manifold_physics.metal`.
struct SpectralCarrierParams {
  uint32_t num_osc;
  uint32_t max_carriers;
  uint32_t num_carriers;
  float dt;
  float coupling_scale;
  float carrier_reg;
  float temperature;
  uint32_t rng_seed;
  float conflict_threshold;
  float offender_weight_floor;
  float gate_width_min;
  float gate_width_max;
  float ema_alpha;
  float recenter_alpha;
  uint32_t mode;
  float anchor_random_eps;
  float stable_amp_threshold;
  float crystallize_amp_threshold;
  float crystallize_conflict_threshold;
  uint32_t crystallize_age;
  float crystallized_coupling_boost;
  float volatile_decay_mul;
  float stable_decay_mul;
  float crystallized_decay_mul;
  float topdown_phase_scale;
  float topdown_energy_scale;
  float topdown_random_energy_eps;
  float repulsion_scale;
};

// Must match `SpatialHashParams` in `manifold_physics.metal`.
struct SpatialHashParams {
  uint32_t num_particles;
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float cell_size;
  float inv_cell_size;
  float domain_min_x;
  float domain_min_y;
  float domain_min_z;
};

// Must match `SpatialCollisionParams` in `manifold_physics.metal`.
struct SpatialCollisionParams {
  uint32_t num_particles;
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float cell_size;
  float inv_cell_size;
  float domain_min_x;
  float domain_min_y;
  float domain_min_z;
  float dt;
  float particle_radius;
  float young_modulus;
  float thermal_conductivity;
  float restitution;
};

// Must match `TiledScatterParams` in `manifold_physics.metal`.
struct TiledScatterParams {
  uint32_t num_particles;
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float grid_spacing;
  float inv_grid_spacing;
  uint32_t tile_size;
};

// Must match `ManifoldPhysicsTextureParams` in `manifold_physics.metal`.
struct ManifoldPhysicsTextureParams {
  uint32_t num_particles;
  uint32_t grid_x;
  uint32_t grid_y;
  uint32_t grid_z;
  float grid_spacing;
  float inv_grid_spacing;
  float dt;
  float G;
  float k_B;
  float sigma_SB;
  float particle_radius;
  float thermal_conductivity;
  float specific_heat;
  float dynamic_viscosity;
  float emissivity;
  float young_modulus;
};

constexpr NSUInteger kThreadsPerThreadgroup = 256;

static id<MTLLibrary> g_lib = nil;
// Manifold physics pipelines
static id<MTLComputePipelineState> g_pipeline_manifold_scatter = nil;
static id<MTLComputePipelineState> g_pipeline_manifold_gather_update = nil;
static id<MTLComputePipelineState> g_pipeline_manifold_diffuse_heat = nil;
static id<MTLComputePipelineState> g_pipeline_manifold_poisson = nil;
static id<MTLComputePipelineState> g_pipeline_manifold_clear_field = nil;
static id<MTLComputePipelineState> g_pipeline_particle_interactions = nil;
// Adaptive thermodynamics (global reduction) pipelines
static id<MTLComputePipelineState> g_pipeline_reduce_float_stats_pass1 = nil;
static id<MTLComputePipelineState> g_pipeline_reduce_float_stats_finalize = nil;
// Spectral carrier (resonance potential) pipelines
static id<MTLComputePipelineState> g_pipeline_spectral_carrier_update_split = nil;
static id<MTLComputePipelineState> g_pipeline_spectral_update_osc_phases = nil;
static id<MTLComputePipelineState> g_pipeline_spectral_topdown_bias_energies = nil;
static id<MTLComputePipelineState> g_pipeline_spectral_spawn_uncoupled = nil;
// Spatial hash grid pipelines (O(N) collisions)
static id<MTLComputePipelineState> g_pipeline_spatial_hash_assign = nil;
static id<MTLComputePipelineState> g_pipeline_spatial_hash_prefix_sum = nil;
static id<MTLComputePipelineState> g_pipeline_spatial_hash_prefix_sum_parallel = nil;
static id<MTLComputePipelineState> g_pipeline_spatial_hash_scatter = nil;
static id<MTLComputePipelineState> g_pipeline_spatial_hash_collisions = nil;
// Tiled scatter pipeline (reduced atomic contention via CAS-based threadgroup atomics)
static id<MTLComputePipelineState> g_pipeline_scatter_particle_tiled = nil;
// Texture-based gather pipeline (hardware trilinear)
static id<MTLComputePipelineState> g_pipeline_gather_update_textured = nil;
// Particle generation pipelines
static id<MTLComputePipelineState> g_pipeline_generate_particle_positions = nil;
static id<MTLComputePipelineState> g_pipeline_initialize_particle_properties = nil;
static std::mutex g_pipeline_mutex;

static std::string metallib_path_for_this_module() {
  Dl_info info;
  if (dladdr((void*)&metallib_path_for_this_module, &info) == 0 || info.dli_fname == nullptr) {
    return std::string();
  }
  fs::path so_path(info.dli_fname);
  fs::path lib_path = so_path.parent_path() / "caramba_ops.metallib";
  return lib_path.string();
}

static void ensure_library_locked(id<MTLDevice> device) {
  if (g_lib != nil) {
    return;
  }

  const std::string lib_path = metallib_path_for_this_module();
  TORCH_CHECK(!lib_path.empty(), "caramba_metal_ops: failed to locate extension path via dladdr()");

  NSString* ns_path = [NSString stringWithUTF8String:lib_path.c_str()];
  NSURL* url = [NSURL fileURLWithPath:ns_path];
  NSError* err = nil;
  // newLibraryWithFile:error: is deprecated; use URL variant on newer macOS.
  g_lib = [device newLibraryWithURL:url error:&err];
  if (g_lib == nil) {
    const char* msg = err ? [[err localizedDescription] UTF8String] : "unknown error";
    TORCH_CHECK(false, "caramba_metal_ops: failed to load metallib at ", lib_path, ": ", msg);
  }
}

static id<MTLComputePipelineState> ensure_pipeline(
    id<MTLDevice> device,
    // Important: this is a STRONG out-parameter. If left un-annotated under ARC,
    // Clang treats it as __autoreleasing and rejects passing addresses of globals.
    id<MTLComputePipelineState> __strong* pipeline,
    const char* fn_name) {
  std::lock_guard<std::mutex> lock(g_pipeline_mutex);
  ensure_library_locked(device);

  if (*pipeline != nil) {
    return *pipeline;
  }

  NSString* ns_fn = [NSString stringWithUTF8String:fn_name];
  id<MTLFunction> fn = [g_lib newFunctionWithName:ns_fn];
  TORCH_CHECK(fn != nil, "caramba_metal_ops: function `", fn_name, "` not found in metallib");

  NSError* err = nil;
  *pipeline = [device newComputePipelineStateWithFunction:fn error:&err];
  if (*pipeline == nil) {
    const char* msg = err ? [[err localizedDescription] UTF8String] : "unknown error";
    TORCH_CHECK(false, "caramba_metal_ops: failed to create compute pipeline: ", msg);
  }

  // Basic sanity check against accidental dispatch mismatch.
  TORCH_CHECK(
      (*pipeline).maxTotalThreadsPerThreadgroup >= kThreadsPerThreadgroup,
      "caramba_metal_ops: pipeline maxTotalThreadsPerThreadgroup (",
      (int)(*pipeline).maxTotalThreadsPerThreadgroup,
      ") < expected threads (",
      (int)kThreadsPerThreadgroup,
      ")");

  return *pipeline;
}

static inline id<MTLBuffer> storage_as_mtlbuffer(const at::Tensor& t) {
  // MPS tensors are backed by MTLBuffer allocations; the storage base pointer is
  // an opaque handle that is compatible with `id<MTLBuffer>` in practice.
  //
  // NOTE: This is intentionally low-level to avoid CPU staging/copies.
  const auto& dp = t.storage().data_ptr();
  void* ctx = dp.get_context();
  TORCH_CHECK(
      ctx != nullptr,
      "caramba_metal_ops: expected MPS storage to provide an MTLBuffer context (got null). "
      "This usually indicates a non-standard tensor storage backend.");
  // Under ARC we must use a bridged cast from void* to ObjC object.
  return (__bridge id<MTLBuffer>)ctx;
}

static inline NSUInteger storage_offset_bytes(const at::Tensor& t) {
  return (NSUInteger)(t.storage_offset() * (int64_t)t.element_size());
}

static void check_contig_3d(const at::Tensor& t, const char* name) {
  TORCH_CHECK(t.is_contiguous(), name, ": must be contiguous");
  TORCH_CHECK(t.dim() == 3, name, ": must be 3D");
  TORCH_CHECK(t.stride(2) == 1, name, ": last dim must be contiguous (stride==1)");
}

static void check_contig_2d(const at::Tensor& t, const char* name) {
  TORCH_CHECK(t.is_contiguous(), name, ": must be contiguous");
  TORCH_CHECK(t.dim() == 2, name, ": must be 2D");
  TORCH_CHECK(t.stride(1) == 1, name, ": last dim must be contiguous (stride==1)");
}

static void check_contig_1d(const at::Tensor& t, const char* name) {
  TORCH_CHECK(t.is_contiguous(), name, ": must be contiguous");
  TORCH_CHECK(t.dim() == 1, name, ": must be 1D");
  TORCH_CHECK(t.stride(0) == 1, name, ": must be contiguous (stride==1)");
}

// ============================================================================
// Manifold Physics Kernels
// ============================================================================

void manifold_scatter_particles(
    at::Tensor particle_pos,   // (N, 3) fp32 MPS
    at::Tensor particle_mass,  // (N,) fp32 MPS
    at::Tensor particle_heat,  // (N,) fp32 MPS
    at::Tensor gravity_field,  // (X, Y, Z) fp32 MPS
    at::Tensor heat_field,     // (X, Y, Z) fp32 MPS
    double grid_spacing) {
  TORCH_CHECK(particle_pos.device().is_mps(), "manifold_scatter: particle_pos must be on MPS");
  TORCH_CHECK(particle_pos.dtype() == at::kFloat, "manifold_scatter: particle_pos must be fp32");
  TORCH_CHECK(particle_pos.is_contiguous(), "manifold_scatter: particle_pos must be contiguous");
  TORCH_CHECK(particle_pos.dim() == 2 && particle_pos.size(1) == 3, "manifold_scatter: particle_pos must be (N, 3)");

  TORCH_CHECK(particle_mass.is_contiguous() && particle_mass.dim() == 1, "manifold_scatter: particle_mass must be contiguous 1D");
  TORCH_CHECK(particle_heat.is_contiguous() && particle_heat.dim() == 1, "manifold_scatter: particle_heat must be contiguous 1D");
  TORCH_CHECK(gravity_field.is_contiguous() && gravity_field.dim() == 3, "manifold_scatter: gravity_field must be contiguous 3D");
  TORCH_CHECK(heat_field.is_contiguous() && heat_field.dim() == 3, "manifold_scatter: heat_field must be contiguous 3D");

  const int64_t N = particle_pos.size(0);
  const int64_t gx = gravity_field.size(0);
  const int64_t gy = gravity_field.size(1);
  const int64_t gz = gravity_field.size(2);

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  TORCH_CHECK(stream != nullptr, "manifold_scatter: failed to get current MPS stream");
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  TORCH_CHECK(encoder != nil, "manifold_scatter: failed to get MTLComputeCommandEncoder");

  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_manifold_scatter, "scatter_particle");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(particle_pos, 0);
  set_tensor(particle_mass, 1);
  set_tensor(particle_heat, 2);
  set_tensor(gravity_field, 3);
  set_tensor(heat_field, 4);

  ManifoldPhysicsParams prm;
  prm.num_particles = (uint32_t)N;
  prm.grid_x = (uint32_t)gx;
  prm.grid_y = (uint32_t)gy;
  prm.grid_z = (uint32_t)gz;
  prm.grid_spacing = (float)grid_spacing;
  prm.inv_grid_spacing = 1.0f / (float)grid_spacing;
  [encoder setBytes:&prm length:sizeof(ManifoldPhysicsParams) atIndex:5];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void manifold_gather_update_particles(
    at::Tensor gravity_potential,  // (X, Y, Z) fp32 MPS
    at::Tensor temperature_field,  // (X, Y, Z) fp32 MPS
    at::Tensor particle_pos,       // (N, 3) fp32 MPS in/out
    at::Tensor particle_vel,       // (N, 3) fp32 MPS in/out
    at::Tensor particle_energy,    // (N,) fp32 MPS in/out
    at::Tensor particle_heat,      // (N,) fp32 MPS in/out
    at::Tensor particle_excitation,// (N,) fp32 MPS in/out
    at::Tensor particle_mass,      // (N,) fp32 MPS
    double dt,
    double grid_spacing,
    // Fundamental constants
    double G,
    double k_B,
    double sigma_SB,
    // Material properties
    double particle_radius,
    double thermal_conductivity,
    double specific_heat,
    double dynamic_viscosity,
    double emissivity,
    double young_modulus) {
  TORCH_CHECK(gravity_potential.device().is_mps(), "manifold_gather_update: gravity_potential must be on MPS");
  TORCH_CHECK(gravity_potential.is_contiguous() && gravity_potential.dim() == 3, "manifold_gather_update: gravity_potential must be contiguous 3D");
  TORCH_CHECK(particle_pos.is_contiguous() && particle_pos.dim() == 2 && particle_pos.size(1) == 3, "manifold_gather_update: particle_pos must be (N, 3)");

  const int64_t N = particle_pos.size(0);
  const int64_t gx = gravity_potential.size(0);
  const int64_t gy = gravity_potential.size(1);
  const int64_t gz = gravity_potential.size(2);

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  TORCH_CHECK(stream != nullptr, "manifold_gather_update: failed to get current MPS stream");
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  TORCH_CHECK(encoder != nil, "manifold_gather_update: failed to get MTLComputeCommandEncoder");

  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_manifold_gather_update, "gather_update_particles");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(gravity_potential, 0);
  set_tensor(temperature_field, 1);
  set_tensor(particle_pos, 2);
  set_tensor(particle_vel, 3);
  set_tensor(particle_energy, 4);
  set_tensor(particle_heat, 5);
  set_tensor(particle_excitation, 6);
  set_tensor(particle_mass, 7);

  ManifoldPhysicsParams prm;
  prm.num_particles = (uint32_t)N;
  prm.grid_x = (uint32_t)gx;
  prm.grid_y = (uint32_t)gy;
  prm.grid_z = (uint32_t)gz;
  prm.grid_spacing = (float)grid_spacing;
  prm.inv_grid_spacing = 1.0f / (float)grid_spacing;
  prm.dt = (float)dt;
  prm.G = (float)G;
  prm.k_B = (float)k_B;
  prm.sigma_SB = (float)sigma_SB;
  prm.particle_radius = (float)particle_radius;
  prm.thermal_conductivity = (float)thermal_conductivity;
  prm.specific_heat = (float)specific_heat;
  prm.dynamic_viscosity = (float)dynamic_viscosity;
  prm.emissivity = (float)emissivity;
  prm.young_modulus = (float)young_modulus;
  [encoder setBytes:&prm length:sizeof(ManifoldPhysicsParams) atIndex:8];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void manifold_diffuse_heat(
    at::Tensor temp_in,   // (X, Y, Z) fp32 MPS
    at::Tensor temp_out,  // (X, Y, Z) fp32 MPS
    double diffusion_coef,
    double dt,
    double grid_spacing) {
  TORCH_CHECK(temp_in.device().is_mps(), "manifold_diffuse_heat: temp_in must be on MPS");
  TORCH_CHECK(temp_in.is_contiguous() && temp_in.dim() == 3, "manifold_diffuse_heat: temp_in must be contiguous 3D");
  TORCH_CHECK(temp_out.is_contiguous() && temp_out.dim() == 3, "manifold_diffuse_heat: temp_out must be contiguous 3D");

  const int64_t gx = temp_in.size(0);
  const int64_t gy = temp_in.size(1);
  const int64_t gz = temp_in.size(2);

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_manifold_diffuse_heat, "diffuse_heat_field");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(temp_in, 0);
  set_tensor(temp_out, 1);

  ManifoldFieldParams prm;
  prm.grid_x = (uint32_t)gx;
  prm.grid_y = (uint32_t)gy;
  prm.grid_z = (uint32_t)gz;
  prm.grid_spacing = (float)grid_spacing;
  prm.inv_grid_spacing = 1.0f / (float)grid_spacing;
  [encoder setBytes:&prm length:sizeof(ManifoldFieldParams) atIndex:2];

  float diff_coef_f = (float)diffusion_coef;
  float dt_f = (float)dt;
  [encoder setBytes:&diff_coef_f length:sizeof(float) atIndex:3];
  [encoder setBytes:&dt_f length:sizeof(float) atIndex:4];

  // Dispatch 3D grid
  const MTLSize tg = MTLSizeMake(8, 8, 4);  // 256 threads total
  const MTLSize grid = MTLSizeMake(
      (gx + 7) / 8,
      (gy + 7) / 8,
      (gz + 3) / 4
  );
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void manifold_poisson_step(
    at::Tensor phi_in,   // (X, Y, Z) fp32 MPS
    at::Tensor rho,      // (X, Y, Z) fp32 MPS
    at::Tensor phi_out,  // (X, Y, Z) fp32 MPS
    double gravity_4pi,
    double grid_spacing) {
  TORCH_CHECK(phi_in.device().is_mps(), "manifold_poisson_step: phi_in must be on MPS");
  TORCH_CHECK(phi_in.is_contiguous() && phi_in.dim() == 3, "manifold_poisson_step: phi_in must be contiguous 3D");
  TORCH_CHECK(rho.is_contiguous() && rho.dim() == 3, "manifold_poisson_step: rho must be contiguous 3D");
  TORCH_CHECK(phi_out.is_contiguous() && phi_out.dim() == 3, "manifold_poisson_step: phi_out must be contiguous 3D");

  const int64_t gx = phi_in.size(0);
  const int64_t gy = phi_in.size(1);
  const int64_t gz = phi_in.size(2);

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_manifold_poisson, "poisson_jacobi_step");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(phi_in, 0);
  set_tensor(rho, 1);
  set_tensor(phi_out, 2);

  ManifoldFieldParams prm;
  prm.grid_x = (uint32_t)gx;
  prm.grid_y = (uint32_t)gy;
  prm.grid_z = (uint32_t)gz;
  prm.grid_spacing = (float)grid_spacing;
  prm.inv_grid_spacing = 1.0f / (float)grid_spacing;
  [encoder setBytes:&prm length:sizeof(ManifoldFieldParams) atIndex:3];

  float gravity_4pi_f = (float)gravity_4pi;
  [encoder setBytes:&gravity_4pi_f length:sizeof(float) atIndex:4];

  const MTLSize tg = MTLSizeMake(8, 8, 4);
  const MTLSize grid = MTLSizeMake(
      (gx + 7) / 8,
      (gy + 7) / 8,
      (gz + 3) / 4
  );
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void manifold_clear_field(at::Tensor field) {
  TORCH_CHECK(field.device().is_mps(), "manifold_clear_field: field must be on MPS");
  TORCH_CHECK(field.is_contiguous(), "manifold_clear_field: field must be contiguous");

  const int64_t num_elements = field.numel();

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_manifold_clear_field, "clear_field");
  [encoder setComputePipelineState:pipeline];

  id<MTLBuffer> buf = storage_as_mtlbuffer(field);
  const NSUInteger off = storage_offset_bytes(field);
  [encoder setBuffer:buf offset:off atIndex:0];

  uint32_t n = (uint32_t)num_elements;
  [encoder setBytes:&n length:sizeof(uint32_t) atIndex:1];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (num_elements + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void particle_interactions(
    at::Tensor particle_pos,       // (N, 3) fp32 MPS
    at::Tensor particle_vel,       // (N, 3) fp32 MPS in/out
    at::Tensor particle_excitation,// (N,) fp32 MPS in/out
    at::Tensor particle_mass,      // (N,) fp32 MPS
    at::Tensor particle_heat,      // (N,) fp32 MPS in/out - heat from collisions
    double dt,
    double particle_radius,
    double young_modulus,
    double thermal_conductivity,
    double restitution) {
  
  const int64_t N = particle_pos.size(0);
  if (N == 0) return;
  
  TORCH_CHECK(particle_pos.device().is_mps(), "particle_interactions: particle_pos must be on MPS");
  TORCH_CHECK(particle_pos.is_contiguous() && particle_pos.dim() == 2 && particle_pos.size(1) == 3,
              "particle_interactions: particle_pos must be contiguous (N, 3)");
  TORCH_CHECK(particle_vel.is_contiguous() && particle_vel.dim() == 2 && particle_vel.size(1) == 3,
              "particle_interactions: particle_vel must be contiguous (N, 3)");
  TORCH_CHECK(particle_excitation.is_contiguous() && particle_excitation.dim() == 1,
              "particle_interactions: particle_excitation must be contiguous 1D");
  TORCH_CHECK(particle_heat.is_contiguous() && particle_heat.dim() == 1,
              "particle_interactions: particle_heat must be contiguous 1D");
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_particle_interactions, "particle_interactions");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(particle_pos, 0);
  set_tensor(particle_vel, 1);
  set_tensor(particle_excitation, 2);
  set_tensor(particle_mass, 3);
  set_tensor(particle_heat, 4);
  
  ParticleInteractionParams prm;
  prm.num_particles = (uint32_t)N;
  prm.dt = (float)dt;
  prm.particle_radius = (float)particle_radius;
  prm.young_modulus = (float)young_modulus;
  prm.thermal_conductivity = (float)thermal_conductivity;
  prm.restitution = (float)restitution;
  [encoder setBytes:&prm length:sizeof(ParticleInteractionParams) atIndex:5];
  
  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

// ============================================================================
// Adaptive Thermodynamics: reduction for global energy statistics
// ============================================================================
// Computes out_stats (4 floats): [mean_abs, mean, std, count]
//
// This stays entirely on the GPU. No CPU sync required.
void thermo_reduce_energy_stats(
    at::Tensor x,         // (N,) fp32 MPS
    at::Tensor out_stats  // (4,) fp32 MPS (output)
) {
  TORCH_CHECK(x.device().is_mps(), "thermo_reduce_energy_stats: x must be on MPS");
  TORCH_CHECK(out_stats.device().is_mps(), "thermo_reduce_energy_stats: out_stats must be on MPS");
  TORCH_CHECK(x.dtype() == at::kFloat, "thermo_reduce_energy_stats: x must be fp32");
  TORCH_CHECK(out_stats.dtype() == at::kFloat, "thermo_reduce_energy_stats: out_stats must be fp32");
  check_contig_1d(x, "thermo_reduce_energy_stats: x");
  check_contig_1d(out_stats, "thermo_reduce_energy_stats: out_stats");
  TORCH_CHECK(out_stats.numel() == 4, "thermo_reduce_energy_stats: out_stats must have 4 elements");

  const int64_t N = x.numel();
  if (N <= 0) {
    // Define a sane empty result: zeros + count=0
    out_stats.zero_();
    return;
  }

  const NSUInteger num_groups = (N + (int64_t)kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;

  // group_stats: (num_groups, 4) contiguous fp32 on MPS
  at::Tensor group_stats = at::empty({(int64_t)num_groups, 4}, x.options());

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  TORCH_CHECK(encoder != nil, "thermo_reduce_energy_stats: failed to get MTLComputeCommandEncoder");

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  // Pass 1: per-threadgroup partial sums
  {
    id<MTLComputePipelineState> pipeline =
        ensure_pipeline(device, &g_pipeline_reduce_float_stats_pass1, "reduce_float_stats_pass1");
    [encoder setComputePipelineState:pipeline];
    set_tensor(x, 0);
    set_tensor(group_stats, 1);
    uint32_t n_u = (uint32_t)N;
    [encoder setBytes:&n_u length:sizeof(uint32_t) atIndex:2];

    const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
    const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
    [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  }

  // Pass 2: finalize to a single stats vector
  {
    id<MTLComputePipelineState> pipeline =
        ensure_pipeline(device, &g_pipeline_reduce_float_stats_finalize, "reduce_float_stats_finalize");
    [encoder setComputePipelineState:pipeline];
    set_tensor(group_stats, 0);
    set_tensor(out_stats, 1);
    uint32_t g_u = (uint32_t)num_groups;
    [encoder setBytes:&g_u length:sizeof(uint32_t) atIndex:2];

    const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
    const MTLSize grid = MTLSizeMake(1, 1, 1);
    [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  }

  stream->endKernelCoalescing();
}

// ============================================================================
// Tiled Scatter (reduced atomic contention)
// ============================================================================

void scatter_particle_tiled(
    at::Tensor particle_pos,       // (N, 3) fp32 MPS
    at::Tensor particle_mass,      // (N,) fp32 MPS
    at::Tensor particle_heat,      // (N,) fp32 MPS
    at::Tensor gravity_field,      // (X, Y, Z) fp32 MPS atomic
    at::Tensor heat_field,         // (X, Y, Z) fp32 MPS atomic
    int64_t grid_x,
    int64_t grid_y,
    int64_t grid_z,
    double grid_spacing) {
  
  const int64_t N = particle_pos.size(0);
  if (N == 0) return;
  
  TORCH_CHECK(particle_pos.device().is_mps(), "scatter_particle_tiled: particle_pos must be on MPS");
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_scatter_particle_tiled, "scatter_particle_tiled");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(particle_pos, 0);
  set_tensor(particle_mass, 1);
  set_tensor(particle_heat, 2);
  set_tensor(gravity_field, 3);
  set_tensor(heat_field, 4);
  
  TiledScatterParams prm;
  prm.num_particles = (uint32_t)N;
  prm.grid_x = (uint32_t)grid_x;
  prm.grid_y = (uint32_t)grid_y;
  prm.grid_z = (uint32_t)grid_z;
  prm.grid_spacing = (float)grid_spacing;
  prm.inv_grid_spacing = 1.0f / (float)grid_spacing;
  prm.tile_size = kThreadsPerThreadgroup;
  [encoder setBytes:&prm length:sizeof(TiledScatterParams) atIndex:5];
  
  // Allocate threadgroup memory for local accumulators
  uint64_t num_cells = grid_x * grid_y * grid_z;
  uint64_t tg_mem_size = num_cells * sizeof(uint32_t);  // atomic_uint per cell
  [encoder setThreadgroupMemoryLength:tg_mem_size atIndex:0];  // local_gravity
  [encoder setThreadgroupMemoryLength:tg_mem_size atIndex:1];  // local_heat
  
  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

// ============================================================================
// Spatial Hash Grid Acceleration (O(N) collisions)
// ============================================================================

void spatial_hash_assign(
    at::Tensor particle_pos,       // (N, 3) fp32 MPS
    at::Tensor particle_cell_idx,  // (N,) uint32 MPS out
    at::Tensor cell_counts,        // (num_cells,) uint32 MPS out (atomic)
    int64_t grid_x,
    int64_t grid_y,
    int64_t grid_z,
    double cell_size,
    double domain_min_x,
    double domain_min_y,
    double domain_min_z) {
  
  const int64_t N = particle_pos.size(0);
  if (N == 0) return;
  
  TORCH_CHECK(particle_pos.device().is_mps(), "spatial_hash_assign: particle_pos must be on MPS");
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_spatial_hash_assign, "spatial_hash_assign");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(particle_pos, 0);
  set_tensor(particle_cell_idx, 1);
  set_tensor(cell_counts, 2);
  
  SpatialHashParams prm;
  prm.num_particles = (uint32_t)N;
  prm.grid_x = (uint32_t)grid_x;
  prm.grid_y = (uint32_t)grid_y;
  prm.grid_z = (uint32_t)grid_z;
  prm.cell_size = (float)cell_size;
  prm.inv_cell_size = 1.0f / (float)cell_size;
  prm.domain_min_x = (float)domain_min_x;
  prm.domain_min_y = (float)domain_min_y;
  prm.domain_min_z = (float)domain_min_z;
  [encoder setBytes:&prm length:sizeof(SpatialHashParams) atIndex:3];
  
  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

void spatial_hash_prefix_sum(
    at::Tensor cell_counts,        // (num_cells,) uint32 MPS
    at::Tensor cell_starts,        // (num_cells + 1,) uint32 MPS out
    int64_t num_cells) {
  
  if (num_cells == 0) return;
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_spatial_hash_prefix_sum, "spatial_hash_prefix_sum");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(cell_counts, 0);
  set_tensor(cell_starts, 1);
  
  uint32_t nc = (uint32_t)num_cells;
  [encoder setBytes:&nc length:sizeof(uint32_t) atIndex:2];
  
  // Single thread for sequential scan
  const MTLSize tg = MTLSizeMake(1, 1, 1);
  const MTLSize grid = MTLSizeMake(1, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

void spatial_hash_scatter(
    at::Tensor particle_cell_idx,  // (N,) uint32 MPS
    at::Tensor sorted_particle_idx,// (N,) uint32 MPS out
    at::Tensor cell_offsets,       // (num_cells,) uint32 MPS (working copy of cell_starts)
    int64_t num_particles) {
  
  if (num_particles == 0) return;
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_spatial_hash_scatter, "spatial_hash_scatter");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(particle_cell_idx, 0);
  set_tensor(sorted_particle_idx, 1);
  set_tensor(cell_offsets, 2);
  
  uint32_t np = (uint32_t)num_particles;
  [encoder setBytes:&np length:sizeof(uint32_t) atIndex:3];
  
  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (num_particles + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

void spatial_hash_collisions(
    at::Tensor particle_pos,       // (N, 3) fp32 MPS
    at::Tensor particle_vel,       // (N, 3) fp32 MPS in/out
    at::Tensor particle_excitation,// (N,) fp32 MPS in/out
    at::Tensor particle_mass,      // (N,) fp32 MPS
    at::Tensor particle_heat,      // (N,) fp32 MPS in/out
    at::Tensor sorted_particle_idx,// (N,) uint32 MPS
    at::Tensor cell_starts,        // (num_cells + 1,) uint32 MPS
    at::Tensor particle_cell_idx,  // (N,) uint32 MPS
    int64_t grid_x,
    int64_t grid_y,
    int64_t grid_z,
    double cell_size,
    double domain_min_x,
    double domain_min_y,
    double domain_min_z,
    double dt,
    double particle_radius,
    double young_modulus,
    double thermal_conductivity,
    double restitution) {
  
  const int64_t N = particle_pos.size(0);
  if (N == 0) return;
  
  TORCH_CHECK(particle_pos.device().is_mps(), "spatial_hash_collisions: particle_pos must be on MPS");
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
  
  id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_spatial_hash_collisions, "spatial_hash_collisions");
  [encoder setComputePipelineState:pipeline];
  
  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };
  
  set_tensor(particle_pos, 0);
  set_tensor(particle_vel, 1);
  set_tensor(particle_excitation, 2);
  set_tensor(particle_mass, 3);
  set_tensor(particle_heat, 4);
  set_tensor(sorted_particle_idx, 5);
  set_tensor(cell_starts, 6);
  set_tensor(particle_cell_idx, 7);
  
  SpatialCollisionParams prm;
  prm.num_particles = (uint32_t)N;
  prm.grid_x = (uint32_t)grid_x;
  prm.grid_y = (uint32_t)grid_y;
  prm.grid_z = (uint32_t)grid_z;
  prm.cell_size = (float)cell_size;
  prm.inv_cell_size = 1.0f / (float)cell_size;
  prm.domain_min_x = (float)domain_min_x;
  prm.domain_min_y = (float)domain_min_y;
  prm.domain_min_z = (float)domain_min_z;
  prm.dt = (float)dt;
  prm.particle_radius = (float)particle_radius;
  prm.young_modulus = (float)young_modulus;
  prm.thermal_conductivity = (float)thermal_conductivity;
  prm.restitution = (float)restitution;
  [encoder setBytes:&prm length:sizeof(SpatialCollisionParams) atIndex:8];
  
  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
  
  stream->endKernelCoalescing();
}

// ============================================================================
// Spectral Carrier Coupling (Resonance Potential, Langevin Flow)
// ============================================================================

void spectral_carrier_update_and_split(
    at::Tensor osc_phase,            // (N,) fp32 MPS
    at::Tensor osc_omega,            // (N,) fp32 MPS
    at::Tensor osc_amp,              // (N,) fp32 MPS
    at::Tensor carrier_real,         // (maxM,) fp32 MPS in/out
    at::Tensor carrier_imag,         // (maxM,) fp32 MPS in/out
    at::Tensor carrier_omega,        // (maxM,) fp32 MPS in/out
    at::Tensor carrier_gate_width,   // (maxM,) fp32 MPS in/out
    at::Tensor carrier_conflict,     // (maxM,) fp32 MPS out
    at::Tensor carrier_state,        // (maxM,) int32 MPS in/out
    at::Tensor carrier_age,          // (maxM,) int32 MPS in/out
    at::Tensor carrier_anchor_idx,   // (maxM*anchors,) int32 MPS in/out
    at::Tensor carrier_anchor_phase, // (maxM*anchors,) fp32 MPS in/out
    at::Tensor carrier_anchor_weight,// (maxM*anchors,) fp32 MPS in/out
    at::Tensor num_carriers,         // (1,) int32 MPS in/out (atomic counter)
    at::Tensor spawned_from_osc,     // (maxM,) int32 MPS out
    at::Tensor random_phases,        // (maxM,) fp32 MPS (uniform [0,1])
    at::Tensor energy_stats,         // (4,) fp32 MPS (mean_abs, mean, std, count)
    int64_t current_carriers,
    int64_t max_carriers,
    double dt,
    double coupling_scale,
    double carrier_reg,
    double temperature,
    uint32_t rng_seed,
    double conflict_threshold,
    double offender_weight_floor,
    double gate_width_min,
    double gate_width_max,
    double ema_alpha,
    double recenter_alpha,
    int64_t mode,
    double anchor_random_eps,
    double stable_amp_threshold,
    double crystallize_amp_threshold,
    double crystallize_conflict_threshold,
    int64_t crystallize_age,
    double crystallized_coupling_boost,
    double volatile_decay_mul,
    double stable_decay_mul,
    double crystallized_decay_mul,
    double topdown_phase_scale,
    double topdown_energy_scale,
    double topdown_random_energy_eps,
    double repulsion_scale) {

  check_contig_1d(osc_phase, "spectral_carrier_update: osc_phase");
  check_contig_1d(osc_omega, "spectral_carrier_update: osc_omega");
  check_contig_1d(osc_amp, "spectral_carrier_update: osc_amp");
  check_contig_1d(carrier_real, "spectral_carrier_update: carrier_real");
  check_contig_1d(carrier_imag, "spectral_carrier_update: carrier_imag");
  check_contig_1d(carrier_omega, "spectral_carrier_update: carrier_omega");
  check_contig_1d(carrier_gate_width, "spectral_carrier_update: carrier_gate_width");
  check_contig_1d(carrier_conflict, "spectral_carrier_update: carrier_conflict");
  check_contig_1d(carrier_state, "spectral_carrier_update: carrier_state");
  check_contig_1d(carrier_age, "spectral_carrier_update: carrier_age");
  check_contig_1d(carrier_anchor_idx, "spectral_carrier_update: carrier_anchor_idx");
  check_contig_1d(carrier_anchor_phase, "spectral_carrier_update: carrier_anchor_phase");
  check_contig_1d(carrier_anchor_weight, "spectral_carrier_update: carrier_anchor_weight");
  check_contig_1d(num_carriers, "spectral_carrier_update: num_carriers");
  check_contig_1d(spawned_from_osc, "spectral_carrier_update: spawned_from_osc");
  check_contig_1d(random_phases, "spectral_carrier_update: random_phases");
  check_contig_1d(energy_stats, "spectral_carrier_update: energy_stats");

  TORCH_CHECK(osc_phase.device().is_mps(), "spectral_carrier_update: osc_phase must be on MPS");
  TORCH_CHECK(osc_phase.dtype() == at::kFloat, "spectral_carrier_update: osc_phase must be fp32");
  TORCH_CHECK(num_carriers.dtype() == at::kInt, "spectral_carrier_update: num_carriers must be int32");
  TORCH_CHECK(carrier_state.dtype() == at::kInt, "spectral_carrier_update: carrier_state must be int32");
  TORCH_CHECK(carrier_age.dtype() == at::kInt, "spectral_carrier_update: carrier_age must be int32");
  TORCH_CHECK(carrier_anchor_idx.dtype() == at::kInt, "spectral_carrier_update: carrier_anchor_idx must be int32");
  TORCH_CHECK(energy_stats.device().is_mps(), "spectral_carrier_update: energy_stats must be on MPS");
  TORCH_CHECK(energy_stats.dtype() == at::kFloat, "spectral_carrier_update: energy_stats must be fp32");
  TORCH_CHECK(energy_stats.numel() == 4, "spectral_carrier_update: energy_stats must have 4 elements");

  const int64_t N = osc_phase.size(0);
  if (N == 0 || current_carriers == 0) return;

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline =
      ensure_pipeline(device, &g_pipeline_spectral_carrier_update_split, "spectral_carrier_update_and_split");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(osc_phase, 0);
  set_tensor(osc_omega, 1);
  set_tensor(osc_amp, 2);
  set_tensor(carrier_real, 3);
  set_tensor(carrier_imag, 4);
  set_tensor(carrier_omega, 5);
  set_tensor(carrier_gate_width, 6);
  set_tensor(carrier_conflict, 7);
  set_tensor(carrier_state, 8);
  set_tensor(carrier_age, 9);
  set_tensor(carrier_anchor_idx, 10);
  set_tensor(carrier_anchor_phase, 11);
  set_tensor(carrier_anchor_weight, 12);
  set_tensor(num_carriers, 13);
  set_tensor(spawned_from_osc, 14);
  set_tensor(random_phases, 15);
  set_tensor(energy_stats, 16);

  SpectralCarrierParams prm;
  prm.num_osc = (uint32_t)N;
  prm.max_carriers = (uint32_t)max_carriers;
  prm.num_carriers = (uint32_t)current_carriers;
  prm.dt = (float)dt;
  prm.coupling_scale = (float)coupling_scale;
  prm.carrier_reg = (float)carrier_reg;
  prm.temperature = (float)temperature;
  prm.rng_seed = (uint32_t)rng_seed;
  prm.conflict_threshold = (float)conflict_threshold;
  prm.offender_weight_floor = (float)offender_weight_floor;
  prm.gate_width_min = (float)gate_width_min;
  prm.gate_width_max = (float)gate_width_max;
  prm.ema_alpha = (float)ema_alpha;
  prm.recenter_alpha = (float)recenter_alpha;
  prm.mode = (uint32_t)mode;
  prm.anchor_random_eps = (float)anchor_random_eps;
  prm.stable_amp_threshold = (float)stable_amp_threshold;
  prm.crystallize_amp_threshold = (float)crystallize_amp_threshold;
  prm.crystallize_conflict_threshold = (float)crystallize_conflict_threshold;
  prm.crystallize_age = (uint32_t)crystallize_age;
  prm.crystallized_coupling_boost = (float)crystallized_coupling_boost;
  prm.volatile_decay_mul = (float)volatile_decay_mul;
  prm.stable_decay_mul = (float)stable_decay_mul;
  prm.crystallized_decay_mul = (float)crystallized_decay_mul;
  prm.topdown_phase_scale = (float)topdown_phase_scale;
  prm.topdown_energy_scale = (float)topdown_energy_scale;
  prm.topdown_random_energy_eps = (float)topdown_random_energy_eps;
  prm.repulsion_scale = (float)repulsion_scale;
  [encoder setBytes:&prm length:sizeof(SpectralCarrierParams) atIndex:17];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (current_carriers + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void spectral_update_oscillator_phases(
    at::Tensor osc_phase,            // (N,) fp32 MPS in/out
    at::Tensor osc_omega,            // (N,) fp32 MPS
    at::Tensor osc_amp,              // (N,) fp32 MPS
    at::Tensor carrier_real,         // (maxM,) fp32 MPS
    at::Tensor carrier_imag,         // (maxM,) fp32 MPS
    at::Tensor carrier_omega,        // (maxM,) fp32 MPS
    at::Tensor carrier_gate_width,   // (maxM,) fp32 MPS
    at::Tensor carrier_state,        // (maxM,) int32 MPS
    at::Tensor carrier_anchor_idx,   // (maxM*anchors,) int32 MPS
    at::Tensor carrier_anchor_phase, // (maxM*anchors,) fp32 MPS
    at::Tensor carrier_anchor_weight,// (maxM*anchors,) fp32 MPS
    at::Tensor energy_stats,         // (4,) fp32 MPS (mean_abs, mean, std, count)
    int64_t num_carriers_i,
    int64_t max_carriers,
    double dt,
    double coupling_scale,
    double temperature,
    uint32_t rng_seed,
    double gate_width_min,
    double gate_width_max,
    double crystallized_coupling_boost,
    double topdown_phase_scale) {

  check_contig_1d(osc_phase, "spectral_update_osc: osc_phase");
  check_contig_1d(osc_omega, "spectral_update_osc: osc_omega");
  check_contig_1d(osc_amp, "spectral_update_osc: osc_amp");
  check_contig_1d(carrier_real, "spectral_update_osc: carrier_real");
  check_contig_1d(carrier_imag, "spectral_update_osc: carrier_imag");
  check_contig_1d(carrier_omega, "spectral_update_osc: carrier_omega");
  check_contig_1d(carrier_gate_width, "spectral_update_osc: carrier_gate_width");
  check_contig_1d(carrier_state, "spectral_update_osc: carrier_state");
  check_contig_1d(carrier_anchor_idx, "spectral_update_osc: carrier_anchor_idx");
  check_contig_1d(carrier_anchor_phase, "spectral_update_osc: carrier_anchor_phase");
  check_contig_1d(carrier_anchor_weight, "spectral_update_osc: carrier_anchor_weight");
  check_contig_1d(energy_stats, "spectral_update_osc: energy_stats");
  TORCH_CHECK(energy_stats.device().is_mps(), "spectral_update_osc: energy_stats must be on MPS");
  TORCH_CHECK(energy_stats.dtype() == at::kFloat, "spectral_update_osc: energy_stats must be fp32");
  TORCH_CHECK(energy_stats.numel() == 4, "spectral_update_osc: energy_stats must have 4 elements");
  TORCH_CHECK(carrier_state.dtype() == at::kInt, "spectral_update_osc: carrier_state must be int32");
  TORCH_CHECK(carrier_anchor_idx.dtype() == at::kInt, "spectral_update_osc: carrier_anchor_idx must be int32");

  const int64_t N = osc_phase.size(0);
  if (N == 0 || num_carriers_i == 0) return;

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline =
      ensure_pipeline(device, &g_pipeline_spectral_update_osc_phases, "spectral_update_oscillator_phases");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(osc_phase, 0);
  set_tensor(osc_omega, 1);
  set_tensor(osc_amp, 2);
  set_tensor(carrier_real, 3);
  set_tensor(carrier_imag, 4);
  set_tensor(carrier_omega, 5);
  set_tensor(carrier_gate_width, 6);
  set_tensor(carrier_state, 7);
  set_tensor(carrier_anchor_idx, 8);
  set_tensor(carrier_anchor_phase, 9);
  set_tensor(carrier_anchor_weight, 10);
  set_tensor(energy_stats, 11);

  uint32_t num_carriers_u = (uint32_t)num_carriers_i;
  [encoder setBytes:&num_carriers_u length:sizeof(uint32_t) atIndex:12];

  // Reuse SpectralCarrierParams for dt/coupling/gate bounds; other fields unused here.
  SpectralCarrierParams prm;
  prm.num_osc = (uint32_t)N;
  prm.max_carriers = (uint32_t)max_carriers;
  prm.num_carriers = (uint32_t)num_carriers_i;
  prm.dt = (float)dt;
  prm.coupling_scale = (float)coupling_scale;
  prm.carrier_reg = 0.0f;
  prm.temperature = (float)temperature;
  prm.rng_seed = (uint32_t)rng_seed;
  prm.conflict_threshold = 0.0f;
  prm.offender_weight_floor = 0.0f;
  prm.gate_width_min = (float)gate_width_min;
  prm.gate_width_max = (float)gate_width_max;
  prm.ema_alpha = 0.0f;
  prm.recenter_alpha = 0.0f;
  prm.mode = 0u;
  prm.anchor_random_eps = 0.0f;
  prm.stable_amp_threshold = 0.0f;
  prm.crystallize_amp_threshold = 0.0f;
  prm.crystallize_conflict_threshold = 0.0f;
  prm.crystallize_age = 1u;
  prm.crystallized_coupling_boost = (float)crystallized_coupling_boost;
  prm.volatile_decay_mul = 1.0f;
  prm.stable_decay_mul = 1.0f;
  prm.crystallized_decay_mul = 1.0f;
  prm.topdown_phase_scale = (float)topdown_phase_scale;
  prm.topdown_energy_scale = 0.0f;
  prm.topdown_random_energy_eps = 0.0f;
  prm.repulsion_scale = 0.0f;
  [encoder setBytes:&prm length:sizeof(SpectralCarrierParams) atIndex:13];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

void spectral_topdown_bias_energies(
    at::Tensor osc_energy,          // (N,) fp32 MPS in/out
    at::Tensor osc_amp,             // (N,) fp32 MPS
    at::Tensor carrier_state,       // (maxM,) int32 MPS
    at::Tensor carrier_anchor_idx,  // (maxM*anchors,) int32 MPS
    at::Tensor carrier_anchor_weight, // (maxM*anchors,) fp32 MPS
    int64_t num_carriers_i,
    int64_t max_carriers,
    double dt,
    uint32_t rng_seed,
    int64_t mode,
    double topdown_energy_scale,
    double topdown_random_energy_eps) {

  check_contig_1d(osc_energy, "spectral_topdown_bias: osc_energy");
  check_contig_1d(osc_amp, "spectral_topdown_bias: osc_amp");
  check_contig_1d(carrier_state, "spectral_topdown_bias: carrier_state");
  check_contig_1d(carrier_anchor_idx, "spectral_topdown_bias: carrier_anchor_idx");
  check_contig_1d(carrier_anchor_weight, "spectral_topdown_bias: carrier_anchor_weight");
  TORCH_CHECK(osc_energy.device().is_mps(), "spectral_topdown_bias: osc_energy must be on MPS");
  TORCH_CHECK(osc_amp.device().is_mps(), "spectral_topdown_bias: osc_amp must be on MPS");
  TORCH_CHECK(osc_energy.dtype() == at::kFloat, "spectral_topdown_bias: osc_energy must be fp32");
  TORCH_CHECK(osc_amp.dtype() == at::kFloat, "spectral_topdown_bias: osc_amp must be fp32");
  TORCH_CHECK(carrier_state.dtype() == at::kInt, "spectral_topdown_bias: carrier_state must be int32");
  TORCH_CHECK(carrier_anchor_idx.dtype() == at::kInt, "spectral_topdown_bias: carrier_anchor_idx must be int32");

  const int64_t N = osc_energy.size(0);
  if (N == 0 || num_carriers_i == 0) return;

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline =
      ensure_pipeline(device, &g_pipeline_spectral_topdown_bias_energies, "spectral_topdown_bias_energies");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(osc_energy, 0);
  set_tensor(osc_amp, 1);
  set_tensor(carrier_state, 2);
  set_tensor(carrier_anchor_idx, 3);
  set_tensor(carrier_anchor_weight, 4);

  uint32_t num_carriers_u = (uint32_t)num_carriers_i;
  [encoder setBytes:&num_carriers_u length:sizeof(uint32_t) atIndex:5];

  SpectralCarrierParams prm;
  prm.num_osc = (uint32_t)N;
  prm.max_carriers = (uint32_t)max_carriers;
  prm.num_carriers = (uint32_t)num_carriers_i;
  prm.dt = (float)dt;
  prm.coupling_scale = 0.0f;
  prm.carrier_reg = 0.0f;
  prm.temperature = 0.0f;
  prm.rng_seed = (uint32_t)rng_seed;
  prm.conflict_threshold = 0.0f;
  prm.offender_weight_floor = 0.0f;
  prm.gate_width_min = 0.0f;
  prm.gate_width_max = 0.0f;
  prm.ema_alpha = 0.0f;
  prm.recenter_alpha = 0.0f;
  prm.mode = (uint32_t)mode;
  prm.anchor_random_eps = 0.0f;
  prm.stable_amp_threshold = 0.0f;
  prm.crystallize_amp_threshold = 0.0f;
  prm.crystallize_conflict_threshold = 0.0f;
  prm.crystallize_age = 1u;
  prm.crystallized_coupling_boost = 0.0f;
  prm.volatile_decay_mul = 1.0f;
  prm.stable_decay_mul = 1.0f;
  prm.crystallized_decay_mul = 1.0f;
  prm.topdown_phase_scale = 0.0f;
  prm.topdown_energy_scale = (float)topdown_energy_scale;
  prm.topdown_random_energy_eps = (float)topdown_random_energy_eps;
  prm.repulsion_scale = 0.0f;
  [encoder setBytes:&prm length:sizeof(SpectralCarrierParams) atIndex:6];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (num_carriers_i + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();
}

int64_t spectral_spawn_uncoupled(
    at::Tensor osc_phase,           // (N,) fp32 MPS
    at::Tensor osc_omega,           // (N,) fp32 MPS
    at::Tensor osc_amp,             // (N,) fp32 MPS
    at::Tensor carrier_omega,       // (maxM,) fp32 MPS (read)
    at::Tensor carrier_gate_width,  // (maxM,) fp32 MPS (read)
    at::Tensor carrier_real,        // (maxM,) fp32 MPS (write for new)
    at::Tensor carrier_imag,        // (maxM,) fp32 MPS (write for new)
    at::Tensor carrier_omega_out,   // (maxM,) fp32 MPS (write for new)
    at::Tensor carrier_gate_width_out, // (maxM,) fp32 MPS (write for new)
    at::Tensor carrier_conflict,    // (maxM,) fp32 MPS (write for new)
    at::Tensor carrier_state,       // (maxM,) int32 MPS (write for new)
    at::Tensor carrier_age,         // (maxM,) int32 MPS (write for new)
    at::Tensor carrier_anchor_idx,  // (maxM*anchors,) int32 MPS (write for new)
    at::Tensor carrier_anchor_phase,// (maxM*anchors,) fp32 MPS (write for new)
    at::Tensor carrier_anchor_weight,// (maxM*anchors,) fp32 MPS (write for new)
    at::Tensor num_carriers_buf,    // (1,) int32 MPS (atomic counter)
    int64_t num_carriers,
    int64_t max_carriers,
    double coupling_threshold,
    double gate_width_init,
    double gate_width_min,
    double gate_width_max) {

  check_contig_1d(osc_phase, "spectral_spawn_uncoupled: osc_phase");
  check_contig_1d(osc_omega, "spectral_spawn_uncoupled: osc_omega");
  check_contig_1d(osc_amp, "spectral_spawn_uncoupled: osc_amp");
  check_contig_1d(carrier_state, "spectral_spawn_uncoupled: carrier_state");
  check_contig_1d(carrier_age, "spectral_spawn_uncoupled: carrier_age");
  check_contig_1d(carrier_anchor_idx, "spectral_spawn_uncoupled: carrier_anchor_idx");
  check_contig_1d(carrier_anchor_phase, "spectral_spawn_uncoupled: carrier_anchor_phase");
  check_contig_1d(carrier_anchor_weight, "spectral_spawn_uncoupled: carrier_anchor_weight");
  TORCH_CHECK(carrier_state.dtype() == at::kInt, "spectral_spawn_uncoupled: carrier_state must be int32");
  TORCH_CHECK(carrier_age.dtype() == at::kInt, "spectral_spawn_uncoupled: carrier_age must be int32");
  TORCH_CHECK(carrier_anchor_idx.dtype() == at::kInt, "spectral_spawn_uncoupled: carrier_anchor_idx must be int32");

  const int64_t N = osc_phase.size(0);
  if (N == 0) return num_carriers;

  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  stream->endKernelCoalescing();
  id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();

  id<MTLComputePipelineState> pipeline =
      ensure_pipeline(device, &g_pipeline_spectral_spawn_uncoupled, "spectral_spawn_uncoupled");
  [encoder setComputePipelineState:pipeline];

  auto set_tensor = [&](const at::Tensor& t, int idx) {
    id<MTLBuffer> buf = storage_as_mtlbuffer(t);
    const NSUInteger off = storage_offset_bytes(t);
    [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
  };

  set_tensor(osc_phase, 0);
  set_tensor(osc_omega, 1);
  set_tensor(osc_amp, 2);
  set_tensor(carrier_omega, 3);
  set_tensor(carrier_gate_width, 4);
  set_tensor(carrier_real, 5);
  set_tensor(carrier_imag, 6);
  set_tensor(carrier_omega_out, 7);
  set_tensor(carrier_gate_width_out, 8);
  set_tensor(carrier_conflict, 9);
  set_tensor(carrier_state, 10);
  set_tensor(carrier_age, 11);
  set_tensor(carrier_anchor_idx, 12);
  set_tensor(carrier_anchor_phase, 13);
  set_tensor(carrier_anchor_weight, 14);
  set_tensor(num_carriers_buf, 15);

  uint32_t num_carriers_u = (uint32_t)num_carriers;
  uint32_t max_carriers_u = (uint32_t)max_carriers;
  float coupling_threshold_f = (float)coupling_threshold;
  float gate_width_init_f = (float)gate_width_init;
  float gate_width_min_f = (float)gate_width_min;
  float gate_width_max_f = (float)gate_width_max;
  uint32_t num_osc_u = (uint32_t)N;

  [encoder setBytes:&num_carriers_u length:sizeof(uint32_t) atIndex:16];
  [encoder setBytes:&max_carriers_u length:sizeof(uint32_t) atIndex:17];
  [encoder setBytes:&coupling_threshold_f length:sizeof(float) atIndex:18];
  [encoder setBytes:&gate_width_init_f length:sizeof(float) atIndex:19];
  [encoder setBytes:&gate_width_min_f length:sizeof(float) atIndex:20];
  [encoder setBytes:&gate_width_max_f length:sizeof(float) atIndex:21];
  [encoder setBytes:&num_osc_u length:sizeof(uint32_t) atIndex:22];

  const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
  const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
  const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
  [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];

  stream->endKernelCoalescing();

  // Return updated carrier count (requires sync)
  int64_t new_count = num_carriers_buf.to(at::kCPU).item<int32_t>();
  return std::min(new_count, max_carriers);
}

// ============================================================================
// Particle Generation Kernels
// ============================================================================

void generate_particles(
    at::Tensor positions,      // (N, 3) fp32 MPS out
    at::Tensor velocities,     // (N, 3) fp32 MPS out
    at::Tensor energies,       // (N,) fp32 MPS out
    at::Tensor heats,          // (N,) fp32 MPS out
    at::Tensor excitations,    // (N,) fp32 MPS out
    at::Tensor masses,         // (N,) fp32 MPS out
    at::Tensor random_pos,     // (N, 3) fp32 MPS (uniform [0,1])
    at::Tensor random_props,   // (N, 4) fp32 MPS (uniform [0,1])
    int64_t pattern,           // 0=cluster, 1=line, 2=sphere, 3=random, 4=grid
    double grid_x,
    double grid_y,
    double grid_z,
    double energy_scale,
    double center_x,
    double center_y,
    double center_z,
    double spread,
    double dir_x,
    double dir_y,
    double dir_z) {
  
  const int64_t N = positions.size(0);
  
  TORCH_CHECK(positions.device().is_mps(), "generate_particles: positions must be on MPS");
  TORCH_CHECK(positions.is_contiguous() && positions.dim() == 2 && positions.size(1) == 3,
              "generate_particles: positions must be contiguous (N, 3)");
  
  id<MTLDevice> device = (id<MTLDevice>)at::mps::MPSDevice::getInstance()->device();
  at::mps::MPSStream* stream = at::mps::getCurrentMPSStream();
  
  // Step 1: Generate positions
  {
    stream->endKernelCoalescing();
    id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
    
    id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_generate_particle_positions, "generate_particle_positions");
    [encoder setComputePipelineState:pipeline];
    
    auto set_tensor = [&](const at::Tensor& t, int idx) {
      id<MTLBuffer> buf = storage_as_mtlbuffer(t);
      const NSUInteger off = storage_offset_bytes(t);
      [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
    };
    
    set_tensor(positions, 0);
    set_tensor(random_pos, 1);
    
    ParticleGenParams prm;
    prm.num_particles = (uint32_t)N;
    prm.grid_x = (float)grid_x;
    prm.grid_y = (float)grid_y;
    prm.grid_z = (float)grid_z;
    prm.energy_scale = (float)energy_scale;
    prm.pattern = (uint32_t)pattern;
    prm.center_x = (float)center_x;
    prm.center_y = (float)center_y;
    prm.center_z = (float)center_z;
    prm.spread = (float)spread;
    prm.dir_x = (float)dir_x;
    prm.dir_y = (float)dir_y;
    prm.dir_z = (float)dir_z;
    [encoder setBytes:&prm length:sizeof(ParticleGenParams) atIndex:2];
    
    const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
    const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
    const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
    [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
    
    stream->endKernelCoalescing();
  }
  
  // Need to sync to compute mean position
  stream->synchronize(at::mps::SyncType::COMMIT_AND_WAIT);
  
  // Compute center from positions
  at::Tensor pos_mean = positions.mean(0);
  // NOTE: avoid `.item()` directly on MPS tensors inside extensions.
  at::Tensor pos_mean_cpu = pos_mean.to(at::kCPU);
  float mean_x = pos_mean_cpu[0].item<float>();
  float mean_y = pos_mean_cpu[1].item<float>();
  float mean_z = pos_mean_cpu[2].item<float>();
  
  // Step 2: Initialize properties
  {
    stream->endKernelCoalescing();
    id<MTLComputeCommandEncoder> encoder = (id<MTLComputeCommandEncoder>)stream->commandEncoder();
    
    id<MTLComputePipelineState> pipeline = ensure_pipeline(device, &g_pipeline_initialize_particle_properties, "initialize_particle_properties");
    [encoder setComputePipelineState:pipeline];
    
    auto set_tensor = [&](const at::Tensor& t, int idx) {
      id<MTLBuffer> buf = storage_as_mtlbuffer(t);
      const NSUInteger off = storage_offset_bytes(t);
      [encoder setBuffer:buf offset:off atIndex:(NSUInteger)idx];
    };
    
    set_tensor(positions, 0);
    set_tensor(velocities, 1);
    set_tensor(energies, 2);
    set_tensor(heats, 3);
    set_tensor(excitations, 4);
    set_tensor(masses, 5);
    set_tensor(random_props, 6);
    
    ParticleGenParams prm;
    prm.num_particles = (uint32_t)N;
    prm.grid_x = (float)grid_x;
    prm.grid_y = (float)grid_y;
    prm.grid_z = (float)grid_z;
    prm.energy_scale = (float)energy_scale;
    prm.pattern = (uint32_t)pattern;
    prm.center_x = (float)center_x;
    prm.center_y = (float)center_y;
    prm.center_z = (float)center_z;
    prm.spread = (float)spread;
    [encoder setBytes:&prm length:sizeof(ParticleGenParams) atIndex:7];
    
    [encoder setBytes:&mean_x length:sizeof(float) atIndex:8];
    [encoder setBytes:&mean_y length:sizeof(float) atIndex:9];
    [encoder setBytes:&mean_z length:sizeof(float) atIndex:10];
    
    const MTLSize tg = MTLSizeMake(kThreadsPerThreadgroup, 1, 1);
    const NSUInteger num_groups = (N + kThreadsPerThreadgroup - 1) / kThreadsPerThreadgroup;
    const MTLSize grid = MTLSizeMake(num_groups, 1, 1);
    [encoder dispatchThreadgroups:grid threadsPerThreadgroup:tg];
    
    stream->endKernelCoalescing();
  }
}

} // namespace

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
  // Manifold physics kernels
  m.def("manifold_scatter_particles", &manifold_scatter_particles, "Scatter particles to gravity/heat fields (Metal/MPS, fp32)");
  m.def("manifold_gather_update_particles", &manifold_gather_update_particles, "Gather fields and update particles (Metal/MPS, fp32)");
  m.def("manifold_diffuse_heat", &manifold_diffuse_heat, "Diffuse heat field (Metal/MPS, fp32)");
  m.def("manifold_poisson_step", &manifold_poisson_step, "Poisson Jacobi step for gravity (Metal/MPS, fp32)");
  m.def("manifold_clear_field", &manifold_clear_field, "Clear a field to zero (Metal/MPS, fp32)");
  // Adaptive thermodynamics (global statistics, GPU-only)
  m.def("thermo_reduce_energy_stats", &thermo_reduce_energy_stats, "Reduce energy stats: [mean_abs, mean, std, count] (Metal/MPS, fp32)");
  m.def("particle_interactions", &particle_interactions, "Particle collision + excitation transfer O(N²) (Metal/MPS, fp32)");
  // Tiled scatter (reduced atomic contention)
  m.def("scatter_particle_tiled", &scatter_particle_tiled, "Tiled scatter with threadgroup reduction (Metal/MPS, fp32)");
  // Spatial hash grid (O(N) collisions)
  m.def("spatial_hash_assign", &spatial_hash_assign, "Assign particles to spatial hash cells (Metal/MPS)");
  m.def("spatial_hash_prefix_sum", &spatial_hash_prefix_sum, "Compute prefix sum of cell counts (Metal/MPS)");
  m.def("spatial_hash_scatter", &spatial_hash_scatter, "Scatter particle indices to sorted array (Metal/MPS)");
  m.def("spatial_hash_collisions", &spatial_hash_collisions, "Particle collisions using spatial hash O(N) (Metal/MPS, fp32)");
  // Spectral (resonance potential) carrier coupling kernels
  m.def("spectral_carrier_update_and_split", &spectral_carrier_update_and_split, "Spectral carrier update + conflict split (Metal/MPS, fp32)");
  m.def("spectral_update_oscillator_phases", &spectral_update_oscillator_phases, "Spectral oscillator phase update from carriers (Metal/MPS, fp32)");
  m.def("spectral_topdown_bias_energies", &spectral_topdown_bias_energies, "Top-down energy bias from crystallized carriers (Metal/MPS, fp32)");
  m.def("spectral_spawn_uncoupled", &spectral_spawn_uncoupled, "Spawn carriers for uncoupled oscillators (Metal/MPS, fp32)");
  // Particle generation kernels
  m.def("generate_particles", &generate_particles, "Generate particles with pattern (Metal/MPS, fp32)");
}



---
File: /optimizer/triton/__init__.py
---

"""CUDA/Triton backend for manifold physics + spectral carriers.

This package is selected when tensors are on CUDA devices.
"""

from __future__ import annotations

__all__: list[str] = []




---
File: /optimizer/triton/manifold_grid_kernels.py
---

"""Triton kernels for 3D manifold grid physics (CUDA).

These mirror the Metal kernels in `optimizer/metal/manifold_physics.metal`:
- clear_field
- scatter_particle (mass/heat to fields with trilinear weights)
- poisson_jacobi_step
- diffuse_heat_field
- gather_update_particles (fused trilinear sample + physics update)

All tensors are expected to be CUDA fp32 and contiguous.
"""

from __future__ import annotations

import torch

try:
    import triton
    import triton.language as tl
except Exception as e:  # pragma: no cover
    triton = None  # type: ignore[assignment]
    tl = None  # type: ignore[assignment]
    _TRITON_IMPORT_ERROR: Exception = e
else:
    _TRITON_IMPORT_ERROR = RuntimeError("unreachable")


def _require_triton() -> None:
    if triton is None or tl is None:  # pragma: no cover
        raise RuntimeError(f"Triton is required for CUDA grid backend: {_TRITON_IMPORT_ERROR!r}")


@triton.jit
def clear_field_kernel(field_ptr, n_elements: tl.constexpr):
    pid = tl.program_id(0)
    offs = pid * 256 + tl.arange(0, 256)
    m = offs < n_elements
    tl.store(field_ptr + offs, 0.0, mask=m)


@triton.jit
def scatter_particle_kernel(
    pos_ptr,  # fp32 [N*3]
    mass_ptr,  # fp32 [N]
    heat_ptr,  # fp32 [N]
    gravity_ptr,  # fp32 [X*Y*Z] atomic
    temp_ptr,  # fp32 [X*Y*Z] atomic
    N: tl.constexpr,
    grid_x: tl.constexpr,
    grid_y: tl.constexpr,
    grid_z: tl.constexpr,
    inv_spacing: tl.constexpr,
):
    i = tl.program_id(0)
    if i >= N:
        return

    px = tl.load(pos_ptr + i * 3 + 0)
    py = tl.load(pos_ptr + i * 3 + 1)
    pz = tl.load(pos_ptr + i * 3 + 2)
    m = tl.load(mass_ptr + i)
    h = tl.load(heat_ptr + i)

    gx = px * inv_spacing
    gy = py * inv_spacing
    gz = pz * inv_spacing

    # clamp to [0, dim-1.001] so base+1 is valid
    gx = tl.maximum(0.0, tl.minimum(gx, float(grid_x) - 1.001))
    gy = tl.maximum(0.0, tl.minimum(gy, float(grid_y) - 1.001))
    gz = tl.maximum(0.0, tl.minimum(gz, float(grid_z) - 1.001))

    bx = tl.floor(gx).to(tl.int32)
    by = tl.floor(gy).to(tl.int32)
    bz = tl.floor(gz).to(tl.int32)
    fx = gx - bx.to(tl.float32)
    fy = gy - by.to(tl.float32)
    fz = gz - bz.to(tl.float32)

    wx0 = 1.0 - fx
    wy0 = 1.0 - fy
    wz0 = 1.0 - fz
    wx1 = fx
    wy1 = fy
    wz1 = fz

    # 8 corners
    stride_z = 1
    stride_y = grid_z
    stride_x = grid_y * grid_z
    base = bx * stride_x + by * stride_y + bz * stride_z

    w000 = wx0 * wy0 * wz0
    w001 = wx0 * wy0 * wz1
    w010 = wx0 * wy1 * wz0
    w011 = wx0 * wy1 * wz1
    w100 = wx1 * wy0 * wz0
    w101 = wx1 * wy0 * wz1
    w110 = wx1 * wy1 * wz0
    w111 = wx1 * wy1 * wz1

    tl.atomic_add(gravity_ptr + base + 0, m * w000)
    tl.atomic_add(gravity_ptr + base + stride_z, m * w001)
    tl.atomic_add(gravity_ptr + base + stride_y, m * w010)
    tl.atomic_add(gravity_ptr + base + stride_y + stride_z, m * w011)
    tl.atomic_add(gravity_ptr + base + stride_x, m * w100)
    tl.atomic_add(gravity_ptr + base + stride_x + stride_z, m * w101)
    tl.atomic_add(gravity_ptr + base + stride_x + stride_y, m * w110)
    tl.atomic_add(gravity_ptr + base + stride_x + stride_y + stride_z, m * w111)

    tl.atomic_add(temp_ptr + base + 0, h * w000)
    tl.atomic_add(temp_ptr + base + stride_z, h * w001)
    tl.atomic_add(temp_ptr + base + stride_y, h * w010)
    tl.atomic_add(temp_ptr + base + stride_y + stride_z, h * w011)
    tl.atomic_add(temp_ptr + base + stride_x, h * w100)
    tl.atomic_add(temp_ptr + base + stride_x + stride_z, h * w101)
    tl.atomic_add(temp_ptr + base + stride_x + stride_y, h * w110)
    tl.atomic_add(temp_ptr + base + stride_x + stride_y + stride_z, h * w111)


@triton.jit
def poisson_jacobi_step_kernel(
    phi_in_ptr,
    rho_ptr,
    phi_out_ptr,
    gravity_4pi: tl.constexpr,
    grid_x: tl.constexpr,
    grid_y: tl.constexpr,
    grid_z: tl.constexpr,
    grid_spacing: tl.constexpr,
):
    pid = tl.program_id(0)
    n = grid_x * grid_y * grid_z
    idx = pid * 256 + tl.arange(0, 256)
    m = idx < n

    stride_z = 1
    stride_y = grid_z
    stride_x = grid_y * grid_z

    # decode idx -> (x,y,z)
    x = idx // stride_x
    rem = idx - x * stride_x
    y = rem // stride_y
    z = rem - y * stride_y

    center = tl.load(phi_in_ptr + idx, mask=m, other=0.0)
    rho = tl.load(rho_ptr + idx, mask=m, other=0.0)

    xm = tl.where(x > 0, tl.load(phi_in_ptr + idx - stride_x, mask=m, other=0.0), 0.0)
    xp = tl.where(x < (grid_x - 1), tl.load(phi_in_ptr + idx + stride_x, mask=m, other=0.0), 0.0)
    ym = tl.where(y > 0, tl.load(phi_in_ptr + idx - stride_y, mask=m, other=0.0), 0.0)
    yp = tl.where(y < (grid_y - 1), tl.load(phi_in_ptr + idx + stride_y, mask=m, other=0.0), 0.0)
    zm = tl.where(z > 0, tl.load(phi_in_ptr + idx - stride_z, mask=m, other=0.0), 0.0)
    zp = tl.where(z < (grid_z - 1), tl.load(phi_in_ptr + idx + stride_z, mask=m, other=0.0), 0.0)

    h2 = grid_spacing * grid_spacing
    out = (xm + xp + ym + yp + zm + zp - h2 * gravity_4pi * rho) * (1.0 / 6.0)
    tl.store(phi_out_ptr + idx, out, mask=m)


@triton.jit
def diffuse_heat_field_kernel(
    temp_in_ptr,
    temp_out_ptr,
    diffusion_coef: tl.constexpr,
    dt: tl.constexpr,
    grid_x: tl.constexpr,
    grid_y: tl.constexpr,
    grid_z: tl.constexpr,
    inv_spacing: tl.constexpr,
):
    pid = tl.program_id(0)
    n = grid_x * grid_y * grid_z
    idx = pid * 256 + tl.arange(0, 256)
    m = idx < n

    stride_z = 1
    stride_y = grid_z
    stride_x = grid_y * grid_z

    x = idx // stride_x
    rem = idx - x * stride_x
    y = rem // stride_y
    z = rem - y * stride_y

    center = tl.load(temp_in_ptr + idx, mask=m, other=0.0)
    # boundary handling: use center value on boundary (Neumann-ish)
    xm = tl.where(x > 0, tl.load(temp_in_ptr + idx - stride_x, mask=m, other=center), center)
    xp = tl.where(x < (grid_x - 1), tl.load(temp_in_ptr + idx + stride_x, mask=m, other=center), center)
    ym = tl.where(y > 0, tl.load(temp_in_ptr + idx - stride_y, mask=m, other=center), center)
    yp = tl.where(y < (grid_y - 1), tl.load(temp_in_ptr + idx + stride_y, mask=m, other=center), center)
    zm = tl.where(z > 0, tl.load(temp_in_ptr + idx - stride_z, mask=m, other=center), center)
    zp = tl.where(z < (grid_z - 1), tl.load(temp_in_ptr + idx + stride_z, mask=m, other=center), center)

    lap = (xm + xp + ym + yp + zm + zp - 6.0 * center) * (inv_spacing * inv_spacing)
    out = center + diffusion_coef * lap * dt
    tl.store(temp_out_ptr + idx, out, mask=m)


@triton.jit
def gather_update_particles_kernel(
    gravity_phi_ptr,  # fp32 [X*Y*Z]
    temp_field_ptr,  # fp32 [X*Y*Z]
    pos_ptr,  # fp32 [N*3] in/out
    vel_ptr,  # fp32 [N*3] in/out
    energy_ptr,  # fp32 [N] in/out
    heat_ptr,  # fp32 [N] in/out
    excitation_ptr,  # fp32 [N] in/out (conserved)
    mass_ptr,  # fp32 [N]
    N: tl.constexpr,
    grid_x: tl.constexpr,
    grid_y: tl.constexpr,
    grid_z: tl.constexpr,
    dt: tl.constexpr,
    grid_spacing: tl.constexpr,
    inv_spacing: tl.constexpr,
    G: tl.constexpr,
    k_B: tl.constexpr,
    sigma_SB: tl.constexpr,
    particle_radius: tl.constexpr,
    thermal_conductivity: tl.constexpr,
    specific_heat: tl.constexpr,
    dynamic_viscosity: tl.constexpr,
    emissivity: tl.constexpr,
    young_modulus: tl.constexpr,
):
    i = tl.program_id(0)
    if i >= N:
        return

    px = tl.load(pos_ptr + i * 3 + 0)
    py = tl.load(pos_ptr + i * 3 + 1)
    pz = tl.load(pos_ptr + i * 3 + 2)
    vx = tl.load(vel_ptr + i * 3 + 0)
    vy = tl.load(vel_ptr + i * 3 + 1)
    vz = tl.load(vel_ptr + i * 3 + 2)
    energy = tl.load(energy_ptr + i)
    heat = tl.load(heat_ptr + i)
    excitation = tl.load(excitation_ptr + i)
    mass = tl.load(mass_ptr + i)

    # trilinear coords
    gx = tl.maximum(0.0, tl.minimum(px * inv_spacing, float(grid_x) - 1.001))
    gy = tl.maximum(0.0, tl.minimum(py * inv_spacing, float(grid_y) - 1.001))
    gz = tl.maximum(0.0, tl.minimum(pz * inv_spacing, float(grid_z) - 1.001))

    bx = tl.floor(gx).to(tl.int32)
    by = tl.floor(gy).to(tl.int32)
    bz = tl.floor(gz).to(tl.int32)
    fx = gx - bx.to(tl.float32)
    fy = gy - by.to(tl.float32)
    fz = gz - bz.to(tl.float32)

    stride_z = 1
    stride_y = grid_z
    stride_x = grid_y * grid_z
    base = bx * stride_x + by * stride_y + bz * stride_z

    # corners
    c000_phi = tl.load(gravity_phi_ptr + base + 0)
    c001_phi = tl.load(gravity_phi_ptr + base + stride_z)
    c010_phi = tl.load(gravity_phi_ptr + base + stride_y)
    c011_phi = tl.load(gravity_phi_ptr + base + stride_y + stride_z)
    c100_phi = tl.load(gravity_phi_ptr + base + stride_x)
    c101_phi = tl.load(gravity_phi_ptr + base + stride_x + stride_z)
    c110_phi = tl.load(gravity_phi_ptr + base + stride_x + stride_y)
    c111_phi = tl.load(gravity_phi_ptr + base + stride_x + stride_y + stride_z)

    c000_T = tl.load(temp_field_ptr + base + 0)
    c001_T = tl.load(temp_field_ptr + base + stride_z)
    c010_T = tl.load(temp_field_ptr + base + stride_y)
    c011_T = tl.load(temp_field_ptr + base + stride_y + stride_z)
    c100_T = tl.load(temp_field_ptr + base + stride_x)
    c101_T = tl.load(temp_field_ptr + base + stride_x + stride_z)
    c110_T = tl.load(temp_field_ptr + base + stride_x + stride_y)
    c111_T = tl.load(temp_field_ptr + base + stride_x + stride_y + stride_z)

    wx0 = 1.0 - fx
    wy0 = 1.0 - fy
    wz0 = 1.0 - fz
    wx1 = fx
    wy1 = fy
    wz1 = fz

    # trilinear sample for temperature
    c00 = c000_T * wz0 + c001_T * wz1
    c01 = c010_T * wz0 + c011_T * wz1
    c10 = c100_T * wz0 + c101_T * wz1
    c11 = c110_T * wz0 + c111_T * wz1
    c0 = c00 * wy0 + c01 * wy1
    c1 = c10 * wy0 + c11 * wy1
    local_T = c0 * wx0 + c1 * wx1

    # gradient estimate like Metal (difference between faces)
    face_x0_phi = c000_phi * wy0 * wz0 + c010_phi * wy1 * wz0 + c001_phi * wy0 * wz1 + c011_phi * wy1 * wz1
    face_x1_phi = c100_phi * wy0 * wz0 + c110_phi * wy1 * wz0 + c101_phi * wy0 * wz1 + c111_phi * wy1 * wz1
    grad_x_phi = (face_x1_phi - face_x0_phi) * inv_spacing

    face_y0_phi = c000_phi * wx0 * wz0 + c100_phi * wx1 * wz0 + c001_phi * wx0 * wz1 + c101_phi * wx1 * wz1
    face_y1_phi = c010_phi * wx0 * wz0 + c110_phi * wx1 * wz0 + c011_phi * wx0 * wz1 + c111_phi * wx1 * wz1
    grad_y_phi = (face_y1_phi - face_y0_phi) * inv_spacing

    face_z0_phi = c000_phi * wx0 * wy0 + c100_phi * wx1 * wy0 + c010_phi * wx0 * wy1 + c110_phi * wx1 * wy1
    face_z1_phi = c001_phi * wx0 * wy0 + c101_phi * wx1 * wy0 + c011_phi * wx0 * wy1 + c111_phi * wx1 * wy1
    grad_z_phi = (face_z1_phi - face_z0_phi) * inv_spacing

    face_x0_T = c000_T * wy0 * wz0 + c010_T * wy1 * wz0 + c001_T * wy0 * wz1 + c011_T * wy1 * wz1
    face_x1_T = c100_T * wy0 * wz0 + c110_T * wy1 * wz0 + c101_T * wy0 * wz1 + c111_T * wy1 * wz1
    grad_x_T = (face_x1_T - face_x0_T) * inv_spacing

    face_y0_T = c000_T * wx0 * wz0 + c100_T * wx1 * wz0 + c001_T * wx0 * wz1 + c101_T * wx1 * wz1
    face_y1_T = c010_T * wx0 * wz0 + c110_T * wx1 * wz0 + c011_T * wx0 * wz1 + c111_T * wx1 * wz1
    grad_y_T = (face_y1_T - face_y0_T) * inv_spacing

    face_z0_T = c000_T * wx0 * wy0 + c100_T * wx1 * wy0 + c010_T * wx0 * wy1 + c110_T * wx1 * wy1
    face_z1_T = c001_T * wx0 * wy0 + c101_T * wx1 * wy0 + c011_T * wx0 * wy1 + c111_T * wx1 * wy1
    grad_z_T = (face_z1_T - face_z0_T) * inv_spacing

    # forces
    gravity_fx = -grad_x_phi * mass * G
    gravity_fy = -grad_y_phi * mass * G
    gravity_fz = -grad_z_phi * mass * G

    particle_T = heat / (tl.maximum(mass, 1e-6) * specific_heat)
    pressure_fx = -grad_x_T * k_B * mass
    pressure_fy = -grad_y_T * k_B * mass
    pressure_fz = -grad_z_T * k_B * mass

    # heat transfer
    r = particle_radius
    heat_transfer_coef = thermal_conductivity * r
    dQ_cond = heat_transfer_coef * (local_T - particle_T) * dt
    heat = heat + dQ_cond
    surface_area = r * r
    T4 = particle_T * particle_T * particle_T * particle_T
    dQ_rad = emissivity * sigma_SB * surface_area * T4 * dt
    heat = tl.maximum(heat - dQ_rad, 0.0)
    particle_T = heat / (tl.maximum(mass, 1e-6) * specific_heat)

    # thermalization
    tau = 10.0
    dQ_th = (energy / tau) * dt
    dQ_th = tl.minimum(dQ_th, energy)
    energy = energy - dQ_th
    heat = heat + dQ_th
    energy = tl.maximum(energy, 0.0)
    heat = tl.maximum(heat, 0.0)

    gamma = 6.0 * 3.14159 * dynamic_viscosity * r
    fx = gravity_fx + pressure_fx
    fy = gravity_fy + pressure_fy
    fz = gravity_fz + pressure_fz

    ax = fx / tl.maximum(mass, 1e-6)
    ay = fy / tl.maximum(mass, 1e-6)
    az = fz / tl.maximum(mass, 1e-6)

    # clamp acceleration
    acc_mag = tl.sqrt(ax * ax + ay * ay + az * az)
    max_acc = 10.0
    scale = tl.where(acc_mag > max_acc, max_acc / acc_mag, 1.0)
    ax = ax * scale
    ay = ay * scale
    az = az * scale

    ke_before = 0.5 * mass * (vx * vx + vy * vy + vz * vz)
    damp = tl.exp(-gamma * dt)
    vx = vx * damp + ax * dt
    vy = vy * damp + ay * dt
    vz = vz * damp + az * dt
    ke_after = 0.5 * mass * (vx * vx + vy * vy + vz * vz)
    ke_lost = tl.maximum(ke_before - ke_after, 0.0)
    heat = heat + ke_lost

    vel_mag = tl.sqrt(vx * vx + vy * vy + vz * vz)
    max_vel = 2.0
    vscale = tl.where(vel_mag > max_vel, max_vel / vel_mag, 1.0)
    vx = vx * vscale
    vy = vy * vscale
    vz = vz * vscale

    # position update
    px = px + vx * dt
    py = py + vy * dt
    pz = pz + vz * dt

    grid_max_x = float(grid_x) * grid_spacing * 0.95
    grid_max_y = float(grid_y) * grid_spacing * 0.95
    grid_max_z = float(grid_z) * grid_spacing * 0.95
    grid_min = 0.5

    # reflect boundaries
    if px < grid_min:
        px = grid_min
        vx = tl.abs(vx) * 0.5
    if py < grid_min:
        py = grid_min
        vy = tl.abs(vy) * 0.5
    if pz < grid_min:
        pz = grid_min
        vz = tl.abs(vz) * 0.5
    if px > grid_max_x:
        px = grid_max_x
        vx = -tl.abs(vx) * 0.5
    if py > grid_max_y:
        py = grid_max_y
        vy = -tl.abs(vy) * 0.5
    if pz > grid_max_z:
        pz = grid_max_z
        vz = -tl.abs(vz) * 0.5

    # write back
    tl.store(pos_ptr + i * 3 + 0, px)
    tl.store(pos_ptr + i * 3 + 1, py)
    tl.store(pos_ptr + i * 3 + 2, pz)
    tl.store(vel_ptr + i * 3 + 0, vx)
    tl.store(vel_ptr + i * 3 + 1, vy)
    tl.store(vel_ptr + i * 3 + 2, vz)
    tl.store(energy_ptr + i, energy)
    tl.store(heat_ptr + i, heat)
    tl.store(excitation_ptr + i, excitation)


def clear_field(field: torch.Tensor) -> None:
    _require_triton()
    n = int(field.numel())
    if n == 0:
        return
    grid = (triton.cdiv(n, 256),)
    clear_field_kernel[grid](field, n_elements=n, num_warps=1)


def scatter_particles(
    *,
    positions: torch.Tensor,
    masses: torch.Tensor,
    heats: torch.Tensor,
    gravity_field: torch.Tensor,
    temperature_field: torch.Tensor,
    grid_spacing: float,
) -> None:
    _require_triton()
    N = int(positions.shape[0])
    if N == 0:
        return
    gx, gy, gz = map(int, gravity_field.shape)
    inv = 1.0 / float(grid_spacing)
    pos = positions.contiguous().view(-1)
    grid = (N,)
    scatter_particle_kernel[grid](
        pos,
        masses.contiguous(),
        heats.contiguous(),
        gravity_field.contiguous().view(-1),
        temperature_field.contiguous().view(-1),
        N=N,
        grid_x=gx,
        grid_y=gy,
        grid_z=gz,
        inv_spacing=inv,
        num_warps=1,
    )


def poisson_jacobi_step(
    *,
    phi_in: torch.Tensor,
    rho: torch.Tensor,
    phi_out: torch.Tensor,
    grid_spacing: float,
    gravity_4pi: float,
) -> None:
    _require_triton()
    gx, gy, gz = map(int, phi_in.shape)
    n = gx * gy * gz
    if n == 0:
        return
    grid = (triton.cdiv(n, 256),)
    poisson_jacobi_step_kernel[grid](
        phi_in.contiguous().view(-1),
        rho.contiguous().view(-1),
        phi_out.contiguous().view(-1),
        gravity_4pi=float(gravity_4pi),
        grid_x=gx,
        grid_y=gy,
        grid_z=gz,
        grid_spacing=float(grid_spacing),
        num_warps=1,
    )


def diffuse_heat_field(
    *,
    temp_in: torch.Tensor,
    temp_out: torch.Tensor,
    diffusion_coef: float,
    dt: float,
    grid_spacing: float,
) -> None:
    _require_triton()
    gx, gy, gz = map(int, temp_in.shape)
    n = gx * gy * gz
    if n == 0:
        return
    inv = 1.0 / float(grid_spacing)
    grid = (triton.cdiv(n, 256),)
    diffuse_heat_field_kernel[grid](
        temp_in.contiguous().view(-1),
        temp_out.contiguous().view(-1),
        diffusion_coef=float(diffusion_coef),
        dt=float(dt),
        grid_x=gx,
        grid_y=gy,
        grid_z=gz,
        inv_spacing=float(inv),
        num_warps=1,
    )


def gather_update_particles(
    *,
    gravity_potential: torch.Tensor,
    temperature_field: torch.Tensor,
    positions: torch.Tensor,
    velocities: torch.Tensor,
    energies: torch.Tensor,
    heats: torch.Tensor,
    excitations: torch.Tensor,
    masses: torch.Tensor,
    dt: float,
    grid_spacing: float,
    G: float,
    k_B: float,
    sigma_SB: float,
    particle_radius: float,
    thermal_conductivity: float,
    specific_heat: float,
    dynamic_viscosity: float,
    emissivity: float,
    young_modulus: float,
) -> None:
    _require_triton()
    N = int(positions.shape[0])
    if N == 0:
        return
    gx, gy, gz = map(int, gravity_potential.shape)
    inv = 1.0 / float(grid_spacing)
    grid = (N,)
    gather_update_particles_kernel[grid](
        gravity_potential.contiguous().view(-1),
        temperature_field.contiguous().view(-1),
        positions.contiguous().view(-1),
        velocities.contiguous().view(-1),
        energies.contiguous(),
        heats.contiguous(),
        excitations.contiguous(),
        masses.contiguous(),
        N=N,
        grid_x=gx,
        grid_y=gy,
        grid_z=gz,
        dt=float(dt),
        grid_spacing=float(grid_spacing),
        inv_spacing=float(inv),
        G=float(G),
        k_B=float(k_B),
        sigma_SB=float(sigma_SB),
        particle_radius=float(particle_radius),
        thermal_conductivity=float(thermal_conductivity),
        specific_heat=float(specific_heat),
        dynamic_viscosity=float(dynamic_viscosity),
        emissivity=float(emissivity),
        young_modulus=float(young_modulus),
        num_warps=1,
    )




---
File: /optimizer/triton/manifold_physics_kernels.py
---

"""Triton kernels for Resonant Manifold (CUDA).

Implements the spectral carrier layer:
- carrier update + split (with crystallization + anchored memory)
- oscillator phase update (with top-down anchor phase bias)
- top-down energy bias from crystallized carriers
- spawn uncoupled oscillators into carriers

These kernels mirror the logic in `optimizer/metal/manifold_physics.metal`.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional

import torch

try:
    import triton
    import triton.language as tl
except Exception as e:  # pragma: no cover
    triton = None  # type: ignore[assignment]
    tl = None  # type: ignore[assignment]
    _TRITON_IMPORT_ERROR: Exception = e
else:
    _TRITON_IMPORT_ERROR = RuntimeError("unreachable")


ANCHORS: int = 8

STATE_VOLATILE = 0
STATE_STABLE = 1
STATE_CRYSTALLIZED = 2


@dataclass(frozen=True, slots=True)
class SpectralParams:
    # core
    dt: float
    coupling_scale: float
    carrier_reg: float
    temperature: float
    rng_seed: int
    conflict_threshold: float
    offender_weight_floor: float
    gate_width_min: float
    gate_width_max: float
    ema_alpha: float
    recenter_alpha: float
    # modes/memory
    mode: int  # 0=online,1=consolidate,2=disambiguate,3=explore
    anchor_random_eps: float
    stable_amp_threshold: float
    crystallize_amp_threshold: float
    crystallize_conflict_threshold: float
    crystallize_age: int
    crystallized_coupling_boost: float
    volatile_decay_mul: float
    stable_decay_mul: float
    crystallized_decay_mul: float
    topdown_phase_scale: float
    topdown_energy_scale: float
    topdown_random_energy_eps: float
    repulsion_scale: float


def _require_triton() -> None:
    if triton is None or tl is None:  # pragma: no cover
        raise RuntimeError(f"Triton is required for CUDA backend: {_TRITON_IMPORT_ERROR!r}")


@triton.jit
def _hash_u32(x: tl.uint32) -> tl.uint32:
    x ^= x >> 16
    x *= 0x7FEB352D
    x ^= x >> 15
    x *= 0x846CA68B
    x ^= x >> 16
    return x


@triton.jit
def _u01_from_u32(x: tl.uint32) -> tl.float32:
    # map to (0,1), avoid exact 0
    u = (x & 0x00FFFFFF).to(tl.float32) * (1.0 / 16777216.0)
    return tl.maximum(u, 1e-7)


@triton.jit
def _box_muller(u1: tl.float32, u2: tl.float32) -> tl.float32:
    r = tl.sqrt(-2.0 * tl.log(u1))
    t = 6.283185307179586 * u2
    return r * tl.cos(t)


@triton.jit
def _randn1(seed: tl.uint32, idx: tl.uint32) -> tl.float32:
    s0 = _hash_u32(seed ^ (idx * 0x9E3779B9))
    s1 = _hash_u32(s0 + 1)
    return _box_muller(_u01_from_u32(s0), _u01_from_u32(s1))


@triton.jit
def _tuning(omega_i: tl.float32, omega_k: tl.float32, gate_w: tl.float32) -> tl.float32:
    d = omega_i - omega_k
    sigma = tl.maximum(gate_w, 1e-4)
    return tl.exp(-(d * d) / (sigma * sigma))


@triton.jit
def _wrap_pi(x: tl.float32) -> tl.float32:
    # wrap to [-pi, pi]
    two_pi = 6.283185307179586
    pi = 3.141592653589793
    return x - two_pi * tl.floor((x + pi) / two_pi)


@triton.jit
def carrier_block_accum_kernel(
    osc_phase_ptr,  # fp32 [N]
    osc_omega_ptr,  # fp32 [N]
    osc_amp_ptr,  # fp32 [N]
    carrier_omega_ptr,  # fp32 [M]
    carrier_gate_ptr,  # fp32 [M]
    # accumulators (atomic adds)
    out_force_r_ptr,  # fp32 [M]
    out_force_i_ptr,  # fp32 [M]
    out_w_sum_ptr,  # fp32 [M]
    out_w_omega_sum_ptr,  # fp32 [M]
    out_w_amp_sum_ptr,  # fp32 [M]
    # sizes
    N: tl.constexpr,
    BLOCK_N: tl.constexpr,
    # params needed for weights
    offender_weight_floor: tl.constexpr,
    gate_width_min: tl.constexpr,
    gate_width_max: tl.constexpr,
):
    k = tl.program_id(0)
    blk = tl.program_id(1)
    omega_k = tl.load(carrier_omega_ptr + k)
    gate_w = tl.load(carrier_gate_ptr + k)
    gate_w = tl.maximum(tl.minimum(gate_w, gate_width_max), gate_width_min)
    off = blk * BLOCK_N
    idx = off + tl.arange(0, BLOCK_N)
    m = idx < N
    omega_i = tl.load(osc_omega_ptr + idx, mask=m, other=0.0)
    amp_i = tl.load(osc_amp_ptr + idx, mask=m, other=0.0)
    phi_i = tl.load(osc_phase_ptr + idx, mask=m, other=0.0)
    t = _tuning(omega_i, omega_k, gate_w)
    w = t * amp_i
    w = tl.where(w > offender_weight_floor, w, 0.0)
    zr = amp_i * tl.cos(phi_i)
    zi = amp_i * tl.sin(phi_i)
    tl.atomic_add(out_force_r_ptr + k, tl.sum(w * zr, axis=0))
    tl.atomic_add(out_force_i_ptr + k, tl.sum(w * zi, axis=0))
    tl.atomic_add(out_w_sum_ptr + k, tl.sum(w, axis=0))
    tl.atomic_add(out_w_omega_sum_ptr + k, tl.sum(w * omega_i, axis=0))
    tl.atomic_add(out_w_amp_sum_ptr + k, tl.sum(w * amp_i, axis=0))


@triton.jit
def carrier_finalize_and_split_kernel(
    osc_phase_ptr,
    osc_omega_ptr,
    osc_amp_ptr,
    carrier_real_ptr,
    carrier_imag_ptr,
    carrier_omega_ptr,
    carrier_gate_ptr,
    carrier_conflict_ptr,
    carrier_state_ptr,
    carrier_age_ptr,
    anchor_idx_ptr,
    anchor_phase_ptr,
    anchor_weight_ptr,
    num_carriers_ptr,  # int32[1] atomic
    spawned_from_ptr,
    random_phases_ptr,
    energy_stats_ptr,
    # accumulators
    force_r_ptr,
    force_i_ptr,
    w_sum_ptr,
    w_omega_sum_ptr,
    w_amp_sum_ptr,
    N: tl.constexpr,
    max_carriers: tl.constexpr,
    # params
    dt: tl.constexpr,
    carrier_reg: tl.constexpr,
    temperature: tl.constexpr,
    rng_seed: tl.constexpr,
    conflict_threshold: tl.constexpr,
    gate_width_min: tl.constexpr,
    gate_width_max: tl.constexpr,
    ema_alpha: tl.constexpr,
    recenter_alpha: tl.constexpr,
    mode: tl.constexpr,
    anchor_random_eps: tl.constexpr,
    stable_amp_threshold: tl.constexpr,
    crystallize_amp_threshold: tl.constexpr,
    crystallize_conflict_threshold: tl.constexpr,
    crystallize_age: tl.constexpr,
    volatile_decay_mul: tl.constexpr,
    stable_decay_mul: tl.constexpr,
    crystallized_decay_mul: tl.constexpr,
    repulsion_scale: tl.constexpr,
):
    k = tl.program_id(0)
    cr = tl.load(carrier_real_ptr + k)
    ci = tl.load(carrier_imag_ptr + k)
    omega_k = tl.load(carrier_omega_ptr + k)
    gate_w = tl.load(carrier_gate_ptr + k)
    gate_w = tl.maximum(tl.minimum(gate_w, gate_width_max), gate_width_min)

    state = tl.load(carrier_state_ptr + k).to(tl.int32)
    age = tl.load(carrier_age_ptr + k).to(tl.int32)

    mean_abs_e = tl.load(energy_stats_ptr + 0)
    e_scale = tl.maximum(mean_abs_e, 1e-8)
    adaptive_decay = tl.exp(-(dt) / e_scale)
    decay_mul = tl.full((), 1.0, tl.float32)
    decay_mul = tl.where(state == STATE_VOLATILE, tl.maximum(volatile_decay_mul, 0.0), decay_mul)
    decay_mul = tl.where(state == STATE_STABLE, tl.maximum(stable_decay_mul, 0.0), decay_mul)
    decay_mul = tl.where(state == STATE_CRYSTALLIZED, tl.maximum(crystallized_decay_mul, 0.0), decay_mul)
    cr = cr * adaptive_decay * decay_mul
    ci = ci * adaptive_decay * decay_mul

    force_r_raw = tl.load(force_r_ptr + k)
    force_i_raw = tl.load(force_i_ptr + k)
    w_sum = tl.load(w_sum_ptr + k)
    w_omega_sum = tl.load(w_omega_sum_ptr + k)
    w_amp_sum = tl.load(w_amp_sum_ptr + k)

    mean_omega = tl.where(w_sum > 1e-8, w_omega_sum / w_sum, omega_k)

    R = tl.sqrt(force_r_raw * force_r_raw + force_i_raw * force_i_raw)
    denom = tl.maximum(w_amp_sum, 1e-8)
    coherence = tl.maximum(tl.minimum(R / denom, 1.0), 0.0)
    inst_conflict = 1.0 - coherence

    prev_conflict = tl.load(carrier_conflict_ptr + k)
    a = tl.maximum(tl.minimum(ema_alpha, 1.0), 0.0)
    conflict = prev_conflict * (1.0 - a) + inst_conflict * a
    tl.store(carrier_conflict_ptr + k, conflict)

    if recenter_alpha != 0.0:
        rc = tl.maximum(tl.minimum(recenter_alpha, 1.0), 0.0)
        omega_k = tl.where(state == STATE_CRYSTALLIZED, omega_k, omega_k * (1.0 - rc) + mean_omega * rc)

    # metabolic shrink (skip for crystallized)
    inv_w = 1.0 / tl.maximum(w_sum, 1e-8)
    force_r = force_r_raw * inv_w
    force_i = force_i_raw * inv_w
    income = tl.sqrt(force_r * force_r + force_i * force_i)
    expense = e_scale
    not_crys = state != STATE_CRYSTALLIZED
    shrink = tl.where(not_crys & (income < expense), tl.exp(-(dt) * (expense - income) / (expense + 1e-8)), 1.0)
    cr = cr * shrink
    ci = ci * shrink

    # Langevin carrier update
    n = _randn1(rng_seed ^ 0xA5A5A5A5, k.to(tl.uint32))
    n2 = _randn1(rng_seed ^ 0xA5A5A5A5, (k.to(tl.uint32) + 1337))
    temp_factor = e_scale / (e_scale + 1.0)
    noise_scale = tl.sqrt(tl.maximum(2.0 * (temperature * temp_factor) * dt, 0.0))
    reg = tl.where(state == STATE_CRYSTALLIZED, 0.0, carrier_reg)
    cr = cr + (force_r - reg * cr) * dt + noise_scale * n
    ci = ci + (force_i - reg * ci) * dt + noise_scale * n2

    # ω repulsion (disambiguate)
    if mode == 2 and repulsion_scale > 0.0:
        curM = tl.load(num_carriers_ptr).to(tl.int32)
        repel = tl.zeros((), tl.float32)
        for k2 in range(0, max_carriers):
            active2 = (k2 < curM) & (k2 != k)
            omega2 = tl.load(carrier_omega_ptr + k2, mask=active2, other=0.0)
            gate2 = tl.load(carrier_gate_ptr + k2, mask=active2, other=0.0)
            gate2 = tl.maximum(tl.minimum(gate2, gate_width_max), gate_width_min)
            d2 = omega_k - omega2
            s = tl.maximum(gate_w + gate2, 1e-3)
            repel += tl.where(active2, d2 * tl.exp(-(d2 * d2) / (s * s)), 0.0)
        omega_k = tl.where(not_crys, omega_k + dt * repulsion_scale * repel, omega_k)

    # crystallization state machine (branchless)
    ampC = tl.sqrt(cr * cr + ci * ci)
    promote = (state == STATE_VOLATILE) & (ampC >= stable_amp_threshold)
    state = tl.where(promote, tl.full((), STATE_STABLE, tl.int32), state)
    age = tl.where(promote, 0, age)

    in_stable = state == STATE_STABLE
    ok = in_stable & (ampC >= crystallize_amp_threshold) & (conflict <= crystallize_conflict_threshold)
    age_next = tl.where(ok, age + 1, tl.where(in_stable, 0, age))
    crystallize = ok & (age_next >= crystallize_age)
    state = tl.where(crystallize, tl.full((), STATE_CRYSTALLIZED, tl.int32), state)
    age = tl.where(crystallize, crystallize_age, age_next)

    # anchor refresh (ε-greedy) using random candidate + stochastic offender
    do_anchor = (state != STATE_CRYSTALLIZED)
    h = _hash_u32((rng_seed ^ (k.to(tl.uint32) * 0xB4B82E39) ^ 0x1C3A5F7D).to(tl.uint32))
    u = _u01_from_u32(h)
    slot = (_hash_u32(h + 0x3C6EF372) % ANCHORS).to(tl.int32)
    base = k * ANCHORS + slot
    eps_anchor = tl.maximum(tl.minimum(anchor_random_eps, 1.0), 0.0)
    cand = (_hash_u32(h + 0x9E3779B9) % N).to(tl.int32)
    offender = (_hash_u32(h + 0x7F4A7C15) % N).to(tl.int32)
    chosen = tl.where(u <= eps_anchor, cand, offender)
    tl.store(anchor_idx_ptr + base, chosen, mask=do_anchor)
    psi = tl.atan2(ci, cr)
    phi_ch = tl.load(osc_phase_ptr + chosen, mask=do_anchor, other=0.0)
    d = _wrap_pi(phi_ch - psi)
    tl.store(anchor_phase_ptr + base, d, mask=do_anchor)
    omega_ch = tl.load(osc_omega_ptr + chosen, mask=do_anchor, other=0.0)
    amp_ch = tl.load(osc_amp_ptr + chosen, mask=do_anchor, other=0.0)
    w_ch = _tuning(omega_ch, omega_k, gate_w) * amp_ch
    tl.store(anchor_weight_ptr + base, w_ch, mask=do_anchor)

    # write back
    tl.store(carrier_real_ptr + k, cr)
    tl.store(carrier_imag_ptr + k, ci)
    tl.store(carrier_omega_ptr + k, omega_k)
    tl.store(carrier_gate_ptr + k, gate_w)
    tl.store(carrier_state_ptr + k, state.to(tl.int32))
    tl.store(carrier_age_ptr + k, age.to(tl.int32))

    # split: spawn when conflict is high; offender chosen stochastically.
    do_split = (state != STATE_CRYSTALLIZED) & (conflict > conflict_threshold) & (w_sum > 1e-8)
    h2 = _hash_u32((rng_seed ^ (k.to(tl.uint32) * 0xA511E9B3) ^ 0x63D83595).to(tl.uint32))
    offender_idx = (_hash_u32(h2 + 0x9E3779B9) % N).to(tl.int32)
    inc = tl.where(do_split, 1, 0).to(tl.int32)
    slot = tl.atomic_add(num_carriers_ptr, inc)
    do_write = do_split & (slot < max_carriers)
    omega_new = tl.load(osc_omega_ptr + offender_idx, mask=do_write, other=0.0)
    amp_new = tl.load(osc_amp_ptr + offender_idx, mask=do_write, other=0.0)
    phi_new = tl.load(osc_phase_ptr + offender_idx, mask=do_write, other=0.0)
    init_scale = 0.5
    nr = init_scale * amp_new * tl.cos(phi_new)
    ni = init_scale * amp_new * tl.sin(phi_new)
    tl.store(carrier_real_ptr + slot, nr, mask=do_write)
    tl.store(carrier_imag_ptr + slot, ni, mask=do_write)
    tl.store(carrier_omega_ptr + slot, omega_new, mask=do_write)
    tl.store(carrier_gate_ptr + slot, gate_w, mask=do_write)
    tl.store(carrier_conflict_ptr + slot, 0.0, mask=do_write)
    tl.store(carrier_state_ptr + slot, tl.full((), STATE_VOLATILE, tl.int32), mask=do_write)
    tl.store(carrier_age_ptr + slot, 0, mask=do_write)
    tl.store(spawned_from_ptr + slot, offender_idx, mask=do_write)
    for j in range(0, ANCHORS):
        b = slot * ANCHORS + j
        tl.store(anchor_idx_ptr + b, tl.full((), -1, tl.int32), mask=do_write)
        tl.store(anchor_phase_ptr + b, 0.0, mask=do_write)
        tl.store(anchor_weight_ptr + b, 0.0, mask=do_write)
    b0 = slot * ANCHORS
    tl.store(anchor_idx_ptr + b0, offender_idx, mask=do_write)
    psi0 = tl.atan2(ni, nr)
    d0 = _wrap_pi(phi_new - psi0)
    tl.store(anchor_phase_ptr + b0, d0, mask=do_write)
    tl.store(anchor_weight_ptr + b0, amp_new, mask=do_write)
    rp = tl.load(random_phases_ptr + slot, mask=do_write, other=0.0)
    r = rp * 6.283185307179586
    rot_r = tl.cos(r)
    rot_i = tl.sin(r)
    rr = tl.load(carrier_real_ptr + slot, mask=do_write, other=0.0)
    ri = tl.load(carrier_imag_ptr + slot, mask=do_write, other=0.0)
    tl.store(carrier_real_ptr + slot, rr * rot_r - ri * rot_i, mask=do_write)
    tl.store(carrier_imag_ptr + slot, rr * rot_i + ri * rot_r, mask=do_write)
    tl.store(carrier_conflict_ptr + k, 0.0, mask=do_split)


@triton.jit
def spectral_update_oscillator_phases_kernel(
    osc_phase_ptr,
    osc_omega_ptr,
    osc_amp_ptr,
    carrier_real_ptr,
    carrier_imag_ptr,
    carrier_omega_ptr,
    carrier_gate_ptr,
    carrier_state_ptr,
    anchor_idx_ptr,
    anchor_phase_ptr,
    anchor_weight_ptr,
    energy_stats_ptr,
    num_carriers_ptr,  # int32 [1]
    N: tl.constexpr,
    max_carriers: tl.constexpr,
    # params
    dt: tl.constexpr,
    coupling_scale: tl.constexpr,
    temperature: tl.constexpr,
    rng_seed: tl.constexpr,
    gate_width_min: tl.constexpr,
    gate_width_max: tl.constexpr,
    crystallized_coupling_boost: tl.constexpr,
    topdown_phase_scale: tl.constexpr,
):
    i = tl.program_id(0)
    phi = tl.load(osc_phase_ptr + i)
    omega_i = tl.load(osc_omega_ptr + i)
    amp_i = tl.load(osc_amp_ptr + i)

    num_car = tl.load(num_carriers_ptr).to(tl.int32)
    torque = tl.zeros((), tl.float32)
    for k in range(0, max_carriers):
        active = k < num_car
        omega_k = tl.load(carrier_omega_ptr + k, mask=active, other=0.0)
        gate_w = tl.load(carrier_gate_ptr + k, mask=active, other=1.0)
        gate_w = tl.maximum(tl.minimum(gate_w, gate_width_max), gate_width_min)
        t = _tuning(omega_i, omega_k, gate_w)
        cr = tl.load(carrier_real_ptr + k, mask=active, other=0.0)
        ci = tl.load(carrier_imag_ptr + k, mask=active, other=0.0)
        psi = tl.atan2(ci, cr)
        R = tl.sqrt(cr * cr + ci * ci)
        st = tl.load(carrier_state_ptr + k, mask=active, other=0).to(tl.int32)
        boost = 1.0 + tl.where(st == STATE_CRYSTALLIZED, tl.maximum(crystallized_coupling_boost, 0.0), 0.0)
        torque += boost * t * (amp_i * R) * tl.sin(psi - phi)

        # top-down phase pull if anchored in crystallized carrier
        if topdown_phase_scale != 0.0:
            base = k * ANCHORS
            is_crys = st == STATE_CRYSTALLIZED
            for j in range(0, ANCHORS):
                idx = tl.load(anchor_idx_ptr + base + j, mask=active, other=-1).to(tl.int32)
                match = is_crys & (idx == i)
                off = tl.load(anchor_phase_ptr + base + j, mask=match, other=0.0)
                w = tl.load(anchor_weight_ptr + base + j, mask=match, other=0.0)
                target = psi + off
                d = _wrap_pi(target - phi)
                torque += topdown_phase_scale * w * tl.sin(d)

    mean_abs_e = tl.load(energy_stats_ptr + 0)
    e_scale = tl.maximum(mean_abs_e, 1e-8)
    temp_factor = e_scale / (e_scale + 1.0)
    noise_scale = tl.sqrt(tl.maximum(2.0 * (temperature * temp_factor) * dt, 0.0))
    n = _randn1(rng_seed ^ 0xC3C3C3C3, i.to(tl.uint32))
    dphi = omega_i + coupling_scale * torque
    phi = phi + dphi * dt + noise_scale * n
    two_pi = 6.283185307179586
    phi = phi - two_pi * tl.floor(phi / two_pi)
    tl.store(osc_phase_ptr + i, phi)


@triton.jit
def spectral_topdown_bias_energies_kernel(
    osc_energy_ptr,  # fp32 [N]
    osc_amp_ptr,  # fp32 [N]
    carrier_state_ptr,  # int32 [M]
    anchor_idx_ptr,  # int32 [M*ANCHORS]
    anchor_weight_ptr,  # fp32 [M*ANCHORS]
    num_carriers_ptr,  # int32 [1]
    N: tl.constexpr,
    max_carriers: tl.constexpr,
    dt: tl.constexpr,
    rng_seed: tl.constexpr,
    topdown_energy_scale: tl.constexpr,
    topdown_random_energy_eps: tl.constexpr,
):
    k = tl.program_id(0)
    num_car = tl.load(num_carriers_ptr).to(tl.int32)
    active = k < num_car
    st = tl.load(carrier_state_ptr + k, mask=active, other=0).to(tl.int32)
    is_crys = active & (st == STATE_CRYSTALLIZED) & (topdown_energy_scale > 0.0)
    base = k * ANCHORS
    wsum = tl.zeros((), tl.float32)
    act = tl.zeros((), tl.float32)
    for j in range(0, ANCHORS):
        idx = tl.load(anchor_idx_ptr + base + j, mask=is_crys, other=-1).to(tl.int32)
        ok = is_crys & (idx >= 0) & (idx < N)
        w = tl.load(anchor_weight_ptr + base + j, mask=ok, other=0.0)
        wsum += w
        act += w * tl.load(osc_amp_ptr + idx, mask=ok, other=0.0)
    ok_w = is_crys & (wsum > 1e-8)
    act = act / wsum
    for j in range(0, ANCHORS):
        idx = tl.load(anchor_idx_ptr + base + j, mask=ok_w, other=-1).to(tl.int32)
        ok = ok_w & (idx >= 0) & (idx < N)
        w = tl.load(anchor_weight_ptr + base + j, mask=ok, other=0.0) / wsum
        a = tl.load(osc_amp_ptr + idx, mask=ok, other=0.0)
        need = 1.0 / (1.0 + a)
        dE = dt * topdown_energy_scale * act * w * need
        tl.atomic_add(osc_energy_ptr + idx, dE, mask=ok)

    if topdown_random_energy_eps > 0.0:
        h = _hash_u32((rng_seed ^ (k.to(tl.uint32) * 0x27D4EB2D) ^ 0x85EBCA6B).to(tl.uint32))
        u = _u01_from_u32(h)
        lucky = ok_w & (u <= topdown_random_energy_eps)
        idx = (_hash_u32(h + 0x165667B1) % N).to(tl.int32)
        dE = dt * (0.25 * topdown_energy_scale) * act
        tl.atomic_add(osc_energy_ptr + idx, dE, mask=lucky)


@triton.jit
def spectral_spawn_uncoupled_kernel(
    osc_phase_ptr,
    osc_omega_ptr,
    osc_amp_ptr,
    carrier_real_ptr,
    carrier_imag_ptr,
    carrier_omega_ptr,
    carrier_gate_ptr,
    carrier_conflict_ptr,
    carrier_state_ptr,
    carrier_age_ptr,
    anchor_idx_ptr,
    anchor_phase_ptr,
    anchor_weight_ptr,
    num_carriers_ptr,  # int32[1] atomic
    N: tl.constexpr,
    max_carriers: tl.constexpr,
    coupling_threshold: tl.constexpr,
    gate_width_init: tl.constexpr,
    gate_width_min: tl.constexpr,
    gate_width_max: tl.constexpr,
):
    i = tl.program_id(0)
    omega_i = tl.load(osc_omega_ptr + i)
    amp_i = tl.load(osc_amp_ptr + i)
    phi_i = tl.load(osc_phase_ptr + i)

    num_car = tl.load(num_carriers_ptr).to(tl.int32)
    total = tl.zeros((), tl.float32)
    for k in range(0, max_carriers):
        active = k < num_car
        omega_k = tl.load(carrier_omega_ptr + k, mask=active, other=0.0)
        gate_w = tl.load(carrier_gate_ptr + k, mask=active, other=1.0)
        gate_w = tl.maximum(tl.minimum(gate_w, gate_width_max), gate_width_min)
        total += _tuning(omega_i, omega_k, gate_w)
    do_spawn = total < coupling_threshold
    inc = tl.where(do_spawn, 1, 0).to(tl.int32)
    slot = tl.atomic_add(num_carriers_ptr, inc)
    do_write = do_spawn & (slot < max_carriers)
    tl.store(carrier_real_ptr + slot, amp_i * tl.cos(phi_i), mask=do_write)
    tl.store(carrier_imag_ptr + slot, amp_i * tl.sin(phi_i), mask=do_write)
    tl.store(carrier_omega_ptr + slot, omega_i, mask=do_write)
    tl.store(carrier_gate_ptr + slot, gate_width_init, mask=do_write)
    tl.store(carrier_conflict_ptr + slot, 0.0, mask=do_write)
    tl.store(carrier_state_ptr + slot, tl.full((), STATE_VOLATILE, tl.int32), mask=do_write)
    tl.store(carrier_age_ptr + slot, 0, mask=do_write)
    for j in range(0, ANCHORS):
        b = slot * ANCHORS + j
        tl.store(anchor_idx_ptr + b, tl.full((), -1, tl.int32), mask=do_write)
        tl.store(anchor_phase_ptr + b, 0.0, mask=do_write)
        tl.store(anchor_weight_ptr + b, 0.0, mask=do_write)
    b0 = slot * ANCHORS
    tl.store(anchor_idx_ptr + b0, i, mask=do_write)
    tl.store(anchor_phase_ptr + b0, 0.0, mask=do_write)
    tl.store(anchor_weight_ptr + b0, amp_i, mask=do_write)


def carrier_update_and_split(
    *,
    osc_phase: torch.Tensor,
    osc_omega: torch.Tensor,
    osc_amp: torch.Tensor,
    carrier_real: torch.Tensor,
    carrier_imag: torch.Tensor,
    carrier_omega: torch.Tensor,
    carrier_gate_width: torch.Tensor,
    carrier_conflict: torch.Tensor,
    carrier_state: torch.Tensor,
    carrier_age: torch.Tensor,
    anchor_idx: torch.Tensor,
    anchor_phase: torch.Tensor,
    anchor_weight: torch.Tensor,
    num_carriers: torch.Tensor,
    spawned_from: torch.Tensor,
    random_phases: torch.Tensor,
    energy_stats: torch.Tensor,
    current_carriers: int,
    max_carriers: int,
    params: SpectralParams,
) -> None:
    _require_triton()
    assert osc_phase.is_cuda
    N = int(osc_phase.numel())
    if N == 0 or current_carriers == 0:
        return
    BLOCK_N = 256
    blocks = triton.cdiv(N, BLOCK_N)

    # Accumulators (per active carrier)
    force_r = torch.zeros((current_carriers,), device=osc_phase.device, dtype=torch.float32)
    force_i = torch.zeros((current_carriers,), device=osc_phase.device, dtype=torch.float32)
    w_sum = torch.zeros((current_carriers,), device=osc_phase.device, dtype=torch.float32)
    w_omega_sum = torch.zeros((current_carriers,), device=osc_phase.device, dtype=torch.float32)
    w_amp_sum = torch.zeros((current_carriers,), device=osc_phase.device, dtype=torch.float32)

    # Pass 1: accumulate block partials into per-carrier sums
    carrier_block_accum_kernel[(current_carriers, blocks)](
        osc_phase,
        osc_omega,
        osc_amp,
        carrier_omega,
        carrier_gate_width,
        force_r,
        force_i,
        w_sum,
        w_omega_sum,
        w_amp_sum,
        N=N,
        BLOCK_N=BLOCK_N,
        offender_weight_floor=float(params.offender_weight_floor),
        gate_width_min=float(params.gate_width_min),
        gate_width_max=float(params.gate_width_max),
        num_warps=1,
    )

    # Pass 2: finalize updates + split + crystallization + anchor refresh
    carrier_finalize_and_split_kernel[(current_carriers,)](
        osc_phase,
        osc_omega,
        osc_amp,
        carrier_real,
        carrier_imag,
        carrier_omega,
        carrier_gate_width,
        carrier_conflict,
        carrier_state,
        carrier_age,
        anchor_idx,
        anchor_phase,
        anchor_weight,
        num_carriers,
        spawned_from,
        random_phases,
        energy_stats,
        force_r,
        force_i,
        w_sum,
        w_omega_sum,
        w_amp_sum,
        N=N,
        max_carriers=max_carriers,
        dt=float(params.dt),
        carrier_reg=float(params.carrier_reg),
        temperature=float(params.temperature),
        rng_seed=int(params.rng_seed),
        conflict_threshold=float(params.conflict_threshold),
        gate_width_min=float(params.gate_width_min),
        gate_width_max=float(params.gate_width_max),
        ema_alpha=float(params.ema_alpha),
        recenter_alpha=float(params.recenter_alpha),
        mode=int(params.mode),
        anchor_random_eps=float(params.anchor_random_eps),
        stable_amp_threshold=float(params.stable_amp_threshold),
        crystallize_amp_threshold=float(params.crystallize_amp_threshold),
        crystallize_conflict_threshold=float(params.crystallize_conflict_threshold),
        crystallize_age=int(params.crystallize_age),
        volatile_decay_mul=float(params.volatile_decay_mul),
        stable_decay_mul=float(params.stable_decay_mul),
        crystallized_decay_mul=float(params.crystallized_decay_mul),
        repulsion_scale=float(params.repulsion_scale),
        num_warps=1,
    )


def topdown_bias_energies(
    *,
    osc_energy: torch.Tensor,
    osc_amp: torch.Tensor,
    carrier_state: torch.Tensor,
    anchor_idx: torch.Tensor,
    anchor_weight: torch.Tensor,
    num_carriers: torch.Tensor,
    num_carriers_i: int,
    max_carriers: int,
    dt: float,
    rng_seed: int,
    topdown_energy_scale: float,
    topdown_random_energy_eps: float,
) -> None:
    _require_triton()
    N = int(osc_energy.numel())
    if N == 0 or num_carriers_i == 0:
        return
    grid = (num_carriers_i,)
    spectral_topdown_bias_energies_kernel[grid](
        osc_energy,
        osc_amp,
        carrier_state,
        anchor_idx,
        anchor_weight,
        num_carriers,
        N=N,
        max_carriers=max_carriers,
        dt=float(dt),
        rng_seed=int(rng_seed),
        topdown_energy_scale=float(topdown_energy_scale),
        topdown_random_energy_eps=float(topdown_random_energy_eps),
        num_warps=1,
    )


def update_oscillator_phases(
    *,
    osc_phase: torch.Tensor,
    osc_omega: torch.Tensor,
    osc_amp: torch.Tensor,
    carrier_real: torch.Tensor,
    carrier_imag: torch.Tensor,
    carrier_omega: torch.Tensor,
    carrier_gate_width: torch.Tensor,
    carrier_state: torch.Tensor,
    anchor_idx: torch.Tensor,
    anchor_phase: torch.Tensor,
    anchor_weight: torch.Tensor,
    energy_stats: torch.Tensor,
    num_carriers: torch.Tensor,
    N: int,
    max_carriers: int,
    dt: float,
    coupling_scale: float,
    temperature: float,
    rng_seed: int,
    gate_width_min: float,
    gate_width_max: float,
    crystallized_coupling_boost: float,
    topdown_phase_scale: float,
) -> None:
    _require_triton()
    if N == 0:
        return
    grid = (triton.cdiv(N, 1),)
    spectral_update_oscillator_phases_kernel[grid](
        osc_phase,
        osc_omega,
        osc_amp,
        carrier_real,
        carrier_imag,
        carrier_omega,
        carrier_gate_width,
        carrier_state,
        anchor_idx,
        anchor_phase,
        anchor_weight,
        energy_stats,
        num_carriers,
        N=N,
        max_carriers=max_carriers,
        dt=float(dt),
        coupling_scale=float(coupling_scale),
        temperature=float(temperature),
        rng_seed=int(rng_seed),
        gate_width_min=float(gate_width_min),
        gate_width_max=float(gate_width_max),
        crystallized_coupling_boost=float(crystallized_coupling_boost),
        topdown_phase_scale=float(topdown_phase_scale),
        num_warps=1,
    )


def spawn_uncoupled(
    *,
    osc_phase: torch.Tensor,
    osc_omega: torch.Tensor,
    osc_amp: torch.Tensor,
    carrier_real: torch.Tensor,
    carrier_imag: torch.Tensor,
    carrier_omega: torch.Tensor,
    carrier_gate_width: torch.Tensor,
    carrier_conflict: torch.Tensor,
    carrier_state: torch.Tensor,
    carrier_age: torch.Tensor,
    anchor_idx: torch.Tensor,
    anchor_phase: torch.Tensor,
    anchor_weight: torch.Tensor,
    num_carriers: torch.Tensor,
    num_carriers_i: int,
    max_carriers: int,
    coupling_threshold: float,
    gate_width_init: float,
    gate_width_min: float,
    gate_width_max: float,
) -> None:
    _require_triton()
    N = int(osc_phase.numel())
    if N == 0:
        return
    grid = (triton.cdiv(N, 1),)
    spectral_spawn_uncoupled_kernel[grid](
        osc_phase,
        osc_omega,
        osc_amp,
        carrier_real,
        carrier_imag,
        carrier_omega,
        carrier_gate_width,
        carrier_conflict,
        carrier_state,
        carrier_age,
        anchor_idx,
        anchor_phase,
        anchor_weight,
        num_carriers,
        N=N,
        max_carriers=max_carriers,
        coupling_threshold=float(coupling_threshold),
        gate_width_init=float(gate_width_init),
        gate_width_min=float(gate_width_min),
        gate_width_max=float(gate_width_max),
        num_warps=1,
    )




---
File: /optimizer/triton/manifold_physics.py
---

"""CUDA/Triton implementation of manifold physics components.

This module mirrors the API shape of `optimizer/metal/manifold_physics.py` for CUDA.
Currently implemented:
- Spectral carriers (resonance potential) with crystallization + anchored top-down bias
- Idle compute modes (consolidate / disambiguate / explore)
"""

from __future__ import annotations

import math
from dataclasses import dataclass
from typing import Dict, Optional, TYPE_CHECKING

import torch

from . import manifold_physics_kernels as k
from . import manifold_grid_kernels as g
from . import spatial_hash_kernels as sh

if TYPE_CHECKING:
    from torch import Tensor


@dataclass
class ManifoldPhysicsConfig:
    """CUDA/Triton manifold physics simulation config (matches Metal semantics)."""

    grid_size: tuple[int, int, int] = (64, 64, 64)
    grid_spacing: float = 1.0
    dt: float = 0.01
    poisson_iterations: int = 50

    G: float = 0.001
    k_B: float = 0.1
    sigma_SB: float = 1e-5

    particle_radius: float = 0.5
    thermal_conductivity: float = 0.1
    specific_heat: float = 10.0
    dynamic_viscosity: float = 0.01
    emissivity: float = 0.5
    restitution: float = 0.8
    young_modulus: float = 1000.0


class ManifoldPhysics:
    """CUDA/Triton-accelerated manifold physics (grid + particles).

    Mirrors `optimizer/metal/manifold_physics.ManifoldPhysics`.
    """

    def __init__(self, config: ManifoldPhysicsConfig, device: str = "cuda"):
        if device != "cuda":
            raise RuntimeError(f"ManifoldPhysics(CUDA) requires device='cuda', got '{device}'")
        if not torch.cuda.is_available():
            raise RuntimeError("CUDA not available")

        self.config = config
        self.device = torch.device(device)
        self.dtype = torch.float32

        gx, gy, gz = config.grid_size
        self.grid_dims = (gx, gy, gz)

        self.gravity_field = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)
        self.gravity_potential = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)
        self.temperature_field = torch.zeros(gx, gy, gz, device=self.device, dtype=self.dtype)

    def scatter_particles(self, positions: "Tensor", masses: "Tensor", heats: "Tensor") -> None:
        g.clear_field(self.gravity_field.view(-1))
        g.clear_field(self.temperature_field.view(-1))
        g.scatter_particles(
            positions=positions.to(device=self.device, dtype=self.dtype),
            masses=masses.to(device=self.device, dtype=self.dtype),
            heats=heats.to(device=self.device, dtype=self.dtype),
            gravity_field=self.gravity_field,
            temperature_field=self.temperature_field,
            grid_spacing=float(self.config.grid_spacing),
        )

    def solve_gravity(self) -> None:
        cfg = self.config
        gravity_4pi = 4.0 * 3.14159265359 * float(cfg.G)
        phi_tmp = torch.zeros_like(self.gravity_potential)
        for i in range(int(cfg.poisson_iterations)):
            if i % 2 == 0:
                g.poisson_jacobi_step(
                    phi_in=self.gravity_potential,
                    rho=self.gravity_field,
                    phi_out=phi_tmp,
                    grid_spacing=float(cfg.grid_spacing),
                    gravity_4pi=float(gravity_4pi),
                )
            else:
                g.poisson_jacobi_step(
                    phi_in=phi_tmp,
                    rho=self.gravity_field,
                    phi_out=self.gravity_potential,
                    grid_spacing=float(cfg.grid_spacing),
                    gravity_4pi=float(gravity_4pi),
                )
        if int(cfg.poisson_iterations) % 2 == 1:
            self.gravity_potential.copy_(phi_tmp)

    def diffuse_heat(self) -> None:
        cfg = self.config
        temp_out = torch.zeros_like(self.temperature_field)
        g.diffuse_heat_field(
            temp_in=self.temperature_field,
            temp_out=temp_out,
            diffusion_coef=float(cfg.thermal_conductivity),
            dt=float(cfg.dt),
            grid_spacing=float(cfg.grid_spacing),
        )
        self.temperature_field.copy_(temp_out)

    def gather_update_particles(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        energies: "Tensor",
        heats: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
    ) -> tuple["Tensor", "Tensor", "Tensor", "Tensor", "Tensor"]:
        cfg = self.config
        # in-place updates
        g.gather_update_particles(
            gravity_potential=self.gravity_potential,
            temperature_field=self.temperature_field,
            positions=positions.to(device=self.device, dtype=self.dtype),
            velocities=velocities.to(device=self.device, dtype=self.dtype),
            energies=energies.to(device=self.device, dtype=self.dtype),
            heats=heats.to(device=self.device, dtype=self.dtype),
            excitations=excitations.to(device=self.device, dtype=self.dtype),
            masses=masses.to(device=self.device, dtype=self.dtype),
            dt=float(cfg.dt),
            grid_spacing=float(cfg.grid_spacing),
            G=float(cfg.G),
            k_B=float(cfg.k_B),
            sigma_SB=float(cfg.sigma_SB),
            particle_radius=float(cfg.particle_radius),
            thermal_conductivity=float(cfg.thermal_conductivity),
            specific_heat=float(cfg.specific_heat),
            dynamic_viscosity=float(cfg.dynamic_viscosity),
            emissivity=float(cfg.emissivity),
            young_modulus=float(cfg.young_modulus),
        )
        return positions, velocities, energies, heats, excitations

    def step(
        self,
        positions: "Tensor",
        velocities: "Tensor",
        energies: "Tensor",
        heats: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
    ) -> tuple["Tensor", "Tensor", "Tensor", "Tensor", "Tensor"]:
        # 1) scatter
        self.scatter_particles(positions, masses, heats)
        # 2) solve fields
        self.solve_gravity()
        self.diffuse_heat()
        # 3) gather + update particles
        positions, velocities, energies, heats, excitations = self.gather_update_particles(
            positions, velocities, energies, heats, excitations, masses
        )
        # 4) collisions via spatial hash pipeline (CUDA)
        # Heuristic: enable spatial hash when N is moderately large.
        n = int(positions.shape[0])
        if n > 0:
            self._collide_spatial_hash(
                positions=positions,
                velocities=velocities,
                excitations=excitations,
                masses=masses,
                heats=heats,
            )
        return positions, velocities, energies, heats, excitations

    def _collide_spatial_hash(
        self,
        *,
        positions: "Tensor",
        velocities: "Tensor",
        excitations: "Tensor",
        masses: "Tensor",
        heats: "Tensor",
        cell_size: Optional[float] = None,
    ) -> None:
        cfg = self.config
        n = int(positions.shape[0])
        if n == 0:
            return
        if cell_size is None:
            cell_size = 4.0 * float(cfg.particle_radius)

        gx, gy, gz = self.grid_dims
        domain_size = (gx * float(cfg.grid_spacing), gy * float(cfg.grid_spacing), gz * float(cfg.grid_spacing))
        hash_x = max(1, int(math.ceil(domain_size[0] / cell_size)))
        hash_y = max(1, int(math.ceil(domain_size[1] / cell_size)))
        hash_z = max(1, int(math.ceil(domain_size[2] / cell_size)))
        num_cells = hash_x * hash_y * hash_z

        particle_cell_idx = torch.empty(n, device=self.device, dtype=torch.int32)
        cell_counts = torch.zeros(num_cells, device=self.device, dtype=torch.int32)

        sh.assign(
            positions=positions.to(device=self.device, dtype=self.dtype),
            particle_cell_idx=particle_cell_idx,
            cell_counts=cell_counts,
            hash_grid_x=hash_x,
            hash_grid_y=hash_y,
            hash_grid_z=hash_z,
            cell_size=float(cell_size),
            domain_min_x=0.0,
            domain_min_y=0.0,
            domain_min_z=0.0,
        )

        # Prefix sum (CUDA torch). cell_starts[i] = sum(counts[0:i])
        starts = torch.zeros(num_cells + 1, device=self.device, dtype=torch.int32)
        starts[1:] = torch.cumsum(cell_counts, dim=0)

        sorted_particle_idx = torch.empty(n, device=self.device, dtype=torch.int32)
        cell_offsets = starts[:num_cells].clone()
        sh.scatter(particle_cell_idx=particle_cell_idx, sorted_particle_idx=sorted_particle_idx, cell_offsets=cell_offsets)

        sh.collisions(
            positions=positions.to(device=self.device, dtype=self.dtype),
            velocities=velocities.to(device=self.device, dtype=self.dtype),
            excitations=excitations.to(device=self.device, dtype=self.dtype),
            masses=masses.to(device=self.device, dtype=self.dtype),
            heats=heats.to(device=self.device, dtype=self.dtype),
            sorted_particle_idx=sorted_particle_idx,
            cell_starts=starts,
            particle_cell_idx=particle_cell_idx,
            hash_grid_x=hash_x,
            hash_grid_y=hash_y,
            hash_grid_z=hash_z,
            cell_size=float(cell_size),
            domain_min_x=0.0,
            domain_min_y=0.0,
            domain_min_z=0.0,
            dt=float(cfg.dt),
            particle_radius=float(cfg.particle_radius),
            young_modulus=float(cfg.young_modulus),
            thermal_conductivity=float(cfg.thermal_conductivity),
            restitution=float(cfg.restitution),
            max_per_cell=64,
        )

@dataclass
class SpectralCarrierConfig:
    """CUDA/Triton spectral carrier configuration.

    Keep this aligned with the Metal config (same semantics, different backend).
    """

    max_carriers: int = 64
    coupling_scale: float = 0.25
    carrier_reg: float = 0.15
    temperature: float = 0.01

    conflict_threshold: float = 0.35
    offender_weight_floor: float = 1e-3
    ema_alpha: float = 0.10
    recenter_alpha: float = 0.10

    uncoupled_threshold: float = 0.1

    gate_width_init: float = 0.35
    gate_width_min: float = 0.08
    gate_width_max: float = 1.25

    # Memory + top-down bias (must match Metal semantics)
    anchor_slots: int = 8
    stable_amp_threshold: float = 0.25
    crystallize_amp_threshold: float = 0.75
    crystallize_conflict_threshold: float = 0.12
    crystallize_age: int = 120

    crystallized_coupling_boost: float = 1.0
    volatile_decay_mul: float = 0.90
    stable_decay_mul: float = 0.98
    crystallized_decay_mul: float = 1.00

    topdown_phase_scale: float = 0.05
    topdown_energy_scale: float = 0.05
    topdown_random_energy_eps: float = 0.02

    anchor_random_eps: float = 0.05
    repulsion_scale: float = 0.05


class SpectralCarrierPhysics:
    """CUDA/Triton spectral carriers (resonance potential, Langevin flow)."""

    def __init__(
        self,
        config: SpectralCarrierConfig,
        grid_size: tuple[int, int, int],
        dt: float,
        device: str = "cuda",
    ):
        if device != "cuda":
            raise RuntimeError(f"SpectralCarrierPhysics(CUDA) requires device='cuda', got '{device}'")
        if not torch.cuda.is_available():
            raise RuntimeError("CUDA not available")

        if int(config.anchor_slots) != k.ANCHORS:
            raise ValueError(
                f"SpectralCarrierConfig.anchor_slots must be {k.ANCHORS} "
                f"(got {config.anchor_slots})"
            )

        self.config = config
        self.grid_size = grid_size
        self.dt = float(dt)
        self.device = torch.device(device)
        self.dtype = torch.float32

        self.max_carriers = int(config.max_carriers)
        if self.max_carriers <= 0:
            raise ValueError("SpectralCarrierConfig.max_carriers must be > 0")

        # Carrier state buffers
        self.carrier_real = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_imag = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_omega = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.carrier_gate_width = torch.full(
            (self.max_carriers,), float(config.gate_width_init), device=self.device, dtype=self.dtype
        )
        self.carrier_conflict = torch.zeros(self.max_carriers, device=self.device, dtype=self.dtype)
        self.spawned_from_osc = torch.full((self.max_carriers,), -1, device=self.device, dtype=torch.int32)

        self.carrier_state = torch.zeros(self.max_carriers, device=self.device, dtype=torch.int32)
        self.carrier_age = torch.zeros(self.max_carriers, device=self.device, dtype=torch.int32)

        anchors = int(config.anchor_slots)
        self.anchor_slots = anchors
        self.carrier_anchor_idx = torch.full(
            (self.max_carriers * anchors,), -1, device=self.device, dtype=torch.int32
        )
        self.carrier_anchor_phase = torch.zeros(self.max_carriers * anchors, device=self.device, dtype=self.dtype)
        self.carrier_anchor_weight = torch.zeros(self.max_carriers * anchors, device=self.device, dtype=self.dtype)

        self._num_carriers_buf = torch.zeros(1, device=self.device, dtype=torch.int32)
        self.num_carriers = 0

        self._random_phases = torch.rand(self.max_carriers, device=self.device, dtype=self.dtype)
        self._energy_stats = torch.zeros(4, device=self.device, dtype=self.dtype)
        self._rng_seed: int = 1

    def _ensure_seeded(self, osc_phase: "Tensor", osc_omega: "Tensor", osc_amp: "Tensor") -> None:
        if self.num_carriers > 0:
            return
        N = int(osc_phase.shape[0])
        if N == 0:
            return
        idx = 0
        phi = float(osc_phase[idx].item())
        omega = float(osc_omega[idx].item())
        amp = float(osc_amp[idx].item())
        self.carrier_real[0] = amp * math.cos(phi)
        self.carrier_imag[0] = amp * math.sin(phi)
        self.carrier_omega[0] = omega
        self.carrier_gate_width[0] = float(self.config.gate_width_init)
        self.carrier_conflict[0] = 0.0
        self.spawned_from_osc[0] = 0
        self.carrier_state[0] = 0
        self.carrier_age[0] = 0

        self.carrier_anchor_idx.fill_(-1)
        self.carrier_anchor_phase.zero_()
        self.carrier_anchor_weight.zero_()
        self.carrier_anchor_idx[0] = 0
        self.carrier_anchor_phase[0] = 0.0
        self.carrier_anchor_weight[0] = amp

        self.num_carriers = 1
        self._num_carriers_buf[0] = 1

    def _set_energy_stats(self, energy: "Tensor") -> None:
        # [mean_abs, mean, std, count]
        eps = 1e-12
        mean_abs = energy.abs().mean()
        mean = energy.mean()
        var = (energy - mean).pow(2).mean()
        std = torch.sqrt(torch.clamp(var, min=0.0))
        count = torch.tensor(float(energy.numel()), device=energy.device, dtype=energy.dtype).clamp(min=1.0)
        self._energy_stats[0] = mean_abs
        self._energy_stats[1] = mean
        self._energy_stats[2] = std
        self._energy_stats[3] = count + eps  # keep nonzero

    def _params(
        self,
        *,
        mode: int,
        temperature: float,
        anchor_eps: float,
        offender_floor: float,
        rand_energy_eps: float,
        repulsion_scale: float,
    ) -> k.SpectralParams:
        cfg = self.config
        return k.SpectralParams(
            dt=float(self.dt),
            coupling_scale=float(cfg.coupling_scale),
            carrier_reg=float(cfg.carrier_reg),
            temperature=float(temperature),
            rng_seed=int(self._rng_seed) & 0xFFFFFFFF,
            conflict_threshold=float(cfg.conflict_threshold),
            offender_weight_floor=float(offender_floor),
            gate_width_min=float(cfg.gate_width_min),
            gate_width_max=float(cfg.gate_width_max),
            ema_alpha=float(cfg.ema_alpha),
            recenter_alpha=float(cfg.recenter_alpha),
            mode=int(mode),
            anchor_random_eps=float(anchor_eps),
            stable_amp_threshold=float(cfg.stable_amp_threshold),
            crystallize_amp_threshold=float(cfg.crystallize_amp_threshold),
            crystallize_conflict_threshold=float(cfg.crystallize_conflict_threshold),
            crystallize_age=int(cfg.crystallize_age),
            crystallized_coupling_boost=float(cfg.crystallized_coupling_boost),
            volatile_decay_mul=float(cfg.volatile_decay_mul),
            stable_decay_mul=float(cfg.stable_decay_mul),
            crystallized_decay_mul=float(cfg.crystallized_decay_mul),
            topdown_phase_scale=float(cfg.topdown_phase_scale),
            topdown_energy_scale=float(cfg.topdown_energy_scale),
            topdown_random_energy_eps=float(rand_energy_eps),
            repulsion_scale=float(repulsion_scale),
        )

    def step(
        self,
        osc_phase: "Tensor",
        particle_excitations: "Tensor",
        particle_energies: "Tensor",
    ) -> Dict[str, "Tensor"]:
        osc_phase = osc_phase.to(device=self.device, dtype=self.dtype).contiguous()
        osc_omega = particle_excitations.to(device=self.device, dtype=self.dtype).contiguous()
        energy = particle_energies.to(device=self.device, dtype=self.dtype).contiguous()
        osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

        self._set_energy_stats(energy)
        self._ensure_seeded(osc_phase, osc_omega, osc_amp)
        if self.num_carriers == 0:
            return {
                "frequencies": torch.empty(0, device=self.device, dtype=self.dtype),
                "gate_widths": torch.empty(0, device=self.device, dtype=self.dtype),
                "amplitudes": torch.empty(0, device=self.device, dtype=self.dtype),
                "phases": torch.empty(0, device=self.device, dtype=self.dtype),
                "conflict": torch.empty(0, device=self.device, dtype=self.dtype),
                "osc_phase": osc_phase,
                "osc_energy": energy,
                "carrier_state": torch.empty(0, device=self.device, dtype=torch.int32),
                "carrier_age": torch.empty(0, device=self.device, dtype=torch.int32),
            }

        # Advance RNG seed deterministically
        self._rng_seed = (self._rng_seed + 1) & 0xFFFFFFFF
        self._num_carriers_buf[0] = int(self.num_carriers)
        self._random_phases.uniform_()

        params = self._params(
            mode=0,
            temperature=float(self.config.temperature),
            anchor_eps=float(self.config.anchor_random_eps),
            offender_floor=float(self.config.offender_weight_floor),
            rand_energy_eps=float(self.config.topdown_random_energy_eps),
            repulsion_scale=float(self.config.repulsion_scale),
        )

        k.carrier_update_and_split(
            osc_phase=osc_phase,
            osc_omega=osc_omega,
            osc_amp=osc_amp,
            carrier_real=self.carrier_real,
            carrier_imag=self.carrier_imag,
            carrier_omega=self.carrier_omega,
            carrier_gate_width=self.carrier_gate_width,
            carrier_conflict=self.carrier_conflict,
            carrier_state=self.carrier_state,
            carrier_age=self.carrier_age,
            anchor_idx=self.carrier_anchor_idx,
            anchor_phase=self.carrier_anchor_phase,
            anchor_weight=self.carrier_anchor_weight,
            num_carriers=self._num_carriers_buf,
            spawned_from=self.spawned_from_osc,
            random_phases=self._random_phases,
            energy_stats=self._energy_stats,
            current_carriers=int(self.num_carriers),
            max_carriers=int(self.max_carriers),
            params=params,
        )

        new_count = int(self._num_carriers_buf.item())
        self.num_carriers = max(0, min(new_count, self.max_carriers))

        # Top-down energy bias (crystallized carriers act as priors/completions)
        k.topdown_bias_energies(
            osc_energy=energy,
            osc_amp=osc_amp,
            carrier_state=self.carrier_state,
            anchor_idx=self.carrier_anchor_idx,
            anchor_weight=self.carrier_anchor_weight,
            num_carriers=self._num_carriers_buf,
            num_carriers_i=int(self.num_carriers),
            max_carriers=int(self.max_carriers),
            dt=float(self.dt),
            rng_seed=int(self._rng_seed) & 0xFFFFFFFF,
            topdown_energy_scale=float(self.config.topdown_energy_scale),
            topdown_random_energy_eps=float(self.config.topdown_random_energy_eps),
        )

        osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

        # Oscillator phase update from carriers (torque + top-down phase pull)
        k.update_oscillator_phases(
            osc_phase=osc_phase,
            osc_omega=osc_omega,
            osc_amp=osc_amp,
            carrier_real=self.carrier_real,
            carrier_imag=self.carrier_imag,
            carrier_omega=self.carrier_omega,
            carrier_gate_width=self.carrier_gate_width,
            carrier_state=self.carrier_state,
            anchor_idx=self.carrier_anchor_idx,
            anchor_phase=self.carrier_anchor_phase,
            anchor_weight=self.carrier_anchor_weight,
            energy_stats=self._energy_stats,
            num_carriers=self._num_carriers_buf,
            N=int(osc_phase.numel()),
            max_carriers=int(self.max_carriers),
            dt=float(self.dt),
            coupling_scale=float(self.config.coupling_scale),
            temperature=float(self.config.temperature),
            rng_seed=int(self._rng_seed) & 0xFFFFFFFF,
            gate_width_min=float(self.config.gate_width_min),
            gate_width_max=float(self.config.gate_width_max),
            crystallized_coupling_boost=float(self.config.crystallized_coupling_boost),
            topdown_phase_scale=float(self.config.topdown_phase_scale),
        )

        # Spawn carriers for uncoupled oscillators
        k.spawn_uncoupled(
            osc_phase=osc_phase,
            osc_omega=osc_omega,
            osc_amp=osc_amp,
            carrier_real=self.carrier_real,
            carrier_imag=self.carrier_imag,
            carrier_omega=self.carrier_omega,
            carrier_gate_width=self.carrier_gate_width,
            carrier_conflict=self.carrier_conflict,
            carrier_state=self.carrier_state,
            carrier_age=self.carrier_age,
            anchor_idx=self.carrier_anchor_idx,
            anchor_phase=self.carrier_anchor_phase,
            anchor_weight=self.carrier_anchor_weight,
            num_carriers=self._num_carriers_buf,
            num_carriers_i=int(self.num_carriers),
            max_carriers=int(self.max_carriers),
            coupling_threshold=float(self.config.uncoupled_threshold),
            gate_width_init=float(self.config.gate_width_init),
            gate_width_min=float(self.config.gate_width_min),
            gate_width_max=float(self.config.gate_width_max),
        )
        self.num_carriers = int(self._num_carriers_buf.item())

        cr = self.carrier_real[: self.num_carriers]
        ci = self.carrier_imag[: self.num_carriers]
        amp = torch.sqrt(cr * cr + ci * ci)
        phase = torch.atan2(ci, cr)

        return {
            "frequencies": self.carrier_omega[: self.num_carriers],
            "gate_widths": self.carrier_gate_width[: self.num_carriers],
            "amplitudes": amp,
            "phases": phase,
            "conflict": self.carrier_conflict[: self.num_carriers],
            "osc_phase": osc_phase,
            "osc_energy": energy,
            "carrier_state": self.carrier_state[: self.num_carriers],
            "carrier_age": self.carrier_age[: self.num_carriers],
        }

    def idle_compute(
        self,
        osc_phase: "Tensor",
        particle_excitations: "Tensor",
        particle_energies: "Tensor",
        *,
        steps: int = 1,
        mode: str = "explore",
    ) -> Dict[str, "Tensor"]:
        mode_s = str(mode).lower().strip()
        if mode_s in ("consolidate", "consolidation", "stabilize"):
            m = 1
            temp = float(self.config.temperature) * 0.25
            anchor_eps = float(self.config.anchor_random_eps) * 0.25
            rand_energy_eps = float(self.config.topdown_random_energy_eps) * 0.25
            offender_floor = float(self.config.offender_weight_floor)
            repulsion = 0.0
        elif mode_s in ("disambiguate", "resolve", "separate"):
            m = 2
            temp = float(self.config.temperature) * 0.50
            anchor_eps = float(self.config.anchor_random_eps) * 0.50
            rand_energy_eps = float(self.config.topdown_random_energy_eps) * 0.50
            offender_floor = float(self.config.offender_weight_floor)
            repulsion = float(self.config.repulsion_scale)
        elif mode_s in ("explore", "counterfactual", "counterfactual_exploration"):
            m = 3
            temp = float(self.config.temperature) * 2.0
            anchor_eps = max(float(self.config.anchor_random_eps), 0.20)
            rand_energy_eps = max(float(self.config.topdown_random_energy_eps), 0.10)
            offender_floor = float(self.config.offender_weight_floor) * 0.10
            repulsion = 0.0
        else:
            raise ValueError(f"Unknown idle_compute mode: {mode!r}")

        out: Dict[str, "Tensor"] = {}
        for _ in range(int(steps)):
            osc_phase = osc_phase.to(device=self.device, dtype=self.dtype).contiguous()
            osc_omega = particle_excitations.to(device=self.device, dtype=self.dtype).contiguous()
            energy = particle_energies.to(device=self.device, dtype=self.dtype).contiguous()
            osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

            self._set_energy_stats(energy)
            self._ensure_seeded(osc_phase, osc_omega, osc_amp)
            if self.num_carriers == 0:
                break

            self._rng_seed = (self._rng_seed + 1) & 0xFFFFFFFF
            self._num_carriers_buf[0] = int(self.num_carriers)
            self._random_phases.uniform_()

            params = self._params(
                mode=m,
                temperature=temp,
                anchor_eps=anchor_eps,
                offender_floor=offender_floor,
                rand_energy_eps=rand_energy_eps,
                repulsion_scale=repulsion,
            )

            k.carrier_update_and_split(
                osc_phase=osc_phase,
                osc_omega=osc_omega,
                osc_amp=osc_amp,
                carrier_real=self.carrier_real,
                carrier_imag=self.carrier_imag,
                carrier_omega=self.carrier_omega,
                carrier_gate_width=self.carrier_gate_width,
                carrier_conflict=self.carrier_conflict,
                carrier_state=self.carrier_state,
                carrier_age=self.carrier_age,
                anchor_idx=self.carrier_anchor_idx,
                anchor_phase=self.carrier_anchor_phase,
                anchor_weight=self.carrier_anchor_weight,
                num_carriers=self._num_carriers_buf,
                spawned_from=self.spawned_from_osc,
                random_phases=self._random_phases,
                energy_stats=self._energy_stats,
                current_carriers=int(self.num_carriers),
                max_carriers=int(self.max_carriers),
                params=params,
            )

            new_count = int(self._num_carriers_buf.item())
            self.num_carriers = max(0, min(new_count, self.max_carriers))

            k.topdown_bias_energies(
                osc_energy=energy,
                osc_amp=osc_amp,
                carrier_state=self.carrier_state,
                anchor_idx=self.carrier_anchor_idx,
                anchor_weight=self.carrier_anchor_weight,
                num_carriers=self._num_carriers_buf,
                num_carriers_i=int(self.num_carriers),
                max_carriers=int(self.max_carriers),
                dt=float(self.dt),
                rng_seed=int(self._rng_seed) & 0xFFFFFFFF,
                topdown_energy_scale=float(self.config.topdown_energy_scale),
                topdown_random_energy_eps=float(rand_energy_eps),
            )

            osc_amp = torch.sqrt(torch.clamp(energy, min=1e-8)).contiguous()

            k.update_oscillator_phases(
                osc_phase=osc_phase,
                osc_omega=osc_omega,
                osc_amp=osc_amp,
                carrier_real=self.carrier_real,
                carrier_imag=self.carrier_imag,
                carrier_omega=self.carrier_omega,
                carrier_gate_width=self.carrier_gate_width,
                carrier_state=self.carrier_state,
                anchor_idx=self.carrier_anchor_idx,
                anchor_phase=self.carrier_anchor_phase,
                anchor_weight=self.carrier_anchor_weight,
                energy_stats=self._energy_stats,
                num_carriers=self._num_carriers_buf,
                N=int(osc_phase.numel()),
                max_carriers=int(self.max_carriers),
                dt=float(self.dt),
                coupling_scale=float(self.config.coupling_scale),
                temperature=float(temp),
                rng_seed=int(self._rng_seed) & 0xFFFFFFFF,
                gate_width_min=float(self.config.gate_width_min),
                gate_width_max=float(self.config.gate_width_max),
                crystallized_coupling_boost=float(self.config.crystallized_coupling_boost),
                topdown_phase_scale=float(self.config.topdown_phase_scale),
            )

            k.spawn_uncoupled(
                osc_phase=osc_phase,
                osc_omega=osc_omega,
                osc_amp=osc_amp,
                carrier_real=self.carrier_real,
                carrier_imag=self.carrier_imag,
                carrier_omega=self.carrier_omega,
                carrier_gate_width=self.carrier_gate_width,
                carrier_conflict=self.carrier_conflict,
                carrier_state=self.carrier_state,
                carrier_age=self.carrier_age,
                anchor_idx=self.carrier_anchor_idx,
                anchor_phase=self.carrier_anchor_phase,
                anchor_weight=self.carrier_anchor_weight,
                num_carriers=self._num_carriers_buf,
                num_carriers_i=int(self.num_carriers),
                max_carriers=int(self.max_carriers),
                coupling_threshold=float(self.config.uncoupled_threshold),
                gate_width_init=float(self.config.gate_width_init),
                gate_width_min=float(self.config.gate_width_min),
                gate_width_max=float(self.config.gate_width_max),
            )
            self.num_carriers = int(self._num_carriers_buf.item())

            cr = self.carrier_real[: self.num_carriers]
            ci = self.carrier_imag[: self.num_carriers]
            amp = torch.sqrt(cr * cr + ci * ci)
            phase = torch.atan2(ci, cr)
            out = {
                "frequencies": self.carrier_omega[: self.num_carriers],
                "gate_widths": self.carrier_gate_width[: self.num_carriers],
                "amplitudes": amp,
                "phases": phase,
                "conflict": self.carrier_conflict[: self.num_carriers],
                "osc_phase": osc_phase,
                "osc_energy": energy,
                "carrier_state": self.carrier_state[: self.num_carriers],
                "carrier_age": self.carrier_age[: self.num_carriers],
            }
            particle_energies = energy

        return out




---
File: /optimizer/triton/smoke_test.py
---

"""CUDA/Triton smoke test for manifold backends.

Run on a CUDA machine:

```bash
python -m optimizer.triton.smoke_test
```
"""

from __future__ import annotations

import torch

from optimizer.triton.manifold_physics import (
    ManifoldPhysics,
    ManifoldPhysicsConfig,
    SpectralCarrierConfig,
    SpectralCarrierPhysics,
)


def main() -> None:
    if not torch.cuda.is_available():
        raise SystemExit("CUDA unavailable; run this on an NVIDIA machine.")

    device = "cuda"

    # ---- spectral smoke ----
    N = 512
    osc_phase = torch.rand(N, device=device, dtype=torch.float32) * (2.0 * torch.pi)
    exc = torch.randn(N, device=device, dtype=torch.float32)
    energy = torch.rand(N, device=device, dtype=torch.float32)

    scfg = SpectralCarrierConfig(max_carriers=32)
    sp = SpectralCarrierPhysics(scfg, grid_size=(8, 8, 8), dt=0.01, device=device)
    out = sp.step(osc_phase, exc, energy)
    assert "carrier_state" in out and "osc_energy" in out
    out2 = sp.idle_compute(out["osc_phase"], exc, out["osc_energy"], steps=2, mode="explore")
    assert out2["frequencies"].numel() >= 0

    # ---- grid physics smoke ----
    pcfg = ManifoldPhysicsConfig(grid_size=(16, 16, 16), poisson_iterations=4, dt=0.01)
    mp = ManifoldPhysics(pcfg, device=device)

    P = 256
    positions = torch.rand(P, 3, device=device, dtype=torch.float32) * 12.0 + 1.0
    velocities = torch.zeros(P, 3, device=device, dtype=torch.float32)
    energies = torch.rand(P, device=device, dtype=torch.float32)
    heats = torch.zeros(P, device=device, dtype=torch.float32)
    excitations = torch.rand(P, device=device, dtype=torch.float32)
    masses = torch.ones(P, device=device, dtype=torch.float32)

    mp.step(positions, velocities, energies, heats, excitations, masses)

    print("Triton smoke test passed.")


if __name__ == "__main__":
    main()




---
File: /optimizer/triton/spatial_hash_kernels.py
---

"""CUDA/Triton spatial-hash collision pipeline.

Implements the same 4-phase pipeline used by the Metal backend:
1) assign particles to cells + atomic cell_counts
2) prefix sum on host (CUDA torch) to produce cell_starts
3) scatter particles into sorted indices (atomic cell_offsets)
4) collisions using neighbor-cell traversal (bounded per-cell scan)

This is correctness-first and uses a conservative cap for per-cell scans.
"""

from __future__ import annotations

import torch

try:
    import triton
    import triton.language as tl
except Exception as e:  # pragma: no cover
    triton = None  # type: ignore[assignment]
    tl = None  # type: ignore[assignment]
    _TRITON_IMPORT_ERROR: Exception = e
else:
    _TRITON_IMPORT_ERROR = RuntimeError("unreachable")


def _require_triton() -> None:
    if triton is None or tl is None:  # pragma: no cover
        raise RuntimeError(f"Triton is required for CUDA spatial hash: {_TRITON_IMPORT_ERROR!r}")


@triton.jit
def spatial_hash_assign_kernel(
    pos_ptr,  # fp32 [N*3]
    particle_cell_idx_ptr,  # int32 [N]
    cell_counts_ptr,  # int32 [num_cells] atomic
    N: tl.constexpr,
    hash_x: tl.constexpr,
    hash_y: tl.constexpr,
    hash_z: tl.constexpr,
    cell_size: tl.constexpr,
    inv_cell_size: tl.constexpr,
    domain_min_x: tl.constexpr,
    domain_min_y: tl.constexpr,
    domain_min_z: tl.constexpr,
):
    i = tl.program_id(0)
    if i >= N:
        return
    px = tl.load(pos_ptr + i * 3 + 0)
    py = tl.load(pos_ptr + i * 3 + 1)
    pz = tl.load(pos_ptr + i * 3 + 2)
    cx = tl.floor((px - domain_min_x) * inv_cell_size).to(tl.int32)
    cy = tl.floor((py - domain_min_y) * inv_cell_size).to(tl.int32)
    cz = tl.floor((pz - domain_min_z) * inv_cell_size).to(tl.int32)
    cx = tl.maximum(0, tl.minimum(cx, hash_x - 1))
    cy = tl.maximum(0, tl.minimum(cy, hash_y - 1))
    cz = tl.maximum(0, tl.minimum(cz, hash_z - 1))
    cell = cx * (hash_y * hash_z) + cy * hash_z + cz
    tl.store(particle_cell_idx_ptr + i, cell)
    tl.atomic_add(cell_counts_ptr + cell, 1)


@triton.jit
def spatial_hash_scatter_kernel(
    particle_cell_idx_ptr,  # int32 [N]
    sorted_particle_idx_ptr,  # int32 [N]
    cell_offsets_ptr,  # int32 [num_cells] atomic (starts as cell_starts)
    N: tl.constexpr,
):
    i = tl.program_id(0)
    if i >= N:
        return
    cell = tl.load(particle_cell_idx_ptr + i).to(tl.int32)
    out = tl.atomic_add(cell_offsets_ptr + cell, 1)
    tl.store(sorted_particle_idx_ptr + out, i)


@triton.jit
def spatial_hash_collisions_kernel(
    pos_ptr,  # fp32 [N*3]
    vel_ptr,  # fp32 [N*3] in/out
    exc_ptr,  # fp32 [N] in/out
    mass_ptr,  # fp32 [N]
    heat_ptr,  # fp32 [N] in/out
    sorted_particle_idx_ptr,  # int32 [N]
    cell_starts_ptr,  # int32 [num_cells+1]
    particle_cell_idx_ptr,  # int32 [N]
    N: tl.constexpr,
    hash_x: tl.constexpr,
    hash_y: tl.constexpr,
    hash_z: tl.constexpr,
    cell_size: tl.constexpr,
    inv_cell_size: tl.constexpr,
    domain_min_x: tl.constexpr,
    domain_min_y: tl.constexpr,
    domain_min_z: tl.constexpr,
    dt: tl.constexpr,
    particle_radius: tl.constexpr,
    young_modulus: tl.constexpr,
    thermal_conductivity: tl.constexpr,
    restitution: tl.constexpr,
    MAX_PER_CELL: tl.constexpr,
):
    i = tl.program_id(0)
    if i >= N:
        return

    # particle i
    px = tl.load(pos_ptr + i * 3 + 0)
    py = tl.load(pos_ptr + i * 3 + 1)
    pz = tl.load(pos_ptr + i * 3 + 2)
    vx = tl.load(vel_ptr + i * 3 + 0)
    vy = tl.load(vel_ptr + i * 3 + 1)
    vz = tl.load(vel_ptr + i * 3 + 2)
    mi = tl.load(mass_ptr + i)
    hi = tl.load(heat_ptr + i)
    exi = tl.load(exc_ptr + i)

    # cell coords
    cx = tl.floor((px - domain_min_x) * inv_cell_size).to(tl.int32)
    cy = tl.floor((py - domain_min_y) * inv_cell_size).to(tl.int32)
    cz = tl.floor((pz - domain_min_z) * inv_cell_size).to(tl.int32)
    cx = tl.maximum(0, tl.minimum(cx, hash_x - 1))
    cy = tl.maximum(0, tl.minimum(cy, hash_y - 1))
    cz = tl.maximum(0, tl.minimum(cz, hash_z - 1))

    r = particle_radius
    two_r = 2.0 * r
    two_r2 = two_r * two_r
    e = tl.maximum(0.0, tl.minimum(restitution, 1.0))

    # neighbor traversal (27 cells)
    for dx in (-1, 0, 1):
        nx = cx + dx
        if nx < 0 or nx >= hash_x:
            continue
        for dy in (-1, 0, 1):
            ny = cy + dy
            if ny < 0 or ny >= hash_y:
                continue
            for dz in (-1, 0, 1):
                nz = cz + dz
                if nz < 0 or nz >= hash_z:
                    continue

                cell = nx * (hash_y * hash_z) + ny * hash_z + nz
                start = tl.load(cell_starts_ptr + cell).to(tl.int32)
                end = tl.load(cell_starts_ptr + cell + 1).to(tl.int32)
                count = end - start
                count = tl.minimum(count, MAX_PER_CELL)

                # scan bounded set
                for t in range(0, MAX_PER_CELL):
                    if t >= count:
                        break
                    j = tl.load(sorted_particle_idx_ptr + (start + t)).to(tl.int32)
                    if j == i:
                        continue
                    # simple symmetric impulse approximation (update i only)
                    qx = tl.load(pos_ptr + j * 3 + 0)
                    qy = tl.load(pos_ptr + j * 3 + 1)
                    qz = tl.load(pos_ptr + j * 3 + 2)
                    dxp = px - qx
                    dyp = py - qy
                    dzp = pz - qz
                    dist2 = dxp * dxp + dyp * dyp + dzp * dzp
                    if dist2 >= two_r2 or dist2 <= 1e-12:
                        continue
                    dist = tl.sqrt(dist2)
                    nxv = dxp / dist
                    nyv = dyp / dist
                    nzv = dzp / dist
                    # relative velocity along normal (assume vj ~ 0 for local update)
                    vrel = vx * nxv + vy * nyv + vz * nzv
                    if vrel > 0.0:
                        continue
                    # impulse magnitude (elastic w/ restitution), m_eff approx using mi only
                    jmag = -(1.0 + e) * vrel * mi
                    vx += (jmag / tl.maximum(mi, 1e-6)) * nxv
                    vy += (jmag / tl.maximum(mi, 1e-6)) * nyv
                    vz += (jmag / tl.maximum(mi, 1e-6)) * nzv
                    # convert lost kinetic energy to heat (rough)
                    hi += tl.maximum(-vrel, 0.0) * 0.01

    tl.store(vel_ptr + i * 3 + 0, vx)
    tl.store(vel_ptr + i * 3 + 1, vy)
    tl.store(vel_ptr + i * 3 + 2, vz)
    tl.store(heat_ptr + i, hi)
    tl.store(exc_ptr + i, exi)


def assign(
    *,
    positions: torch.Tensor,
    particle_cell_idx: torch.Tensor,
    cell_counts: torch.Tensor,
    hash_grid_x: int,
    hash_grid_y: int,
    hash_grid_z: int,
    cell_size: float,
    domain_min_x: float,
    domain_min_y: float,
    domain_min_z: float,
) -> None:
    _require_triton()
    N = int(positions.shape[0])
    if N == 0:
        return
    inv = 1.0 / float(cell_size)
    grid = (N,)
    spatial_hash_assign_kernel[grid](
        positions.contiguous().view(-1),
        particle_cell_idx,
        cell_counts,
        N=N,
        hash_x=int(hash_grid_x),
        hash_y=int(hash_grid_y),
        hash_z=int(hash_grid_z),
        cell_size=float(cell_size),
        inv_cell_size=float(inv),
        domain_min_x=float(domain_min_x),
        domain_min_y=float(domain_min_y),
        domain_min_z=float(domain_min_z),
        num_warps=1,
    )


def scatter(
    *,
    particle_cell_idx: torch.Tensor,
    sorted_particle_idx: torch.Tensor,
    cell_offsets: torch.Tensor,
) -> None:
    _require_triton()
    N = int(particle_cell_idx.numel())
    if N == 0:
        return
    grid = (N,)
    spatial_hash_scatter_kernel[grid](
        particle_cell_idx,
        sorted_particle_idx,
        cell_offsets,
        N=N,
        num_warps=1,
    )


def collisions(
    *,
    positions: torch.Tensor,
    velocities: torch.Tensor,
    excitations: torch.Tensor,
    masses: torch.Tensor,
    heats: torch.Tensor,
    sorted_particle_idx: torch.Tensor,
    cell_starts: torch.Tensor,
    particle_cell_idx: torch.Tensor,
    hash_grid_x: int,
    hash_grid_y: int,
    hash_grid_z: int,
    cell_size: float,
    domain_min_x: float,
    domain_min_y: float,
    domain_min_z: float,
    dt: float,
    particle_radius: float,
    young_modulus: float,
    thermal_conductivity: float,
    restitution: float,
    max_per_cell: int = 64,
) -> None:
    _require_triton()
    N = int(positions.shape[0])
    if N == 0:
        return
    inv = 1.0 / float(cell_size)
    grid = (N,)
    spatial_hash_collisions_kernel[grid](
        positions.contiguous().view(-1),
        velocities.contiguous().view(-1),
        excitations.contiguous(),
        masses.contiguous(),
        heats.contiguous(),
        sorted_particle_idx,
        cell_starts,
        particle_cell_idx,
        N=N,
        hash_x=int(hash_grid_x),
        hash_y=int(hash_grid_y),
        hash_z=int(hash_grid_z),
        cell_size=float(cell_size),
        inv_cell_size=float(inv),
        domain_min_x=float(domain_min_x),
        domain_min_y=float(domain_min_y),
        domain_min_z=float(domain_min_z),
        dt=float(dt),
        particle_radius=float(particle_radius),
        young_modulus=float(young_modulus),
        thermal_conductivity=float(thermal_conductivity),
        restitution=float(restitution),
        MAX_PER_CELL=int(max_per_cell),
        num_warps=1,
    )




---
File: /optimizer/__init__.py
---

"""Optimizer module: accelerator kernels + backend detection.

This package provides low-level optimizations (Metal on MPS, Triton on CUDA).

Caramba kernel policy:
- Deterministic dispatch to validated backends
- Fail loudly for missing *required* fast paths
"""
from __future__ import annotations

__all__: list[str] = []

# Initialize kernel registry at package import so any missing/invalid kernel backends
# fail loudly before training/inference begins.
from optimizer.kernel_registry import KERNELS as _KERNELS  # noqa: F401



---
File: /optimizer/kernel_registry.py
---

"""Kernel registry and startup validation.

Caramba operates on a strict policy when an accelerator is available:
- Pick the fastest supported kernel path deterministically.
- Validate required kernel backends at startup.
- If a required kernel backend is unavailable, fail loudly with an actionable error.
- Log the chosen performance paths exactly once at initialization.

In CPU-only environments (no CUDA/MPS), the registry initializes in a "no fused
kernels" mode so import-time behavior remains safe and unit tests can run.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Final

import torch

from optimizer.runtime import metal_build_tools_available, metal_supported, triton_supported


@dataclass(frozen=True, slots=True)
class KernelRegistry:
    cuda_available: bool
    mps_available: bool
    triton_available: bool
    metal_supported: bool
    metal_build_tools_available: bool
    metal_ops_loaded: bool


_REGISTRY: KernelRegistry | None = None
_LOGGED: bool = False


def _cuda_device_summary() -> str:
    if not torch.cuda.is_available():
        return "CUDA unavailable"
    try:
        idx = int(torch.cuda.current_device())
        name = str(torch.cuda.get_device_name(idx))
        cap = ".".join(str(x) for x in torch.cuda.get_device_capability(idx))
        return f"{name} (sm_{cap})"
    except Exception as e:
        logger.warning(f"CUDA available but device query failed: {e!r}")
        return "CUDA available (device query failed)"


def initialize_kernels() -> KernelRegistry:
    """Initialize and validate accelerator kernel backends.

    This must run exactly once per process (idempotent).
    """
    global _REGISTRY, _LOGGED
    if _REGISTRY is not None:
        return _REGISTRY

    cuda_available = bool(torch.cuda.is_available())
    mps_available = bool(torch.backends.mps.is_available())
    # CPU-only mode: no validation, no fused kernels.
    if not cuda_available and not mps_available:
        _REGISTRY = KernelRegistry(
            cuda_available=False,
            mps_available=False,
            triton_available=False,
            metal_supported=bool(metal_supported()),
            metal_build_tools_available=bool(metal_build_tools_available()),
            metal_ops_loaded=False,
        )
        return _REGISTRY

    # NOTE: We no longer hard-require Caramba's custom Triton/Metal kernels at startup.
    # The project now prefers the Hugging Face Kernel Hub (`kernels`) when available,
    # and falls back to PyTorch implementations otherwise.
    metal_ops_loaded = False

    _REGISTRY = KernelRegistry(
        cuda_available=cuda_available,
        mps_available=mps_available,
        triton_available=bool(triton_supported()),
        metal_supported=bool(metal_supported()),
        metal_build_tools_available=bool(metal_build_tools_available()),
        metal_ops_loaded=bool(metal_ops_loaded),
    )


    return _REGISTRY


KERNELS: Final[KernelRegistry] = initialize_kernels()



---
File: /optimizer/kernels.py
---

"""Hardware abstraction layer (HAL) for high-impact kernels.

Caramba operates on a strict kernel policy:
- Dispatch deterministically to the best supported kernel path.
- Validate required kernel backends at startup (see `optimizer/kernel_registry.py`).
- If an expected fast path is unavailable, raise immediately (no silent fallbacks).

Notes:
- Many CUDA code paths currently rely on PyTorch's native CUDA kernels for norms/RoPE.
  This module keeps the public API stable while dispatching to the best validated backend.
"""

from __future__ import annotations

from collections.abc import Callable
from typing import Any, TypeVar, cast

import torch
from torch import Tensor
import torch.nn.functional as F

from optimizer.kernel_registry import KERNELS


def _require(cond: bool, *, msg: str) -> None:
    if not cond:
        raise RuntimeError(msg)


_F = TypeVar("_F", bound=Callable[..., object])


def _typed(fn: _F) -> _F:
    """Typed no-op decorator.

    We avoid `torch.compiler.disable` here because it causes graph breaks at
    every callsite (see `TORCH_LOGS=+dynamo`), which can materially reduce
    throughput (tok/s) and increase Dynamo resume complexity.
    """

    return cast(_F, fn)


def _use_custom_kernels() -> bool:
    """Whether to use Caramba's custom Triton/Metal kernels.

    Default is **off**. Set `CARAMBA_USE_CUSTOM_KERNELS=1` to re-enable.
    """
    import os

    return str(os.environ.get("CARAMBA_USE_CUSTOM_KERNELS", "0")).lower() in ("1", "true", "yes", "on")


# ---- Hugging Face Kernel Hub (kernels) optional integrations ----
_HF_RMSNORM: Any | None = None
_HF_RMSNORM_CHECKED: bool = False
_HF_RMSNORM_ERROR: Exception | None = None


def _hf_rmsnorm(*, x: Tensor, weight: Tensor, eps: float) -> Tensor | None:
    """Best-effort Kernel Hub RMSNorm.

    Uses `kernels-community/rmsnorm` when a compatible build exists for the
    current environment; otherwise returns None.
    """
    global _HF_RMSNORM, _HF_RMSNORM_CHECKED, _HF_RMSNORM_ERROR
    if not _HF_RMSNORM_CHECKED:
        _HF_RMSNORM_CHECKED = True
        try:
            import kernels as _kernels  # type: ignore[import-not-found]
            from kernels import has_kernel  # type: ignore[import-not-found]

            # Prefer an explicit version when available.
            # kernels' typing stubs currently annotate `version` as `str|None`,
            # but the docs allow ints. Use a string to satisfy type checkers.
            if has_kernel("kernels-community/rmsnorm", version="1") or has_kernel("kernels-community/rmsnorm"):
                _HF_RMSNORM = _kernels.get_kernel("kernels-community/rmsnorm", version="1")
        except Exception as e:
            _HF_RMSNORM_ERROR = e
            _HF_RMSNORM = None

    if _HF_RMSNORM is None:
        return None

    try:
        fn = getattr(_HF_RMSNORM, "apply_rms_norm", None)
        if callable(fn):
            out = fn(x, weight, float(eps))
            return out if isinstance(out, torch.Tensor) else None
    except Exception:
        # Kernel present but failed for this input/device; fall back.
        return None

    return None


# ---- Optional backend imports (top-level; errors raised on use) ----
_METAL_IMPORT_ERROR: Exception | None = None
_TRITON_IMPORT_ERROR: Exception | None = None

_rmsnorm_fp16: Any | None = None
_rope_fp16: Any | None = None
_layernorm_fp16: Any | None = None
_dba_decode_fp16: Any | None = None
_MetalSSMSelectiveScan: Any | None = None
_AdamWMasterStep: Any | None = None
_lion_fp16: Any | None = None

try:
    from optimizer.metal import (
        AdamWMasterStep as _AdamWMasterStep,
        MetalSSMSelectiveScan as _MetalSSMSelectiveScan,
        dba_decode_fp16 as _dba_decode_fp16,
        layernorm_fp16 as _layernorm_fp16,
        lion_fp16 as _lion_fp16,
        rmsnorm_fp16 as _rmsnorm_fp16,
        rope_fp16 as _rope_fp16,
    )
except Exception as e:
    _METAL_IMPORT_ERROR = e

_rmsnorm_triton: Any | None = None
_rope_triton: Any | None = None
_layernorm_triton: Any | None = None
_fused_selective_scan: Any | None = None
_adamw_triton_master_step: Any | None = None

# Triton optional kernels are not bundled in this repository snapshot.
# We keep the HAL API stable and fall back to PyTorch implementations unless
# explicitly enabled and present.
_TRITON_IMPORT_ERROR = ImportError(
    "Optional Triton kernels (rmsnorm/rope/layernorm/adamw/ssm) are not available in this build."
)


@_typed
def rmsnorm(*, x: Tensor, weight: Tensor | None, eps: float) -> Tensor:
    """RMSNorm: y = x * rsqrt(mean(x^2) + eps) * weight."""
    if weight is not None:
        y_hf = _hf_rmsnorm(x=x, weight=weight, eps=float(eps))
        if y_hf is not None:
            return y_hf

    if _use_custom_kernels() and x.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="RMSNorm on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.float32),
            msg=f"RMSNorm on MPS requires fp16/fp32, got dtype={x.dtype}.",
        )
        if _rmsnorm_fp16 is None:
            raise RuntimeError(f"Metal RMSNorm import failed: {_METAL_IMPORT_ERROR!r}")
        return _rmsnorm_fp16(x=x, weight=weight, eps=float(eps))

    if _use_custom_kernels() and x.device.type == "cuda":
        _require(
            bool(KERNELS.cuda_available and KERNELS.triton_available),
            msg="RMSNorm on CUDA requires Triton to be available and validated at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.bfloat16),
            msg=f"RMSNorm on CUDA requires fp16/bf16, got dtype={x.dtype}.",
        )
        if _rmsnorm_triton is None:
            raise RuntimeError(f"Triton RMSNorm import failed: {_TRITON_IMPORT_ERROR!r}")
        return _rmsnorm_triton(x=x, weight=weight, eps=float(eps))

    x_f = x.float()
    inv_rms = torch.rsqrt(x_f.pow(2).mean(dim=-1, keepdim=True) + float(eps))
    y = (x_f * inv_rms).to(dtype=x.dtype)
    if weight is not None:
        y = y * weight
    return y


@_typed
def rope_apply(*, x: Tensor, cos: Tensor, sin: Tensor, rot_dim: int) -> Tensor:
    """Apply RoPE using cos/sin tables for the sequence window.

    Expects:
    - x: (B, H, T, D)
    - cos/sin: (T, rot_dim/2)
    """
    if _use_custom_kernels() and x.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="RoPE on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.float32),
            msg=f"RoPE on MPS requires fp16/fp32, got dtype={x.dtype}.",
        )
        if _rope_fp16 is None:
            raise RuntimeError(f"Metal RoPE import failed: {_METAL_IMPORT_ERROR!r}")
        return _rope_fp16(x=x, cos=cos, sin=sin, rot_dim=int(rot_dim))

    if _use_custom_kernels() and x.device.type == "cuda":
        _require(
            bool(KERNELS.cuda_available and KERNELS.triton_available),
            msg="RoPE on CUDA requires Triton to be available and validated at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.bfloat16),
            msg=f"RoPE on CUDA requires fp16/bf16, got dtype={x.dtype}.",
        )
        if _rope_triton is None:
            raise RuntimeError(f"Triton RoPE import failed: {_TRITON_IMPORT_ERROR!r}")
        return _rope_triton(x=x, cos=cos, sin=sin, rot_dim=int(rot_dim))

    T = int(x.shape[2])
    cos2 = cos[:T].unsqueeze(0).unsqueeze(0).to(dtype=x.dtype, device=x.device)
    sin2 = sin[:T].unsqueeze(0).unsqueeze(0).to(dtype=x.dtype, device=x.device)
    rot = int(rot_dim)
    x_rot = x[..., :rot]
    x_pass = x[..., rot:]
    # HF Llama applies rotate_half on a half-split representation:
    # y1 = x1*cos - x2*sin
    # y2 = x1*sin + x2*cos
    x1 = x_rot[..., : rot // 2]
    x2 = x_rot[..., rot // 2 : rot]
    y1 = x1 * cos2 - x2 * sin2
    y2 = x1 * sin2 + x2 * cos2
    return torch.cat([y1, y2, x_pass], dim=-1)


@_typed
def layernorm(*, x: Tensor, weight: Tensor | None, bias: Tensor | None, eps: float) -> Tensor:
    """LayerNorm over the last dimension.

    This matches PyTorch's `F.layer_norm(x, normalized_shape=(D,))` behavior.
    """
    if _use_custom_kernels() and x.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="LayerNorm on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.float32),
            msg=f"LayerNorm on MPS requires fp16/fp32, got dtype={x.dtype}.",
        )
        if _layernorm_fp16 is None:
            raise RuntimeError(f"Metal LayerNorm import failed: {_METAL_IMPORT_ERROR!r}")
        return _layernorm_fp16(x=x, weight=weight, bias=bias, eps=float(eps))

    if _use_custom_kernels() and x.device.type == "cuda":
        _require(
            bool(KERNELS.cuda_available and KERNELS.triton_available),
            msg="LayerNorm on CUDA requires Triton to be available and validated at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.bfloat16),
            msg=f"LayerNorm on CUDA requires fp16/bf16, got dtype={x.dtype}.",
        )
        if _layernorm_triton is None:
            raise RuntimeError(f"Triton LayerNorm import failed: {_TRITON_IMPORT_ERROR!r}")
        return _layernorm_triton(x=x, weight=weight, bias=bias, eps=float(eps))

    D = int(x.shape[-1])
    return F.layer_norm(x, normalized_shape=(D,), weight=weight, bias=bias, eps=float(eps))


@_typed
def attention_decode(
    *,
    q_sem: Tensor,
    q_geo: Tensor,
    k_sem: Tensor,
    k_geo: Tensor,
    v: Tensor,
    k_sem_null: Tensor | None = None,
    k_geo_null: Tensor | None = None,
    v_null: Tensor | None = None,
    sem_scale: float | None = None,
    geo_scale: float | None = None,
) -> Tensor:
    """Fused decode attention (HAL).

    Current supported fast paths:
    - MPS (Metal): decoupled DBA decode (fp16)

    Signature (kwargs-only):
      q_sem, q_geo, k_sem, k_geo, v,
      k_sem_null=None, k_geo_null=None, v_null=None,
      sem_scale=None, geo_scale=None
    """
    if q_sem.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="Attention decode on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            q_sem.dtype == torch.float16,
            msg=f"Attention decode on MPS requires fp16, got dtype={q_sem.dtype}.",
        )
        if _dba_decode_fp16 is None:
            raise RuntimeError(f"Metal attention decode import failed: {_METAL_IMPORT_ERROR!r}")
        return _dba_decode_fp16(
            q_sem=q_sem,
            q_geo=q_geo,
            k_sem=k_sem,
            k_geo=k_geo,
            v=v,
            k_sem_null=k_sem_null,
            k_geo_null=k_geo_null,
            v_null=v_null,
            sem_scale=sem_scale,
            geo_scale=geo_scale,
        )

    raise RuntimeError(
        "attention_decode: no supported backend for this device/dtype.\n"
        f"device={q_sem.device.type} dtype={q_sem.dtype}\n"
        "Use the decoupled attention fused decode paths (CUDA Triton) or Metal DBA decode (MPS fp16)."
    )


@_typed
def scan(
    *,
    x: Tensor,
    dt: Tensor,
    A: Tensor,
    B: Tensor,
    C: Tensor,
    D: Tensor,
) -> Tensor:
    """Fused scan/SSM kernels (HAL).

    Signature (kwargs-only):
      x, dt, A, B, C, D
    """
    if x.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="SSM scan on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            x.dtype == torch.float16,
            msg=f"SSM scan on MPS requires fp16, got dtype={x.dtype}.",
        )
        if _MetalSSMSelectiveScan is None:
            raise RuntimeError(f"Metal SSM import failed: {_METAL_IMPORT_ERROR!r}")
        return _MetalSSMSelectiveScan().run(x=x, dt=dt, A=A, B=B, C=C, D=D)

    if x.device.type == "cuda":
        _require(
            bool(KERNELS.cuda_available and KERNELS.triton_available),
            msg="SSM scan on CUDA requires Triton kernels to be available and validated at startup.",
        )
        _require(
            x.dtype in (torch.float16, torch.bfloat16),
            msg=f"SSM scan on CUDA requires fp16/bf16, got dtype={x.dtype}.",
        )
        if _fused_selective_scan is None:
            raise RuntimeError(f"Triton SSM import failed: {_TRITON_IMPORT_ERROR!r}")
        return _fused_selective_scan(x, dt, A, B, C, D)

    raise RuntimeError(
        "scan: no supported backend for this device/dtype.\n"
        f"device={x.device.type} dtype={x.dtype}\n"
        "Supported backends: Metal (MPS fp16), Triton (CUDA fp16/bf16)."
    )


@_typed
def adamw_step(
    *,
    p: Tensor,
    grad: Tensor,
    master: Tensor,
    exp_avg: Tensor,
    exp_avg_sq: Tensor,
    step_size: float,
    beta1: float,
    beta2: float,
    eps: float,
    lr_wd: float,
) -> None:
    """Fused AdamW update (HAL).

    This is the low-level per-tensor update used by `AdamWMaster` when fused.
    """
    if p.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="AdamW step on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            p.dtype in (torch.float16, torch.float32),
            msg=f"AdamW step on MPS requires fp16/fp32 params, got dtype={p.dtype}.",
        )
        if _AdamWMasterStep is None:
            raise RuntimeError(f"Metal AdamW import failed: {_METAL_IMPORT_ERROR!r}")
        _AdamWMasterStep().run(
            p=p,
            grad=grad,
            master=master,
            exp_avg=exp_avg,
            exp_avg_sq=exp_avg_sq,
            step_size=float(step_size),
            beta1=float(beta1),
            beta2=float(beta2),
            eps=float(eps),
            lr_wd=float(lr_wd),
            verbose_build=False,
        )
        return

    if p.device.type == "cuda":
        _require(
            bool(KERNELS.cuda_available and KERNELS.triton_available),
            msg="AdamW step on CUDA requires Triton to be available and validated at startup.",
        )
        _require(
            p.dtype in (torch.float16, torch.bfloat16),
            msg=f"AdamW step on CUDA requires fp16/bf16 params, got dtype={p.dtype}.",
        )
        _require(
            grad.dtype == p.dtype,
            msg="AdamW step on CUDA requires grad dtype to match param dtype.",
        )
        _require(
            master.dtype == torch.float32 and exp_avg.dtype == torch.float32 and exp_avg_sq.dtype == torch.float32,
            msg="AdamW step on CUDA requires fp32 master/exp_avg/exp_avg_sq.",
        )
        _require(
            p.is_contiguous() and grad.is_contiguous() and master.is_contiguous() and exp_avg.is_contiguous() and exp_avg_sq.is_contiguous(),
            msg="AdamW step on CUDA requires all tensors to be contiguous.",
        )
        if _adamw_triton_master_step is None:
            raise RuntimeError(f"Triton AdamW import failed: {_TRITON_IMPORT_ERROR!r}")
        _adamw_triton_master_step(
            p=p.view(-1),
            grad=grad.view(-1),
            master=master.view(-1),
            exp_avg=exp_avg.view(-1),
            exp_avg_sq=exp_avg_sq.view(-1),
            step_size=float(step_size),
            beta1=float(beta1),
            beta2=float(beta2),
            eps=float(eps),
            lr_wd=float(lr_wd),
        )
        return

    raise RuntimeError(
        "adamw_step: no supported backend for this device/dtype.\n"
        f"device={p.device.type} dtype={p.dtype}\n"
        "Supported backends: Metal (MPS fp16) and Triton (CUDA fp16/bf16)."
    )


def lion_step(
    *,
    p: Tensor,
    grad: Tensor,
    m: Tensor,
    lr: float,
    beta1: float,
    weight_decay: float = 0.0,
) -> None:
    """Fused Lion update (HAL)."""
    if p.device.type == "mps":
        _require(
            bool(KERNELS.mps_available and KERNELS.metal_ops_loaded),
            msg="Lion step on MPS requires the Metal extension to be available and loaded at startup.",
        )
        _require(
            p.dtype in (torch.float16, torch.float32),
            msg=f"Lion step on MPS requires fp16/fp32 params, got dtype={p.dtype}.",
        )
        if _lion_fp16 is None:
            raise RuntimeError(f"Metal Lion import failed: {_METAL_IMPORT_ERROR!r}")
        _lion_fp16(
            p=p,
            grad=grad,
            m=m,
            lr=float(lr),
            beta1=float(beta1),
            weight_decay=float(weight_decay),
            verbose_build=False,
        )
        return

    raise RuntimeError(
        "lion_step: no supported backend for this device/dtype.\n"
        f"device={p.device.type} dtype={p.dtype}\n"
        "CUDA fused optimizer parity kernel is not available in this build."
    )



---
File: /optimizer/manifold_physics.py
---

"""Unified manifold physics backend router.

This module provides a stable import path that chooses the best backend based
on the requested device:
- MPS  -> `optimizer.metal.manifold_physics`
- CUDA -> `optimizer.triton.manifold_physics`
"""

from __future__ import annotations

from typing import Literal, overload


@overload
def get_backend(device: Literal["mps"]) -> Literal["metal"]: ...


@overload
def get_backend(device: Literal["cuda"]) -> Literal["triton"]: ...


def get_backend(device: str) -> str:
    if device == "mps":
        return "metal"
    if device == "cuda":
        return "triton"
    raise RuntimeError(f"Unsupported device for manifold physics: {device!r} (expected 'mps' or 'cuda')")


def _load(device: str):
    b = get_backend(device)
    if b == "metal":
        from optimizer.metal.manifold_physics import (  # type: ignore[import-not-found]
            ManifoldPhysics,
            ManifoldPhysicsConfig,
            SpectralCarrierPhysics,
            SpectralCarrierConfig,
            ParticleGenerator,
            manifold_physics_available,
        )

        return (
            ManifoldPhysics,
            ManifoldPhysicsConfig,
            SpectralCarrierPhysics,
            SpectralCarrierConfig,
            ParticleGenerator,
            manifold_physics_available,
        )

    from optimizer.triton.manifold_physics import (  # type: ignore[import-not-found]
        ManifoldPhysics,
        ManifoldPhysicsConfig,
        SpectralCarrierPhysics,
        SpectralCarrierConfig,
    )

    def manifold_physics_available() -> bool:
        # CUDA backend availability is equivalent to torch.cuda.is_available()
        try:
            import torch

            return bool(torch.cuda.is_available())
        except Exception:
            return False

    ParticleGenerator = None  # CUDA path: generator remains torch-based upstream
    return (
        ManifoldPhysics,
        ManifoldPhysicsConfig,
        SpectralCarrierPhysics,
        SpectralCarrierConfig,
        ParticleGenerator,
        manifold_physics_available,
    )


def ManifoldPhysicsConfig(*args, device: str = "mps", **kwargs):  # type: ignore[misc]
    _, Cfg, *_ = _load(device)
    return Cfg(*args, **kwargs)


def SpectralCarrierConfig(*args, device: str = "mps", **kwargs):  # type: ignore[misc]
    *_, SCfg, _PG, _avail = _load(device)
    return SCfg(*args, **kwargs)


def manifold_physics_available(*, device: str = "mps") -> bool:
    *_, avail = _load(device)
    return bool(avail())


def ManifoldPhysics(*args, device: str = "mps", **kwargs):  # type: ignore[misc]
    MP, *_ = _load(device)
    return MP(*args, device=device, **kwargs)


def SpectralCarrierPhysics(*args, device: str = "mps", **kwargs):  # type: ignore[misc]
    _MP, _Cfg, SP, *_rest = _load(device)
    return SP(*args, device=device, **kwargs)


def ParticleGenerator(*args, device: str = "mps", **kwargs):  # type: ignore[misc]
    *_rest, PG, _avail = _load(device)
    if PG is None:
        raise RuntimeError("ParticleGenerator is only implemented for the Metal/MPS backend.")
    return PG(*args, device=device, **kwargs)




---
File: /optimizer/runtime.py
---

"""Backend availability detection (Triton + Metal/MPS).

Caramba has optional fused kernels that depend on accelerator-specific toolchains:
- Triton (CUDA) for fused decode / SSM kernels
- Metal (MPS) for Apple Silicon fused DBA decode (custom MSL kernel + ObjC++ bridge)

This module centralizes runtime detection in a way that is safe for import + type
checking: at type-check time we force optional backends off.
"""

from __future__ import annotations

import importlib.util
import platform
import shutil
import subprocess
from typing import TYPE_CHECKING
import torch

__all__ = [
    "triton_supported",
    "metal_supported",
]


def has_module(name: str) -> bool:
    try:
        return importlib.util.find_spec(name) is not None
    except (ImportError, ValueError, AttributeError):
        return False

def metal_build_tools_available() -> bool:
    """Whether the host can compile Metal shaders via Xcode toolchain.

    Notes:
    - Having `xcrun` in PATH is not sufficient; the active developer directory
      must contain the `metal` and `metallib` tools.
    - This function is intentionally conservative: if we can't *prove* the tools
      exist, we return False so training can surface a clear, actionable error.
    """
    # Do not call metal_supported() here: metal_supported() is a *runtime* check,
    # while this function is a *toolchain* check. Keeping them independent avoids
    # accidental recursion and makes errors actionable.
    if TYPE_CHECKING:
        return False

    if platform.system() != "Darwin":
        return False

    try:
        if not bool(torch.backends.mps.is_available()):
            return False
    except Exception:
        return False

    if shutil.which("xcrun") is None:
        return False

    try:
        subprocess.check_output(["xcrun", "-sdk", "macosx", "--find", "metal"], stderr=subprocess.STDOUT)
        subprocess.check_output(["xcrun", "-sdk", "macosx", "--find", "metallib"], stderr=subprocess.STDOUT)
    except Exception:
        return False
    return True

def triton_supported() -> bool:
    return bool(has_module("triton") and has_module("triton.language"))

def metal_supported() -> bool:
    """Whether the current runtime *can* execute custom Metal (MPS) ops.

    This indicates platform + PyTorch MPS support. It does NOT guarantee that the
    custom extension is already built/loaded; higher-level code may JIT build it.
    """
    if TYPE_CHECKING:
        return False

    if platform.system() != "Darwin":
        return False

    try:
        return bool(torch.backends.mps.is_available())
    except Exception:
        return False



---
File: /sensorium/experiments/__init__.py
---

"""Experiment entrypoints.

This package previously contained a legacy, Torch/Python semantic stack.
The *current* experiments are kernel-based (Metal on macOS) and produce
paper-ready artifacts under `paper/tables/` and `paper/figures/`.

We intentionally avoid importing legacy modules at import-time to prevent
mixing old/new implementations.
"""

from .kernel_rule_shift import KernelRuleShiftConfig, run_kernel_rule_shift
from .kernel_ablations import run_kernel_ablation_study
from .kernel_continuous import KernelContinuousConfig, run_kernel_continuous
from .kernel_next_token import KernelNextTokenConfig, run_kernel_next_token
from .kernel_timeseries import KernelTimeSeriesConfig, run_kernel_timeseries
from .kernel_text_diffusion import KernelTextDiffusionConfig, run_kernel_text_diffusion
from .kernel_mnist_bytes import KernelMNISTBytesConfig, run_kernel_mnist_bytes
from .kernel_image_gen import KernelImageGenConfig, run_kernel_image_gen
from .kernel_audio_gen import KernelAudioGenConfig, run_kernel_audio_gen
from .kernel_cocktail_party import KernelCocktailPartyConfig, run_kernel_cocktail_party

__all__ = [
    "KernelRuleShiftConfig",
    "run_kernel_rule_shift",
    "run_kernel_ablation_study",
    "KernelContinuousConfig",
    "run_kernel_continuous",
    "KernelNextTokenConfig",
    "run_kernel_next_token",
    "KernelTimeSeriesConfig",
    "run_kernel_timeseries",
    "KernelTextDiffusionConfig",
    "run_kernel_text_diffusion",
    "KernelMNISTBytesConfig",
    "run_kernel_mnist_bytes",
    "KernelImageGenConfig",
    "run_kernel_image_gen",
    "KernelAudioGenConfig",
    "run_kernel_audio_gen",
    "KernelCocktailPartyConfig",
    "run_kernel_cocktail_party",
]



---
File: /sensorium/experiments/ablations.py
---

"""
Ablation Study

Tests the contribution of individual components by disabling them.
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List, Optional

import torch

from ..core.config import PhysicsConfig
from ..semantic.hierarchical import HierarchicalSemanticManifold
from ..semantic.manifold import SemanticManifold


def run_single_condition(
    *,
    condition_name: str,
    steps: int,
    shift_at: int,
    context_len: int,
    dt: float,
    device: torch.device,
    use_hierarchy: bool = True,
    use_pondering: bool = True,
    use_homeostasis: bool = True,
) -> Dict[str, Any]:
    """Run a single ablation condition."""
    
    vocab = ["<bos>", "the", "cat", "sat", "on", "mat", "<eos>"]
    tid = {t: i for i, t in enumerate(vocab)}
    
    fwd = [tid["<bos>"], tid["the"], tid["cat"], tid["sat"], tid["on"], tid["the"], tid["mat"], tid["<eos>"]]
    rev = [tid["<bos>"], tid["mat"], tid["the"], tid["on"], tid["sat"], tid["cat"], tid["the"], tid["<eos>"]]
    
    # Pre-generate stream
    stream: List[int] = []
    pos = 0
    seq = fwd
    for t in range(steps + 1):
        if t == shift_at:
            seq = rev
            pos = 0
        stream.append(seq[pos])
        pos = (pos + 1) % len(seq)
    
    # Configure based on ablation
    cfg = PhysicsConfig(
        dt=dt,
        eps=1e-8,
        tau=1.0 if use_homeostasis else 1000.0,  # Very slow homeostasis = effectively off
    )
    
    if use_hierarchy:
        brain = HierarchicalSemanticManifold(
            cfg, device,
            vocab=vocab,
            embed_dim=min(16, len(vocab)),
            chunk_min_len=2,
            chunk_max_len=4,
        )
    else:
        brain = SemanticManifold(
            config=cfg,
            device=device,
            vocab=vocab,
            embed_dim=min(16, len(vocab)),
        )
    
    history: List[int] = []
    acc = torch.zeros(steps, dtype=torch.float32)
    
    for t in range(steps):
        cur = int(stream[t])
        nxt = int(stream[t + 1])
        
        history.append(cur)
        if len(history) > context_len:
            history = history[-context_len:]
        
        ctx = torch.tensor(history, device=device, dtype=torch.long)
        brain.ingest_ids(ctx)
        brain.step_grammar()
        out = brain.output_state()
        
        pred = int(out.token_index)
        acc[t] = 1.0 if pred == nxt else 0.0
        
        brain.observe_next_token(nxt, probs=out.probs)
        
        if use_pondering:
            brain.idle_think(steps=1, dream_steps=context_len)
    
    # Rolling accuracy
    win = max(1, len(fwd))
    kern = torch.ones(win, dtype=torch.float32) / float(win)
    acc_smooth = torch.nn.functional.conv1d(
        acc.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2
    ).view(-1)[:steps]
    
    pre_shift_acc = float(acc_smooth[shift_at - 100:shift_at].mean().item())
    post_shift_acc_recovered = float(acc_smooth[-100:].mean().item())
    
    # Find recovery
    threshold = pre_shift_acc * 0.8
    recovery_step = None
    for t in range(shift_at, min(shift_at + 500, steps)):
        if float(acc_smooth[t].item()) >= threshold:
            recovery_step = t - shift_at
            break
    
    return {
        "condition": condition_name,
        "pre_shift_accuracy": pre_shift_acc,
        "post_shift_accuracy": post_shift_acc_recovered,
        "recovery_steps": recovery_step,
    }


def generate_ablation_table(results: List[Dict[str, Any]]) -> str:
    """Generate LaTeX table for ablation results."""
    rows = []
    for r in results:
        recovery = str(r['recovery_steps']) if r['recovery_steps'] else "$>$500"
        rows.append(
            f"    {r['condition']} & {r['pre_shift_accuracy']:.1%} & {r['post_shift_accuracy']:.1%} & {recovery} \\\\"
        )
    
    return r"""\begin{table}[t]
\centering
\caption{Ablation study. Each row disables one component from the full system.}
\label{tab:ablation}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Pre-shift Acc.} & \textbf{Post-shift Acc.} & \textbf{Recovery Steps} \\
\midrule
""" + "\n".join(rows) + r"""
\bottomrule
\end{tabular}
\end{table}
"""


def run_ablation_study(
    device: torch.device,
    tables_dir: Path,
    figures_dir: Path,
    steps: int = 2000,
    shift_at: int = 1000,
    context_len: int = 6,
    dt: float = 0.02,
):
    """Run all ablation conditions and generate table."""
    conditions = [
        ("Full system", True, True, True),
        ("No hierarchy", False, True, True),
        ("No pondering", True, False, True),
        ("No homeostasis", True, True, False),
    ]
    
    results = []
    for name, hier, pond, homeo in conditions:
        print(f"  Running: {name}...")
        result = run_single_condition(
            condition_name=name,
            steps=steps,
            shift_at=shift_at,
            context_len=context_len,
            dt=dt,
            device=device,
            use_hierarchy=hier,
            use_pondering=pond,
            use_homeostasis=homeo,
        )
        results.append(result)
        print(f"    Pre: {result['pre_shift_accuracy']:.1%}, "
              f"Post: {result['post_shift_accuracy']:.1%}, "
              f"Recovery: {result['recovery_steps']}")
    
    # Generate table
    table_content = generate_ablation_table(results)
    table_path = tables_dir / "ablation.tex"
    tables_dir.mkdir(parents=True, exist_ok=True)
    figures_dir.mkdir(parents=True, exist_ok=True)
    table_path.write_text(table_content, encoding="utf-8")
    print(f"  [TABLE] ablation.tex")
    
    # Combine metrics
    metrics = {
        "conditions": results,
        "full_pre": results[0]["pre_shift_accuracy"],
        "full_post": results[0]["post_shift_accuracy"],
        "full_recovery": results[0]["recovery_steps"],
    }

    return metrics



---
File: /sensorium/experiments/audio_gen.py
---

"""Audio/Music Generation Experiment

Uses NSynth or similar audio datasets from HuggingFace.
Tests spectral manifold's audio synthesis capabilities.

Goal: Generate audio via thermodynamic diffusion in frequency space.
Metrics: Reconstruction MSE, Spectral distance
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale


class AudioGenerationExperiment(BaseExperiment):
    """Audio generation using thermodynamic dynamics in frequency space.
    
    The approach:
    1. Encode audio samples to frequency-space particles via FFT
    2. Build attractors from frequency distributions
    3. For generation: seed with noise, let particles diffuse
    4. Decode via inverse FFT
    """
    
    name = "audio_gen"
    goal = "Generate audio via thermodynamic diffusion in frequency space"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.sample_rate = 16000
            self.audio_length = 8000  # 0.5 seconds
            self.top_k_freq = 50
            self.max_samples = 100
        elif scale == Scale.MEDIUM:
            self.sample_rate = 16000
            self.audio_length = 16000  # 1 second
            self.top_k_freq = 200
            self.max_samples = 1000
        else:
            self.sample_rate = 22050
            self.audio_length = 44100  # 2 seconds
            self.top_k_freq = 500
            self.max_samples = 10000
        
        # Frequency statistics (learned from training data)
        self._freq_attractors: Dict[int, List[Tuple[float, float]]] = {}
    
    def setup(self) -> None:
        """Load audio dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading audio dataset (speech_commands)...")
        
        # Use Google Speech Commands as a simple audio dataset
        # It's smaller and easier to work with than NSynth
        try:
            dataset = load_dataset(
                "google/speech_commands",
                "v0.02",
                streaming=True,
            )
            self.audio_key = "audio"
            self.has_real_data = True
        except Exception as e:
            print(f"    Could not load speech_commands: {e}")
            print(f"    Falling back to synthetic audio")
            self.has_real_data = False
            dataset = None
        
        if self.has_real_data and dataset is not None:
            self.train_stream = dataset["train"]
            self.eval_stream = dataset["validation"]
            
            # Prefetch audio samples
            self._train_audio: List[torch.Tensor] = []
            self._eval_audio: List[torch.Tensor] = []
            
            self._load_audio(
                self.train_stream,
                self._train_audio,
                min(self.scale_config.max_train_samples or 1000, self.max_samples),
            )
            self._load_audio(
                self.eval_stream,
                self._eval_audio,
                min(self.scale_config.max_eval_samples or 200, self.max_samples // 5),
            )
        else:
            # Generate synthetic audio for testing
            self._train_audio = [self._generate_synthetic() for _ in range(100)]
            self._eval_audio = [self._generate_synthetic() for _ in range(20)]
        
        print(f"    Train samples: {len(self._train_audio)}")
        print(f"    Eval samples: {len(self._eval_audio)}")
        print(f"    Sample rate: {self.sample_rate}")
        print(f"    Audio length: {self.audio_length} samples ({self.audio_length/self.sample_rate:.2f}s)")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _generate_synthetic(self) -> torch.Tensor:
        """Generate synthetic audio for testing when real data unavailable."""
        t = torch.linspace(0, self.audio_length / self.sample_rate, self.audio_length)
        
        # Random combination of sine waves
        freq1 = 220 + torch.randint(0, 440, (1,)).item()  # A3-A4 range
        freq2 = freq1 * 2  # Octave
        freq3 = freq1 * 1.5  # Fifth
        
        audio = (
            0.5 * torch.sin(2 * torch.pi * freq1 * t) +
            0.3 * torch.sin(2 * torch.pi * freq2 * t) +
            0.2 * torch.sin(2 * torch.pi * freq3 * t)
        )
        
        # Add envelope
        envelope = torch.exp(-3 * t / (self.audio_length / self.sample_rate))
        audio = audio * envelope
        
        return audio
    
    def _load_audio(
        self,
        stream,
        output: List[torch.Tensor],
        max_samples: int,
    ) -> None:
        """Load audio from stream."""
        for sample in stream:
            audio_data = sample[self.audio_key]
            
            # Extract array from audio dict
            if isinstance(audio_data, dict):
                arr = audio_data.get("array", [])
                sr = audio_data.get("sampling_rate", self.sample_rate)
            else:
                arr = audio_data
                sr = self.sample_rate
            
            # Convert to tensor
            audio = torch.tensor(arr, dtype=torch.float32)
            
            # Resample if needed
            if sr != self.sample_rate:
                # Simple resampling (not ideal but works for demo)
                ratio = self.sample_rate / sr
                new_len = int(len(audio) * ratio)
                audio = torch.nn.functional.interpolate(
                    audio.unsqueeze(0).unsqueeze(0),
                    size=new_len,
                    mode='linear',
                    align_corners=False,
                ).squeeze()
            
            # Pad or truncate to fixed length
            if len(audio) < self.audio_length:
                audio = torch.nn.functional.pad(audio, (0, self.audio_length - len(audio)))
            else:
                audio = audio[:self.audio_length]
            
            # Normalize
            max_val = audio.abs().max()
            if max_val > 0:
                audio = audio / max_val
            
            output.append(audio)
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[torch.Tensor]:
        """Iterate over training audio."""
        for audio in self._train_audio:
            yield audio
    
    def train_step(self, batch: torch.Tensor) -> Dict[str, float]:
        """One step of thermodynamic audio learning."""
        audio = batch.to(self.device)
        
        # Clear and encode audio
        self.manifold.clear()
        self.manifold.encode_audio(audio, sample_rate=self.sample_rate, top_k=self.top_k_freq)
        
        # Run dynamics
        for _ in range(5):
            self.manifold.step()
        
        # Store frequency attractors
        for p in self.manifold._particles:
            if p.modality == Modality.AUDIO and p.position.numel() == 1:
                freq_bin = int(p.position[0].item())
                
                if freq_bin not in self._freq_attractors:
                    self._freq_attractors[freq_bin] = []
                
                phase = p.phase[0].item() if p.phase is not None else 0.0
                self._freq_attractors[freq_bin].append((p.energy.item(), phase))
        
        # Decode and compute reconstruction error
        reconstructed = self.manifold.decode_audio(self.audio_length, self.sample_rate)
        mse = ((audio - reconstructed) ** 2).mean().item()
        
        return {"mse": mse}
    
    def _generate_audio(self) -> torch.Tensor:
        """Generate new audio using learned attractors."""
        self.manifold.clear()
        
        if not self._freq_attractors:
            return torch.randn(self.audio_length, device=self.device)
        
        # Create particles from attractor statistics
        for freq_bin, stats in self._freq_attractors.items():
            if not stats:
                continue
            
            mean_energy = sum(e for e, _ in stats) / len(stats)
            mean_phase = sum(p for _, p in stats) / len(stats)
            
            noise = torch.randn(1, device=self.device).item() * 0.1
            
            position = torch.tensor([float(freq_bin)], device=self.device)
            phase = torch.tensor([mean_phase + noise], device=self.device)
            
            self.manifold.add_particle(
                position=position,
                energy=max(0.001, mean_energy + noise * 0.1),
                modality=Modality.AUDIO,
                phase=phase,
            )
        
        # Run dynamics
        for _ in range(10):
            self.manifold.step()
        
        return self.manifold.decode_audio(self.audio_length, self.sample_rate)
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate reconstruction and generation quality."""
        mse_total = 0.0
        spectral_dist_total = 0.0
        count = 0
        
        for audio in self._eval_audio[:20]:
            audio = audio.to(self.device)
            
            self.manifold.clear()
            self.manifold.encode_audio(audio, sample_rate=self.sample_rate, top_k=self.top_k_freq)
            
            for _ in range(5):
                self.manifold.step()
            
            reconstructed = self.manifold.decode_audio(self.audio_length, self.sample_rate)
            
            # Time-domain MSE
            mse_total += ((audio - reconstructed) ** 2).mean().item()
            
            # Spectral distance
            orig_spec = torch.fft.rfft(audio).abs()
            recon_spec = torch.fft.rfft(reconstructed).abs()
            spectral_dist_total += ((orig_spec - recon_spec) ** 2).mean().item()
            
            count += 1
        
        recon_mse = mse_total / max(count, 1)
        spectral_dist = spectral_dist_total / max(count, 1)
        
        # Generate some samples
        gen_audio = [self._generate_audio() for _ in range(5)]
        
        # Basic generation metrics
        gen_energy = torch.stack(gen_audio).abs().mean().item()
        
        return {
            "reconstruction_mse": recon_mse,
            "spectral_distance": spectral_dist,
            "gen_energy": gen_energy,
            "num_freq_attractors": len(self._freq_attractors),
            "eval_samples": count,
        }
    
    def save_samples(self, out_dir: str, num_samples: int = 4) -> None:
        """Save generated audio samples."""
        try:
            import scipy.io.wavfile as wav
            from pathlib import Path
            import numpy as np
            
            out_path = Path(out_dir)
            out_path.mkdir(parents=True, exist_ok=True)
            
            for i in range(num_samples):
                audio = self._generate_audio().cpu().numpy()
                audio = np.clip(audio, -1, 1)
                audio = (audio * 32767).astype(np.int16)
                
                wav.write(
                    str(out_path / f"generated_{i}.wav"),
                    self.sample_rate,
                    audio,
                )
            
            print(f"    Saved {num_samples} audio samples to {out_path}")
            
        except ImportError:
            print("    (scipy not available, skipping audio saving)")


def run_audio_gen_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = AudioGenerationExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Save samples
    exp.save_samples("./artifacts/audio_gen")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /sensorium/experiments/base.py
---

"""Base experiment class for all experiments.

This provides the common infrastructure for:
- Scale management (toy, medium, full)
- HuggingFace dataset streaming
- Training loops (thermodynamic style)
- Metric collection
- Result formatting
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from sensorium.core.config import PhysicsConfig


class Scale(Enum):
    """Experiment scale levels."""
    TOY = "toy"
    MEDIUM = "medium"
    FULL = "full"


@dataclass
class ScaleConfig:
    """Configuration for a specific scale."""
    name: str
    # Data limits
    max_train_samples: Optional[int]
    max_eval_samples: Optional[int]
    # Model size (if applicable)
    embed_dim: int
    # Training
    train_steps: int
    eval_every: int
    # Physics
    dt: float = 0.02
    
    
# Default scale configurations
SCALE_CONFIGS = {
    Scale.TOY: ScaleConfig(
        name="toy",
        max_train_samples=1000,
        max_eval_samples=100,
        embed_dim=64,
        train_steps=500,
        eval_every=100,
    ),
    Scale.MEDIUM: ScaleConfig(
        name="medium",
        max_train_samples=10000,
        max_eval_samples=1000,
        embed_dim=256,
        train_steps=5000,
        eval_every=500,
    ),
    Scale.FULL: ScaleConfig(
        name="full",
        max_train_samples=None,  # Use full dataset
        max_eval_samples=5000,
        embed_dim=512,
        train_steps=50000,
        eval_every=1000,
    ),
}


@dataclass
class TrainingState:
    """Tracks training progress."""
    step: int = 0
    epoch: int = 0
    samples_seen: int = 0
    metrics_history: Dict[str, List[float]] = field(default_factory=dict)
    
    def record(self, name: str, value: float) -> None:
        if name not in self.metrics_history:
            self.metrics_history[name] = []
        self.metrics_history[name].append(value)
    
    def get_latest(self, name: str, default: float = 0.0) -> float:
        if name in self.metrics_history and self.metrics_history[name]:
            return self.metrics_history[name][-1]
        return default
    
    def get_mean(self, name: str, window: int = 100) -> float:
        if name not in self.metrics_history:
            return 0.0
        values = self.metrics_history[name][-window:]
        return sum(values) / len(values) if values else 0.0


@dataclass 
class ExperimentResult:
    """Container for experiment outputs."""
    name: str
    scale: str
    goal: str
    success: bool
    metrics: Dict[str, Any]
    failure_reason: Optional[str] = None
    tables: Dict[str, str] = field(default_factory=dict)
    figures: Dict[str, Path] = field(default_factory=dict)
    
    def summary(self) -> str:
        status = "SUCCESS" if self.success else f"FAILED: {self.failure_reason}"
        lines = [
            f"Experiment: {self.name} ({self.scale})",
            f"Goal: {self.goal}",
            f"Status: {status}",
            "Metrics:",
        ]
        for k, v in self.metrics.items():
            if not isinstance(v, (list, dict)):
                lines.append(f"  {k}: {v}")
        return "\n".join(lines)


class BaseExperiment(ABC):
    """Base class for all experiments.
    
    Subclasses should implement:
    - setup(): Initialize model, load data
    - train_step(): One step of thermodynamic training
    - evaluate(): Compute metrics on eval set
    - cleanup(): Optional cleanup
    """
    
    name: str = "base"
    goal: str = "Base experiment"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        self.scale = scale
        self.scale_config = SCALE_CONFIGS[scale]
        self.device = device or self._get_device()
        self.seed = seed
        
        # Set seeds
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        
        # Training state
        self.state = TrainingState()
        
        # Physics config
        self.physics_config = PhysicsConfig(
            dt=self.scale_config.dt,
            eps=1e-8,
        )
        
        # Will be set by subclasses
        self.model = None
        self.train_data = None
        self.eval_data = None
    
    def _get_device(self) -> torch.device:
        if torch.cuda.is_available():
            return torch.device("cuda")
        # Prefer MPS on Apple Silicon when torch_scatter isn't installed.
        if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            try:
                import torch_scatter  # type: ignore  # noqa: F401

                has_torch_scatter = True
            except Exception:
                has_torch_scatter = False
            if not has_torch_scatter:
                return torch.device("mps")
        return torch.device("cpu")
    
    @abstractmethod
    def setup(self) -> None:
        """Initialize model and load data."""
        pass
    
    @abstractmethod
    def train_step(self, batch: Any) -> Dict[str, float]:
        """Execute one training step.
        
        In thermodynamic training, this typically means:
        1. Ingest context
        2. Run grammar step / physics
        3. Observe next token / target
        4. Optionally run idle pondering
        
        Returns dict of metrics for this step.
        """
        pass
    
    @abstractmethod
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on the eval set.
        
        Returns dict of evaluation metrics.
        """
        pass
    
    def cleanup(self) -> None:
        """Optional cleanup after experiment."""
        pass
    
    def train_iterator(self) -> Iterator[Any]:
        """Iterate over training data.
        
        Override if you need custom batching.
        """
        if self.train_data is None:
            return iter([])
        return iter(self.train_data)
    
    def _format_metrics(self, metrics: Dict[str, float], max_items: int = 4) -> str:
        """Format metrics for display."""
        items = []
        for k, v in list(metrics.items())[:max_items]:
            if isinstance(v, float):
                if abs(v) < 0.01 or abs(v) > 1000:
                    items.append(f"{k}={v:.2e}")
                else:
                    items.append(f"{k}={v:.4f}")
            else:
                items.append(f"{k}={v}")
        return ", ".join(items)
    
    def run(self) -> ExperimentResult:
        """Run the full experiment."""
        try:
            from tqdm import tqdm
        except ImportError:
            tqdm = None
        
        print(f"\n{'='*60}")
        print(f"EXPERIMENT: {self.name} ({self.scale.value})")
        print(f"Goal: {self.goal}")
        print(f"Device: {self.device}")
        print(f"{'='*60}")
        
        try:
            # Setup
            print("\n[1] Setup...")
            self.setup()
            print(f"    Model initialized")
            print(f"    Train samples: {self.scale_config.max_train_samples or 'all'}")
            print(f"    Eval samples: {self.scale_config.max_eval_samples or 'all'}")
            
            # Training loop
            print(f"\n[2] Training ({self.scale_config.train_steps} steps)...")
            
            data_iter = self.train_iterator()
            
            # Create progress bar
            if tqdm is not None:
                pbar = tqdm(
                    range(self.scale_config.train_steps),
                    desc="Training",
                    unit="step",
                    ncols=100,
                    leave=True,
                )
            else:
                pbar = range(self.scale_config.train_steps)
            
            last_metrics: Dict[str, float] = {}
            
            for step in pbar:
                self.state.step = step
                
                # Get next batch (cycle if needed)
                try:
                    batch = next(data_iter)
                except StopIteration:
                    self.state.epoch += 1
                    data_iter = self.train_iterator()
                    try:
                        batch = next(data_iter)
                    except StopIteration:
                        print("    Warning: No training data available")
                        break
                
                # Train step
                step_metrics = self.train_step(batch)
                for k, v in step_metrics.items():
                    self.state.record(k, v)
                
                self.state.samples_seen += 1
                
                # Update progress bar with metrics
                if tqdm is not None:
                    # Show rolling averages
                    display_metrics = {
                        k: self.state.get_mean(k, window=50)
                        for k in list(step_metrics.keys())[:3]
                    }
                    display_metrics["epoch"] = self.state.epoch
                    pbar.set_postfix(display_metrics)
                
                # Periodic evaluation
                if (step + 1) % self.scale_config.eval_every == 0:
                    eval_metrics = self.evaluate()
                    last_metrics = eval_metrics
                    
                    if tqdm is None:
                        # Fallback text output
                        train_summary = self._format_metrics(
                            {k: self.state.get_mean(k) for k in step_metrics.keys()}
                        )
                        eval_summary = self._format_metrics(eval_metrics)
                        print(f"    Step {step+1}: train=[{train_summary}]")
                        print(f"              eval=[{eval_summary}]")
                    else:
                        # Brief eval summary in tqdm
                        tqdm.write(f"  [Eval @ {step+1}] {self._format_metrics(eval_metrics)}")
            
            if tqdm is not None and hasattr(pbar, 'close'):
                pbar.close()
            
            # Final evaluation
            print(f"\n[3] Final evaluation...")
            final_metrics = self.evaluate()
            
            print(f"\n    {'─'*40}")
            for k, v in final_metrics.items():
                if isinstance(v, float):
                    if abs(v) < 0.01 or abs(v) > 1000:
                        print(f"    {k:.<30} {v:.4e}")
                    else:
                        print(f"    {k:.<30} {v:.4f}")
                else:
                    print(f"    {k:.<30} {v}")
            print(f"    {'─'*40}")
            
            # Cleanup
            self.cleanup()
            
            # Success
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=True,
                metrics={
                    "final": final_metrics,
                    "training_history": self.state.metrics_history,
                    "steps": self.state.step,
                    "epochs": self.state.epoch,
                    "samples_seen": self.state.samples_seen,
                },
            )
            
        except Exception as e:
            import traceback
            tb = traceback.format_exc()
            print(f"\n[FAILED] {e}")
            print(tb)
            
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=False,
                metrics={"training_history": self.state.metrics_history},
                failure_reason=str(e),
            )



---
File: /sensorium/experiments/harness.py
---

"""Kernel experiment harness (Metal/MPS).

Goal: run experiments on the *new* custom-kernel implementation and generate
paper artifacts automatically under `paper/` so `paper/main.tex` picks them up.

Usage:
  - Run rule shift (writes `paper/tables/rule_shift_summary.tex` + `paper/figures/rule_shift.pdf`)
    `python3 -m sensorium.experiments.harness --experiment rule_shift`

  - Run ablations (writes `paper/tables/ablation.tex` and also refreshes rule_shift outputs)
    `python3 -m sensorium.experiments.harness --experiment ablation`

  - Run both
    `python3 -m sensorium.experiments.harness --experiment all`
"""

from __future__ import annotations

from pathlib import Path
import argparse
from typing import Optional

import torch

from .kernel_rule_shift import KernelRuleShiftConfig, run_kernel_rule_shift
from .kernel_ablations import run_kernel_ablation_study
from .kernel_continuous import KernelContinuousConfig, run_kernel_continuous
from .kernel_next_token import KernelNextTokenConfig, run_kernel_next_token
from .kernel_timeseries import KernelTimeSeriesConfig, run_kernel_timeseries
from .kernel_mnist_bytes import KernelMNISTBytesConfig, run_kernel_mnist_bytes
from .kernel_image_gen import KernelImageGenConfig, run_kernel_image_gen
from .kernel_audio_gen import KernelAudioGenConfig, run_kernel_audio_gen
from .kernel_text_diffusion import KernelTextDiffusionConfig, run_kernel_text_diffusion
from .kernel_cocktail_party import KernelCocktailPartyConfig, run_kernel_cocktail_party


def get_device_str() -> str:
    """Prefer Metal/MPS on macOS."""
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return "mps"
    return "cpu"


def run_paper_pipeline(*, device: str, run_rule_shift: bool, run_ablation: bool) -> None:
    paper_dir = Path("./paper")
    paper_dir.mkdir(parents=True, exist_ok=True)

    if run_rule_shift:
        print("[RUN] kernel rule_shift → paper/tables + paper/figures")
        cfg = KernelRuleShiftConfig(device=device)
        run_kernel_rule_shift(cfg, out_dir=paper_dir)

    if run_ablation:
        print("[RUN] kernel ablation → paper/tables/ablation.tex")
        run_kernel_ablation_study(device=device, out_dir=paper_dir, base_cfg=KernelRuleShiftConfig(device=device))


def run_kernel_experiments_all(*, device: str) -> None:
    """Run all kernel experiments and refresh paper artifacts."""
    run_paper_pipeline(device=device, run_rule_shift=True, run_ablation=True)
    # Also produce a stable kernel-physics visualization.
    run_kernel_continuous(KernelContinuousConfig(device=device, dashboard_enabled=False), out_dir=Path("./paper"))
    # Universal Tokenizer benchmarks + modality demos
    run_kernel_next_token(KernelNextTokenConfig(device=device), out_dir=Path("./paper"))
    run_kernel_timeseries(KernelTimeSeriesConfig(device=device), out_dir=Path("./paper"))
    run_kernel_text_diffusion(KernelTextDiffusionConfig(device=device), out_dir=Path("./paper"))
    # Vision/audio (may require torchvision; audio uses synthetic by default)
    run_kernel_mnist_bytes(KernelMNISTBytesConfig(device=device), out_dir=Path("./paper"))
    run_kernel_image_gen(KernelImageGenConfig(device=device), out_dir=Path("./paper"))
    run_kernel_audio_gen(KernelAudioGenConfig(device=device), out_dir=Path("./paper"))
    run_kernel_cocktail_party(KernelCocktailPartyConfig(device=device), out_dir=Path("./paper"))


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Run kernel-based sensorium experiments (Metal/MPS)"
    )
    parser.add_argument(
        "--experiment",
        choices=[
            "rule_shift",
            "ablation",
            "continuous",
            "next_token",
            "timeseries",
            "text_diffusion",
            "mnist_bytes",
            "image_gen",
            "audio_gen",
            "cocktail_party",
            "all",
        ],
        default="all",
        help="Which experiment to run (default: all).",
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="Device string (default: auto; prefers 'mps')",
    )
    
    args = parser.parse_args()

    device = args.device or get_device_str()
    print("=" * 60)
    print("SENSORIUM KERNEL EXPERIMENTS")
    print("=" * 60)
    print(f"Device: {device}")
    print(f"Experiment: {args.experiment}")

    if args.experiment == "all":
        run_kernel_experiments_all(device=device)
    elif args.experiment == "continuous":
        run_kernel_continuous(KernelContinuousConfig(device=device, dashboard_enabled=False), out_dir=Path("./paper"))
    elif args.experiment == "next_token":
        run_kernel_next_token(KernelNextTokenConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "timeseries":
        run_kernel_timeseries(KernelTimeSeriesConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "text_diffusion":
        run_kernel_text_diffusion(KernelTextDiffusionConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "mnist_bytes":
        run_kernel_mnist_bytes(KernelMNISTBytesConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "image_gen":
        run_kernel_image_gen(KernelImageGenConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "audio_gen":
        run_kernel_audio_gen(KernelAudioGenConfig(device=device), out_dir=Path("./paper"))
    elif args.experiment == "cocktail_party":
        run_kernel_cocktail_party(KernelCocktailPartyConfig(device=device), out_dir=Path("./paper"))
    else:
        run_paper_pipeline(
            device=device,
            run_rule_shift=args.experiment == "rule_shift",
            run_ablation=args.experiment == "ablation",
        )


if __name__ == "__main__":
    main()



---
File: /sensorium/experiments/image_gen.py
---

"""Image Generation Experiment

Uses MNIST / CIFAR-10 from HuggingFace.
Standard image benchmarks.

Goal: Generate images via thermodynamic diffusion in frequency space.
Metrics: Reconstruction MSE, FID (if we can compute it)
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale


class ImageGenerationExperiment(BaseExperiment):
    """Image generation using thermodynamic dynamics in frequency space.
    
    The approach:
    1. Encode training images to frequency-space particles
    2. Build attractors from the frequency distributions
    3. For generation: seed with noise, let particles diffuse toward attractors
    4. Decode via inverse FFT
    """
    
    name = "image_gen"
    goal = "Generate images via thermodynamic diffusion in frequency space"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.dataset_name = "mnist"
            self.image_size = 28
            self.top_k_freq = 50
        elif scale == Scale.MEDIUM:
            self.dataset_name = "mnist"
            self.image_size = 28
            self.top_k_freq = 200
        else:
            self.dataset_name = "cifar10"
            self.image_size = 32
            self.top_k_freq = 500
        
        # Frequency statistics (learned from training data)
        self._freq_attractors: Dict[Tuple[int, int], List[Tuple[float, float]]] = {}
    
    def setup(self) -> None:
        """Load image dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading {self.dataset_name}...")
        
        if self.dataset_name == "mnist":
            dataset = load_dataset(
                "ylecun/mnist",
                streaming=True,
                trust_remote_code=True,
            )
            self.image_key = "image"
        else:  # cifar10
            dataset = load_dataset(
                "uoft-cs/cifar10",
                streaming=True,
                trust_remote_code=True,
            )
            self.image_key = "img"
        
        # Store iterators
        self.train_stream = dataset["train"]
        self.eval_stream = dataset["test"]
        
        # Prefetch images
        self._train_images: List[torch.Tensor] = []
        self._eval_images: List[torch.Tensor] = []
        self._train_labels: List[int] = []
        self._eval_labels: List[int] = []
        
        self._load_images(
            self.train_stream,
            self._train_images,
            self._train_labels,
            self.scale_config.max_train_samples or 1000,
        )
        self._load_images(
            self.eval_stream,
            self._eval_images,
            self._eval_labels,
            self.scale_config.max_eval_samples or 200,
        )
        
        print(f"    Train images: {len(self._train_images)}")
        print(f"    Eval images: {len(self._eval_images)}")
        print(f"    Image size: {self.image_size}x{self.image_size}")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _load_images(
        self,
        stream,
        images: List[torch.Tensor],
        labels: List[int],
        max_samples: int,
    ) -> None:
        """Load images from stream."""
        for sample in stream:
            img = sample[self.image_key]
            
            # Convert PIL to tensor if needed
            if hasattr(img, "convert"):
                img = img.convert("L")  # Grayscale
                import numpy as np
                img = np.array(img, dtype=np.float32) / 255.0
                img = torch.from_numpy(img)
            else:
                img = torch.tensor(img, dtype=torch.float32)
                if img.max() > 1.0:
                    img = img / 255.0
                if img.ndim == 3:
                    img = img.mean(dim=-1)  # Grayscale
            
            # Resize if needed
            if img.shape[0] != self.image_size or img.shape[1] != self.image_size:
                img = torch.nn.functional.interpolate(
                    img.unsqueeze(0).unsqueeze(0),
                    size=(self.image_size, self.image_size),
                    mode="bilinear",
                    align_corners=False,
                ).squeeze()
            
            images.append(img)
            labels.append(sample.get("label", 0))
            
            if len(images) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[torch.Tensor, int]]:
        """Iterate over training images."""
        for img, label in zip(self._train_images, self._train_labels):
            yield img, label
    
    def train_step(self, batch: Tuple[torch.Tensor, int]) -> Dict[str, float]:
        """One step of thermodynamic image learning.
        
        Training = building attractor statistics from images.
        """
        image, label = batch
        image = image.to(self.device)
        
        # Clear and encode image
        self.manifold.clear()
        self.manifold.encode_image(image, top_k=self.top_k_freq)
        
        # Run dynamics to let structure emerge
        for _ in range(5):
            self.manifold.step()
        
        # Store frequency attractors (building a generative model)
        for p in self.manifold._particles:
            if p.modality == Modality.IMAGE and p.position.numel() == 2:
                u = int(p.position[0].item())
                v = int(p.position[1].item())
                key = (u, v)
                
                if key not in self._freq_attractors:
                    self._freq_attractors[key] = []
                
                # Store (energy, phase) for this frequency
                phase = p.phase[0].item() if p.phase is not None else 0.0
                self._freq_attractors[key].append((p.energy.item(), phase))
        
        # Decode and compute reconstruction error
        reconstructed = self.manifold.decode_image((self.image_size, self.image_size))
        mse = ((image - reconstructed) ** 2).mean().item()
        
        return {"mse": mse}
    
    def _generate_image(self) -> torch.Tensor:
        """Generate a new image using learned attractors."""
        self.manifold.clear()
        
        if not self._freq_attractors:
            # No attractors learned yet, return noise
            return torch.randn(self.image_size, self.image_size, device=self.device)
        
        # Create particles from attractor statistics
        for (u, v), stats in self._freq_attractors.items():
            if not stats:
                continue
            
            # Use mean energy and phase
            mean_energy = sum(e for e, _ in stats) / len(stats)
            mean_phase = sum(p for _, p in stats) / len(stats)
            
            # Add some noise for generation diversity
            noise = torch.randn(1, device=self.device).item() * 0.1
            
            position = torch.tensor([float(u), float(v)], device=self.device)
            phase = torch.tensor([mean_phase + noise], device=self.device)
            
            self.manifold.add_particle(
                position=position,
                energy=max(0.001, mean_energy + noise * 0.1),
                modality=Modality.IMAGE,
                phase=phase,
            )
        
        # Run dynamics
        for _ in range(10):
            self.manifold.step()
        
        # Decode
        return self.manifold.decode_image((self.image_size, self.image_size))
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate reconstruction and generation quality."""
        # Reconstruction quality on eval set
        mse_total = 0.0
        count = 0
        
        for image in self._eval_images[:50]:
            image = image.to(self.device)
            
            self.manifold.clear()
            self.manifold.encode_image(image, top_k=self.top_k_freq)
            
            for _ in range(5):
                self.manifold.step()
            
            reconstructed = self.manifold.decode_image((self.image_size, self.image_size))
            mse_total += ((image - reconstructed) ** 2).mean().item()
            count += 1
        
        recon_mse = mse_total / max(count, 1)
        
        # Generate some samples and compute metrics
        gen_images = [self._generate_image() for _ in range(10)]
        
        # Basic generation metrics
        gen_mean = torch.stack(gen_images).mean().item()
        gen_std = torch.stack(gen_images).std().item()
        
        # Compare to training distribution
        train_mean = torch.stack(self._train_images[:100]).mean().item()
        train_std = torch.stack(self._train_images[:100]).std().item()
        
        mean_diff = abs(gen_mean - train_mean)
        std_diff = abs(gen_std - train_std)
        
        return {
            "reconstruction_mse": recon_mse,
            "gen_mean": gen_mean,
            "gen_std": gen_std,
            "mean_diff": mean_diff,
            "std_diff": std_diff,
            "num_attractors": len(self._freq_attractors),
            "eval_images": count,
        }
    
    def save_samples(self, out_dir: str, num_samples: int = 16) -> None:
        """Save generated samples for visual inspection."""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            from pathlib import Path
            
            out_path = Path(out_dir)
            out_path.mkdir(parents=True, exist_ok=True)
            
            # Generate samples
            samples = [self._generate_image().cpu().numpy() for _ in range(num_samples)]
            
            # Plot grid
            rows = int(num_samples ** 0.5)
            cols = (num_samples + rows - 1) // rows
            
            fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
            axes = axes.flatten() if num_samples > 1 else [axes]
            
            for ax, sample in zip(axes, samples):
                ax.imshow(sample, cmap='gray')
                ax.axis('off')
            
            for ax in axes[len(samples):]:
                ax.axis('off')
            
            fig.tight_layout()
            fig.savefig(out_path / "generated_samples.png", dpi=150)
            plt.close(fig)
            
            print(f"    Saved samples to {out_path / 'generated_samples.png'}")
            
        except ImportError:
            print("    (matplotlib not available, skipping sample saving)")


def run_image_gen_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = ImageGenerationExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Save samples
    exp.save_samples("./artifacts/image_gen")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /sensorium/experiments/kernel_ablations.py
---

"""Kernel-based ablation study (Metal/MPS).

Writes:
- `paper/tables/ablation.tex`
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from optimizer.manifold_physics import SpectralCarrierConfig

from .kernel_rule_shift import KernelRuleShiftConfig, run_kernel_rule_shift


def _row(name: str, pre: float, post: float, rec: Optional[int]) -> str:
    rs = str(rec) if rec is not None else "N/A"
    return f"{name} & {pre:.3f} & {post:.3f} & {rs} \\\\"


def run_kernel_ablation_study(
    *,
    device: str = "mps",
    out_dir: Path = Path("./paper"),
    base_cfg: Optional[KernelRuleShiftConfig] = None,
) -> Dict[str, Any]:
    cfg = base_cfg or KernelRuleShiftConfig(device=device)

    conditions: List[Tuple[str, SpectralCarrierConfig]] = []

    # Full system (defaults)
    conditions.append(("Full", SpectralCarrierConfig()))

    # No top-down bias
    conditions.append(
        (
            "No top-down",
            SpectralCarrierConfig(
                topdown_phase_scale=0.0,
                topdown_energy_scale=0.0,
                topdown_random_energy_eps=0.0,
            ),
        )
    )

    # No crystallization (effectively disables long-term memory)
    conditions.append(
        (
            "No crystallization",
            SpectralCarrierConfig(
                stable_amp_threshold=1e9,
                crystallize_amp_threshold=1e9,
                crystallize_age=10**9,
                crystallized_coupling_boost=0.0,
            ),
        )
    )

    # No splitting (forces single-spectrum compromise)
    conditions.append(
        (
            "No splitting",
            SpectralCarrierConfig(
                conflict_threshold=1e9,
            ),
        )
    )

    # No exploration (anchors become greedy)
    conditions.append(
        (
            "No exploration",
            SpectralCarrierConfig(
                anchor_random_eps=0.0,
                topdown_random_energy_eps=0.0,
            ),
        )
    )

    rows: List[str] = []
    results: List[Dict[str, Any]] = []
    for name, scfg in conditions:
        m = run_kernel_rule_shift(cfg, spectral_cfg=scfg, out_dir=out_dir)
        pre = float(m["pre_shift_alignment"])
        post = float(m["post_shift_alignment_immediate"])
        rec = m["recovery_steps"]
        rows.append(_row(name, pre, post, rec))
        results.append({"condition": name, "pre": pre, "post": post, "recovery_steps": rec})

    table = r"""\begin{table}[t]
\centering
\caption{Kernel ablations. We disable individual carrier-memory mechanisms and report alignment before/after rule reversal.}
\label{tab:ablation}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Pre-shift} & \textbf{Post-shift} & \textbf{Recovery steps} \\
\midrule
""" + "\n".join(rows) + r"""
\bottomrule
\end{tabular}
\end{table}
"""

    out_dir = Path(out_dir)
    tables_dir = out_dir / "tables"
    tables_dir.mkdir(parents=True, exist_ok=True)
    (tables_dir / "ablation.tex").write_text(table, encoding="utf-8")

    return {"conditions": results}




---
File: /sensorium/experiments/kernel_audio_gen.py
---

"""Kernel audio handling via Universal Tokenizer (waveform inpainting demo).

We quantize waveform samples to bytes and reconstruct a missing segment by
sampling bytes, similar to the MNIST inpainting experiment.

Writes:
- `paper/tables/audio_gen_summary.tex`
- `paper/figures/audio_gen.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelAudioGenConfig:
    device: str = "mps"
    length: int = 4000
    train_samples: int = 40
    eval_samples: int = 10
    hash_vocab_size: int = 4096
    mask_frac: float = 0.20


def _synthetic_audio(n: int, seed: int) -> torch.Tensor:
    g = torch.Generator().manual_seed(int(seed))
    t = torch.linspace(0, 1.0, n)
    f1 = 220.0 + float(torch.randint(0, 440, (1,), generator=g).item())
    f2 = f1 * 2.0
    f3 = f1 * 1.5
    y = 0.5 * torch.sin(2 * torch.pi * f1 * t) + 0.3 * torch.sin(2 * torch.pi * f2 * t) + 0.2 * torch.sin(2 * torch.pi * f3 * t)
    env = torch.exp(-3.0 * t)
    y = y * env
    y = y / (y.abs().max() + 1e-8)
    return y.to(torch.float32)


def _to_bytes(y: torch.Tensor) -> torch.Tensor:
    # [-1,1] -> [0,255]
    z = (y.clamp(-1.0, 1.0) + 1.0) * 0.5
    return (z * 255.0).round().clamp(0, 255).to(torch.uint8)


def _from_bytes(b: torch.Tensor) -> torch.Tensor:
    z = b.to(torch.float32) / 255.0
    return (z * 2.0 - 1.0).to(torch.float32)


def run_kernel_audio_gen(cfg: KernelAudioGenConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    train = [_to_bytes(_synthetic_audio(int(cfg.length), seed=i)) for i in range(int(cfg.train_samples))]
    eval_ = [_to_bytes(_synthetic_audio(int(cfg.length), seed=1000 + i)) for i in range(int(cfg.eval_samples))]

    eng_cfg = KernelEngineConfig(device=cfg.device, hash_vocab_size=int(cfg.hash_vocab_size))
    eng = KernelTokenEngine(eng_cfg)

    # Train by streaming a few samples (carriers build up).
    for wav in train:
        eng.reset()
        for p, bv in enumerate(wav.tolist()):
            tid = hash_id(int(bv), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 128) == 0:
                eng.step(p)

    mse_sum = 0.0
    demo: List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]] = []
    for wav in eval_:
        eng.reset()
        n = int(wav.numel())
        mask_n = int(float(cfg.mask_frac) * n)
        mask_idx = torch.randperm(n)[:mask_n]
        masked = wav.clone()
        masked[mask_idx] = 128  # mid-level

        observed = torch.ones(n, dtype=torch.bool)
        observed[mask_idx] = False
        for p in range(n):
            if not bool(observed[p]):
                continue
            bv = int(masked[p].item())
            tid = hash_id(bv, p, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 128) == 0:
                eng.step(p)

        recon = masked.clone()
        for p in mask_idx.tolist():
            b_pred, _scores = eng.predict_byte(int(p))
            recon[int(p)] = int(b_pred)
            tid = hash_id(int(b_pred), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            eng.step(int(p))

        gt = _from_bytes(wav)
        rr = _from_bytes(recon)
        mse = float(((gt - rr) ** 2).mean().item())
        mse_sum += mse
        if len(demo) < 3:
            demo.append((gt, _from_bytes(masked), rr))

    mse_avg = float(mse_sum / max(1, len(eval_)))

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel audio inpainting via Universal Tokenizer byte completion (synthetic audio).}
\label{tab:audio_gen}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Waveform MSE & """ + f"{mse_avg:.4f}" + r""" \\
Mask fraction & """ + f"{float(cfg.mask_frac):.2f}" + r""" \\
Eval samples & """ + f"{len(eval_)}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "audio_gen_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        fig, axes = plt.subplots(len(demo), 1, figsize=(9, 2.2 * len(demo)))
        if len(demo) == 1:
            axes = [axes]
        for i, (gt, ms, rc) in enumerate(demo):
            ax = axes[i]
            ax.plot(gt.numpy(), label="gt", linewidth=1.0, alpha=0.8)
            ax.plot(ms.numpy(), label="masked", linewidth=1.0, alpha=0.6)
            ax.plot(rc.numpy(), label="recon", linewidth=1.0, alpha=0.8)
            ax.set_xlim(0, int(cfg.length))
            ax.legend(loc="upper right", fontsize=7)
        fig.tight_layout()
        fig.savefig(fdir / "audio_gen.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {"mse": mse_avg}




---
File: /sensorium/experiments/kernel_cocktail_party.py
---

"""Kernel cocktail party (two-speaker) separation experiment.

Uses `two_speakers.wav` bundled in this folder.

Mechanism (kernel stack):
1) Build carrier spectrum from a short prompt window A → select top-K carriers (mask A)
2) Build carrier spectrum from a short prompt window B → select top-K carriers (mask B)
3) Run autoregressive byte sampling on the overlap window using masked carrier scoring,
   producing two different reconstructions ("speaker A" and "speaker B").

Writes:
- `paper/tables/cocktail_party_summary.tex`
- `paper/figures/cocktail_party.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import numpy as np
import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelCocktailPartyConfig:
    device: str = "mps"
    wav_path: Path = Path("sensorium/experiments/two_speakers.wav")

    # Windowing assumption (best-effort):
    prompt_seconds: float = 1.0
    prompt_a_start_s: float = 0.0
    prompt_b_start_s: float = 1.0
    overlap_start_s: float = 2.0
    overlap_seconds: float = 2.0

    # Byte modeling
    hash_vocab_size: int = 4096
    carrier_top_k: int = 16
    ingest_step_every: int = 256


def _read_wav_mono(path: Path) -> Tuple[int, np.ndarray]:
    import wave

    with wave.open(str(path), "rb") as wf:
        sr = wf.getframerate()
        nchan = wf.getnchannels()
        sampwidth = wf.getsampwidth()
        nframes = wf.getnframes()
        raw = wf.readframes(nframes)

    if sampwidth == 2:
        x = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
    elif sampwidth == 1:
        x = (np.frombuffer(raw, dtype=np.uint8).astype(np.float32) - 128.0) / 128.0
    else:
        raise RuntimeError(f"Unsupported sample width: {sampwidth}")

    if nchan > 1:
        x = x.reshape(-1, nchan).mean(axis=1)
    return int(sr), x


def _float_to_bytes(x: np.ndarray) -> np.ndarray:
    # [-1,1] -> [0,255]
    z = np.clip((x + 1.0) * 0.5, 0.0, 1.0)
    return np.clip(np.round(z * 255.0), 0, 255).astype(np.uint8)


def _bytes_to_float(b: np.ndarray) -> np.ndarray:
    z = b.astype(np.float32) / 255.0
    return (z * 2.0 - 1.0).astype(np.float32)


def _carrier_mask_from_engine(eng: KernelTokenEngine, top_k: int) -> torch.Tensor:
    st = eng._last_carrier_state
    if st is None:
        return torch.zeros((0,), device=eng.dev, dtype=torch.bool)
    amp = st["amplitudes"]
    m = int(amp.numel())
    if m == 0:
        return torch.zeros((0,), device=eng.dev, dtype=torch.bool)
    k = min(int(top_k), m)
    idx = torch.topk(amp, k=k, largest=True).indices
    mask = torch.zeros((m,), device=eng.dev, dtype=torch.bool)
    mask[idx] = True
    return mask


def _stft_mag(x: np.ndarray, *, n_fft: int = 512, hop: int = 128) -> np.ndarray:
    # Torch STFT for consistency.
    t = torch.tensor(x, dtype=torch.float32)
    Z = torch.stft(t, n_fft=n_fft, hop_length=hop, win_length=n_fft, return_complex=True)
    mag = torch.abs(Z).numpy()
    return mag


def run_kernel_cocktail_party(cfg: KernelCocktailPartyConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    wav_path = Path(cfg.wav_path)
    if not wav_path.exists():
        raise FileNotFoundError(str(wav_path))

    sr, x = _read_wav_mono(wav_path)
    b = _float_to_bytes(x)

    def sl(start_s: float, dur_s: float) -> slice:
        i0 = int(start_s * sr)
        i1 = int((start_s + dur_s) * sr)
        i0 = max(0, min(i0, len(b)))
        i1 = max(0, min(i1, len(b)))
        return slice(i0, i1)

    a_sl = sl(cfg.prompt_a_start_s, cfg.prompt_seconds)
    b_sl = sl(cfg.prompt_b_start_s, cfg.prompt_seconds)
    o_sl = sl(cfg.overlap_start_s, cfg.overlap_seconds)

    prompt_a = b[a_sl]
    prompt_b = b[b_sl]
    overlap = b[o_sl]
    if len(overlap) < 256:
        raise RuntimeError("Overlap window too short in two_speakers.wav")

    eng_cfg = KernelEngineConfig(device=cfg.device, hash_vocab_size=int(cfg.hash_vocab_size), carrier_every=1)

    # Build A mask
    engA = KernelTokenEngine(eng_cfg)
    engA.reset()
    for i, bv in enumerate(prompt_a.tolist()):
        tid = hash_id(int(bv), int(i), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engA.inject_id(tid)
        if (i % int(cfg.ingest_step_every)) == 0:
            engA.step(i)
    engA.step(int(len(prompt_a)))
    maskA = _carrier_mask_from_engine(engA, top_k=int(cfg.carrier_top_k))

    # Build B mask
    engB = KernelTokenEngine(eng_cfg)
    engB.reset()
    for i, bv in enumerate(prompt_b.tolist()):
        tid = hash_id(int(bv), int(i), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engB.inject_id(tid)
        if (i % int(cfg.ingest_step_every)) == 0:
            engB.step(i)
    engB.step(int(len(prompt_b)))
    maskB = _carrier_mask_from_engine(engB, top_k=int(cfg.carrier_top_k))

    # Reconstruct overlap twice
    reconA = np.zeros_like(overlap)
    reconB = np.zeros_like(overlap)

    engA2 = KernelTokenEngine(eng_cfg)
    engA2.reset()
    # prime with prompt A
    for i, bv in enumerate(prompt_a.tolist()):
        tid = hash_id(int(bv), int(i), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engA2.inject_id(tid)
        if (i % int(cfg.ingest_step_every)) == 0:
            engA2.step(i)
    engA2.step(int(len(prompt_a)))
    # sample overlap bytes with maskA
    for t in range(int(len(overlap))):
        pos = int(t)  # local position
        bb, _scores = engA2.predict_byte(pos, carrier_mask=maskA)
        reconA[t] = bb
        tid = hash_id(int(bb), pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engA2.inject_id(tid)
        engA2.step(pos)

    engB2 = KernelTokenEngine(eng_cfg)
    engB2.reset()
    for i, bv in enumerate(prompt_b.tolist()):
        tid = hash_id(int(bv), int(i), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engB2.inject_id(tid)
        if (i % int(cfg.ingest_step_every)) == 0:
            engB2.step(i)
    engB2.step(int(len(prompt_b)))
    for t in range(int(len(overlap))):
        pos = int(t)
        bb, _scores = engB2.predict_byte(pos, carrier_mask=maskB)
        reconB[t] = bb
        tid = hash_id(int(bb), pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        engB2.inject_id(tid)
        engB2.step(pos)

    # Metrics (best-effort, no ground-truth stems):
    mix = _bytes_to_float(overlap)
    a = _bytes_to_float(reconA)
    c = _bytes_to_float(reconB)
    eps = 1e-8
    rms_mix = float(np.sqrt(np.mean(mix * mix) + eps))
    rms_a = float(np.sqrt(np.mean(a * a) + eps))
    rms_c = float(np.sqrt(np.mean(c * c) + eps))
    scale = rms_mix / (rms_a + rms_c + eps)
    a_s = a * scale
    c_s = c * scale
    recon_sum = np.clip(a_s + c_s, -1.0, 1.0)
    recon_mse = float(np.mean((recon_sum - mix) ** 2))
    cos_ac = float(np.dot(a_s, c_s) / (np.linalg.norm(a_s) * np.linalg.norm(c_s) + eps))

    # Write artifacts
    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel cocktail-party separation (two-speaker mixture). Prompts build carrier masks; overlap is reconstructed twice using masked carrier scoring.}
\label{tab:cocktail_party}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Overlap length (s) & """ + f"{len(overlap)/sr:.2f}" + r""" \\
Top-K carriers per speaker & """ + f"{int(cfg.carrier_top_k)}" + r""" \\
Mixture reconstruction MSE (A+B) & """ + f"{recon_mse:.4f}" + r""" \\
Cosine similarity (A vs B) & """ + f"{cos_ac:.3f}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "cocktail_party_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        m_mix = _stft_mag(mix)
        m_a = _stft_mag(a_s)
        m_b = _stft_mag(c_s)

        def logimg(m):
            return np.log1p(m)

        fig, axes = plt.subplots(3, 1, figsize=(10, 7), sharex=True)
        axes[0].imshow(logimg(m_mix), aspect="auto", origin="lower")
        axes[0].set_title("Mixture (overlap)")
        axes[1].imshow(logimg(m_a), aspect="auto", origin="lower")
        axes[1].set_title("Separated A (masked carriers)")
        axes[2].imshow(logimg(m_b), aspect="auto", origin="lower")
        axes[2].set_title("Separated B (masked carriers)")
        axes[2].set_xlabel("frame")
        for ax in axes:
            ax.set_ylabel("freq")
        fig.tight_layout()
        fig.savefig(fdir / "cocktail_party.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {
        "sr": sr,
        "recon_mse": recon_mse,
        "cos_ab": cos_ac,
        "overlap_seconds": float(len(overlap) / sr),
    }




---
File: /sensorium/experiments/kernel_continuous.py
---

"""Kernel-based continuous simulation (finite run).

This is the kernel analogue of the interactive simulator, but runs for a fixed
number of steps so it can be used in an experiment pipeline.

Outputs (best-effort):
- `paper/figures/continuous_final.png`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

import torch

from optimizer.manifold_physics import (
    ManifoldPhysics,
    ManifoldPhysicsConfig,
    SpectralCarrierPhysics,
    SpectralCarrierConfig,
    ParticleGenerator,
)
from sensorium.manifold.visualizer import SimulationDashboard
from sensorium.manifold.carriers import CarrierState


@dataclass(frozen=True, slots=True)
class KernelContinuousConfig:
    device: str = "mps"
    grid_size: tuple[int, int, int] = (32, 32, 32)
    dt: float = 0.02
    steps: int = 1500

    num_particles_init: int = 600
    inject_every: int = 50
    inject_min: int = 40
    inject_max: int = 80

    # Dashboard
    dashboard_enabled: bool = False
    dashboard_update_interval: int = 10
    dashboard_video_path: Optional[Path] = None


def run_kernel_continuous(cfg: KernelContinuousConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    if cfg.device != "mps":
        raise RuntimeError("Kernel continuous experiment currently expects device='mps' (Metal).")

    dev = torch.device(cfg.device)
    dtype = torch.float32
    two_pi = float(2.0 * torch.pi)

    # Physics
    mp_cfg = ManifoldPhysicsConfig(
        grid_size=cfg.grid_size,
        dt=float(cfg.dt),
        poisson_iterations=25,
        device=cfg.device,
    )
    physics = ManifoldPhysics(mp_cfg, device=cfg.device)

    # Generator (Metal kernel)
    generator = ParticleGenerator(grid_size=cfg.grid_size, device=cfg.device)

    # Carriers
    scfg = SpectralCarrierConfig(max_carriers=64)
    carrier_physics = SpectralCarrierPhysics(config=scfg, grid_size=cfg.grid_size, dt=float(cfg.dt), device=cfg.device)
    carriers = CarrierState.empty(cfg.device, dtype)

    # Initial particles
    init = generator.generate_file(num_particles=int(cfg.num_particles_init), pattern="cluster", energy_scale=1.0)
    positions = init["positions"].to(dev, dtype=dtype)
    velocities = init["velocities"].to(dev, dtype=dtype)
    energies = init["energies"].to(dev, dtype=dtype)
    heats = init["heats"].to(dev, dtype=dtype)
    excitations = init["excitations"].to(dev, dtype=dtype)
    masses = init["masses"].to(dev, dtype=dtype)
    osc_phase = torch.rand(int(cfg.num_particles_init), device=dev, dtype=dtype) * two_pi

    # Dashboard (optional)
    dashboard = None
    if cfg.dashboard_enabled:
        # Build a minimal compatible config-like object for the dashboard.
        from sensorium.manifold.config import SimulationConfig

        sim_cfg = SimulationConfig(
            grid_size=cfg.grid_size,
            dt=float(cfg.dt),
            poisson_iterations=25,
            device=cfg.device,
            dashboard_enabled=True,
            dashboard_update_interval=int(cfg.dashboard_update_interval),
        )
        dashboard = SimulationDashboard(sim_cfg)
        if cfg.dashboard_video_path:
            dashboard.start_recording(Path(cfg.dashboard_video_path))

    # Run
    for step in range(int(cfg.steps)):
        if cfg.inject_every > 0 and (step % int(cfg.inject_every) == 0) and step > 0:
            n_new = int(cfg.inject_min + (step * 1103515245 + 12345) % max(1, (cfg.inject_max - cfg.inject_min + 1)))
            pat = ParticleGenerator.PATTERN_NAMES[(step // cfg.inject_every) % len(ParticleGenerator.PATTERN_NAMES)]
            new = generator.generate_file(num_particles=n_new, pattern=pat, energy_scale=1.0)
            positions = torch.cat([positions, new["positions"]])
            velocities = torch.cat([velocities, new["velocities"]])
            energies = torch.cat([energies, new["energies"]])
            heats = torch.cat([heats, new["heats"]])
            excitations = torch.cat([excitations, new["excitations"]])
            masses = torch.cat([masses, new["masses"]])
            osc_phase = torch.cat([osc_phase, torch.rand(n_new, device=dev, dtype=dtype) * two_pi])

            if dashboard:
                dashboard.record_injection(
                    step=step,
                    file_id=int(new["file_id"]),
                    pattern=str(new["pattern"]),
                    num_particles=int(n_new),
                    total_energy=float(new["energies"].sum().detach().to("cpu").item()),
                )

        positions, velocities, energies, heats, excitations = physics.step(
            positions, velocities, energies, heats, excitations, masses
        )

        if step % 10 == 0:
            cst = carrier_physics.step(osc_phase, excitations, energies)
            osc_phase = cst["osc_phase"]
            carriers = CarrierState(
                frequencies=cst["frequencies"],
                gate_widths=cst["gate_widths"],
                amplitudes=cst["amplitudes"],
                phases=cst["phases"],
            )

        if dashboard and (step % int(cfg.dashboard_update_interval) == 0):
            dashboard.update(
                step=step,
                positions=positions,
                velocities=velocities,
                energies=energies,
                heats=heats,
                excitations=excitations,
                step_time_ms=0.0,
                carriers=carriers,
                gravity_field=physics.gravity_potential,
            )

    # Save final snapshot (always)
    out_dir = Path(out_dir)
    fig_dir = out_dir / "figures"
    fig_dir.mkdir(parents=True, exist_ok=True)

    if dashboard is None:
        # Create a dashboard just for a final render.
        from sensorium.manifold.config import SimulationConfig

        sim_cfg = SimulationConfig(
            grid_size=cfg.grid_size,
            dt=float(cfg.dt),
            poisson_iterations=25,
            device=cfg.device,
            dashboard_enabled=True,
            dashboard_update_interval=1,
        )
        dashboard = SimulationDashboard(sim_cfg)
        dashboard.update(
            step=int(cfg.steps),
            positions=positions,
            velocities=velocities,
            energies=energies,
            heats=heats,
            excitations=excitations,
            step_time_ms=0.0,
            carriers=carriers,
            gravity_field=physics.gravity_potential,
        )

    dashboard.save(fig_dir / "continuous_final.png")
    try:
        dashboard.close()
    except Exception:
        pass

    return {
        "steps": int(cfg.steps),
        "final_particles": int(positions.shape[0]),
        "final_energy": float(energies.sum().detach().to("cpu").item()),
        "final_heat": float(heats.sum().detach().to("cpu").item()),
    }




---
File: /sensorium/experiments/kernel_engine.py
---

"""Shared kernel experiment utilities (Metal/MPS).

This provides a small "experiment runtime" for the kernel stack:
- inject token IDs as particle bursts into 3D space
- evolve manifold physics via Metal kernels
- evolve spectral carriers via Metal kernels
- score candidate IDs (and invert to byte values by brute force)
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Tuple

import torch

from optimizer.manifold_physics import (
    ManifoldPhysics,
    ManifoldPhysicsConfig,
    SpectralCarrierPhysics,
    SpectralCarrierConfig,
)


@dataclass(frozen=True, slots=True)
class KernelEngineConfig:
    device: str = "mps"
    grid_size: tuple[int, int, int] = (32, 32, 32)
    dt: float = 0.02

    # Injection
    particles_per_token: int = 8
    injection_spread: float = 0.6
    energy_scale: float = 1.0

    # Carrier cadence
    carrier_every: int = 1

    # Universal tokenizer hash (must match sensorium/core/tokenizer.py)
    hash_vocab_size: int = 4096
    hash_prime: int = 31
    special_size: int = 5  # <pad>,<unk>,<bos>,<eos>,<mask>
    num_labels: int = 0

    # ID -> omega mapping
    omega_range: float = 2.0
    omega_mod: int = 2048


def hash_id(byte_val: int, pos: int, *, hash_vocab_size: int, hash_prime: int, special_size: int) -> int:
    return int((int(byte_val) * int(hash_prime) + int(pos)) % int(hash_vocab_size) + int(special_size))


def label_id(label: int, *, special_size: int, hash_vocab_size: int) -> int:
    return int(int(special_size) + int(hash_vocab_size) + int(label))


def omega_from_id(token_id: int, *, omega_range: float, omega_mod: int) -> float:
    return float((int(token_id) % int(omega_mod)) / float(omega_mod) * float(omega_range))


def center_from_id(token_id: int, grid_size: tuple[int, int, int]) -> torch.Tensor:
    gx, gy, gz = grid_size
    x = (int(token_id) * 73856093) % gx
    y = (int(token_id) * 19349663) % gy
    z = (int(token_id) * 83492791) % gz
    return torch.tensor(
        [
            1 + (x % max(1, gx - 2)),
            1 + (y % max(1, gy - 2)),
            1 + (z % max(1, gz - 2)),
        ],
        dtype=torch.float32,
    )


class KernelTokenEngine:
    def __init__(
        self,
        cfg: KernelEngineConfig,
        *,
        physics_cfg: Optional[ManifoldPhysicsConfig] = None,
        spectral_cfg: Optional[SpectralCarrierConfig] = None,
    ):
        if cfg.device != "mps":
            raise RuntimeError("KernelTokenEngine currently expects device='mps' (Metal).")
        if not torch.backends.mps.is_available():
            raise RuntimeError("MPS backend not available")

        self.cfg = cfg
        self.dev = torch.device(cfg.device)
        self.dtype = torch.float32
        self.two_pi = float(2.0 * torch.pi)

        mp_cfg = physics_cfg or ManifoldPhysicsConfig(
            grid_size=cfg.grid_size,
            dt=float(cfg.dt),
            poisson_iterations=25,
            device=cfg.device,
        )
        self.physics = ManifoldPhysics(mp_cfg, device=cfg.device)

        scfg = spectral_cfg or SpectralCarrierConfig(max_carriers=64)
        self.carriers = SpectralCarrierPhysics(config=scfg, grid_size=cfg.grid_size, dt=float(cfg.dt), device=cfg.device)

        self.reset()

    def reset(self) -> None:
        self.positions = torch.empty((0, 3), device=self.dev, dtype=self.dtype)
        self.velocities = torch.empty((0, 3), device=self.dev, dtype=self.dtype)
        self.energies = torch.empty((0,), device=self.dev, dtype=self.dtype)
        self.heats = torch.empty((0,), device=self.dev, dtype=self.dtype)
        self.excitations = torch.empty((0,), device=self.dev, dtype=self.dtype)
        self.masses = torch.empty((0,), device=self.dev, dtype=self.dtype)
        self.osc_phase = torch.empty((0,), device=self.dev, dtype=self.dtype)
        self._last_carrier_state = None

    def inject_id(self, token_id: int, *, particles: Optional[int] = None, energy_scale: Optional[float] = None) -> None:
        n = int(particles if particles is not None else self.cfg.particles_per_token)
        en_scale = float(energy_scale if energy_scale is not None else self.cfg.energy_scale)

        center = center_from_id(int(token_id), self.cfg.grid_size).to(device=self.dev, dtype=self.dtype)
        pos = center.view(1, 3) + torch.randn(n, 3, device=self.dev, dtype=self.dtype) * float(self.cfg.injection_spread)
        pos = pos.clamp(0.5, float(min(self.cfg.grid_size) - 1.5))
        vel = torch.randn(n, 3, device=self.dev, dtype=self.dtype) * 0.05

        om = float(omega_from_id(int(token_id), omega_range=self.cfg.omega_range, omega_mod=self.cfg.omega_mod))
        ex = torch.full((n,), om, device=self.dev, dtype=self.dtype) + torch.randn(n, device=self.dev, dtype=self.dtype) * 0.01

        en = torch.full((n,), en_scale, device=self.dev, dtype=self.dtype)
        ht = torch.zeros((n,), device=self.dev, dtype=self.dtype)
        ms = en.clone()
        ph = torch.rand(n, device=self.dev, dtype=self.dtype) * self.two_pi

        self.positions = torch.cat([self.positions, pos], dim=0)
        self.velocities = torch.cat([self.velocities, vel], dim=0)
        self.energies = torch.cat([self.energies, en], dim=0)
        self.heats = torch.cat([self.heats, ht], dim=0)
        self.excitations = torch.cat([self.excitations, ex], dim=0)
        self.masses = torch.cat([self.masses, ms], dim=0)
        self.osc_phase = torch.cat([self.osc_phase, ph], dim=0)

    def step(self, t: int) -> None:
        self.positions, self.velocities, self.energies, self.heats, self.excitations = self.physics.step(
            self.positions,
            self.velocities,
            self.energies,
            self.heats,
            self.excitations,
            self.masses,
        )

        if (t % int(self.cfg.carrier_every)) == 0 and int(self.osc_phase.numel()) > 0:
            self._last_carrier_state = self.carriers.step(self.osc_phase, self.excitations, self.energies)
            self.osc_phase = self._last_carrier_state["osc_phase"]

    def score_ids(self, token_ids: torch.Tensor, *, carrier_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """Score candidate IDs via current carrier spectrum.

        Returns non-negative scores (higher is better).
        """
        if self._last_carrier_state is None:
            return torch.zeros_like(token_ids, dtype=torch.float32, device=token_ids.device)

        om_c = self._last_carrier_state["frequencies"]  # (M,)
        sig = self._last_carrier_state["gate_widths"].clamp(min=1e-3)  # (M,)
        amp = self._last_carrier_state["amplitudes"].clamp(min=0.0)  # (M,)
        if int(om_c.numel()) == 0:
            return torch.zeros_like(token_ids, dtype=torch.float32, device=token_ids.device)

        if carrier_mask is not None:
            carrier_mask = carrier_mask.to(device=om_c.device)
            if carrier_mask.dtype != torch.bool:
                carrier_mask = carrier_mask.to(torch.bool)
            if int(carrier_mask.numel()) == int(om_c.numel()):
                om_c = om_c[carrier_mask]
                sig = sig[carrier_mask]
                amp = amp[carrier_mask]
            if int(om_c.numel()) == 0:
                return torch.zeros_like(token_ids, dtype=torch.float32, device=token_ids.device)

        om_q = (token_ids.to(torch.long) % int(self.cfg.omega_mod)).to(torch.float32) / float(self.cfg.omega_mod) * float(self.cfg.omega_range)  # (K,)
        # tuning: (M,K)
        diff = om_c.view(-1, 1) - om_q.view(1, -1)
        tuning = torch.exp(-(diff * diff) / (sig.view(-1, 1) * sig.view(-1, 1)))
        scores = (amp.view(-1, 1) * tuning).sum(dim=0)
        return scores.to(torch.float32)

    def predict_byte(self, pos: int, *, carrier_mask: Optional[torch.Tensor] = None) -> Tuple[int, torch.Tensor]:
        """Predict next byte at sequence position `pos`.

        Returns (argmax_byte, scores[256]).
        """
        cand_bytes = torch.arange(256, device=self.dev, dtype=torch.long)
        cand_ids = (cand_bytes * int(self.cfg.hash_prime) + int(pos)) % int(self.cfg.hash_vocab_size)
        cand_ids = cand_ids + int(self.cfg.special_size)
        scores = self.score_ids(cand_ids, carrier_mask=carrier_mask)
        b = int(torch.argmax(scores).item())
        return b, scores




---
File: /sensorium/experiments/kernel_image_gen.py
---

"""Kernel image handling via Universal Tokenizer (MNIST inpainting demo).

We demonstrate "native image handling" in the sense of the Universal Tokenizer:
pixels are bytes, hashed with position, with completion by sampling bytes.

Writes:
- `paper/tables/image_gen_summary.tex`
- `paper/figures/image_gen.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelImageGenConfig:
    device: str = "mps"
    train_images: int = 60
    eval_images: int = 12
    hash_vocab_size: int = 4096
    mask_frac: float = 0.20


def _load_mnist_images(n_train: int, n_eval: int) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:
    try:
        from torchvision import datasets, transforms
    except Exception as e:
        raise ImportError("torchvision is required for kernel_image_gen") from e
    data_dir = Path("./data/mnist")
    data_dir.mkdir(parents=True, exist_ok=True)
    tfm = transforms.ToTensor()
    tr = datasets.MNIST(root=str(data_dir), train=True, download=True, transform=tfm)
    te = datasets.MNIST(root=str(data_dir), train=False, download=True, transform=tfm)
    train = []
    eval_ = []
    for i in range(min(n_train, len(tr))):
        img, _y = tr[i]
        train.append((img * 255.0).to(torch.uint8).view(-1))
    for i in range(min(n_eval, len(te))):
        img, _y = te[i]
        eval_.append((img * 255.0).to(torch.uint8).view(-1))
    return train, eval_


def run_kernel_image_gen(cfg: KernelImageGenConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    train_imgs, eval_imgs = _load_mnist_images(int(cfg.train_images), int(cfg.eval_images))
    eng_cfg = KernelEngineConfig(device=cfg.device, hash_vocab_size=int(cfg.hash_vocab_size))
    eng = KernelTokenEngine(eng_cfg)

    # "Train" by streaming a few full images (build carriers).
    for img in train_imgs:
        eng.reset()
        for p, bv in enumerate(img.tolist()):
            tid = hash_id(int(bv), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 64) == 0:
                eng.step(p)

    # Evaluate inpainting
    mse_sum = 0.0
    samples: List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]] = []
    for img in eval_imgs:
        eng.reset()
        img_bytes = img.clone()
        n = int(img_bytes.numel())
        mask_n = int(float(cfg.mask_frac) * n)
        mask_idx = torch.randperm(n)[:mask_n]
        masked = img_bytes.clone()
        masked[mask_idx] = 0

        # Ingest observed bytes
        observed = torch.ones(n, dtype=torch.bool)
        observed[mask_idx] = False
        for p in range(n):
            if not bool(observed[p]):
                continue
            bv = int(masked[p].item())
            tid = hash_id(bv, p, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 64) == 0:
                eng.step(p)

        # Fill missing sequentially
        recon = masked.clone()
        for p in mask_idx.tolist():
            b_pred, _scores = eng.predict_byte(int(p))
            recon[int(p)] = int(b_pred)
            tid = hash_id(int(b_pred), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            eng.step(int(p))

        # MSE in [0,1] space
        gt = img_bytes.to(torch.float32) / 255.0
        rr = recon.to(torch.float32) / 255.0
        mse = float(((gt - rr) ** 2).mean().item())
        mse_sum += mse
        if len(samples) < 6:
            samples.append((img_bytes.view(28, 28), masked.view(28, 28), recon.view(28, 28)))

    mse_avg = float(mse_sum / max(1, len(eval_imgs)))

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel MNIST inpainting via Universal Tokenizer byte completion.}
\label{tab:image_gen}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Reconstruction MSE & """ + f"{mse_avg:.4f}" + r""" \\
Mask fraction & """ + f"{float(cfg.mask_frac):.2f}" + r""" \\
Eval images & """ + f"{len(eval_imgs)}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "image_gen_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        fig, axes = plt.subplots(len(samples), 3, figsize=(7, 2.2 * len(samples)))
        if len(samples) == 1:
            axes = axes.reshape(1, 3)
        for i, (gt, ms, rc) in enumerate(samples):
            for j, (im, title) in enumerate([(gt, "original"), (ms, "masked"), (rc, "recon")]):
                ax = axes[i, j]
                ax.imshow(im.numpy(), cmap="gray", vmin=0, vmax=255)
                ax.set_axis_off()
                if i == 0:
                    ax.set_title(title, fontsize=9)
        fig.tight_layout()
        fig.savefig(fdir / "image_gen.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {"reconstruction_mse": mse_avg}




---
File: /sensorium/experiments/kernel_mnist_bytes.py
---

"""Kernel MNIST bytes classification (Universal Tokenizer).

We treat each image as a sequence of bytes; each (byte, position) hashes to an ID.
We train by streaming: [image_ids..., label_id]. Inference scores label IDs.

Writes:
- `paper/tables/mnist_bytes_summary.tex`
- `paper/figures/mnist_bytes.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id, label_id


@dataclass(frozen=True, slots=True)
class KernelMNISTBytesConfig:
    device: str = "mps"
    train_samples: int = 300
    eval_samples: int = 100
    steps_per_sample: int = 1  # ingest cost is dominated by injections, not step count
    hash_vocab_size: int = 4096
    num_labels: int = 10


def _load_mnist(max_train: int, max_eval: int) -> tuple[List[torch.Tensor], List[int], List[torch.Tensor], List[int]]:
    try:
        from torchvision import datasets, transforms
    except Exception as e:
        raise ImportError("torchvision is required for MNIST kernel experiments") from e

    data_dir = Path("./data/mnist")
    data_dir.mkdir(parents=True, exist_ok=True)
    tfm = transforms.ToTensor()
    tr = datasets.MNIST(root=str(data_dir), train=True, download=True, transform=tfm)
    te = datasets.MNIST(root=str(data_dir), train=False, download=True, transform=tfm)

    train_imgs: List[torch.Tensor] = []
    train_lbls: List[int] = []
    for i in range(min(max_train, len(tr))):
        img, y = tr[i]
        b = (img * 255.0).to(torch.uint8).view(-1)
        train_imgs.append(b)
        train_lbls.append(int(y))

    eval_imgs: List[torch.Tensor] = []
    eval_lbls: List[int] = []
    for i in range(min(max_eval, len(te))):
        img, y = te[i]
        b = (img * 255.0).to(torch.uint8).view(-1)
        eval_imgs.append(b)
        eval_lbls.append(int(y))

    return train_imgs, train_lbls, eval_imgs, eval_lbls


def run_kernel_mnist_bytes(cfg: KernelMNISTBytesConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    train_imgs, train_lbls, eval_imgs, eval_lbls = _load_mnist(int(cfg.train_samples), int(cfg.eval_samples))

    eng_cfg = KernelEngineConfig(
        device=cfg.device,
        hash_vocab_size=int(cfg.hash_vocab_size),
        num_labels=int(cfg.num_labels),
    )
    eng = KernelTokenEngine(eng_cfg)

    # Train: stream image bytes then label (online).
    for idx, (img, y) in enumerate(zip(train_imgs, train_lbls)):
        eng.reset()
        # image
        for p, bv in enumerate(img.tolist()):
            tid = hash_id(int(bv), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 64) == 0:
                eng.step(p)
        # observe label
        lid = label_id(int(y), special_size=eng_cfg.special_size, hash_vocab_size=eng_cfg.hash_vocab_size)
        eng.inject_id(lid, particles=eng_cfg.particles_per_token * 2, energy_scale=eng_cfg.energy_scale * 1.5)
        eng.step(int(idx))

    # Eval: score label IDs after streaming image.
    correct = 0
    conf = torch.zeros((cfg.num_labels, cfg.num_labels), dtype=torch.int32)
    for img, y in zip(eval_imgs, eval_lbls):
        eng.reset()
        for p, bv in enumerate(img.tolist()):
            tid = hash_id(int(bv), int(p), hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
            eng.inject_id(tid)
            if (p % 64) == 0:
                eng.step(p)

        label_ids = torch.tensor(
            [label_id(i, special_size=eng_cfg.special_size, hash_vocab_size=eng_cfg.hash_vocab_size) for i in range(cfg.num_labels)],
            device=eng.dev,
            dtype=torch.long,
        )
        scores = eng.score_ids(label_ids)
        pred = int(torch.argmax(scores).item())
        conf[int(y), pred] += 1
        if pred == int(y):
            correct += 1

    acc = float(correct / max(1, len(eval_lbls)))

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel MNIST classification from raw bytes using the Universal Tokenizer (position-aware hashing).}
\label{tab:mnist_bytes}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Accuracy & """ + f"{acc:.3f}" + r""" \\
Train samples & """ + f"{len(train_lbls)}" + r""" \\
Eval samples & """ + f"{len(eval_lbls)}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "mnist_bytes_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        fig, ax = plt.subplots(1, 1, figsize=(6, 5))
        ax.imshow(conf.numpy(), cmap="Blues")
        ax.set_xlabel("pred")
        ax.set_ylabel("true")
        ax.set_title(f"MNIST confusion (acc={acc:.2f})")
        fig.tight_layout()
        fig.savefig(fdir / "mnist_bytes.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {"accuracy": acc}




---
File: /sensorium/experiments/kernel_next_token.py
---

"""Kernel next-token (byte) prediction via Universal Tokenizer.

We treat text as raw UTF-8 bytes. At each position, we:
1) ingest context bytes (by injecting their hashed IDs)
2) score all 256 candidate next-bytes using carrier spectrum
3) take argmax as prediction, then "observe" by ingesting the true byte

Writes paper artifacts:
- `paper/tables/next_token_summary.tex`
- `paper/figures/next_token.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelNextTokenConfig:
    device: str = "mps"
    steps: int = 800
    context_warmup: int = 64  # bytes to warm up before scoring
    max_bytes: int = 4000
    omega_range: float = 2.0
    hash_vocab_size: int = 4096


def _load_text_bytes() -> bytes:
    # Default corpus: paper text (available locally; no network).
    try:
        p = Path("./paper/main.tex")
        return p.read_bytes()
    except Exception:
        return b"The cat sat on the mat.\n" * 200


def run_kernel_next_token(cfg: KernelNextTokenConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    data = _load_text_bytes()[: int(cfg.max_bytes)]
    if len(data) < (cfg.context_warmup + 2):
        raise RuntimeError("Not enough bytes for next-token experiment.")

    eng_cfg = KernelEngineConfig(
        device=cfg.device,
        omega_range=float(cfg.omega_range),
        hash_vocab_size=int(cfg.hash_vocab_size),
    )
    eng = KernelTokenEngine(eng_cfg)
    eng.reset()

    correct = 0
    nll_sum = 0.0
    acc_ts: List[float] = []
    nll_ts: List[float] = []

    # Warmup ingest
    for i in range(int(cfg.context_warmup)):
        tid = hash_id(data[i], i, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        eng.step(i)

    # Predict/observe loop
    start = int(cfg.context_warmup)
    total = min(int(cfg.steps), len(data) - start - 1)
    for t in range(total):
        pos = start + t
        true_b = int(data[pos])

        pred_b, scores = eng.predict_byte(pos)
        if pred_b == true_b:
            correct += 1

        # Convert scores -> probs via softmax for NLL.
        probs = torch.softmax(scores / 0.5, dim=0)
        nll = float((-torch.log(probs[true_b] + 1e-12)).detach().to("cpu").item())
        nll_sum += nll

        acc_ts.append(float(correct / (t + 1)))
        nll_ts.append(float(nll_sum / (t + 1)))

        # Observe: ingest true byte
        tid = hash_id(true_b, pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        eng.step(pos)

    acc = float(correct / max(1, total))
    avg_nll = float(nll_sum / max(1, total))
    ppl = float(torch.exp(torch.tensor(avg_nll)).item())

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel next-byte prediction using the Universal Tokenizer (UTF-8 bytes).}
\label{tab:next_token}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Accuracy & """ + f"{acc:.3f}" + r""" \\
Perplexity (softmax score) & """ + f"{ppl:.2f}" + r""" \\
Steps & """ + f"{total}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "next_token_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        x = list(range(total))
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(9, 5), sharex=True)
        ax1.plot(x, acc_ts, label="accuracy", linewidth=1.3)
        ax1.set_ylabel("accuracy")
        ax1.legend(loc="lower right", fontsize=8)
        ax2.plot(x, nll_ts, label="NLL", linewidth=1.3)
        ax2.set_ylabel("NLL")
        ax2.set_xlabel("step")
        ax2.legend(loc="upper right", fontsize=8)
        fig.tight_layout()
        fig.savefig(fdir / "next_token.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {"accuracy": acc, "ppl": ppl, "steps": total}




---
File: /sensorium/experiments/kernel_rule_shift.py
---

"""Kernel-based rule-shift experiment (Metal/MPS).

Runs the *new* implementation:
- Particle/grid physics: `optimizer.manifold_physics.ManifoldPhysics` (Metal kernels)
- Spectral carrier memory: `optimizer.manifold_physics.SpectralCarrierPhysics` (Metal kernels)

Produces paper-ready artifacts:
- `paper/tables/rule_shift_summary.tex`
- `paper/figures/rule_shift.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import torch

from optimizer.manifold_physics import (
    ManifoldPhysics,
    ManifoldPhysicsConfig,
    SpectralCarrierPhysics,
    SpectralCarrierConfig,
)
from sensorium.core.tokenizer import UniversalTokenizer, UniversalTokenizerConfig


@dataclass(frozen=True, slots=True)
class KernelRuleShiftConfig:
    device: str = "mps"
    grid_size: tuple[int, int, int] = (32, 32, 32)
    dt: float = 0.02
    steps: int = 2000
    shift_at: int = 1000

    # Injection
    particles_per_token: int = 8
    injection_spread: float = 0.6
    energy_scale: float = 1.0

    # Carrier update cadence
    carrier_every: int = 5

    # Universal tokenizer
    hash_vocab_size: int = 4096

    # Omega mapping for token ids -> oscillator excitation frequency
    omega_range: float = 2.0
    omega_bins: int = 64


def _token_stream(tokenizer: UniversalTokenizer) -> Tuple[List[int], List[int]]:
    # A deterministic phrase; forward is bytes in-order, reverse is bytes reversed.
    phrase = "<bos> The cat sat on the mat <eos>"
    ids = tokenizer.encode_text(phrase, add_bos_eos=False).to(torch.long).tolist()
    if len(ids) < 2:
        ids = [tokenizer.bos_id, tokenizer.eos_id]
    return ids, list(reversed(ids))


def _omega_from_id(token_id: int, *, omega_range: float) -> float:
    # Map integer IDs into [0, omega_range) deterministically.
    m = 2048
    return float((int(token_id) % m) / float(m) * float(omega_range))


def _center_from_id(token_id: int, grid_size: tuple[int, int, int]) -> torch.Tensor:
    # 3D integer hash -> center coordinate inside the grid.
    gx, gy, gz = grid_size
    x = (int(token_id) * 73856093) % gx
    y = (int(token_id) * 19349663) % gy
    z = (int(token_id) * 83492791) % gz
    # Keep away from borders for stability.
    return torch.tensor([1 + (x % max(1, gx - 2)), 1 + (y % max(1, gy - 2)), 1 + (z % max(1, gz - 2))], dtype=torch.float32)


def _hist_cosine(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-8) -> float:
    a = a.to(torch.float32)
    b = b.to(torch.float32)
    num = float((a * b).sum().item())
    den = float(torch.sqrt((a * a).sum() + eps).item() * torch.sqrt((b * b).sum() + eps).item())
    return num / (den + eps)


def _expected_hist(
    token_ids: List[int],
    *,
    omega_bins: int,
    omega_range: float,
) -> torch.Tensor:
    # CPU histogram of expected omegas (uniform weights).
    h = torch.zeros(int(omega_bins), dtype=torch.float32)
    for tid in token_ids:
        w = _omega_from_id(int(tid), omega_range=omega_range)
        bi = int(min(omega_bins - 1, max(0, (w / omega_range) * omega_bins)))
        h[bi] += 1.0
    if float(h.sum().item()) > 0:
        h /= h.sum()
    return h


def _carrier_hist(
    omega: torch.Tensor,
    amp: torch.Tensor,
    *,
    omega_bins: int,
    omega_range: float,
) -> torch.Tensor:
    # CPU histogram of carriers, weighted by amplitude.
    om = omega.detach().to("cpu", dtype=torch.float32).clamp(0.0, float(omega_range))
    aa = amp.detach().to("cpu", dtype=torch.float32).clamp(min=0.0)
    h = torch.zeros(int(omega_bins), dtype=torch.float32)
    if int(om.numel()) == 0:
        return h
    for o, a in zip(om.tolist(), aa.tolist()):
        bi = int(min(omega_bins - 1, max(0, (float(o) / omega_range) * omega_bins)))
        h[bi] += float(a)
    if float(h.sum().item()) > 0:
        h /= h.sum()
    return h


def run_kernel_rule_shift(
    cfg: KernelRuleShiftConfig,
    *,
    spectral_cfg: Optional[SpectralCarrierConfig] = None,
    out_dir: Path = Path("./paper"),
) -> Dict[str, Any]:
    """Run rule shift and write paper artifacts."""
    device = cfg.device
    if device != "mps":
        raise RuntimeError("Kernel rule shift currently expects device='mps' (Metal).")

    tok = UniversalTokenizer(UniversalTokenizerConfig(hash_vocab_size=int(cfg.hash_vocab_size), num_labels=0))
    fwd, rev = _token_stream(tok)
    exp_fwd = _expected_hist(fwd, omega_bins=cfg.omega_bins, omega_range=cfg.omega_range)
    exp_rev = _expected_hist(rev, omega_bins=cfg.omega_bins, omega_range=cfg.omega_range)

    # Physics + carriers (Metal kernels)
    mp_cfg = ManifoldPhysicsConfig(grid_size=cfg.grid_size, dt=float(cfg.dt), poisson_iterations=25, device=device)
    physics = ManifoldPhysics(mp_cfg, device=device)

    scfg = spectral_cfg or SpectralCarrierConfig(
        max_carriers=64,
        coupling_scale=0.25,
        carrier_reg=0.15,
        temperature=0.01,
        conflict_threshold=0.35,
        offender_weight_floor=1e-3,
        ema_alpha=0.10,
        recenter_alpha=0.10,
        gate_width_init=0.35,
        gate_width_min=0.08,
        gate_width_max=1.25,
        # memory/topdown defaults are in dataclass
    )
    carriers = SpectralCarrierPhysics(config=scfg, grid_size=cfg.grid_size, dt=float(cfg.dt), device=device)

    # State tensors on MPS
    dev = torch.device(device)
    dtype = torch.float32
    positions = torch.empty((0, 3), device=dev, dtype=dtype)
    velocities = torch.empty((0, 3), device=dev, dtype=dtype)
    energies = torch.empty((0,), device=dev, dtype=dtype)
    heats = torch.empty((0,), device=dev, dtype=dtype)
    excitations = torch.empty((0,), device=dev, dtype=dtype)
    masses = torch.empty((0,), device=dev, dtype=dtype)
    osc_phase = torch.empty((0,), device=dev, dtype=dtype)

    # Time series (CPU)
    score_fwd: List[float] = []
    score_rev: List[float] = []
    total_energy: List[float] = []
    total_heat: List[float] = []
    num_carriers: List[int] = []
    num_crystallized: List[int] = []

    two_pi = float(2.0 * torch.pi)

    for t in range(int(cfg.steps)):
        seq = fwd if t < int(cfg.shift_at) else rev
        token_id = int(seq[t % len(seq)])

        # Inject a small burst for this token.
        n = int(cfg.particles_per_token)
        center = _center_from_id(token_id, cfg.grid_size).to(device=dev, dtype=dtype)
        pos = center.view(1, 3) + torch.randn(n, 3, device=dev, dtype=dtype) * float(cfg.injection_spread)
        pos = pos.clamp(0.5, float(min(cfg.grid_size) - 1.5))
        vel = torch.randn(n, 3, device=dev, dtype=dtype) * 0.05
        en = torch.full((n,), float(cfg.energy_scale), device=dev, dtype=dtype)
        ht = torch.zeros((n,), device=dev, dtype=dtype)
        om = float(_omega_from_id(token_id, omega_range=cfg.omega_range))
        ex = torch.full((n,), om, device=dev, dtype=dtype) + torch.randn(n, device=dev, dtype=dtype) * 0.01
        ms = en.clone()
        ph = torch.rand(n, device=dev, dtype=dtype) * two_pi

        positions = torch.cat([positions, pos], dim=0)
        velocities = torch.cat([velocities, vel], dim=0)
        energies = torch.cat([energies, en], dim=0)
        heats = torch.cat([heats, ht], dim=0)
        excitations = torch.cat([excitations, ex], dim=0)
        masses = torch.cat([masses, ms], dim=0)
        osc_phase = torch.cat([osc_phase, ph], dim=0)

        # Physics step (Metal kernels)
        positions, velocities, energies, heats, excitations = physics.step(
            positions, velocities, energies, heats, excitations, masses
        )

        # Carrier update cadence (Metal kernels)
        if (t % int(cfg.carrier_every)) == 0 and int(osc_phase.numel()) > 0:
            cst = carriers.step(osc_phase, excitations, energies)
            osc_phase = cst["osc_phase"]
            # alignment scores
            h = _carrier_hist(
                cst["frequencies"],
                cst["amplitudes"],
                omega_bins=cfg.omega_bins,
                omega_range=cfg.omega_range,
            )
            score_fwd.append(_hist_cosine(h, exp_fwd))
            score_rev.append(_hist_cosine(h, exp_rev))
            num_carriers.append(int(cst["frequencies"].numel()))
            cs = cst.get("carrier_state")
            if cs is None:
                num_crystallized.append(0)
            else:
                num_crystallized.append(int((cs.detach().to("cpu") == 2).sum().item()))
        else:
            # Repeat last value for plotting continuity.
            score_fwd.append(score_fwd[-1] if score_fwd else 0.0)
            score_rev.append(score_rev[-1] if score_rev else 0.0)
            num_carriers.append(num_carriers[-1] if num_carriers else 0)
            num_crystallized.append(num_crystallized[-1] if num_crystallized else 0)

        total_energy.append(float(energies.sum().detach().to("cpu").item()))
        total_heat.append(float(heats.sum().detach().to("cpu").item()))

    # Summaries
    s_at = int(cfg.shift_at)
    pre_win = 200
    post_win = 50
    pre_fwd = float(torch.tensor(score_fwd[max(0, s_at - pre_win) : s_at]).mean().item()) if s_at > 0 else float(score_fwd[-1])
    post_immediate = float(torch.tensor(score_rev[s_at : min(len(score_rev), s_at + post_win)]).mean().item()) if s_at < len(score_rev) else float(score_rev[-1])
    threshold = 0.8 * pre_fwd
    recovery_steps: Optional[int] = None
    for i in range(s_at, len(score_rev)):
        if float(score_rev[i]) >= threshold:
            recovery_steps = int(i - s_at)
            break

    metrics = {
        "steps": int(cfg.steps),
        "shift_at": int(cfg.shift_at),
        "pre_shift_alignment": float(pre_fwd),
        "post_shift_alignment_immediate": float(post_immediate),
        "recovery_steps": recovery_steps,
        "final_carriers": int(num_carriers[-1]) if num_carriers else 0,
        "final_crystallized": int(num_crystallized[-1]) if num_crystallized else 0,
        "score_fwd": score_fwd,
        "score_rev": score_rev,
        "energy": total_energy,
        "heat": total_heat,
        "num_carriers": num_carriers,
        "num_crystallized": num_crystallized,
    }

    # Write paper artifacts
    out_dir = Path(out_dir)
    tables_dir = out_dir / "tables"
    figures_dir = out_dir / "figures"
    tables_dir.mkdir(parents=True, exist_ok=True)
    figures_dir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel rule-shift adaptation. We measure alignment between the carrier spectrum and the expected regime spectrum before and after a reversal at step """ + str(int(cfg.shift_at)) + r""".}
\label{tab:rule_shift}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Pre-shift alignment & """ + f"{pre_fwd:.3f}" + r""" \\
Post-shift alignment (immediate) & """ + f"{post_immediate:.3f}" + r""" \\
Steps to 80\% recovery & """ + (str(recovery_steps) if recovery_steps is not None else "N/A") + r""" \\
Final carrier count & """ + f"{metrics['final_carriers']}" + r""" \\
Final crystallized carriers & """ + f"{metrics['final_crystallized']}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tables_dir / "rule_shift_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        x = list(range(int(cfg.steps)))
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 7), sharex=True)
        ax1.plot(x, score_fwd, label="alignment to fwd", linewidth=1.2)
        ax1.plot(x, score_rev, label="alignment to rev", linewidth=1.2)
        ax1.axvline(int(cfg.shift_at), color="r", linestyle="--", alpha=0.7)
        ax1.set_ylabel("alignment")
        ax1.legend(loc="upper right", fontsize=8)

        ax2.plot(x, total_energy, label="total energy", alpha=0.8)
        ax2.plot(x, total_heat, label="total heat", alpha=0.8)
        ax2.axvline(int(cfg.shift_at), color="r", linestyle="--", alpha=0.7)
        ax2.set_ylabel("energy / heat")
        ax2.legend(loc="upper right", fontsize=8)

        ax3.plot(x, num_carriers, label="#carriers", alpha=0.9)
        ax3.plot(x, num_crystallized, label="#crystallized", alpha=0.9)
        ax3.axvline(int(cfg.shift_at), color="r", linestyle="--", alpha=0.7)
        ax3.set_ylabel("count")
        ax3.set_xlabel("step")
        ax3.legend(loc="upper right", fontsize=8)

        fig.tight_layout()
        fig.savefig(figures_dir / "rule_shift.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        # Best-effort: paper will show placeholder box if figure missing.
        pass

    return metrics




---
File: /sensorium/experiments/kernel_text_diffusion.py
---

"""Kernel text "diffusion" (byte denoising) via Universal Tokenizer.

We corrupt a byte sequence by masking bytes, then reconstruct by sequentially
sampling bytes using carrier scores.

Writes:
- `paper/tables/text_diffusion_summary.tex`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelTextDiffusionConfig:
    device: str = "mps"
    max_bytes: int = 1500
    mask_frac: float = 0.20
    hash_vocab_size: int = 4096


def _load_bytes() -> bytes:
    try:
        return Path("./paper/main.tex").read_bytes()
    except Exception:
        return b"Thermodynamic manifold diffusion experiment.\n" * 200


def run_kernel_text_diffusion(cfg: KernelTextDiffusionConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    data = bytearray(_load_bytes()[: int(cfg.max_bytes)])
    if len(data) < 64:
        raise RuntimeError("Not enough bytes for text diffusion demo.")

    eng_cfg = KernelEngineConfig(device=cfg.device, hash_vocab_size=int(cfg.hash_vocab_size))
    eng = KernelTokenEngine(eng_cfg)
    eng.reset()

    n = len(data)
    mask_n = int(float(cfg.mask_frac) * n)
    mask_idx = torch.randperm(n)[:mask_n].tolist()
    masked = bytearray(data)
    for i in mask_idx:
        masked[i] = 0  # NUL placeholder

    observed = [True] * n
    for i in mask_idx:
        observed[i] = False

    # Ingest observed bytes
    for pos in range(n):
        if not observed[pos]:
            continue
        tid = hash_id(masked[pos], pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        if (pos % 64) == 0:
            eng.step(pos)

    # Reconstruct masked bytes sequentially
    recon = bytearray(masked)
    correct = 0
    for pos in mask_idx:
        b_pred, _scores = eng.predict_byte(pos)
        recon[pos] = int(b_pred)
        if int(b_pred) == int(data[pos]):
            correct += 1
        tid = hash_id(int(b_pred), pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        eng.step(pos)

    acc = float(correct / max(1, len(mask_idx)))

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    tdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel byte denoising (``text diffusion'') using the Universal Tokenizer.}
\label{tab:text_diffusion}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Masked-byte accuracy & """ + f"{acc:.3f}" + r""" \\
Mask fraction & """ + f"{float(cfg.mask_frac):.2f}" + r""" \\
Bytes & """ + f"{n}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "text_diffusion_summary.tex").write_text(table, encoding="utf-8")

    return {"masked_accuracy": acc}




---
File: /sensorium/experiments/kernel_timeseries.py
---

"""Kernel time-series forecasting (byte-quantized).

We quantize a synthetic time series to bytes and run next-byte prediction
using the same kernel engine as text.

Writes:
- `paper/tables/timeseries_summary.tex`
- `paper/figures/timeseries.pdf`
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List

import torch

from .kernel_engine import KernelEngineConfig, KernelTokenEngine, hash_id


@dataclass(frozen=True, slots=True)
class KernelTimeSeriesConfig:
    device: str = "mps"
    length: int = 3000
    steps: int = 800
    context_warmup: int = 64
    hash_vocab_size: int = 4096


def _make_series(n: int) -> torch.Tensor:
    t = torch.arange(n, dtype=torch.float32)
    y = 0.001 * t + 0.5 * torch.sin(2 * torch.pi * t / 24.0) + 0.3 * torch.sin(2 * torch.pi * t / (24.0 * 7.0))
    y = y + 0.05 * torch.randn_like(y)
    return y


def _to_bytes(y: torch.Tensor) -> bytes:
    # Normalize to [0, 255]
    y = y.to(torch.float32)
    lo = float(y.min().item())
    hi = float(y.max().item())
    z = (y - lo) / max(1e-8, (hi - lo))
    b = torch.clamp((z * 255.0).round(), 0, 255).to(torch.uint8)
    return bytes(b.tolist())


def run_kernel_timeseries(cfg: KernelTimeSeriesConfig, *, out_dir: Path = Path("./paper")) -> Dict[str, Any]:
    y = _make_series(int(cfg.length))
    data = _to_bytes(y)

    eng_cfg = KernelEngineConfig(device=cfg.device, hash_vocab_size=int(cfg.hash_vocab_size))
    eng = KernelTokenEngine(eng_cfg)
    eng.reset()

    # Warmup
    for i in range(int(cfg.context_warmup)):
        tid = hash_id(data[i], i, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        eng.step(i)

    correct = 0
    mae_sum = 0.0
    mse_sum = 0.0
    mae_ts: List[float] = []
    mse_ts: List[float] = []

    total = min(int(cfg.steps), len(data) - int(cfg.context_warmup) - 2)
    start = int(cfg.context_warmup)

    for t in range(total):
        pos = start + t
        true_b = int(data[pos])
        pred_b, _scores = eng.predict_byte(pos)
        if pred_b == true_b:
            correct += 1
        err = float(pred_b - true_b)
        mae_sum += abs(err)
        mse_sum += err * err
        mae_ts.append(mae_sum / (t + 1))
        mse_ts.append(mse_sum / (t + 1))

        tid = hash_id(true_b, pos, hash_vocab_size=eng_cfg.hash_vocab_size, hash_prime=eng_cfg.hash_prime, special_size=eng_cfg.special_size)
        eng.inject_id(tid)
        eng.step(pos)

    acc = float(correct / max(1, total))
    mae = float(mae_sum / max(1, total))
    mse = float(mse_sum / max(1, total))

    out_dir = Path(out_dir)
    tdir = out_dir / "tables"
    fdir = out_dir / "figures"
    tdir.mkdir(parents=True, exist_ok=True)
    fdir.mkdir(parents=True, exist_ok=True)

    table = r"""\begin{table}[t]
\centering
\caption{Kernel time-series forecasting via next-byte prediction on a quantized synthetic series.}
\label{tab:timeseries}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Accuracy (exact byte) & """ + f"{acc:.3f}" + r""" \\
MAE (byte) & """ + f"{mae:.2f}" + r""" \\
MSE (byte) & """ + f"{mse:.2f}" + r""" \\
Steps & """ + f"{total}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
    (tdir / "timeseries_summary.tex").write_text(table, encoding="utf-8")

    try:
        import matplotlib

        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        x = list(range(total))
        fig, ax = plt.subplots(1, 1, figsize=(9, 3))
        ax.plot(x, mse_ts, label="MSE (byte)", linewidth=1.3)
        ax.plot(x, mae_ts, label="MAE (byte)", linewidth=1.3)
        ax.set_xlabel("step")
        ax.legend(loc="upper right", fontsize=8)
        fig.tight_layout()
        fig.savefig(fdir / "timeseries.pdf", format="pdf", bbox_inches="tight", dpi=150)
        plt.close(fig)
    except Exception:
        pass

    return {"accuracy": acc, "mae": mae, "mse": mse, "steps": total}




---
File: /sensorium/experiments/mnist_bytes.py
---

"""MNIST Raw Bytes Classification Experiment

Demonstrates true modality-agnostic learning: classify MNIST digits
using raw pixel bytes as tokens. No encoder, no spectral decomposition—
just a stream of 784 bytes per image.

The manifold treats images as "text in a 256-character alphabet" and
learns byte-level transition patterns that distinguish digit classes.

Key claim: The same dynamics that learn language can learn vision,
because the manifold doesn't know what modality it's processing.
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from sensorium.semantic.manifold import SemanticManifold
from sensorium.semantic.hierarchical import HierarchicalSemanticManifold
from sensorium.core.tokenizer import UniversalTokenizer, UniversalTokenizerConfig

from .base import BaseExperiment, ExperimentResult, Scale, ScaleConfig

DEFAULT_OUT_DIR = Path("./artifacts/mnist_bytes")

# Custom scale configs for MNIST (different from text experiments)
# Note: embed_dim should be <= vocab_size for proper embeddings
MNIST_SCALE_CONFIGS = {
    Scale.TOY: ScaleConfig(
        name="toy",
        max_train_samples=1000,
        max_eval_samples=200,
        embed_dim=512,  # Smaller than hash_vocab_size (4096) + 10 labels
        train_steps=1000,
        eval_every=200,
        dt=0.02,
    ),
    Scale.MEDIUM: ScaleConfig(
        name="medium",
        max_train_samples=10000,
        max_eval_samples=1000,
        embed_dim=512,
        train_steps=10000,
        eval_every=1000,
        dt=0.02,
    ),
    Scale.FULL: ScaleConfig(
        name="full",
        max_train_samples=60000,
        max_eval_samples=10000,
        embed_dim=512,
        train_steps=60000,
        eval_every=5000,
        dt=0.02,
    ),
}


class MNISTBytesExperiment(BaseExperiment):
    """MNIST classification using raw pixel bytes with position-aware hashing.
    
    Each image is a sequence of 784 bytes (28x28 pixels, 0-255).
    Each (byte_value, position) pair is hashed to a unique token ID,
    preserving spatial information while treating the image as a byte stream.
    
    The label is appended as a special token after the image bytes.
    
    Training: Feed [hashed_bytes..., label_token], learn transitions.
    Inference: Feed [hashed_bytes...], predict which label has highest flow.
    """
    
    name = "mnist_bytes"
    goal = "Classify MNIST digits from raw pixel bytes (no encoder)"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
        context_window: int = 64,  # How many recent bytes to use as context
        dashboard: bool = False,  # Enable real-time dashboard
        ponder: bool = False,  # Enable expensive idle pondering
        hash_vocab_size: int = 4096,  # Size of hashed token vocabulary
    ):
        super().__init__(scale, device, seed)
        
        # Override scale config with MNIST-specific settings
        self.scale_config = MNIST_SCALE_CONFIGS[scale]
        
        # Universal tokenizer (bytes+index hashing) + label tokens
        self.num_labels = 10
        self.tokenizer = UniversalTokenizer(
            UniversalTokenizerConfig(hash_vocab_size=int(hash_vocab_size), num_labels=self.num_labels)
        )
        self.vocab_size = int(self.tokenizer.vocab_size)
        self.label_offset = int(self.tokenizer.label_offset)
        
        # Context window (can't use all 784 bytes as context—too long)
        self.context_window = context_window
        
        # Dashboard
        self.use_dashboard = dashboard
        self._dashboard = None
        self.enable_ponder = ponder
        
        # Vocab (for manifold compatibility / dashboards)
        self.vocab = self.tokenizer.vocab
        
        # Data storage
        self._train_images: List[torch.Tensor] = []
        self._train_labels: List[int] = []
        self._eval_images: List[torch.Tensor] = []
        self._eval_labels: List[int] = []
        
        # Manifold
        self.manifold: Optional[SemanticManifold] = None
    
    def setup(self) -> None:
        """Load MNIST and initialize manifold."""
        print("    Loading MNIST...")
        
        try:
            from torchvision import datasets, transforms
        except ImportError:
            raise ImportError("Please install torchvision: pip install torchvision")
        
        # Load MNIST (downloads if needed)
        data_dir = Path("./data/mnist")
        data_dir.mkdir(parents=True, exist_ok=True)
        
        train_dataset = datasets.MNIST(
            root=str(data_dir),
            train=True,
            download=True,
            transform=transforms.ToTensor(),
        )
        
        eval_dataset = datasets.MNIST(
            root=str(data_dir),
            train=False,
            download=True,
            transform=transforms.ToTensor(),
        )
        
        # Convert to byte tensors (0-255)
        max_train = self.scale_config.max_train_samples or len(train_dataset)
        max_eval = self.scale_config.max_eval_samples or len(eval_dataset)
        
        print(f"    Processing {max_train} training images...")
        for i in range(min(max_train, len(train_dataset))):
            img, label = train_dataset[i]
            # img is (1, 28, 28) float in [0, 1] -> convert to bytes
            img_bytes = (img * 255).to(torch.uint8).flatten()
            self._train_images.append(img_bytes)
            self._train_labels.append(int(label))
        
        print(f"    Processing {max_eval} evaluation images...")
        for i in range(min(max_eval, len(eval_dataset))):
            img, label = eval_dataset[i]
            img_bytes = (img * 255).to(torch.uint8).flatten()
            self._eval_images.append(img_bytes)
            self._eval_labels.append(int(label))
        
        print(f"    Train images: {len(self._train_images)}")
        print(f"    Eval images: {len(self._eval_images)}")
        print(
            f"    UniversalTokenizer: vocab_size={self.tokenizer.vocab_size} "
            f"(hash_vocab_size={self.tokenizer.hash_vocab_size} + labels={self.num_labels})"
        )
        print(f"    Context window: {self.context_window} bytes")
        print(f"    Position-aware hashing: enabled (prime={self.tokenizer.cfg.hash_prime})")
        
        # Initialize hierarchical semantic manifold (with chunks)
        self.manifold = HierarchicalSemanticManifold(
            config=self.physics_config,
            device=self.device,
            vocab=self.vocab,
            embed_dim=self.scale_config.embed_dim,
            chunk_min_len=2,  # Minimum chunk length (bigrams)
            chunk_max_len=4,  # Maximum chunk length (4-grams)
        )
    
    def _image_to_sequence(self, img_bytes: torch.Tensor, label: int) -> torch.Tensor:
        """Convert image bytes + label to a token sequence.
        
        Returns: tensor of shape (785,) with byte tokens followed by label token.
        """
        img_bytes = img_bytes.to(torch.uint8).flatten()
        img_tokens = self.tokenizer.encode_bytes(img_bytes, add_bos_eos=False)
        label_token = torch.tensor([self.tokenizer.label_id(int(label))], dtype=torch.long)
        return torch.cat([img_tokens, label_token], dim=0)
    
    def train_iterator(self) -> Iterator[Tuple[torch.Tensor, int]]:
        """Iterate over training images.
        
        Yields: (image_bytes_tensor, label)
        """
        indices = torch.randperm(len(self._train_images)).tolist()
        for idx in indices:
            yield self._train_images[idx], self._train_labels[idx]
    
    def train_step(self, batch: Tuple[torch.Tensor, int]) -> Dict[str, float]:
        """One step of training: stream full image as position-hashed byte sequence, then observe label.
        
        Each (byte_value, position) pair is hashed to a unique token, preserving spatial info.
        The manifold learns sequential transitions throughout the image,
        building up a representation that associates position-aware byte patterns with labels.
        
        Returns dict with standard metrics:
        - loss: cross-entropy loss (same as surprise)
        - ppl: perplexity = exp(loss)
        - entropy: entropy of prediction distribution
        """
        img_bytes, label = batch
        
        img_tokens = self.tokenizer.encode_bytes(img_bytes.to(torch.uint8), add_bos_eos=False).to(self.device)
        
        # Stream the full image as a sequence of hashed tokens
        # Process in chunks to build up context incrementally
        chunk_size = self.context_window
        n_chunks = (len(img_tokens) + chunk_size - 1) // chunk_size
        
        # Accumulate per-token losses for average
        token_losses = []
        
        for i in range(n_chunks):
            start = i * chunk_size
            end = min(start + chunk_size, len(img_tokens))
            chunk = img_tokens[start:end]
            
            # Ingest this chunk
            self.manifold.ingest_ids(chunk)
            
            # Run grammar step to process transitions within the chunk
            self.manifold.step_grammar()
            
            # Observe token-to-token transitions within the chunk
            for j in range(len(chunk) - 1):
                obs = self.manifold.observe_next_token(
                    int(chunk[j + 1].item()),
                    cur_id=int(chunk[j].item()),
                )
                # surprise = -log(P(next|cur)) = cross-entropy loss per token
                token_losses.append(obs.get("surprise", 0.0))
        
        # After streaming the full image, observe the label transition
        # The label follows the last hashed token of the image
        # Use predict_from_token on the LAST token specifically (not the whole context)
        last_token = int(img_tokens[-1].item())
        probs = self.manifold.predict_from_token(last_token)
        probs_sum = probs.sum()
        if probs_sum > self.manifold.cfg.eps:
            probs = probs / probs_sum
        else:
            # No outgoing edges yet - use uniform over labels
            probs = torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)
            for i in range(self.num_labels):
                probs[self.label_offset + i] = 1.0 / self.num_labels
        
        label_token = self.tokenizer.label_id(int(label))
        label_prob = float(probs[label_token].detach().item())
        obs = self.manifold.observe_next_token(label_token, probs=probs, cur_id=last_token)
        
        # The label prediction loss is the most important one
        label_loss = obs.get("surprise", 0.0)
        token_losses.append(label_loss)
        
        # Compute standard metrics
        # Loss: average cross-entropy across all tokens (including label)
        avg_loss = sum(token_losses) / len(token_losses) if token_losses else 0.0
        
        # Perplexity: exp(loss) - how "surprised" the model is on average
        # Clamp to avoid overflow
        import math
        ppl = math.exp(min(avg_loss, 20.0))  # Cap at exp(20) ≈ 485 million
        
        # Entropy of current prediction distribution
        entropy = float(self.manifold.entropy().item())
        
        # Return with standard metric names
        result = {
            "loss": avg_loss,
            "ppl": ppl,
            "entropy": entropy,
            "label_loss": label_loss,  # Loss specifically on label prediction
            "label_prob": label_prob,
            **obs,  # Include original observation metrics
        }
        
        return result
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate classification accuracy on eval set."""
        correct = 0
        total = 0
        
        # Per-class accuracy tracking
        class_correct = [0] * 10
        class_total = [0] * 10
        
        for img_bytes, label in zip(self._eval_images, self._eval_labels):
            img_tokens = self.tokenizer.encode_bytes(img_bytes.to(torch.uint8), add_bos_eos=False).to(self.device)
            
            # Reset excitation state for fresh prediction on each sample
            self.manifold.attractors.set(
                "excitation",
                torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32),
            )
            
            # Stream the full image as a sequence of hashed tokens (same as training)
            chunk_size = self.context_window
            n_chunks = (len(img_tokens) + chunk_size - 1) // chunk_size
            
            for i in range(n_chunks):
                start = i * chunk_size
                end = min(start + chunk_size, len(img_tokens))
                chunk = img_tokens[start:end]
                
                self.manifold.ingest_ids(chunk)
                self.manifold.step_grammar()
            
            # Run additional grammar steps to let the state settle
            for _ in range(2):
                self.manifold.step_grammar()
            
            # Predict label from the LAST token specifically
            # This is what matters: given the last pixel, what label follows?
            last_token = int(img_tokens[-1].item())
            probs = self.manifold.predict_from_token(last_token)
            probs_sum = probs.sum()
            if probs_sum > self.manifold.cfg.eps:
                probs = probs / probs_sum
            
            # Get label predictions
            label_probs = probs[self.label_offset : self.label_offset + self.num_labels]
            predicted_label = int(torch.argmax(label_probs).item())
            
            if predicted_label == label:
                correct += 1
                class_correct[label] += 1
            
            total += 1
            class_total[label] += 1
        
        accuracy = correct / total if total > 0 else 0.0
        
        # Per-class accuracies
        per_class = {}
        for i in range(10):
            if class_total[i] > 0:
                per_class[f"acc_digit_{i}"] = class_correct[i] / class_total[i]
        
        return {
            "accuracy": accuracy,
            "correct": correct,
            "total": total,
            "graph_edges": self.manifold.graph.num_edges,
            **per_class,
        }
    
    def run(self) -> ExperimentResult:
        """Run the MNIST bytes experiment with custom artifact generation."""
        print(f"\n{'='*60}")
        print(f"EXPERIMENT: {self.name} ({self.scale.value})")
        print(f"Goal: {self.goal}")
        print(f"Device: {self.device}")
        print(f"{'='*60}")
        
        try:
            from tqdm import tqdm
        except ImportError:
            tqdm = None
        
        try:
            print("\n[1] Setup...")
            self.setup()
            
            out_dir = DEFAULT_OUT_DIR / self.scale.value
            out_dir.mkdir(parents=True, exist_ok=True)
            
            steps = self.scale_config.train_steps
            print(f"\n[2] Training ({steps} steps)...")
            
            data_iter = self.train_iterator()
            
            # Initialize dashboard if requested
            if self.use_dashboard:
                from ..core.dashboard import Dashboard, SimpleDashboard
                import sys
                if sys.platform == "darwin":
                    # macOS GUI backends must run on the main thread.
                    self._dashboard = SimpleDashboard(self.manifold, vocab=self.vocab)
                    self._dashboard_mode = "simple"
                    print("    Dashboard: using simple mode on macOS")
                else:
                    try:
                        self._dashboard = Dashboard(self.manifold, vocab=self.vocab)
                        self._dashboard.start()
                        self._dashboard_mode = "threaded"
                    except Exception as e:
                        print(f"    Dashboard init failed ({e}), using simple mode")
                        self._dashboard = SimpleDashboard(self.manifold, vocab=self.vocab)
                        self._dashboard_mode = "simple"
            
            if tqdm is not None:
                pbar = tqdm(range(steps), desc="Training", unit="step")
            else:
                pbar = range(steps)
            
            for t in pbar:
                self.state.step = t
                
                try:
                    batch = next(data_iter)
                except StopIteration:
                    self.state.epoch += 1
                    data_iter = self.train_iterator()
                    batch = next(data_iter)
                
                metrics = self.train_step(batch)
                
                # Update dashboard every 10 steps (for debugging)
                if self._dashboard is not None and t % 10 == 0:
                    if self._dashboard_mode == "threaded":
                        self._dashboard.update(step=t, extra=metrics)
                    else:
                        self._dashboard.update_and_render(step=t, extra=metrics)
                
                # Occasional stochastic traversal (but not too often—it's expensive)
                if self.enable_ponder and t > 0 and t % 500 == 0:
                    self.manifold.idle_think(steps=1, dream_steps=2)
            
            if tqdm is not None and hasattr(pbar, 'close'):
                pbar.close()
            
            # One final stochastic traversal to consolidate
            if self.enable_ponder:
                print("    Running final stochastic traversal...")
                self.manifold.idle_think(steps=2, dream_steps=4)
            
            print("\n[3] Final evaluation...")
            final_metrics = self.evaluate()
            
            print(f"\n    {'─'*40}")
            print(f"    Accuracy: {final_metrics['accuracy']:.4f}")
            print(f"    Correct: {final_metrics['correct']} / {final_metrics['total']}")
            print(f"    Graph edges: {final_metrics['graph_edges']}")
            print(f"    {'─'*40}")
            
            # Save metrics
            metrics = {
                "config": asdict(self.physics_config),
                "scale": self.scale.value,
                "final_eval": final_metrics,
            }
            
            (out_dir / "metrics.json").write_text(
                json.dumps(metrics, indent=2, default=str),
                encoding="utf-8",
            )
            
            # Generate plots
            self._generate_plots(out_dir, final_metrics)
            
            # Close dashboard and generate 3D graph
            if self._dashboard is not None:
                if self._dashboard_mode == "threaded":
                    self._dashboard.save_snapshot(str(out_dir / "dashboard_final.png"))
                    self._dashboard.stop()
                else:
                    self._dashboard.save(str(out_dir / "dashboard_final.png"))
                    # Generate 3D bond graph visualization
                    try:
                        self._dashboard.render_3d_graph(
                            save_path=str(out_dir / "bond_graph_3d.png"),
                            max_nodes=300,
                            max_edges=1000,
                        )
                    except Exception as e:
                        print(f"    (3D graph generation failed: {e})")
                    self._dashboard.close()
            
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=True,
                metrics={"final": final_metrics},
            )
            
        except Exception as e:
            import traceback
            tb = traceback.format_exc()
            print(f"\n[FAILED] {e}")
            print(tb)
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=False,
                metrics={},
                failure_reason=str(e),
            )
    
    def _generate_plots(
        self,
        out_dir: Path,
        final_metrics: Dict[str, Any],
    ) -> None:
        """Generate visualization plots."""
        try:
            import matplotlib
            matplotlib.use("Agg")
            import matplotlib.pyplot as plt
        except ImportError:
            print("    (matplotlib not available, skipping plots)")
            return
        
        fig, ax = plt.subplots(figsize=(8, 5))
        
        # Per-class accuracy bar chart
        class_accs = [final_metrics.get(f"acc_digit_{i}", 0) for i in range(10)]
        bars = ax.bar(range(10), class_accs, color='steelblue')
        ax.axhline(y=0.1, color='gray', linestyle='--', alpha=0.5, label='Random baseline (10%)')
        ax.axhline(y=final_metrics['accuracy'], color='red', linestyle='-', alpha=0.7, label=f'Overall: {final_metrics["accuracy"]:.1%}')
        ax.set_xlabel("Digit Class")
        ax.set_ylabel("Accuracy")
        ax.set_title(f"MNIST Classification from Raw Bytes\n(No encoder, {final_metrics['graph_edges']} edges learned)")
        ax.set_xticks(range(10))
        ax.set_ylim(0, 1)
        ax.legend()
        
        plt.tight_layout()
        fig.savefig(out_dir / "mnist_bytes.png", dpi=150)
        plt.close(fig)
        
        print(f"    Saved plot to {out_dir / 'mnist_bytes.png'}")


def run_mnist_bytes_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = MNISTBytesExperiment(scale=scale, device=device)
    result = exp.run()
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="MNIST Raw Bytes Classification")
    parser.add_argument(
        "--scale",
        type=str,
        default="toy",
        choices=["toy", "medium", "full"],
        help="Experiment scale",
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="Device (cpu, cuda, mps)",
    )
    parser.add_argument(
        "--dashboard",
        action="store_true",
        help="Enable real-time dashboard visualization",
    )
    parser.add_argument(
        "--ponder",
        action="store_true",
        help="Enable expensive idle pondering steps",
    )
    
    args = parser.parse_args()
    
    scale = Scale(args.scale)
    device = torch.device(args.device) if args.device else None
    
    exp = MNISTBytesExperiment(
        scale=scale,
        device=device,
        dashboard=args.dashboard,
        ponder=args.ponder,
    )
    result = exp.run()
    if result.success:
        print("\n✓ Experiment completed successfully")
    else:
        print("\n✗ Experiment failed")



---
File: /sensorium/experiments/next_token.py
---

"""Next Token Prediction Experiment

Uses WikiText-2 / WikiText-103 from HuggingFace.
Standard language modeling benchmark.

Goal: Predict next token from context.
Metrics: Accuracy, Perplexity (where applicable)
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from sensorium.core.diagnostics import SemanticDiagnosticsLogger
from sensorium.core.viz import plot_pondering_jsonl
from sensorium.core.tokenizer import UniversalTokenizer, UniversalTokenizerConfig
from sensorium.semantic.hierarchical import HierarchicalSemanticManifold

from .base import BaseExperiment, Scale

DEFAULT_OUT_DIR = Path("./artifacts/next_token")


class NextTokenExperiment(BaseExperiment):
    """Next token prediction using the semantic manifold.
    
    This is the core capability of the system.
    """
    
    name = "next_token"
    goal = "Predict next token from context (language modeling)"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.dataset_name = "wikitext-2-raw-v1"
            self.context_length = 32
        elif scale == Scale.MEDIUM:
            self.dataset_name = "wikitext-2-raw-v1"
            self.context_length = 64
        else:
            self.dataset_name = "wikitext-103-raw-v1"
            self.context_length = 128

        # Universal Tokenizer (paper §3): deterministic hashing of (byte, index).
        hash_vocab = 4096 if scale == Scale.TOY else (16384 if scale == Scale.MEDIUM else 65536)
        self.tokenizer = UniversalTokenizer(UniversalTokenizerConfig(hash_vocab_size=hash_vocab, num_labels=0))
        self._train_steps: int = int(self.scale_config.train_steps)
    
    def setup(self) -> None:
        """Load WikiText and pre-tokenize to universal byte-hash IDs."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading {self.dataset_name}...")
        
        dataset = load_dataset(
            "wikitext",
            self.dataset_name,
            streaming=True
        )
        
        print(
            f"    UniversalTokenizer: vocab_size={self.tokenizer.vocab_size} "
            f"(hash_vocab_size={self.tokenizer.hash_vocab_size})"
        )
        
        # Store dataset iterators
        self.train_stream = dataset["train"]
        self.eval_stream = dataset["validation"]
        
        # Prefetch and tokenize data
        self._train_sequences: List[List[int]] = []
        self._eval_sequences: List[List[int]] = []
        
        self._tokenize_stream(
            self.train_stream,
            self._train_sequences,
            self.scale_config.max_train_samples or 10000,
        )
        self._tokenize_stream(
            self.eval_stream,
            self._eval_sequences,
            self.scale_config.max_eval_samples or 1000,
        )
        
        print(f"    Train sequences: {len(self._train_sequences)}")
        print(f"    Eval sequences: {len(self._eval_sequences)}")
        
        # Initialize semantic manifold
        self.manifold = HierarchicalSemanticManifold(
            self.physics_config,
            self.device,
            vocab=self.tokenizer.vocab,
            embed_dim=min(self.scale_config.embed_dim, self.tokenizer.vocab_size),
            chunk_min_len=2,
            chunk_max_len=4,
        )

    def _reset_artifacts(self, out_dir: Path) -> None:
        """Ensure deterministic artifact outputs (overwrite vs append)."""
        out_dir.mkdir(parents=True, exist_ok=True)
        for p in [
            out_dir / "pondering.jsonl",
            out_dir / "pondering.csv",
            out_dir / "next_token_metrics.json",
            out_dir / "next_token_data.json",
            out_dir / "next_token.png",
            out_dir / "pondering.png",
            out_dir / "tables" / "next_token_summary.tex",
        ]:
            try:
                if p.exists():
                    p.unlink()
            except Exception:
                # Best-effort cleanup; we still want the experiment to run.
                pass

    @staticmethod
    def _topological_entropy(src: torch.Tensor, w: torch.Tensor, eps: float) -> float:
        """Mean per-src entropy of outgoing normalized weights."""
        if src.numel() == 0:
            return 0.0
        w = w.clamp(min=0.0)
        if float(w.sum().item()) <= eps:
            return 0.0
        src_u, inv = torch.unique(src, return_inverse=True)
        out_sum = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
        out_sum.index_add_(0, inv, w)
        p = w / (out_sum[inv] + eps)
        edge_ent = -p * torch.log(p + eps)
        ent_src = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
        ent_src.index_add_(0, inv, edge_ent)
        return float(ent_src.mean().item())

    @staticmethod
    def _rolling_mean(x: torch.Tensor, win: int) -> torch.Tensor:
        win = max(1, int(win))
        if x.numel() == 0:
            return x
        kern = torch.ones(win, dtype=torch.float32, device=x.device) / float(win)
        y = torch.nn.functional.conv1d(x.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2).view(-1)
        return y[: x.numel()]

    def _generate_artifacts(self, *, out_dir: Path, metrics: Dict[str, Any]) -> Dict[str, Path]:
        """Write figures/tables for paper artifacts."""
        figures: Dict[str, Path] = {}
        tables_dir = out_dir / "tables"
        tables_dir.mkdir(parents=True, exist_ok=True)

        # LaTeX table (summary)
        final = metrics.get("final_eval", {}) if isinstance(metrics, dict) else {}
        acc = float(final.get("accuracy", 0.0))
        ppl = float(final.get("perplexity", float("inf")))
        edges = int(final.get("graph_edges", 0))
        chunks = int(final.get("chunks", 0))
        table = (
            r"""\begin{table}[t]
\centering
\caption{Next-token prediction after a single online training pass (no gradient optimization).}
\label{tab:next_token}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Validation accuracy & """
            + f"{acc:.1%}"
            + r""" \\
Validation perplexity & """
            + (f"{ppl:.2f}" if ppl != float("inf") else r"$\infty$")
            + r""" \\
Graph edges & """
            + f"{edges}"
            + r""" \\
Chunks & """
            + f"{chunks}"
            + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
        )
        table_path = tables_dir / "next_token_summary.tex"
        table_path.write_text(table, encoding="utf-8")

        # Figures
        try:
            import matplotlib

            matplotlib.use("Agg")
            import matplotlib.pyplot as plt

            steps = int(metrics["steps"])
            x = list(range(steps))

            fig, ax = plt.subplots(3, 1, figsize=(10, 7), sharex=True)
            ax[0].plot(x, metrics["acc_smooth"], label="accuracy (rolling)", linewidth=1.5)
            ax[0].set_ylabel("accuracy")
            ax[0].set_ylim(0.0, 1.05)
            ax[0].legend(loc="upper right", fontsize=8)

            ax[1].plot(x, metrics["nll_smooth"], label="NLL (rolling)", linewidth=1.2)
            ax[1].set_ylabel("NLL")
            ax[1].legend(loc="upper right", fontsize=8)

            ax[2].plot(x, metrics["energy"], label="system energy", alpha=0.7)
            ax[2].plot(x, metrics["topo_entropy"], label="topology entropy", alpha=0.7)
            ax[2].plot(x, metrics["chunks_ts"], label="#chunks", alpha=0.7)
            ax[2].set_ylabel("energy / entropy / count")
            ax[2].set_xlabel("train step")
            ax[2].legend(loc="upper right", fontsize=8)

            fig.tight_layout()
            fig_path = out_dir / "next_token.png"
            fig.savefig(fig_path, dpi=150)
            plt.close(fig)
            figures["next_token"] = fig_path
        except Exception:
            pass

        # Pondering plot from JSONL (if any)
        try:
            ponder_png = plot_pondering_jsonl(out_dir / "pondering.jsonl", out_dir / "pondering.png")
            if ponder_png.exists():
                figures["pondering"] = ponder_png
        except Exception:
            pass

        return figures

    def run(self):  # type: ignore[override]
        """Run experiment and generate paper artifacts.

        Key property: this system does *not* optimize a loss; we do not run evaluation
        during training. We pump tokens (online structural updates), then evaluate once.
        """
        print(f"\n{'='*60}")
        print(f"EXPERIMENT: {self.name} ({self.scale.value})")
        print(f"Goal: {self.goal}")
        print(f"Device: {self.device}")
        print(f"{'='*60}")

        from .base import ExperimentResult

        try:
            print("\n[1] Setup...")
            self.setup()

            out_dir = DEFAULT_OUT_DIR / self.scale.value
            self._reset_artifacts(out_dir)

            # Attach diagnostics for pondering traces (written only when idle_think is called).
            ponder_jsonl = out_dir / "pondering.jsonl"
            ponder_csv = out_dir / "pondering.csv"
            self.manifold.set_diagnostics(
                SemanticDiagnosticsLogger(csv_path=str(ponder_csv), jsonl_path=str(ponder_jsonl))
            )

            steps = int(self._train_steps)
            print(f"\n[2] Training ({steps} steps; no in-loop eval)...")

            # Per-step metrics
            acc = torch.zeros(steps, dtype=torch.float32)
            nll = torch.zeros(steps, dtype=torch.float32)
            entropy = torch.zeros(steps, dtype=torch.float32)
            energy = torch.zeros(steps, dtype=torch.float32)
            topo = torch.zeros(steps, dtype=torch.float32)
            chunks_ts = torch.zeros(steps, dtype=torch.float32)

            data_iter = self.train_iterator()
            for t in range(steps):
                try:
                    context, target = next(data_iter)
                except StopIteration:
                    # Restart streaming iterator if it ended early.
                    data_iter = self.train_iterator()
                    context, target = next(data_iter)

                context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(context_tensor)

                # Fixed steps for speed (dt-calibrated heuristic)
                num_steps = 3 if self.scale == Scale.TOY else 5
                for _ in range(num_steps):
                    self.manifold.step_grammar()

                out = self.manifold.output_state()
                pred = int(out.token_index)
                acc[t] = 1.0 if pred == int(target) else 0.0

                p = float(out.probs[int(target)].clamp(min=1e-10).item())
                nll[t] = float((-torch.log(torch.tensor(p, dtype=torch.float32))).item())
                entropy[t] = float(out.meta.get("entropy", 0.0))

                # System metrics (exclude long-term structural mass where possible)
                _exc = self.manifold.attractors.get("excitation").abs().sum()
                _heat = self.manifold.attractors.get("heat").abs().sum()
                _cexc = self.manifold.chunks.excitation.abs().sum()
                _cheat = self.manifold.chunks.heat.abs().sum()
                energy[t] = (_exc + _heat + _cexc + _cheat).detach().to(torch.float32).cpu()
                topo[t] = torch.tensor(
                    self._topological_entropy(self.manifold.graph.src.detach(), self.manifold.graph.w.detach(), eps=self.physics_config.eps),
                    dtype=torch.float32,
                )
                chunks_ts[t] = float(self.manifold.chunks.num_chunks)

                # Online structural update ("learning")
                self.manifold.observe_next_token(int(target), probs=out.probs)

                # Idle pondering cadence (deterministic; writes diagnostics via logger)
                if t > 0 and (t % 50 == 0):
                    self.manifold.idle_think(steps=1, dream_steps=2)

            # Smooth curves for readability
            acc_smooth = self._rolling_mean(acc, win=200).cpu().tolist()
            nll_smooth = self._rolling_mean(nll, win=200).cpu().tolist()

            # Save training time series + config
            metrics: Dict[str, Any] = {
                "config": asdict(self.physics_config),
                "scale": self.scale.value,
                "dataset": self.dataset_name,
                "context_length": int(self.context_length),
                "vocab_size": int(self.tokenizer.vocab_size),
                "hash_vocab_size": int(self.tokenizer.hash_vocab_size),
                "steps": steps,
                "acc": acc.cpu().tolist(),
                "acc_smooth": acc_smooth,
                "nll": nll.cpu().tolist(),
                "nll_smooth": nll_smooth,
                "entropy": entropy.cpu().tolist(),
                "energy": energy.cpu().tolist(),
                "topo_entropy": topo.cpu().tolist(),
                "chunks_ts": chunks_ts.cpu().tolist(),
            }

            (out_dir / "next_token_metrics.json").write_text(json.dumps(metrics, indent=2), encoding="utf-8")

            print("\n[3] Final evaluation...")
            final_eval = self.evaluate()
            metrics["final_eval"] = final_eval

            # Save a compact summary JSON (avoids duplicating full time series)
            summary = {k: v for k, v in metrics.items() if not isinstance(v, list)}
            (out_dir / "next_token_data.json").write_text(json.dumps(summary, indent=2, default=str), encoding="utf-8")

            figures = self._generate_artifacts(out_dir=out_dir, metrics=metrics)

            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=True,
                metrics={"final": final_eval, "artifacts_dir": str(out_dir)},
                tables={"next_token_summary": (out_dir / "tables" / "next_token_summary.tex").read_text(encoding="utf-8")},
                figures=figures,
            )
        except Exception as e:
            import traceback

            tb = traceback.format_exc()
            print(f"\n[FAILED] {e}")
            print(tb)
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=False,
                metrics={},
                failure_reason=str(e),
            )
    
    def _tokenize_stream(
        self,
        stream,
        output: List[List[int]],
        max_samples: int,
    ) -> None:
        """Tokenize a stream into universal byte-hash sequences."""
        for sample in stream:
            text = sample["text"]
            if not text.strip():
                continue
            ids_t = self.tokenizer.encode_text(text, add_bos_eos=True)
            if int(ids_t.numel()) < 2:
                continue
            output.append(ids_t.to(torch.long).tolist())
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[List[int], int]]:
        """Iterate over training (context, next_token) pairs."""
        for sequence in self._train_sequences:
            # Sliding window
            for i in range(len(sequence) - 1):
                start = max(0, i - self.context_length + 1)
                context = sequence[start:i+1]
                target = sequence[i + 1]
                yield context, target
    
    def _run_grammar_steps(self, num_steps: int = 5) -> None:
        """Run a fixed number of grammar steps.
        
        Note: thinking_complete() can be slow to converge, so for experiments
        we use a fixed number of steps calibrated to dt.
        """
        for _ in range(num_steps):
            self.manifold.step_grammar()
    
    def train_step(self, batch: Tuple[List[int], int]) -> Dict[str, float]:
        """One step of thermodynamic language modeling."""
        context, target = batch
        
        # Convert to tensor
        context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
        
        # Ingest context
        self.manifold.ingest_ids(context_tensor)
        
        # Run grammar dynamics (fixed steps for speed)
        # Toy scale benefits from fewer steps on CPU.
        num_steps = 3 if self.scale == Scale.TOY else 5
        self._run_grammar_steps(num_steps=num_steps)
        
        # Get prediction
        output = self.manifold.output_state()
        predicted = output.token_index
        
        # Observe actual next token (this is the learning!)
        probs = output.probs
        self.manifold.observe_next_token(target, probs=probs)
        
        # Optionally do some pondering
        # NOTE: idle_think/dreaming is comparatively expensive; avoid doing it on
        # step 0 (it makes the progress bar look "stuck") and run it less often.
        if self.state.step > 0 and self.state.step % 50 == 0:
            self.manifold.idle_think(steps=1, dream_steps=2)
        
        # Metrics
        correct = 1.0 if predicted == target else 0.0
        
        # Compute approximate perplexity contribution
        prob = probs[target].item()
        log_prob = -torch.log(torch.tensor(prob + 1e-10)).item()
        
        return {
            "accuracy": correct,
            "log_prob": log_prob,
            "entropy": output.meta.get("entropy", 0.0),
        }
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on validation set."""
        correct = 0
        total = 0
        total_log_prob = 0.0
        
        # Note: evaluation is run once after the online training pass.
        # `_eval_sequences` is already bounded during prefetch/tokenization by scale.
        for sequence in self._eval_sequences:
            for i in range(len(sequence) - 1):
                start = max(0, i - self.context_length + 1)
                context = sequence[start:i+1]
                target = sequence[i + 1]
                
                context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(context_tensor)
                num_steps = 3 if self.scale == Scale.TOY else 5
                self._run_grammar_steps(num_steps=num_steps)
                
                output = self.manifold.output_state()
                predicted = output.token_index
                
                if predicted == target:
                    correct += 1
                
                prob = output.probs[target].item()
                total_log_prob += -torch.log(torch.tensor(prob + 1e-10)).item()
                
                total += 1
                
                # Don't learn during eval
        
        if total == 0:
            return {"accuracy": 0.0, "perplexity": float("inf")}
        
        avg_log_prob = total_log_prob / total
        perplexity = torch.exp(torch.tensor(avg_log_prob)).item()
        
        return {
            "accuracy": correct / total,
            "perplexity": perplexity,
            "eval_tokens": total,
            "graph_edges": self.manifold.graph.num_edges,
            "chunks": self.manifold.chunks.num_chunks,
        }


def run_next_token_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = NextTokenExperiment(scale=scale, device=device)
    result = exp.run()
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /sensorium/experiments/result.py
---

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List


@dataclass
class LaTeXTable:
    """Container for LaTeX table outputs."""
    name: str
    header: List[str]
    rows: List[List[str|int|float]]


    def to_latex(self) -> str:
        """Convert the table to LaTeX format."""
        return f"\\begin{{table}}[h]\n\\centering\n\\caption{{{self.name}}}\n\\label{{tab:{self.name}}}\n\\begin{{tabular}}{{{'l' * len(self.header)}}}\n\\toprule\n{' & '.join(self.header)}\n\\midrule\n{'\n'.join([' & '.join(map(str, row)) for row in self.rows])}n\\bottomrule\n\\end{{tabular}}\n\\end{{table}}"

    def to_markdown(self) -> str:
        """Convert the table to Markdown format."""
        return f"| {self.name} |\n| {' | '.join(self.header)} |\n| {' | '.join([' | '.join(map(str, row)) for row in self.rows])} |\n"


@dataclass
class ExperimentResult:
    """Container for experiment outputs."""
    name: str
    goal: str
    metrics: Dict[str, float|int|str|List[float|int|str]]
    tables: Dict[str, str]  # name -> LaTeX content
    figures: Dict[str, Path]  # name -> path to generated figure


---
File: /sensorium/experiments/rule_shift.py
---

"""
Rule Shift Experiment

Tests the system's ability to adapt when the underlying sequential pattern
reverses mid-stream.
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List, Tuple

import torch

from ..core.config import PhysicsConfig
from ..semantic.hierarchical import HierarchicalSemanticManifold
from ..core.tokenizer import UniversalTokenizer, UniversalTokenizerConfig


def _topological_entropy(src: torch.Tensor, w: torch.Tensor, eps: float) -> float:
    """Mean per-src entropy of outgoing normalized weights."""
    if src.numel() == 0:
        return 0.0
    w = w.clamp(min=0.0)
    if float(w.sum().item()) <= eps:
        return 0.0
    src_u, inv = torch.unique(src, return_inverse=True)
    out_sum = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    out_sum.index_add_(0, inv, w)
    p = w / (out_sum[inv] + eps)
    edge_ent = -p * torch.log(p + eps)
    ent_src = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    ent_src.index_add_(0, inv, edge_ent)
    return float(ent_src.mean().item())


def _make_stream(vocab: List[str]) -> Tuple[Dict[str, int], List[int], List[int]]:
    """Create forward and reverse token streams."""
    tid = {t: i for i, t in enumerate(vocab)}
    fwd = [
        tid["<bos>"], tid["the"], tid["cat"], tid["sat"],
        tid["on"], tid["the"], tid["mat"], tid["<eos>"],
    ]
    rev = [
        tid["<bos>"], tid["mat"], tid["the"], tid["on"],
        tid["sat"], tid["cat"], tid["the"], tid["<eos>"],
    ]
    return tid, fwd, rev


def _make_universal_stream(tokenizer: UniversalTokenizer) -> Tuple[List[int], List[int]]:
    """Create forward/reverse streams using Universal Tokenizer IDs.

    We byte-tokenize the phrase and treat it as the repeating sequence.
    """
    phrase = "<bos> The cat sat on the mat <eos>"
    ids = tokenizer.encode_text(phrase, add_bos_eos=False).to(torch.long).tolist()
    # Ensure at least 2 tokens
    if len(ids) < 2:
        ids = [tokenizer.bos_id, tokenizer.eos_id]
    fwd = ids
    rev = list(reversed(ids))
    return fwd, rev


def run_rule_shift(
    *,
    steps: int,
    shift_at: int,
    context_len: int,
    dt: float,
    device: torch.device,
) -> Dict[str, Any]:
    """
    Run the rule shift experiment.
    
    Returns:
        Dictionary with all metrics and raw data
    """
    # Universal tokenizer stream (paper §3)
    tok = UniversalTokenizer(UniversalTokenizerConfig(hash_vocab_size=4096, num_labels=0))
    fwd, rev = _make_universal_stream(tok)
    vocab = tok.vocab
    
    # Pre-generate the full token stream
    stream: List[int] = []
    pos = 0
    seq = fwd
    for t in range(steps + 1):
        if t == shift_at:
            seq = rev
            pos = 0
        stream.append(seq[pos])
        pos = (pos + 1) % len(seq)
    
    cfg = PhysicsConfig(dt=dt, eps=1e-8)
    brain = HierarchicalSemanticManifold(
        cfg, device,
        vocab=vocab,
        embed_dim=min(64, len(vocab)),
        chunk_min_len=2,
        chunk_max_len=4,
    )
    
    history: List[int] = []
    
    # Metrics tensors
    acc = torch.zeros(steps, dtype=torch.float32)
    energy = torch.zeros(steps, dtype=torch.float32)
    topo = torch.zeros(steps, dtype=torch.float32)
    chunks = torch.zeros(steps, dtype=torch.float32)
    ponder_shortcuts = torch.zeros(steps, dtype=torch.float32)
    ponder_dead_ends = torch.zeros(steps, dtype=torch.float32)
    ponder_hunger = torch.zeros(steps, dtype=torch.float32)
    
    for t in range(steps):
        cur = int(stream[t])
        nxt = int(stream[t + 1])
        
        history.append(cur)
        if len(history) > context_len:
            history = history[-context_len:]
        
        ctx = torch.tensor(history, device=device, dtype=torch.long)
        brain.ingest_ids(ctx)
        brain.step_grammar()
        out = brain.output_state()
        
        pred = int(out.token_index)
        acc[t] = 1.0 if pred == nxt else 0.0
        
        # Dynamic system energy
        _exc = brain.attractors.get('excitation').abs().sum()
        _heat = brain.attractors.get('heat').abs().sum()
        _cexc = brain.chunks.excitation.abs().sum()
        _cheat = brain.chunks.heat.abs().sum()
        energy[t] = (_exc + _heat + _cexc + _cheat).detach().to(torch.float32).cpu()
        
        topo[t] = torch.tensor(
            _topological_entropy(brain.graph.src.detach(), brain.graph.w.detach(), eps=cfg.eps),
            dtype=torch.float32,
        )
        chunks[t] = float(brain.chunks.num_chunks)
        
        # Online learning
        brain.observe_next_token(nxt, probs=out.probs)
        
        # Idle pondering
        p = brain.idle_think(steps=1, dream_steps=context_len)
        ponder_shortcuts[t] = float(p.get("shortcuts", 0.0))
        ponder_dead_ends[t] = float(p.get("dead_ends", 0.0))
        ponder_hunger[t] = float(brain.hunger.mean().detach().cpu().item())
    
    # Rolling accuracy
    win = max(1, len(fwd))
    kern = torch.ones(win, dtype=torch.float32) / float(win)
    acc_smooth = torch.nn.functional.conv1d(
        acc.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2
    ).view(-1)[:steps]
    
    # Compute summary statistics
    pre_shift_acc = float(acc_smooth[shift_at - 100:shift_at].mean().item())
    post_shift_acc_immediate = float(acc_smooth[shift_at:shift_at + 50].mean().item())
    post_shift_acc_recovered = float(acc_smooth[shift_at + 200:shift_at + 300].mean().item()) if shift_at + 300 <= steps else float(acc_smooth[-100:].mean().item())
    
    # Find recovery point (first time accuracy returns to 80% of pre-shift)
    threshold = pre_shift_acc * 0.8
    recovery_step = None
    for t in range(shift_at, min(shift_at + 500, steps)):
        if float(acc_smooth[t].item()) >= threshold:
            recovery_step = t - shift_at
            break
    
    return {
        "config": asdict(cfg),
        "steps": steps,
        "shift_at": shift_at,
        "context_len": context_len,
        "vocab": vocab,
        "pre_shift_accuracy": pre_shift_acc,
        "post_shift_accuracy_immediate": post_shift_acc_immediate,
        "post_shift_accuracy_recovered": post_shift_acc_recovered,
        "recovery_steps": recovery_step,
        "final_chunks": int(chunks[-1].item()),
        "acc": acc.cpu().tolist(),
        "acc_smooth": acc_smooth.cpu().tolist(),
        "energy": energy.cpu().tolist(),
        "topo_entropy": topo.cpu().tolist(),
        "chunks": chunks.cpu().tolist(),
        "ponder_shortcuts": ponder_shortcuts.cpu().tolist(),
        "ponder_dead_ends": ponder_dead_ends.cpu().tolist(),
        "ponder_hunger_mean": ponder_hunger.cpu().tolist(),
    }


def generate_rule_shift_table(metrics: Dict[str, Any]) -> str:
    """Generate LaTeX table for rule shift results."""
    return r"""\begin{table}[t]
\centering
\caption{Rule-shift experiment results. The system adapts to a complete reversal of sequential structure at step """ + str(metrics.get('shift_at', 1000)) + r""".}
\label{tab:rule_shift}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Pre-shift accuracy & """ + f"{metrics.get('pre_shift_accuracy', 0):.1%}" + r""" \\
Post-shift accuracy (immediate) & """ + f"{metrics.get('post_shift_accuracy_immediate', 0):.1%}" + r""" \\
Post-shift accuracy (recovered) & """ + f"{metrics.get('post_shift_accuracy_recovered', 0):.1%}" + r""" \\
Steps to 80\% recovery & """ + f"{metrics.get('recovery_steps', 'N/A')}" + r""" \\
Final chunk count & """ + f"{metrics.get('final_chunks', 0)}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""


def generate_rule_shift_figures(
    metrics: Dict[str, Any],
    figures_dir: Path,
) -> Dict[str, Path]:
    """Generate figures for rule shift experiment."""
    try:
        import matplotlib
        matplotlib.use('Agg')  # Non-interactive backend
        import matplotlib.pyplot as plt
        from matplotlib.backends.backend_pdf import PdfPages
    except ImportError:
        print("  [WARN] matplotlib not available, skipping figures")
        return {}
    
    figures = {}
    steps = metrics["steps"]
    shift_at = metrics["shift_at"]
    x = list(range(steps))
    
    # Figure 1: Main rule shift dynamics
    fig, (ax1, ax3) = plt.subplots(2, 1, figsize=(10, 6), sharex=True)
    ax2 = ax1.twinx()
    
    # Top panel: accuracy and system metrics
    ax1.plot(x, metrics["acc_smooth"], 'b-', label="Accuracy (rolling)", linewidth=1.5)
    ax1.axvline(shift_at, color='r', linestyle='--', alpha=0.7, label="Rule shift")
    ax1.set_ylim(0.0, 1.05)
    ax1.set_ylabel("Accuracy", color='b')
    ax1.tick_params(axis='y', labelcolor='b')
    
    ax2.plot(x, metrics["energy"], 'g-', alpha=0.6, label="System energy", linewidth=1)
    ax2.plot(x, metrics["topo_entropy"], 'm-', alpha=0.6, label="Topo. entropy", linewidth=1)
    ax2.set_ylabel("Energy / Entropy", color='g')
    ax2.tick_params(axis='y', labelcolor='g')
    
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=8)
    
    # Bottom panel: pondering metrics
    ax3.plot(x, metrics["ponder_shortcuts"], 'c-', label="Shortcuts/step", linewidth=1)
    ax3.plot(x, metrics["ponder_dead_ends"], 'orange', label="Dead ends/step", linewidth=1)
    ax3.plot(x, metrics["ponder_hunger_mean"], 'purple', label="Hunger (mean)", linewidth=1)
    ax3.axvline(shift_at, color='r', linestyle='--', alpha=0.7)
    ax3.set_xlabel("Time step")
    ax3.set_ylabel("Pondering metrics")
    ax3.legend(loc='upper right', fontsize=8)
    
    fig.tight_layout()
    
    # Save as PDF
    fig_path = figures_dir / "rule_shift.pdf"
    fig.savefig(fig_path, format='pdf', bbox_inches='tight', dpi=150)
    plt.close(fig)
    figures["rule_shift"] = fig_path
    print(f"  [FIGURE] rule_shift.pdf")
    
    # Figure 2: Pondering detail
    fig2, ax = plt.subplots(figsize=(8, 4))
    ax.fill_between(x, 0, metrics["ponder_shortcuts"], alpha=0.3, label="Shortcuts")
    ax.fill_between(x, 0, metrics["ponder_dead_ends"], alpha=0.3, label="Dead ends")
    ax.plot(x, metrics["ponder_hunger_mean"], 'k-', linewidth=1.5, label="Hunger")
    ax.axvline(shift_at, color='r', linestyle='--', alpha=0.7, label="Rule shift")
    ax.set_xlabel("Time step")
    ax.set_ylabel("Count / Mean")
    ax.set_title("Idle Pondering Behavior")
    ax.legend(loc='upper right')
    fig2.tight_layout()
    
    fig_path2 = figures_dir / "pondering.pdf"
    fig2.savefig(fig_path2, format='pdf', bbox_inches='tight', dpi=150)
    plt.close(fig2)
    figures["pondering"] = fig_path2
    print(f"  [FIGURE] pondering.pdf")
    
    return figures


def run_rule_shift_experiment(
    device: torch.device,
    tables_dir: Path,
    figures_dir: Path,
    steps: int = 2000,
    shift_at: int = 1000,
    context_len: int = 6,
    dt: float = 0.02,
):
    """
    Run the complete rule shift experiment and generate artifacts.
    """
    from .harness import ExperimentResult
    
    print("  Running rule shift simulation...")
    metrics = run_rule_shift(
        steps=steps,
        shift_at=shift_at,
        context_len=context_len,
        dt=dt,
        device=device,
    )
    
    print(f"  Pre-shift accuracy: {metrics['pre_shift_accuracy']:.1%}")
    print(f"  Post-shift (immediate): {metrics['post_shift_accuracy_immediate']:.1%}")
    print(f"  Post-shift (recovered): {metrics['post_shift_accuracy_recovered']:.1%}")
    if metrics['recovery_steps']:
        print(f"  Recovery steps: {metrics['recovery_steps']}")
    
    # Generate table
    table_content = generate_rule_shift_table(metrics)
    table_path = tables_dir / "rule_shift_summary.tex"
    table_path.write_text(table_content)
    print(f"  [TABLE] rule_shift_summary.tex")
    
    # Generate figures
    figures = generate_rule_shift_figures(metrics, figures_dir)
    
    # Save raw data as JSON
    json_path = figures_dir.parent / "rule_shift_data.json"
    # Only save summary, not full time series (too large)
    summary = {k: v for k, v in metrics.items() if not isinstance(v, list)}
    json_path.write_text(json.dumps(summary, indent=2))
    
    return ExperimentResult(
        name="Rule Shift",
        metrics=metrics,
        tables={"rule_shift_summary": table_content},
        figures=figures,
    )



---
File: /sensorium/experiments/text_diffusion.py
---

"""Text Generation by Thermodynamic Annealing

This is an experimental, novel approach to text generation.
Instead of autoregressive next-token prediction, we:

1. Initialize with a noisy/random distribution of token particles
2. Let thermodynamic dynamics pull them toward attractors
3. The attractors are shaped by the prompt/context
4. Read out the final token sequence

This is NOT diffusion in the DDPM sense. It's thermodynamic annealing.
The text "crystallizes" from noise via energy minimization.

Goal: Generate coherent text from prompt via thermodynamic annealing.
Metrics: Perplexity of generated text, coherence (measured by continuation)
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from sensorium.semantic.hierarchical import HierarchicalSemanticManifold
from sensorium.core.tokenizer import UniversalTokenizer, UniversalTokenizerConfig

from .base import BaseExperiment, Scale


class TextDiffusionExperiment(BaseExperiment):
    """Text generation via thermodynamic annealing.
    
    EXPERIMENTAL: This is a novel approach, expect failures!
    """
    
    name = "text_diffusion"
    goal = "Generate text via thermodynamic annealing (experimental)"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.vocab_size = 500
            self.context_length = 16
            self.gen_length = 8
            self.annealing_steps = 50
        elif scale == Scale.MEDIUM:
            self.vocab_size = 5000
            self.context_length = 32
            self.gen_length = 16
            self.annealing_steps = 100
        else:
            self.vocab_size = 20000
            self.context_length = 64
            self.gen_length = 32
            self.annealing_steps = 200
        
        hash_vocab = 4096 if scale == Scale.TOY else (16384 if scale == Scale.MEDIUM else 65536)
        self.tokenizer = UniversalTokenizer(UniversalTokenizerConfig(hash_vocab_size=hash_vocab, num_labels=0))
    
    def setup(self) -> None:
        """Load dataset and pre-tokenize with the universal tokenizer."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading wikitext-2-raw-v1...")
        
        # `trust_remote_code` is no longer supported by `datasets` for security reasons.
        dataset = load_dataset("wikitext", "wikitext-2-raw-v1", streaming=True)
        
        print(
            f"    UniversalTokenizer: vocab_size={self.tokenizer.vocab_size} "
            f"(hash_vocab_size={self.tokenizer.hash_vocab_size})"
        )
        
        # Prefetch and tokenize data
        self._train_sequences: List[List[int]] = []
        self._eval_sequences: List[List[int]] = []
        
        self._tokenize_stream(dataset["train"], self._train_sequences, 2000)
        self._tokenize_stream(dataset["validation"], self._eval_sequences, 500)
        
        print(f"    Train sequences: {len(self._train_sequences)}")
        print(f"    Eval sequences: {len(self._eval_sequences)}")
        
        # Initialize manifold
        self.manifold = HierarchicalSemanticManifold(
            self.physics_config,
            self.device,
            vocab=self.tokenizer.vocab,
            embed_dim=min(self.scale_config.embed_dim, self.tokenizer.vocab_size),
            chunk_min_len=2,
            chunk_max_len=4,
        )

    def _think_until_complete(self, *, max_steps: int = 20) -> None:
        """Run grammar steps until confidence-based halting or max_steps.

        Note: `thinking_complete()` can be slow to converge in general, so we cap
        the number of steps for experiments.
        """
        max_steps = int(max_steps)
        if max_steps <= 0:
            return
        for _ in range(max_steps):
            self.manifold.step_grammar()
            try:
                if self.manifold.thinking_complete():
                    break
            except Exception:
                # If a subclass doesn't support the halting test, fall back to fixed steps.
                break
    
    def _tokenize_stream(
        self,
        stream,
        output: List[List[int]],
        max_samples: int,
    ) -> None:
        """Tokenize stream into universal byte-hash sequences."""
        for sample in stream:
            text = sample["text"]
            if not text.strip():
                continue

            ids_t = self.tokenizer.encode_text(text, add_bos_eos=True)
            if int(ids_t.numel()) < self.context_length + self.gen_length:
                continue
            output.append(ids_t.to(torch.long).tolist())
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[List[int], List[int]]]:
        """Iterate over (context, target) pairs for annealing training."""
        for sequence in self._train_sequences:
            # Random starting point
            max_start = len(sequence) - self.context_length - self.gen_length
            if max_start <= 0:
                continue
            
            start = torch.randint(0, max_start, (1,)).item()
            context = sequence[start:start + self.context_length]
            target = sequence[start + self.context_length:start + self.context_length + self.gen_length]
            
            yield context, target
    
    def _run_grammar_steps(self, num_steps: int = 5) -> None:
        """Run a fixed number of grammar steps."""
        for _ in range(num_steps):
            self.manifold.step_grammar()
    
    def train_step(self, batch: Tuple[List[int], List[int]]) -> Dict[str, float]:
        """Training step for thermodynamic text annealing.
        
        The key insight: we train by showing the manifold complete sequences,
        so it learns the structure. Then at generation time, we use that
        structure to "anneal" from noise.
        """
        context, target = batch
        full_sequence = context + target
        
        # Process the full sequence through the manifold
        seq_tensor = torch.tensor(full_sequence, device=self.device, dtype=torch.long)
        self.manifold.ingest_ids(seq_tensor)
        self._run_grammar_steps(5)
        
        # Observe each transition (this builds the bond structure)
        for i in range(len(full_sequence) - 1):
            current = full_sequence[i]
            next_token = full_sequence[i + 1]
            
            # Get current prediction
            ctx = torch.tensor(full_sequence[:i+1], device=self.device, dtype=torch.long)
            self.manifold.ingest_ids(ctx)
            self._run_grammar_steps(5)
            output = self.manifold.output_state()
            
            # Observe (learn)
            self.manifold.observe_next_token(next_token, probs=output.probs)
        
        # Compute how well we can reconstruct
        correct = 0
        for i in range(len(target)):
            ctx_len = self.context_length + i
            ctx = torch.tensor(full_sequence[:ctx_len], device=self.device, dtype=torch.long)
            self.manifold.ingest_ids(ctx)
            self._run_grammar_steps(5)
            output = self.manifold.output_state()
            
            if output.token_index == target[i]:
                correct += 1
        
        accuracy = correct / len(target)
        
        # Occasionally ponder
        if self.state.step % 20 == 0:
            self.manifold.idle_think(steps=2, dream_steps=8)
        
        return {"accuracy": accuracy}
    
    def _generate_by_annealing(
        self, 
        context: List[int],
        temperature_schedule: Optional[List[float]] = None,
    ) -> List[int]:
        """Generate text by thermodynamic annealing.
        
        1. Start with random token candidates for each position
        2. Iteratively refine using manifold dynamics
        3. Lower "temperature" over time to crystallize the sequence
        """
        if temperature_schedule is None:
            # Exponential cooling schedule
            temperature_schedule = [
                1.0 * (0.9 ** i) for i in range(self.annealing_steps)
            ]
        
        # Initialize: random tokens for generation positions
        generated = [
            torch.randint(0, self.tokenizer.vocab_size, (1,)).item()
            for _ in range(self.gen_length)
        ]
        
        for step, temp in enumerate(temperature_schedule):
            # For each position, consider alternatives
            for pos in range(self.gen_length):
                # Build context for this position
                prefix = context + generated[:pos]
                
                ctx_tensor = torch.tensor(prefix, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(ctx_tensor)
                
                # Run dynamics
                self._run_grammar_steps(5)
                
                output = self.manifold.output_state()
                probs = output.probs
                
                # Temperature-scaled sampling
                if temp > 0.01:
                    # Sample with temperature
                    scaled_logits = output.logits / temp
                    scaled_probs = torch.softmax(scaled_logits, dim=0)
                    
                    # Mix with current token (momentum)
                    current_prob = torch.zeros_like(scaled_probs)
                    current_prob[generated[pos]] = 0.5
                    mixed_probs = 0.5 * scaled_probs + current_prob
                    mixed_probs = mixed_probs / mixed_probs.sum()
                    
                    new_token = torch.multinomial(mixed_probs, 1).item()
                else:
                    # Greedy at low temperature
                    new_token = output.token_index
                
                generated[pos] = new_token
        
        return generated
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate generation quality."""
        total_accuracy = 0.0
        total_perplexity = 0.0
        count = 0
        
        for sequence in self._eval_sequences[:20]:
            if len(sequence) < self.context_length + self.gen_length:
                continue
            
            context = sequence[:self.context_length]
            target = sequence[self.context_length:self.context_length + self.gen_length]
            
            # Generate by annealing
            generated = self._generate_by_annealing(context)
            
            # Compare to target
            correct = sum(1 for g, t in zip(generated, target) if g == t)
            accuracy = correct / len(target)
            total_accuracy += accuracy
            
            # Compute perplexity of generated sequence
            log_prob_sum = 0.0
            full_gen = context + generated
            for i in range(len(context), len(full_gen) - 1):
                ctx = torch.tensor(full_gen[:i+1], device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(ctx)
                self._think_until_complete(max_steps=20)
                output = self.manifold.output_state()
                
                next_token = full_gen[i + 1] if i + 1 < len(full_gen) else generated[-1]
                prob = output.probs[next_token].item()
                log_prob_sum += -torch.log(torch.tensor(prob + 1e-10)).item()
            
            if len(generated) > 1:
                avg_log_prob = log_prob_sum / (len(generated) - 1)
                perplexity = torch.exp(torch.tensor(avg_log_prob)).item()
                total_perplexity += perplexity
            
            count += 1
        
        if count == 0:
            return {"accuracy": 0.0, "perplexity": float("inf")}
        
        return {
            "accuracy": total_accuracy / count,
            "perplexity": total_perplexity / count,
            "samples_evaluated": count,
            "graph_edges": self.manifold.graph.num_edges,
            "chunks": self.manifold.chunks.num_chunks,
        }
    
    def generate_samples(self, num_samples: int = 5) -> List[str]:
        """Generate sample ID sequences for inspection.

        Universal tokenization is not trivially invertible (hash collisions),
        so we log IDs rather than attempting to decode to text.
        """
        samples = []
        
        for sequence in self._eval_sequences[:num_samples]:
            if len(sequence) < self.context_length + self.gen_length:
                continue
            
            context = sequence[:self.context_length]
            generated = self._generate_by_annealing(context)
            
            samples.append({
                "context_ids": context,
                "generated_ids": generated,
            })
        
        return samples


def run_text_diffusion_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = TextDiffusionExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Generate some samples for inspection
    samples = exp.generate_samples(3)
    for i, sample in enumerate(samples):
        print(f"\n  Sample {i+1}:")
        print(f"    Context IDs (tail): {sample['context_ids'][-16:]}")
        print(f"    Generated IDs: {sample['generated_ids']}")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
        "samples": samples,
    }



---
File: /sensorium/experiments/timeseries.py
---

"""Time Series Prediction Experiment

Uses the ETT (Electricity Transformer Temperature) dataset from HuggingFace.
This is a standard benchmark for time series forecasting.

Goal: Predict future values from context window.
Metrics: MSE, MAE
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch
from torch.nn import functional as F

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale, ScaleConfig


class TimeSeriesExperiment(BaseExperiment):
    """Time series prediction using thermodynamic dynamics.
    
    The approach:
    1. Treat each time step as a particle in 1D "value space"
    2. Context window creates attractors
    3. Predict by letting a query particle diffuse toward attractors
    4. Read out the final position as the predicted value
    """
    
    name = "timeseries"
    goal = "Predict future values from historical context"
    
    # Dataset config
    dataset_name = "ettm1"  # ETT-small dataset
    context_length = 96     # ~4 days at 15-min intervals
    prediction_length = 24  # ~1 day ahead
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
        feature: str = "OT",  # Oil Temperature (main target)
    ):
        super().__init__(scale, device, seed)
        self.feature = feature
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.context_length = 24
            self.prediction_length = 6
        elif scale == Scale.MEDIUM:
            self.context_length = 48
            self.prediction_length = 12
        else:
            self.context_length = 96
            self.prediction_length = 24
    
    def setup(self) -> None:
        """Load ETT dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError(
                "Please install datasets: pip install datasets"
            )
        
        print(f"    Loading electricity dataset (streaming)...")
        
        # Use chronos_datasets which has proper parquet format
        # The 'monash_electricity_hourly' subset has hourly electricity consumption
        try:
            dataset = load_dataset(
                "autogluon/chronos_datasets",
                "monash_electricity_hourly",
                streaming=True,
            )
            self._use_real_data = True
            
            # Prepare data iterators
            self.train_stream = dataset["train"]
            
            # Buffer for streaming
            self._train_buffer: List[Dict] = []
            self._eval_buffer: List[Dict] = []
            self._train_iter = iter(self.train_stream)
            
            # Prefetch some data - each row is a full time series
            self._prefetch_buffer(self._train_buffer, self._train_iter, 100)
            
            # Extract values from the first time series
            if self._train_buffer and "target" in self._train_buffer[0]:
                # chronos format has 'target' as list of values
                all_values = []
                for row in self._train_buffer:
                    target = row.get("target", [])
                    if isinstance(target, list):
                        all_values.extend(target)
                    elif hasattr(target, "tolist"):
                        all_values.extend(target.tolist())
                
                if all_values:
                    self._mean = sum(all_values) / len(all_values)
                    self._std = (sum((v - self._mean)**2 for v in all_values) / len(all_values)) ** 0.5
                else:
                    self._mean, self._std = 0.0, 1.0
            else:
                self._mean, self._std = 0.0, 1.0
                
        except Exception as e:
            print(f"    Could not load real data: {e}")
            print(f"    Falling back to synthetic data")
            self._use_real_data = False
            self._train_buffer = []
            self._eval_buffer = []
            self._mean, self._std = 0.0, 1.0
        
        self._std = max(self._std, 1e-8)
        
        # Flatten time series data into single array
        self._train_values: List[float] = []
        self._eval_values: List[float] = []
        
        if self._use_real_data and self._train_buffer:
            for row in self._train_buffer:
                target = row.get("target", [])
                if isinstance(target, list):
                    self._train_values.extend(target)
                elif hasattr(target, "tolist"):
                    self._train_values.extend(target.tolist())
            
            # Use last 20% as eval
            split_idx = int(len(self._train_values) * 0.8)
            self._eval_values = self._train_values[split_idx:]
            self._train_values = self._train_values[:split_idx]
        else:
            # Generate synthetic data
            self._train_values = self._generate_synthetic_series(5000)
            self._eval_values = self._generate_synthetic_series(1000)
        
        print(f"    Using real data: {self._use_real_data}")
        print(f"    Train values: {len(self._train_values)}")
        print(f"    Eval values: {len(self._eval_values)}")
        print(f"    Mean: {self._mean:.4f}, Std: {self._std:.4f}")
        print(f"    Context: {self.context_length}, Prediction: {self.prediction_length}")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _prefetch_buffer(
        self, 
        buffer: List[Dict], 
        iterator: Iterator,
        count: int,
    ) -> None:
        """Prefetch data into buffer."""
        for _ in range(count):
            try:
                buffer.append(next(iterator))
            except StopIteration:
                break
    
    def _generate_synthetic_series(self, length: int) -> List[float]:
        """Generate synthetic time series for testing."""
        import math
        values = []
        for t in range(length):
            # Mix of trends, seasonality, and noise
            trend = 0.001 * t
            daily = math.sin(2 * math.pi * t / 24) * 0.5
            weekly = math.sin(2 * math.pi * t / (24 * 7)) * 0.3
            noise = (torch.randn(1).item()) * 0.1
            values.append(trend + daily + weekly + noise)
        return values
    
    def _normalize(self, value: float) -> float:
        return (value - self._mean) / self._std
    
    def _denormalize(self, value: float) -> float:
        return value * self._std + self._mean
    
    def _get_window(self, values: List[float], start: int) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:
        """Extract context and target windows from flat value list."""
        total_len = self.context_length + self.prediction_length
        
        if start + total_len > len(values):
            return None
        
        context = torch.tensor([
            self._normalize(values[start + i])
            for i in range(self.context_length)
        ], dtype=torch.float32, device=self.device)
        
        target = torch.tensor([
            self._normalize(values[start + self.context_length + i])
            for i in range(self.prediction_length)
        ], dtype=torch.float32, device=self.device)
        
        return context, target
    
    def train_iterator(self) -> Iterator[Tuple[torch.Tensor, torch.Tensor]]:
        """Iterate over training windows."""
        max_samples = self.scale_config.max_train_samples or len(self._train_values)
        total_len = self.context_length + self.prediction_length
        
        # Sliding windows over the flat value array
        for start in range(0, min(max_samples, len(self._train_values) - total_len)):
            window = self._get_window(self._train_values, start)
            if window is not None:
                yield window
    
    def train_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -> Dict[str, float]:
        """One step of thermodynamic time series learning."""
        context, target = batch
        
        # Clear manifold
        self.manifold.clear()
        
        # Encode context as particles
        # Position = (time_index, value)
        for t, value in enumerate(context):
            position = torch.tensor([float(t), value.item()], device=self.device)
            self.manifold.add_particle(
                position=position,
                energy=1.0 / len(context),
                modality=Modality.UNKNOWN,
            )
        
        # Add attractors at context positions (for diffusion)
        for t, value in enumerate(context):
            position = torch.tensor([float(t), value.item()], device=self.device)
            self.manifold.add_attractor(
                position=position,
                energy=1.0 / len(context),
            )
        
        # Run thermodynamic dynamics
        for _ in range(5):
            self.manifold.step()
        
        # Predict: add query particles at future time indices
        predictions = []
        for t in range(self.prediction_length):
            query_time = self.context_length + t
            
            # Initialize query at extrapolated position
            if len(context) >= 2:
                # Simple linear extrapolation for initial position
                slope = (context[-1] - context[-2]).item()
                init_value = context[-1].item() + slope * (t + 1)
            else:
                init_value = context[-1].item()
            
            query_pos = torch.tensor([float(query_time), init_value], device=self.device)
            self.manifold.add_particle(
                position=query_pos,
                energy=1.0,
                modality=Modality.UNKNOWN,
            )
        
        # Let queries diffuse
        for _ in range(10):
            self.manifold.step()
        
        # Read out predictions (from last prediction_length particles)
        for i in range(self.prediction_length):
            idx = len(context) + i
            if idx < len(self.manifold._particles):
                pred_value = self.manifold._particles[idx].position[1].item()
                predictions.append(pred_value)
            else:
                predictions.append(0.0)
        
        predictions = torch.tensor(predictions, device=self.device)
        
        # Compute loss (for monitoring, not for gradients!)
        mse = F.mse_loss(predictions, target).item()
        mae = F.l1_loss(predictions, target).item()
        
        return {"mse": mse, "mae": mae}
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on eval set."""
        mse_total = 0.0
        mae_total = 0.0
        count = 0
        
        total_len = self.context_length + self.prediction_length
        max_samples = self.scale_config.max_eval_samples or len(self._eval_values)
        
        # Step by total_len to get non-overlapping windows
        for start in range(0, min(max_samples, len(self._eval_values) - total_len), total_len):
            window = self._get_window(self._eval_values, start)
            if window is None:
                break
            
            context, target = window
            
            # Same as train_step but without recording history
            self.manifold.clear()
            
            for t, value in enumerate(context):
                position = torch.tensor([float(t), value.item()], device=self.device)
                self.manifold.add_particle(position=position, energy=1.0/len(context))
                self.manifold.add_attractor(position=position, energy=1.0/len(context))
            
            for _ in range(5):
                self.manifold.step()
            
            predictions = []
            for t in range(self.prediction_length):
                query_time = self.context_length + t
                if len(context) >= 2:
                    slope = (context[-1] - context[-2]).item()
                    init_value = context[-1].item() + slope * (t + 1)
                else:
                    init_value = context[-1].item()
                
                query_pos = torch.tensor([float(query_time), init_value], device=self.device)
                self.manifold.add_particle(position=query_pos, energy=1.0)
            
            for _ in range(10):
                self.manifold.step()
            
            for i in range(self.prediction_length):
                idx = len(context) + i
                if idx < len(self.manifold._particles):
                    predictions.append(self.manifold._particles[idx].position[1].item())
                else:
                    predictions.append(0.0)
            
            predictions = torch.tensor(predictions, device=self.device)
            
            mse_total += F.mse_loss(predictions, target).item()
            mae_total += F.l1_loss(predictions, target).item()
            count += 1
        
        if count == 0:
            return {"mse": float("nan"), "mae": float("nan")}
        
        return {
            "mse": mse_total / count,
            "mae": mae_total / count,
            "rmse": (mse_total / count) ** 0.5,
            "eval_samples": count,
        }


def run_timeseries_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = TimeSeriesExperiment(scale=scale, device=device)
    result = exp.run()
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /sensorium/manifold/carriers.py
---

from dataclasses import dataclass
import torch


@dataclass
class CarrierState:
    """Spectral carriers that mediate entanglement in frequency space.
    
    Carriers exist purely in frequency space - they have NO spatial position.
    They are characterized by:
    - frequency (ω): the center frequency they couple to
    - gate_width (σ): tolerance/specialization (how broad/narrow their coupling)
    - amplitude: complex magnitude of accumulated drive
    - phase: complex phase of the carrier
    
    Coupling to oscillators is determined by frequency alignment:
        tuning = exp(-(ω_osc - ω_carrier)² / σ²)
    
    For visualization purposes, carrier positions are computed by the
    dashboard based on the centroid of coupled oscillators.
    """
    frequencies: torch.Tensor   # (M,) - carrier center frequencies
    gate_widths: torch.Tensor   # (M,) - coupling tolerance (σ)
    amplitudes: torch.Tensor    # (M,) - complex amplitude magnitude
    phases: torch.Tensor        # (M,) - complex amplitude phase
    
    @classmethod
    def empty(cls, device: str, dtype: torch.dtype) -> "CarrierState":
        return cls(
            frequencies=torch.empty(0, device=device, dtype=dtype),
            gate_widths=torch.empty(0, device=device, dtype=dtype),
            amplitudes=torch.empty(0, device=device, dtype=dtype),
            phases=torch.empty(0, device=device, dtype=dtype),
        )
    
    @property
    def num_carriers(self) -> int:
        return self.frequencies.shape[0]



---
File: /sensorium/manifold/config.py
---

from dataclasses import dataclass, field
from pathlib import Path
import torch


@dataclass
class SimulationConfig:
    """Configuration for the simulation."""
    
    # Grid and time
    grid_size: tuple[int, int, int] = (32, 32, 32)
    grid_spacing: float = 1.0
    dt: float = 0.01
    poisson_iterations: int = 50         # Need 30-50 for proper pressure solving
    
    # Fundamental physical constants (with correct relative magnitudes)
    # Hierarchy: Gravity << Radiation << Thermal << Elastic
    G: float = 0.001                     # Gravity is weakest (long-range, slow)
    k_B: float = 0.1                     # Moderate thermal pressure
    sigma_SB: float = 1e-5               # Radiation is a slow leak (real σ ≈ 5.67e-8)
    
    # Material properties
    particle_radius: float = 0.5         # Particle radius
    thermal_conductivity: float = 0.1    # Heat transfer rate
    specific_heat: float = 10.0          # Higher = more thermal inertia/stability
    dynamic_viscosity: float = 0.01      # Low for gas-like behavior
    emissivity: float = 0.5              # Radiation efficiency (0-1)
    restitution: float = 0.8             # Collision elasticity (0-1)
    young_modulus: float = 1000.0        # High to prevent interpenetration
    
    # Simulation
    num_particles: int = 1000
    num_steps: int = 500
    
    # Device
    device: str = "mps" if torch.backends.mps.is_available() else "cpu"
    dtype: torch.dtype = field(default_factory=lambda: torch.float32)
    
    # Dashboard
    dashboard_enabled: bool = True
    dashboard_update_interval: int = 10  # Update every N steps

    # Optional: record the live dashboard to a video file (mp4/gif).
    # If set, the visualizer will append frames as it runs and finalize on exit.
    dashboard_video_path: Path | None = None
    dashboard_video_fps: int = 30
    dashboard_video_dpi: int = 150
    
    # Profiling
    profile_enabled: bool = False
    profile_warmup_steps: int = 10
    profile_output_dir: Path = field(default_factory=lambda: Path("artifacts/profiles"))
    
    # Continuous/indefinite mode
    continuous: bool = False
    inject_interval_min: float = 10.0  # seconds
    inject_interval_max: float = 60.0  # seconds
    inject_interval_step: float = 5.0  # quantization step
    inject_particles_min: int = 30
    inject_particles_max: int = 100



---
File: /sensorium/manifold/generator.py
---

import torch
from typing import Dict, Optional


class SyntheticDataGenerator:
    """Generates synthetic 'files' - bursts of related particles.
    
    Each 'file' represents a coherent input (like an image, text chunk, etc.)
    with particles that have related positions and energies.
    """
    
    def __init__(
        self,
        device: str = "cpu",
        dtype: torch.dtype = torch.float32,
        grid_size: tuple[int, int, int] = (32, 32, 32),
    ):
        self.device = device
        self.dtype = dtype
        self.grid_size = grid_size
        self.file_count = 0
        
        # Pattern types for variety
        self.patterns = ["cluster", "line", "sphere", "random", "grid"]
    
    def generate_file(
        self,
        num_particles: int = 50,
        pattern: Optional[str] = None,
        energy_scale: float = 1.0,
    ) -> Dict[str, torch.Tensor]:
        """Generate a synthetic 'file' - a burst of related particles.
        
        Returns dict with positions, energies, etc. for new particles.
        """
        import random
        
        self.file_count += 1
        pattern = pattern or random.choice(self.patterns)
        
        gx, gy, gz = self.grid_size
        grid_center = torch.tensor([gx/2, gy/2, gz/2], device=self.device, dtype=self.dtype)
        
        if pattern == "cluster":
            # Tight cluster around a random point
            center = torch.rand(3, device=self.device, dtype=self.dtype) * torch.tensor(
                [gx * 0.6, gy * 0.6, gz * 0.6], device=self.device, dtype=self.dtype
            ) + torch.tensor([gx * 0.2, gy * 0.2, gz * 0.2], device=self.device, dtype=self.dtype)
            spread = min(gx, gy, gz) * 0.15
            positions = center + torch.randn(num_particles, 3, device=self.device, dtype=self.dtype) * spread
            
        elif pattern == "line":
            # Particles along a random line
            start = torch.rand(3, device=self.device, dtype=self.dtype) * torch.tensor(
                [gx, gy, gz], device=self.device, dtype=self.dtype
            ) * 0.3
            direction = torch.randn(3, device=self.device, dtype=self.dtype)
            direction = direction / (direction.norm() + 1e-8)
            t = torch.linspace(0, min(gx, gy, gz) * 0.7, num_particles, device=self.device, dtype=self.dtype)
            positions = start + t.unsqueeze(1) * direction
            # Add some noise
            positions += torch.randn(num_particles, 3, device=self.device, dtype=self.dtype) * 0.5
            
        elif pattern == "sphere":
            # Hollow sphere shell
            center = grid_center + torch.randn(3, device=self.device, dtype=self.dtype) * 3
            radius = min(gx, gy, gz) * 0.2 + torch.rand(1).item() * 5
            # Random points on unit sphere
            theta = torch.rand(num_particles, device=self.device, dtype=self.dtype) * 2 * 3.14159
            phi = torch.acos(2 * torch.rand(num_particles, device=self.device, dtype=self.dtype) - 1)
            x = torch.sin(phi) * torch.cos(theta)
            y = torch.sin(phi) * torch.sin(theta)
            z = torch.cos(phi)
            positions = center + radius * torch.stack([x, y, z], dim=1)
            
        elif pattern == "grid":
            # Regular grid pattern
            side = int(num_particles ** (1/3)) + 1
            coords = torch.stack(torch.meshgrid(
                torch.linspace(2, gx-2, side, device=self.device),
                torch.linspace(2, gy-2, side, device=self.device),
                torch.linspace(2, gz-2, side, device=self.device),
                indexing='ij'
            ), dim=-1).reshape(-1, 3)[:num_particles]
            positions = coords + torch.randn(len(coords), 3, device=self.device, dtype=self.dtype) * 0.3
            # Pad if needed
            if len(positions) < num_particles:
                extra = num_particles - len(positions)
                positions = torch.cat([positions, torch.rand(extra, 3, device=self.device, dtype=self.dtype) * 
                                       torch.tensor([gx, gy, gz], device=self.device, dtype=self.dtype)])
            
        else:  # random
            positions = torch.rand(num_particles, 3, device=self.device, dtype=self.dtype) * torch.tensor(
                [gx - 2, gy - 2, gz - 2], device=self.device, dtype=self.dtype
            ) + 1
        
        # Clamp to valid range
        positions = positions.clamp(0.5, min(gx, gy, gz) - 1.5)
        
        # Generate energies - higher near the pattern center
        if pattern in ["cluster", "sphere"]:
            center = positions.mean(dim=0)
            dist_from_center = (positions - center).norm(dim=1)
            max_dist = dist_from_center.max() + 1e-8
            energies = (1 - dist_from_center / max_dist) * energy_scale + 0.1
        else:
            energies = torch.rand(num_particles, device=self.device, dtype=self.dtype) * energy_scale * 0.5 + 0.5
        
        # Small initial velocities pointing toward center
        center = positions.mean(dim=0)
        velocities = (center - positions) * 0.01
        velocities += torch.randn_like(velocities) * 0.05
        
        return {
            "positions": positions,
            "velocities": velocities,
            "energies": energies,
            "heats": torch.zeros(num_particles, device=self.device, dtype=self.dtype),
            "excitations": torch.rand(num_particles, device=self.device, dtype=self.dtype) * 0.1,
            "masses": energies.clone(),
            "pattern": pattern,
            "file_id": self.file_count,
        }



---
File: /sensorium/manifold/profiler.py
---

from typing import Optional, Any
from pathlib import Path
import time

from .config import SimulationConfig


def create_profiler(config: "SimulationConfig") -> Optional[Any]:
    """Create a torch profiler if profiling is enabled."""
    if not config.profile_enabled:
        return None
    
    # Use torch.profiler for GPU profiling
    from torch.profiler import profile, ProfilerActivity, schedule
    
    activities = [ProfilerActivity.CPU]
    if config.device == "cuda":
        activities.append(ProfilerActivity.CUDA)
    # Note: MPS profiling is limited, but CPU profiling still works
    
    return profile(
        activities=activities,
        schedule=schedule(
            wait=config.profile_warmup_steps,
            warmup=2,
            active=config.num_steps - config.profile_warmup_steps - 2,
            repeat=1,
        ),
        on_trace_ready=lambda p: save_profiler_trace(p, config.profile_output_dir),
        record_shapes=True,
        profile_memory=True,
        with_stack=True,
    )


def save_profiler_trace(profiler, output_dir: Path) -> None:
    """Save profiler trace and print summary."""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Save Chrome trace for visualization
    trace_path = output_dir / f"trace_{int(time.time())}.json"
    profiler.export_chrome_trace(str(trace_path))
    print(f"\nProfiler trace saved to {trace_path}")
    print("View in Chrome: chrome://tracing")
    
    # Print summary table
    print("\n" + profiler.key_averages().table(sort_by="cpu_time_total", row_limit=20))



---
File: /sensorium/manifold/simulator.py
---

from typing import Dict, Any
import time
from pathlib import Path
from dataclasses import dataclass
import torch
from .config import SimulationConfig
from .visualizer import SimulationDashboard
from .carriers import CarrierState
from .profiler import create_profiler
from optimizer.manifold_physics import (
    ManifoldPhysics,
    ManifoldPhysicsConfig,
    SpectralCarrierPhysics,
    SpectralCarrierConfig,
    ParticleGenerator,
)


def run_simulation(config: SimulationConfig) -> Dict[str, Any]:
    """Run an indefinite simulation with random file injections.
    
    Press Ctrl+C to stop.
    """
    import random
    
    print("=" * 60)
    print("THERMO-MANIFOLD CONTINUOUS SIMULATION")
    print("=" * 60)
    print(f"Device:        {config.device}")
    print(f"Grid:          {config.grid_size}")
    print(f"Initial:       {config.num_particles} particles")
    print(f"Inject every:  {config.inject_interval_min}-{config.inject_interval_max}s")
    print(f"Inject size:   {config.inject_particles_min}-{config.inject_particles_max} particles")
    print(f"Dashboard:     {'ON' if config.dashboard_enabled else 'OFF'}")
    print("=" * 60)
    print("Press Ctrl+C to stop\n")
    
    # Initialize physics engine
    physics_config = ManifoldPhysicsConfig(
        grid_size=config.grid_size,
        grid_spacing=config.grid_spacing,
        dt=config.dt,
        poisson_iterations=config.poisson_iterations,
        # Fundamental constants
        G=config.G,
        k_B=config.k_B,
        sigma_SB=config.sigma_SB,
        # Material properties
        particle_radius=config.particle_radius,
        thermal_conductivity=config.thermal_conductivity,
        specific_heat=config.specific_heat,
        dynamic_viscosity=config.dynamic_viscosity,
        emissivity=config.emissivity,
        restitution=config.restitution,
        young_modulus=config.young_modulus,
    )
    physics = ManifoldPhysics(physics_config, device=str(config.device))
    print("[INFO] Using kernel-accelerated physics")
    
    # Initialize particle state
    state = ParticleState.random(config.num_particles, config)
    
    # Initialize Metal-accelerated data generator
    generator = ParticleGenerator(
        grid_size=config.grid_size,
        device=str(config.device),
    )
    print("[INFO] Using kernel-accelerated particle generation")
    
    # Initialize dashboard
    dashboard = SimulationDashboard(config) if config.dashboard_enabled else None
    if dashboard is not None and getattr(config, "dashboard_video_path", None):
        dashboard.start_recording(
            Path(config.dashboard_video_path),
            fps=int(getattr(config, "dashboard_video_fps", 30)),
            dpi=int(getattr(config, "dashboard_video_dpi", 150)),
        )
    
    # Initialize Metal-accelerated spectral carrier physics (entanglement layer)
    spectral_cfg = SpectralCarrierConfig(
        max_carriers=64,
        coupling_scale=0.25,
        carrier_reg=0.15,
        temperature=0.01,
        conflict_threshold=0.35,
        offender_weight_floor=1e-3,
        ema_alpha=0.10,
        recenter_alpha=0.10,
        gate_width_init=0.35,
        gate_width_min=0.08,
        gate_width_max=1.25,
        seed_carriers=3,
    )
    carrier_physics = SpectralCarrierPhysics(
        config=spectral_cfg,
        grid_size=config.grid_size,
        dt=config.dt,
        device=str(config.device),
    )
    print("[INFO] Using kernel-accelerated spectral carriers (resonance potential)")
    
    # Initialize empty carriers for dashboard (will be populated on first carrier update)
    carriers = CarrierState.empty(config.device, config.dtype)
    
    # Schedule first injection
    def next_injection_time() -> float:
        """Get next injection time with quantized intervals."""
        min_t = config.inject_interval_min
        max_t = config.inject_interval_max
        step = config.inject_interval_step
        
        # Quantize to step intervals
        num_steps = int((max_t - min_t) / step) + 1
        interval = min_t + random.randint(0, num_steps - 1) * step
        return time.time() + interval
    
    next_inject = next_injection_time()
    
    print("Starting simulation...")
    start_time = time.time()
    step = 0
    
    try:
        while True:
            step_start = time.perf_counter()
            
            # Check if it's time to inject a new file
            current_time = time.time()
            if current_time >= next_inject:
                # Generate and inject new file (Metal-accelerated)
                num_new = random.randint(config.inject_particles_min, config.inject_particles_max)
                file_data = generator.generate_file(num_particles=num_new)
                
                # Concatenate new particles with existing (tensors already on MPS)
                state.positions = torch.cat([state.positions, file_data["positions"]])
                state.velocities = torch.cat([state.velocities, file_data["velocities"]])
                state.energies = torch.cat([state.energies, file_data["energies"]])
                state.heats = torch.cat([state.heats, file_data["heats"]])
                state.excitations = torch.cat([state.excitations, file_data["excitations"]])
                state.masses = torch.cat([state.masses, file_data["masses"]])
                # Oscillator phase for new particles (wave space)
                two_pi = float(2.0 * torch.pi)
                new_phase = torch.rand(num_new, device=config.device, dtype=config.dtype) * two_pi
                state.osc_phase = torch.cat([state.osc_phase, new_phase])
                
                total_new_energy = file_data["energies"].sum().item()
                
                print(f"[{time.strftime('%H:%M:%S')}] INJECT #{file_data['file_id']}: "
                      f"+{num_new} particles ({file_data['pattern']}) "
                      f"E={total_new_energy:.1f} → Total: {len(state.positions)} particles")
                
                if dashboard:
                    dashboard.record_injection(
                        step=step,
                        file_id=file_data["file_id"],
                        pattern=file_data["pattern"],
                        num_particles=num_new,
                        total_energy=total_new_energy,
                    )
                
                # Schedule next injection
                next_inject = next_injection_time()
                secs_until = next_inject - time.time()
                print(f"     Next injection in {secs_until:.0f}s")
            
            # Physics step
            state.positions, state.velocities, state.energies, state.heats, state.excitations = \
                physics.step(
                    state.positions,
                    state.velocities,
                    state.energies,
                    state.heats,
                    state.excitations,
                    state.masses,
                )
            
            # Update carriers (entanglement layer - every 10 steps, Metal-accelerated)
            if step % 10 == 0:
                carrier_state = carrier_physics.step(
                    state.osc_phase,
                    state.excitations,
                    state.energies,
                )
                # Oscillator phases are updated in-place; keep reference explicit.
                state.osc_phase = carrier_state["osc_phase"]
                # Convert to CarrierState for dashboard compatibility
                carriers = CarrierState(
                    frequencies=carrier_state["frequencies"],
                    gate_widths=carrier_state["gate_widths"],
                    amplitudes=carrier_state["amplitudes"],
                    phases=carrier_state["phases"],
                )
            
            step_time_ms = (time.perf_counter() - step_start) * 1000
            
            # Update dashboard
            if dashboard and step % config.dashboard_update_interval == 0:
                dashboard.update(
                    step=step,
                    positions=state.positions,
                    velocities=state.velocities,
                    energies=state.energies,
                    heats=state.heats,
                    excitations=state.excitations,
                    step_time_ms=step_time_ms,
                    carriers=carriers,
                    gravity_field=physics.gravity_potential,
                )
            
            # Progress indicator (every 500 steps)
            if step % 500 == 0:
                elapsed = time.time() - start_time
                total_energy = state.energies.sum().item()
                total_heat = state.heats.sum().item()
                print(f"Step {step:6d} | {elapsed/60:.1f}m | {len(state.positions):5d}p | "
                      f"E={total_energy:.1f} H={total_heat:.1f} | {step_time_ms:.1f}ms")
            
            step += 1
    
    except KeyboardInterrupt:
        print("\n\nSimulation stopped by user.")
    
    finally:
        total_time = time.time() - start_time
        if dashboard is not None:
            # Ensure we finalize any active video writer.
            try:
                dashboard.stop_recording()
            except Exception:
                pass
        
        print("\n" + "=" * 60)
        print("SIMULATION SUMMARY")
        print("=" * 60)
        print(f"Total time:     {total_time/60:.1f} minutes")
        print(f"Total steps:    {step:,}")
        print(f"Files injected: {generator.file_count}")
        print(f"Final particles: {len(state.positions):,}")
        print(f"Final energy:   {state.energies.sum().item():.2f}")
        print(f"Final heat:     {state.heats.sum().item():.2f}")
        
        if dashboard:
            dashboard.save(Path("artifacts") / "continuous_final.png")
            dashboard.close()
    
    return {
        "steps": step,
        "total_time_s": total_time,
        "files_injected": generator.file_count,
        "final_particles": len(state.positions),
        "final_energy": float(state.energies.sum().item()),
        "final_heat": float(state.heats.sum().item()),
    }


@dataclass
class ParticleState:
    """Holds all particle state tensors."""
    positions: torch.Tensor   # (N, 3)
    velocities: torch.Tensor  # (N, 3)
    energies: torch.Tensor    # (N,)
    heats: torch.Tensor       # (N,)
    excitations: torch.Tensor # (N,)
    masses: torch.Tensor      # (N,)
    osc_phase: torch.Tensor   # (N,) oscillator phase (wave space)
    
    @classmethod
    def random(cls, n: int, config: SimulationConfig) -> "ParticleState":
        """Create random initial state."""
        device = config.device
        dtype = config.dtype
        grid = config.grid_size
        
        # Positions: random in grid space
        positions = torch.rand(n, 3, device=device, dtype=dtype) * torch.tensor(
            [grid[0], grid[1], grid[2]], device=device, dtype=dtype
        ) * 0.5 + torch.tensor([grid[0]/4, grid[1]/4, grid[2]/4], device=device, dtype=dtype)
        
        # Small random velocities
        velocities = torch.randn(n, 3, device=device, dtype=dtype) * 0.1
        
        # Energy: random, uniform
        energies = torch.rand(n, device=device, dtype=dtype) * 0.5 + 0.5
        
        # Heat: starts at zero
        heats = torch.zeros(n, device=device, dtype=dtype)
        
        # Excitation (= oscillator frequency): diverse initial values
        # Spread across [0, 2] to ensure spectral diversity for carrier coupling
        excitations = torch.rand(n, device=device, dtype=dtype) * 2.0
        
        # Masses: proportional to energy
        masses = energies.clone()

        # Oscillator phase: uniform [0, 2π)
        two_pi = float(2.0 * torch.pi)
        osc_phase = torch.rand(n, device=device, dtype=dtype) * two_pi
        
        return cls(
            positions=positions,
            velocities=velocities,
            energies=energies,
            heats=heats,
            excitations=excitations,
            masses=masses,
            osc_phase=osc_phase,
        )



---
File: /sensorium/manifold/visualizer.py
---

"""Real-time dashboard for monitoring the thermo-manifold simulation.

Uses matplotlib FuncAnimation for proper smooth animation.
The simulation pushes state to a queue, and FuncAnimation pulls from it.
"""

from typing import Dict, Any, Optional, List
from pathlib import Path
from collections import deque
from dataclasses import dataclass
import atexit
import threading
import time
import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from .config import SimulationConfig
from .carriers import CarrierState


@dataclass
class FrameData:
    """Data for one animation frame."""
    step: int
    positions: np.ndarray          # Particle positions (N, 3)
    velocities: np.ndarray
    energies: np.ndarray
    heats: np.ndarray
    excitations: np.ndarray        # Oscillator frequencies (N,)
    step_time_ms: float
    # Carrier data (carriers have no inherent position - computed for viz)
    carrier_frequencies: Optional[np.ndarray] = None   # (M,)
    carrier_gate_widths: Optional[np.ndarray] = None   # (M,)
    carrier_amplitudes: Optional[np.ndarray] = None    # (M,)


class SimulationDashboard:
    """Real-time dashboard using FuncAnimation for smooth animation."""
    
    def __init__(self, config: SimulationConfig, update_every: int = 1, max_particles: Optional[int] = None):
        self.config = config
        self._update_every = update_every
        # If None, render all particles (no sampling)
        self._max_particles = max_particles
        
        # Animation state
        self._fig = None
        self._anim = None
        self._latest_frame: Optional[FrameData] = None
        self._frame_lock = threading.Lock()

        # Optional video recording (incremental writer; suitable for continuous runs)
        self._record_lock = threading.Lock()
        self._record_writer = None
        self._record_path: Optional[Path] = None
        self._recording: bool = False
        
        # Axes
        self._ax3d = None
        self._ax_combined = None   # Combined metrics (top right left)
        self._ax_info = None       # Info text (top right right)
        self._ax_waves = None      # Wave visualization (bottom right)
        
        # 3D artists
        self._plot_particles = None
        self._plot_halos = None
        self._plot_carriers = None
        self._plot_arrows = []
        self._plot_links = []
        
        # History for 2D plots
        self._history: Dict[str, deque] = {
            "step": deque(maxlen=500),
            "total_energy": deque(maxlen=500),
            "total_heat": deque(maxlen=500),
            "mean_excitation": deque(maxlen=500),
            "max_velocity": deque(maxlen=500),
            "step_time_ms": deque(maxlen=500),
        }
        self._injections: List[Dict[str, Any]] = []
    
    def _init_figure(self) -> None:
        """Initialize matplotlib figure and start animation."""
        plt.ion()
        
        self._fig = plt.figure(figsize=(16, 8))
        
        # Layout: 3D on left, top-right has combined chart + info, bottom-right has wave viz
        margin = 0.03
        left_w = 0.48
        right_x = left_w + 2*margin
        right_w = 1.0 - right_x - margin
        top_h = 0.35
        bottom_h = 0.55
        
        # 3D view (left side, full height)
        self._ax3d = self._fig.add_axes([margin, margin, left_w, 1-2*margin], projection="3d")
        
        # Top right: combined metrics (left) + info text (right)
        self._ax_combined = self._fig.add_axes([right_x, 1 - margin - top_h, right_w * 0.65, top_h])
        self._ax_info = self._fig.add_axes([right_x + right_w * 0.68, 1 - margin - top_h, right_w * 0.30, top_h])
        
        # Bottom right: wave visualization (full width)
        self._ax_waves = self._fig.add_axes([right_x, margin, right_w, bottom_h])
        
        # Setup 3D axis
        ax = self._ax3d
        ax.set_facecolor('white')
        ax.xaxis.pane.set_facecolor('#f0f0f0')
        ax.yaxis.pane.set_facecolor('#f0f0f0')
        ax.zaxis.pane.set_facecolor('#f0f0f0')
        gx, gy, gz = self.config.grid_size
        ax.set_xlim(0, gx); ax.set_ylim(0, gy); ax.set_zlim(0, gz)
        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')
        ax.tick_params(labelsize=6)
        
        # Initialize 3D artists
        self._plot_particles, = ax.plot([], [], [], 'o',
            color=(0.5, 0.5, 0.5, 0.6), markersize=4, markeredgecolor='k',
            markeredgewidth=0.3, linestyle='None')
        
        self._plot_halos, = ax.plot([], [], [], 'o',
            color='none', markersize=6, markeredgecolor='orange',
            markeredgewidth=2, linestyle='None', fillstyle='none')
        
        self._plot_carriers, = ax.plot([], [], [], 's',
            color=(0.3, 0.6, 0.8, 0.7), markersize=6, markeredgecolor='k',
            markeredgewidth=0.4, linestyle='None')
        
        # Start animation - interval in ms
        self._anim = FuncAnimation(
            self._fig, 
            self._animate_frame,
            blit=False,   # 3D doesn't support blitting
            # Avoid unbounded caching for an open-ended animation.
            cache_frame_data=False
        )
        
        plt.show(block=False)
    
    def _compute_carrier_positions(
        self,
        carrier_frequencies: np.ndarray,   # (M,) carrier center frequencies
        carrier_gate_widths: np.ndarray,   # (M,) carrier gate widths (σ)
        particle_positions: np.ndarray,    # (N, 3) particle positions
        oscillator_frequencies: np.ndarray,# (N,) oscillator frequencies (excitations)
    ) -> np.ndarray:
        """Compute carrier positions for visualization.
        
        Carriers have no inherent spatial position (they exist in frequency space).
        For visualization, we position each carrier at the weighted centroid of
        the oscillators it couples to, based on frequency alignment:
        
            tuning_ik = exp(-(ω_i - ω_k)² / σ_k²)
            position_k = Σ_i (tuning_ik * pos_i) / Σ_i tuning_ik
        
        - Single coupled oscillator: carrier near that oscillator
        - Multiple coupled: carrier at weighted centroid
        """
        M = len(carrier_frequencies)
        if M == 0:
            return np.empty((0, 3))
        
        N = len(particle_positions)
        if N == 0:
            # No particles, put carriers at center
            gx, gy, gz = self.config.grid_size
            center = np.array([gx / 2.0, gy / 2.0, gz / 2.0])
            return np.tile(center, (M, 1))
        
        # Compute coupling matrix: (M, N)
        # tuning_ik = exp(-(ω_i - ω_k)² / σ_k²)
        omega_diff = carrier_frequencies[:, np.newaxis] - oscillator_frequencies[np.newaxis, :]  # (M, N)
        sigma_sq = (carrier_gate_widths ** 2)[:, np.newaxis]  # (M, 1)
        sigma_sq = np.maximum(sigma_sq, 1e-8)
        tuning = np.exp(-(omega_diff ** 2) / sigma_sq)  # (M, N)
        
        # Weighted centroid: (M, N) @ (N, 3) = (M, 3)
        weight_sum = tuning.sum(axis=1, keepdims=True)  # (M, 1)
        weight_sum = np.maximum(weight_sum, 1e-8)
        weighted_pos = tuning @ particle_positions  # (M, 3)
        centroid = weighted_pos / weight_sum  # (M, 3)
        
        # For single-coupled carriers, add small offset so visible near but not on particle
        significant_couplings = (tuning > 0.1).sum(axis=1)  # (M,)
        single_coupled = (significant_couplings == 1)
        if single_coupled.any():
            idx = np.arange(M)
            offset_dir = np.stack([
                np.sin(idx * 1.0),
                np.sin(idx * 1.7),
                np.sin(idx * 2.3)
            ], axis=1)  # (M, 3)
            centroid[single_coupled] = centroid[single_coupled] + offset_dir[single_coupled] * 0.5
        
        return centroid
    
    def _animate_frame(self, frame_num: int):
        """Animation function called by FuncAnimation."""
        with self._frame_lock:
            frame = self._latest_frame
        
        if frame is None:
            return []
        
        pos = frame.positions
        vel = frame.velocities
        heat = frame.heats
        exc = frame.excitations
        energy = frame.energies
        n = len(pos)
        
        ax = self._ax3d
        
        # Update particles
        self._plot_particles.set_xdata(pos[:, 0])
        self._plot_particles.set_ydata(pos[:, 1])
        self._plot_particles.set_3d_properties(pos[:, 2])
        
        # Update halos
        heat_norm = heat / (heat.max() + 1e-8)
        hot_mask = heat_norm > 0.15
        if hot_mask.any():
            hot_pos = pos[hot_mask]
            self._plot_halos.set_xdata(hot_pos[:, 0])
            self._plot_halos.set_ydata(hot_pos[:, 1])
            self._plot_halos.set_3d_properties(hot_pos[:, 2])
            avg_heat = heat_norm[hot_mask].mean()
            self._plot_halos.set_markeredgecolor((1.0, 1.0 - avg_heat, 0.0, 0.5 + 0.4 * avg_heat))
            self._plot_halos.set_markeredgewidth(1 + 3 * avg_heat)
        else:
            self._plot_halos.set_xdata([])
            self._plot_halos.set_ydata([])
            self._plot_halos.set_3d_properties([])
        
        # Update carriers - compute positions from frequency coupling
        if frame.carrier_frequencies is not None and len(frame.carrier_frequencies) > 0:
            gate_widths = frame.carrier_gate_widths if frame.carrier_gate_widths is not None else np.full(len(frame.carrier_frequencies), 0.35)
            cpos = self._compute_carrier_positions(
                frame.carrier_frequencies,
                gate_widths,
                pos,
                exc,
            )
            self._plot_carriers.set_xdata(cpos[:, 0])
            self._plot_carriers.set_ydata(cpos[:, 1])
            self._plot_carriers.set_3d_properties(cpos[:, 2])
            num_carriers = len(cpos)
        else:
            cpos = None
            self._plot_carriers.set_xdata([])
            self._plot_carriers.set_ydata([])
            self._plot_carriers.set_3d_properties([])
            num_carriers = 0
        
        # Update arrows
        for arrow in self._plot_arrows:
            try:
                arrow.remove()
            except:
                pass
        self._plot_arrows = []
        
        vel_mags = np.linalg.norm(vel, axis=1)
        vel_max = vel_mags.max() + 1e-8
        if vel_max > 0.01:
            skip = max(1, n // 30)
            for i in range(0, n, skip):
                if vel_mags[i] > 0.01:
                    t = vel_mags[i] / vel_max
                    arrow, = ax.plot(
                        [pos[i, 0], pos[i, 0] + vel[i, 0] * 3],
                        [pos[i, 1], pos[i, 1] + vel[i, 1] * 3],
                        [pos[i, 2], pos[i, 2] + vel[i, 2] * 3],
                        color=(t, 0.2, 1-t, 0.7), linewidth=0.8
                    )
                    self._plot_arrows.append(arrow)
        
        # Update links (less frequently)
        if frame.step % 5 == 0:
            for link in self._plot_links:
                try:
                    link.remove()
                except:
                    pass
            self._plot_links = []
            
            if cpos is not None and len(cpos) > 0:
                cfreq = frame.carrier_frequencies
                gate_widths = frame.carrier_gate_widths if frame.carrier_gate_widths is not None else np.full(len(cfreq), 0.35)
                camp = np.abs(frame.carrier_amplitudes) if frame.carrier_amplitudes is not None else np.ones(len(cfreq))
                camp_norm = camp / (camp.max() + 1e-8)
                
                for ci in range(min(len(cpos), 20)):
                    # Compute actual tuning: T = exp(-(ω_osc - ω_carrier)² / σ²)
                    d = exc - cfreq[ci]
                    sigma_sq = gate_widths[ci] ** 2
                    tuning = np.exp(-(d * d) / max(sigma_sq, 1e-8))
                    
                    # Show top coupled oscillators (tuning > 0.3 means well-aligned)
                    well_coupled = tuning > 0.3
                    if well_coupled.any():
                        # Get indices of well-coupled oscillators, sorted by tuning
                        coupled_idx = np.where(well_coupled)[0]
                        # Limit to top 5 per carrier to avoid clutter
                        if len(coupled_idx) > 5:
                            top_tuning = tuning[coupled_idx]
                            top_order = np.argsort(top_tuning)[-5:]
                            coupled_idx = coupled_idx[top_order]
                        
                        for pi in coupled_idx:
                            t = tuning[pi]
                            s = t * camp_norm[ci]
                            link, = ax.plot(
                                [pos[pi, 0], cpos[ci, 0]],
                                [pos[pi, 1], cpos[ci, 1]],
                                [pos[pi, 2], cpos[ci, 2]],
                                'k--', linewidth=0.3 + s * 1.5, alpha=0.2 + 0.5 * t
                            )
                            self._plot_links.append(link)
        
        ax.set_title(f'Step {frame.step} | {n}p | {num_carriers}c', fontsize=9)
        
        # Update 2D plots
        self._update_2d_plots(frame)

        # If recording, append this frame to the output video.
        # We do this after all artists/axes have been updated.
        with self._record_lock:
            if self._recording and self._record_writer is not None:
                try:
                    self._record_writer.grab_frame()
                except Exception as e:
                    # Disable recording on error to avoid breaking the live dashboard.
                    print(f"[dashboard] recording failed ({self._record_path}): {e}")
                    try:
                        self._record_writer.finish()
                    except Exception:
                        pass
                    self._record_writer = None
                    self._recording = False
        
        return [self._plot_particles, self._plot_halos, self._plot_carriers]
    
    def _update_2d_plots(self, frame: FrameData) -> None:
        """Update the combined metrics and wave visualization."""
        energy = frame.energies
        heat = frame.heats
        exc = frame.excitations
        steps = list(self._history["step"])
        
        # Combined metrics chart (energy, heat, conservation)
        ax = self._ax_combined
        ax.clear()
        if len(steps) > 1:
            e_hist = list(self._history["total_energy"])
            h_hist = list(self._history["total_heat"])
            ax.plot(steps, e_hist, 'b-', lw=1.5, label='Energy')
            ax.plot(steps, h_hist, 'r-', lw=1.5, label='Heat')
            ax.plot(steps, [e+h for e,h in zip(e_hist, h_hist)], 'purple', ls='--', lw=1.5, label='Total')
            ax.legend(fontsize=7, loc='upper left')
        ax.set_title('Energy Conservation', fontsize=10)
        ax.tick_params(labelsize=7)
        ax.set_xlabel('Step', fontsize=8)
        
        # Info text block
        ax = self._ax_info
        ax.clear()
        ax.axis('off')
        total_e = float(energy.sum())
        total_h = float(heat.sum())
        num_carriers = len(frame.carrier_frequencies) if frame.carrier_frequencies is not None else 0
        avg_ms = np.mean(list(self._history["step_time_ms"])[-50:]) if self._history["step_time_ms"] else 0
        fps = 1000/avg_ms if avg_ms > 0 else 0
        
        ax.text(0.05, 0.95, f"""Step: {frame.step:,}
Particles: {len(frame.positions)}
Carriers: {num_carriers}

Energy: {total_e:.1f}
Heat: {total_h:.1f}
Total: {total_e+total_h:.1f}

{frame.step_time_ms:.1f} ms/step
{fps:.0f} steps/sec""", transform=ax.transAxes, fontsize=9, va='top', family='monospace')
        
        # Wave visualization - show top carriers with their coupled oscillators
        ax = self._ax_waves
        ax.clear()
        
        if frame.carrier_frequencies is not None and len(frame.carrier_frequencies) > 0:
            cfreq = frame.carrier_frequencies
            cgate = frame.carrier_gate_widths if frame.carrier_gate_widths is not None else np.full(len(cfreq), 0.35)
            camp = np.abs(frame.carrier_amplitudes) if frame.carrier_amplitudes is not None else np.ones(len(cfreq))
            
            # Sort carriers by amplitude, take top 3
            top_idx = np.argsort(camp)[-3:][::-1]
            
            # Time axis for wave display (show ~2 pulse cycles)
            t = np.linspace(0, 4 * np.pi, 400)
            
            colors = ['#2ecc71', '#3498db', '#e74c3c']
            
            for i, ci in enumerate(top_idx):
                if ci >= len(cfreq):
                    continue
                    
                carrier_omega = cfreq[ci]
                carrier_gate = cgate[ci]
                carrier_amp = camp[ci]
                y_offset = i * 3.0  # Vertical offset for this carrier
                
                # Find oscillators coupled to this carrier
                d = exc - carrier_omega
                sigma_sq = max(carrier_gate * carrier_gate, 1e-8)
                tuning = np.exp(-(d * d) / sigma_sq)
                coupled_mask = tuning > 0.3
                
                # Draw the BLOCK PULSE (gate open/closed)
                # Pulse width is inversely related to frequency (wavelength)
                # Higher frequency = narrower pulse, lower frequency = wider pulse
                pulse_period = 2 * np.pi  # One full cycle
                pulse_width = pulse_period * 0.5  # 50% duty cycle
                
                # Create block pulse pattern
                pulse_phase = (t % pulse_period)
                pulse_on = pulse_phase < pulse_width
                pulse_height = 0.8
                
                # Draw block pulse as filled rectangles
                ax.fill_between(t, y_offset - pulse_height/2, y_offset + pulse_height/2,
                               where=pulse_on, color=colors[i % len(colors)], alpha=0.3,
                               label=f'C{ci}: ω={carrier_omega:.2f}')
                
                # Draw individual coupled sines (faint, inside the pulse)
                combined_wave = np.zeros_like(t)
                coupled_count = 0
                for oi in np.where(coupled_mask)[0][:8]:  # Limit to 8 per carrier
                    osc_omega = exc[oi]
                    # Scale frequency to show visible oscillation
                    display_freq = max(osc_omega, 0.5) * 3  # Ensure visible waves
                    osc_amp = tuning[oi] * 0.4
                    wave = osc_amp * np.sin(display_freq * t)
                    # Only show wave where pulse is on
                    wave_masked = np.where(pulse_on, wave, 0)
                    ax.plot(t, wave_masked + y_offset, color=colors[i % len(colors)], 
                           alpha=0.2, lw=0.8)
                    combined_wave += wave
                    coupled_count += 1
                
                # Draw combined wave (bold) - the sum of all coupled oscillators
                if coupled_count > 0:
                    combined_wave = combined_wave / max(coupled_count, 1)
                    # Mask to pulse region
                    combined_masked = np.where(pulse_on, combined_wave, 0)
                    ax.plot(t, combined_masked + y_offset, color=colors[i % len(colors)], 
                           lw=2.5, alpha=0.9)
                
                # Add label showing coupled count
                ax.text(t[-1] + 0.2, y_offset, f'{coupled_count} osc', fontsize=7, 
                       va='center', color=colors[i % len(colors)])
            
            ax.legend(fontsize=7, loc='upper left')
            ax.set_xlim(0, 4 * np.pi + 1)
            ax.set_ylim(-1.5, 9)
        
        ax.set_title('Wave Space: Top Carriers (pulse envelope + coupled oscillators)', fontsize=10)
        ax.tick_params(labelsize=7)
        ax.set_xlabel('Phase', fontsize=8)
        ax.set_ylabel('Amplitude', fontsize=8)
    
    def update(
        self,
        step: int,
        positions: torch.Tensor,
        velocities: torch.Tensor,
        energies: torch.Tensor,
        heats: torch.Tensor,
        excitations: torch.Tensor,
        step_time_ms: float,
        extra: Optional[Dict[str, Any]] = None,
        gravity_field: Optional[torch.Tensor] = None,
        carriers: Optional[CarrierState] = None,
    ) -> None:
        """Push new frame data to the animation."""
        if self._fig is None:
            self._init_figure()
        
        # Convert to numpy
        pos = positions.detach().cpu().numpy()
        vel = velocities.detach().cpu().numpy()
        energy = energies.detach().cpu().numpy()
        heat = heats.detach().cpu().numpy()
        exc = excitations.detach().cpu().numpy()
        
        n = len(pos)
        
        # Sample if needed (disabled by default; set max_particles to an int to enable)
        if self._max_particles is not None and n > self._max_particles:
            idx = np.random.choice(n, self._max_particles, replace=False)
            pos, vel, energy, heat, exc = pos[idx], vel[idx], energy[idx], heat[idx], exc[idx]
        
        # Carrier data (carriers have no position - computed in viz from frequencies)
        cfreq, cgate, camp = None, None, None
        if carriers is not None and carriers.num_carriers > 0:
            cfreq = carriers.frequencies.cpu().numpy()
            cgate = carriers.gate_widths.cpu().numpy()
            camp = carriers.amplitudes.cpu().numpy()
        
        # Update history
        self._history["step"].append(step)
        self._history["total_energy"].append(float(energy.sum()))
        self._history["total_heat"].append(float(heat.sum()))
        self._history["mean_excitation"].append(float(exc.mean()))
        self._history["max_velocity"].append(float(np.linalg.norm(vel, axis=1).max()))
        self._history["step_time_ms"].append(step_time_ms)
        
        # Create frame data
        frame = FrameData(
            step=step,
            positions=pos,
            velocities=vel,
            energies=energy,
            heats=heat,
            excitations=exc,
            step_time_ms=step_time_ms,
            carrier_frequencies=cfreq,
            carrier_gate_widths=cgate,
            carrier_amplitudes=camp,
        )
        
        # Update latest frame (thread-safe)
        with self._frame_lock:
            self._latest_frame = frame
        
        # Process events to keep animation responsive
        self._fig.canvas.flush_events()
    
    def record_injection(self, step: int, file_id: int, pattern: str, num_particles: int, total_energy: float) -> None:
        """Record injection event."""
        self._injections.append({
            "step": step, "file_id": file_id, "pattern": pattern,
            "num_particles": num_particles, "energy": total_energy, "time": time.time()
        })
        if len(self._injections) > 20:
            self._injections = self._injections[-20:]
    
    def save(self, path: Path) -> None:
        """Save figure."""
        if self._fig is not None:
            # Stop animation before saving
            if self._anim is not None:
                es = getattr(self._anim, "event_source", None)
                if es is not None:
                    try:
                        es.stop()
                    except Exception:
                        # It's fine if the event source is already shut down.
                        pass
            path.parent.mkdir(parents=True, exist_ok=True)
            self._fig.savefig(path, dpi=150, bbox_inches='tight')
            print(f"Dashboard saved to {path}")

    def start_recording(
        self,
        path: Path,
        *,
        fps: int = 30,
        dpi: int = 150,
        codec: str = "libx264",
        bitrate: Optional[int] = None,
    ) -> None:
        """Start recording the animated dashboard to a video file.

        This is incremental (grabs frames as the dashboard runs), so it works for
        `--continuous` runs. The file is finalized when `stop_recording()` or
        `close()` is called (also registered via `atexit`).
        """
        if self._fig is None:
            self._init_figure()

        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        with self._record_lock:
            # Close any existing writer
            if self._record_writer is not None:
                try:
                    self._record_writer.finish()
                except Exception:
                    pass
                self._record_writer = None
                self._recording = False

            suffix = path.suffix.lower()
            if suffix == ".gif":
                # GIF fallback (no ffmpeg required)
                from matplotlib.animation import PillowWriter
                writer = PillowWriter(fps=fps)
            else:
                # MP4/MOV/etc via ffmpeg
                from matplotlib.animation import FFMpegWriter
                writer_kwargs: Dict[str, Any] = {"fps": fps, "codec": codec}
                if bitrate is not None:
                    writer_kwargs["bitrate"] = int(bitrate)
                writer = FFMpegWriter(**writer_kwargs)

            # Initialize writer and mark active
            writer.setup(self._fig, str(path), dpi=dpi)
            self._record_writer = writer
            self._record_path = path
            self._recording = True

        atexit.register(self.stop_recording)
        print(f"[dashboard] recording to {path} ({fps} fps)")

    def stop_recording(self) -> None:
        """Stop recording and finalize the video file (if active)."""
        with self._record_lock:
            if self._record_writer is None:
                self._recording = False
                return
            try:
                self._record_writer.finish()
            finally:
                self._record_writer = None
                self._recording = False
                self._record_path = None
                print("[dashboard] recording finalized")
    
    def close(self) -> None:
        """Close dashboard."""
        self.stop_recording()
        if self._anim is not None:
            es = getattr(self._anim, "event_source", None)
            if es is not None:
                try:
                    es.stop()
                except Exception:
                    pass
            self._anim = None
        if self._fig is not None:
            plt.close(self._fig)
            self._fig = None



---
File: /run.py
---

#!/usr/bin/env python3
"""Thermo-Manifold Simulation Entrypoint

Instrumented simulation runner with:
- GPU profiling for performance bottleneck identification
- Real-time dashboard for understanding dynamics
- Clean separation between physics engine and observations

Usage:
    python run.py                    # Run with defaults
    python run.py --profile          # Run with GPU profiling
    python run.py --no-dashboard     # Run headless (for benchmarks)
    python run.py --steps 1000       # Custom step count
"""

from __future__ import annotations

import argparse
from pathlib import Path
import torch
from sensorium.manifold.config import SimulationConfig
from sensorium.manifold.simulator import run_simulation


def main():
    parser = argparse.ArgumentParser(
        description="Thermo-Manifold Simulation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    
    parser.add_argument("--steps", type=int, default=500, help="Number of simulation steps (ignored in continuous mode)")
    parser.add_argument("--particles", type=int, default=1000, help="Initial number of particles")
    parser.add_argument("--grid", type=int, default=32, help="Grid size (cubic)")
    parser.add_argument("--profile", action="store_true", help="Enable GPU profiling")
    parser.add_argument("--no-dashboard", action="store_true", help="Disable real-time dashboard")
    parser.add_argument("--dashboard-video", type=str, default=None, help="Record dashboard to video file (e.g. artifacts/dashboard.mp4 or .gif)")
    parser.add_argument("--dashboard-fps", type=int, default=30, help="Dashboard video FPS (default: 30)")
    parser.add_argument("--device", type=str, default=None, help="Device (mps, cuda, cpu)")
    
    # Continuous mode options
    parser.add_argument("--continuous", "-c", action="store_true", 
                        help="Run indefinitely with random file injections")
    parser.add_argument("--inject-min", type=float, default=10.0,
                        help="Minimum seconds between file injections (default: 10)")
    parser.add_argument("--inject-max", type=float, default=60.0,
                        help="Maximum seconds between file injections (default: 60)")
    parser.add_argument("--inject-particles-min", type=int, default=30,
                        help="Minimum particles per injection (default: 30)")
    parser.add_argument("--inject-particles-max", type=int, default=100,
                        help="Maximum particles per injection (default: 100)")
    
    args = parser.parse_args()
    
    # Build config
    device = args.device
    if device is None:
        if torch.backends.mps.is_available():
            device = "mps"
        elif torch.cuda.is_available():
            device = "cuda"
        else:
            device = "cpu"
    
    config = SimulationConfig(
        grid_size=(args.grid, args.grid, args.grid),
        num_particles=args.particles,
        num_steps=args.steps,
        device=device,
        profile_enabled=args.profile,
        dashboard_enabled=not args.no_dashboard,
        dashboard_video_path=(None if args.dashboard_video is None else Path(args.dashboard_video)),
        dashboard_video_fps=int(args.dashboard_fps),
        continuous=args.continuous,
        inject_interval_min=args.inject_min,
        inject_interval_max=args.inject_max,
        inject_particles_min=args.inject_particles_min,
        inject_particles_max=args.inject_particles_max,
    )
    
    result = run_simulation(config)
    print("\nFinal results:")
    print(f"  Energy: {result['final_energy']:.4f}")
    print(f"  Heat:   {result['final_heat']:.4f}")
    print(f"  Total:  {result['final_energy'] + result['final_heat']:.4f}")


if __name__ == "__main__":
    main()

