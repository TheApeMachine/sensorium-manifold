Directory Structure:

└── ./
    ├── thermo_manifold
    │   ├── bridge
    │   │   ├── __init__.py
    │   │   └── manifold.py
    │   ├── core
    │   │   ├── __init__.py
    │   │   ├── config.py
    │   │   ├── diagnostics.py
    │   │   ├── scatter.py
    │   │   ├── state.py
    │   │   └── viz.py
    │   ├── demos
    │   │   ├── __init__.py
    │   │   ├── cross_modal_demo.py
    │   │   ├── rule_shift_demo.py
    │   │   ├── unified_demo.py
    │   │   └── unified_multimodal_demo.py
    │   ├── experiments
    │   │   ├── __init__.py
    │   │   ├── ablations.py
    │   │   ├── audio_gen.py
    │   │   ├── base.py
    │   │   ├── harness.py
    │   │   ├── image_gen.py
    │   │   ├── next_token.py
    │   │   ├── result.py
    │   │   ├── rule_shift.py
    │   │   ├── text_diffusion.py
    │   │   └── timeseries.py
    │   ├── physics
    │   │   ├── __init__.py
    │   │   └── engine.py
    │   ├── semantic
    │   │   ├── __init__.py
    │   │   ├── bipartite_graph.py
    │   │   ├── bond_graph.py
    │   │   ├── chunk_store.py
    │   │   ├── hierarchical.py
    │   │   ├── manifold.py
    │   │   └── radix_trie.py
    │   ├── spectral
    │   │   ├── __init__.py
    │   │   ├── manifold.py
    │   │   └── unified.py
    │   ├── tests
    │   │   ├── __init__.py
    │   │   ├── test_bridge_heat.py
    │   │   ├── test_hunger.py
    │   │   ├── test_multi_resolution_chunks.py
    │   │   └── test_transitive_closure.py
    │   └── __init__.py
    └── README.md



---
File: /thermo_manifold/bridge/__init__.py
---

"""Bridge manifold for cross-modal transduction."""

from .manifold import BridgeManifold

__all__ = ["BridgeManifold"]



---
File: /thermo_manifold/bridge/manifold.py
---

from __future__ import annotations

import math
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import torch

from ..core.scatter import scatter_sum, segment_softmax
from ..core.diagnostics import BridgeDiagnosticsLogger


@dataclass
class BridgeOutput:
    """Spectral readout from the bridge."""

    spec_logits: torch.Tensor
    spec_probs: torch.Tensor
    meta: Dict[str, Any]


@dataclass
class BridgeObserveOutput:
    """Diagnostics from an observe() call."""

    mismatch: torch.Tensor
    mismatch_mean: float
    mismatch_min: float
    mismatch_max: float
    sem_entropy: float
    spec_entropy: float
    ratio: float
    heat_mean: float
    energy_mean: float


@dataclass
class BindEdges:
    src: torch.Tensor
    dst: torch.Tensor
    weight: torch.Tensor
    mass_in: torch.Tensor
    entropy: torch.Tensor


class BridgeManifold:
    """Vector-to-vector transduction via emergent carriers.

    This replaces the old ID->ID bipartite graph with a carrier population that couples
    a semantic vector space (R^D) to a spectral coordinate space (R).

    Design goals:
    - No dense semantic->spectral lookup table.
    - No backprop.
    - No Python-side per-edge loops.
    - Generalization via continuous semantic vectors.
    """

    def __init__(
        self,
        *,
        sem_dim: int,
        spec_bins: torch.Tensor,
        dt: float,
        device: torch.device,
        num_carriers: Optional[int] = None,
        eps: float = 1e-8,
        tau: float = 1.0,
        sem_horizon: bool = True,
        spec_horizon: bool = True,
        horizon_k: Optional[int] = None,
        diagnostics: Optional[BridgeDiagnosticsLogger] = None,
    ):
        self.device = device
        self.dt = float(dt)
        self.eps = float(eps)
        self.tau = float(tau)
        self.sem_horizon = bool(sem_horizon)
        self.spec_horizon = bool(spec_horizon)
        self.horizon_k = None if horizon_k is None else int(horizon_k)
        self._diagnostics = diagnostics
        self._observe_step = 0

        self.sem_dim = int(sem_dim)

        bins = spec_bins.to(device=device, dtype=torch.float32).flatten()
        if bins.numel() == 0:
            raise ValueError("spec_bins must be non-empty")
        # Keep bins sorted to enable event-horizon neighbor search.
        self.spec_bins, self._bin_order = torch.sort(bins)
        self.num_bins = int(self.spec_bins.numel())

        if num_carriers is None:
            # Emergent-ish default: carriers scale sublinearly with output resolution.
            num_carriers = max(1, int(round(math.sqrt(self.num_bins))))
        self.num_carriers = int(num_carriers)

        # Carrier state.
        self.sem_pos = torch.randn(self.num_carriers, self.sem_dim, device=device, dtype=torch.float32)
        self.sem_pos = self.sem_pos / (self.sem_pos.norm(dim=1, keepdim=True) + self.eps)

        # Initialize spectral positions by sampling from the output bin range.
        lo = float(self.spec_bins.min().item())
        hi = float(self.spec_bins.max().item())
        if math.isclose(lo, hi):
            self.spec_pos = torch.full((self.num_carriers,), lo, device=device, dtype=torch.float32)
        else:
            u = torch.rand(self.num_carriers, device=device, dtype=torch.float32)
            self.spec_pos = lo + (hi - lo) * u

        self.energy = torch.zeros(self.num_carriers, device=device, dtype=torch.float32)
        self.heat = torch.zeros(self.num_carriers, device=device, dtype=torch.float32)

        # Homeostasis baseline.
        self._energy_baseline: Optional[torch.Tensor] = None
        # Projection axis for semantic event-horizon selection.
        self._sem_axis = torch.randn(self.sem_dim, device=device, dtype=torch.float32)
        self._sem_axis = self._sem_axis / (self._sem_axis.norm() + self.eps)

    # ----------------------------
    # Homeostasis
    # ----------------------------

    def _ratio(self, total: torch.Tensor) -> torch.Tensor:
        """Return total / baseline with an emergent baseline timescale."""
        dt = self.dt
        eps = self.eps
        total = total.to(torch.float32)
        if self._energy_baseline is None:
            self._energy_baseline = total.detach().clone()
            return torch.tensor(1.0, device=self.device, dtype=torch.float32)
        base = self._energy_baseline
        alpha = dt / (self.tau + dt)
        base_new = base * (1.0 - alpha) + total.detach() * alpha
        self._energy_baseline = base_new
        ratio = torch.log1p(total) / (torch.log1p(base_new) + eps)
        return ratio.clamp(min=eps)

    # ----------------------------
    # Locality helpers
    # ----------------------------

    def _neighbor_window_1d(self, query: torch.Tensor, key: torch.Tensor, k: int) -> torch.Tensor:
        if query.numel() == 0 or key.numel() == 0 or k <= 0:
            return torch.empty((int(query.numel()), 0), device=self.device, dtype=torch.long)
        m = int(key.numel())
        k = min(int(k), m)
        key_sorted, order = torch.sort(key)
        pos = torch.searchsorted(key_sorted, query)
        half = k // 2
        start = (pos - half).clamp(min=0, max=max(0, m - k))
        offsets = torch.arange(k, device=self.device, dtype=torch.long).unsqueeze(0)
        win = start.to(torch.long).unsqueeze(1) + offsets
        return order.index_select(0, win.reshape(-1)).reshape(win.shape)

    def _semantic_neighbors(self, sem_pos: torch.Tensor, k: int) -> torch.Tensor:
        proj_carriers = self.sem_pos @ self._sem_axis
        proj_query = sem_pos @ self._sem_axis
        return self._neighbor_window_1d(proj_query, proj_carriers, k)

    # ----------------------------
    # Core coupling primitives
    # ----------------------------

    def _semantic_bind(self, sem_pos: torch.Tensor, sem_energy: torch.Tensor) -> BindEdges:
        """Return sparse binding edges from semantic particles to carriers."""
        eps = self.eps

        sem_pos = sem_pos.to(device=self.device, dtype=torch.float32)
        sem_energy = sem_energy.to(device=self.device, dtype=torch.float32).flatten()
        if sem_pos.ndim == 1:
            sem_pos = sem_pos.view(1, -1)
        n = int(sem_pos.shape[0])
        if sem_pos.numel() == 0 or self.num_carriers == 0:
            mass_in = torch.zeros(self.num_carriers, device=self.device, dtype=torch.float32)
            empty = torch.empty(0, device=self.device, dtype=torch.long)
            return BindEdges(src=empty, dst=empty, weight=torch.empty(0, device=self.device), mass_in=mass_in, entropy=torch.tensor(0.0, device=self.device))

        if self.sem_horizon:
            k = self.horizon_k if self.horizon_k is not None else max(1, int(round(math.sqrt(self.num_carriers))))
            idx = self._semantic_neighbors(sem_pos, k)
        else:
            idx = torch.arange(self.num_carriers, device=self.device, dtype=torch.long).view(1, -1).expand(n, -1)

        # Distances on candidate edges.
        cand = self.sem_pos.index_select(0, idx.reshape(-1)).reshape(idx.shape + (-1,))
        diff = sem_pos.unsqueeze(1) - cand
        dist2 = (diff * diff).sum(dim=2)
        d_scale = torch.sqrt(dist2.mean() + eps)
        sharpness = 1.0 / (d_scale + eps)
        logits = -dist2 * sharpness
        w = torch.softmax(logits, dim=1)
        entropy = -(w * torch.log(w + eps)).sum(dim=1).mean()

        src = torch.arange(n, device=self.device, dtype=torch.long).repeat_interleave(idx.shape[1])
        dst = idx.reshape(-1)
        weight = w.reshape(-1)
        mass_in = scatter_sum(weight * sem_energy[src], dst, self.num_carriers)
        return BindEdges(src=src, dst=dst, weight=weight, mass_in=mass_in, entropy=entropy)

    def _spectral_bind(self, spec_pos: torch.Tensor, spec_energy: torch.Tensor) -> BindEdges:
        """Return sparse binding edges from spectral particles to carriers."""
        eps = self.eps

        spec_pos = spec_pos.to(device=self.device, dtype=torch.float32).flatten()
        spec_energy = spec_energy.to(device=self.device, dtype=torch.float32).flatten()
        n = int(spec_pos.shape[0])
        if spec_pos.numel() == 0 or self.num_carriers == 0:
            mass_in = torch.zeros(self.num_carriers, device=self.device, dtype=torch.float32)
            empty = torch.empty(0, device=self.device, dtype=torch.long)
            return BindEdges(src=empty, dst=empty, weight=torch.empty(0, device=self.device), mass_in=mass_in, entropy=torch.tensor(0.0, device=self.device))

        if self.spec_horizon:
            k = self.horizon_k if self.horizon_k is not None else max(1, int(round(math.sqrt(self.num_carriers))))
            idx = self._neighbor_window_1d(spec_pos, self.spec_pos, k)
        else:
            idx = torch.arange(self.num_carriers, device=self.device, dtype=torch.long).view(1, -1).expand(n, -1)

        cand = self.spec_pos.index_select(0, idx.reshape(-1)).reshape(idx.shape)
        dist = (spec_pos.unsqueeze(1) - cand).abs()
        d_scale = dist.mean() + eps
        sharpness = 1.0 / d_scale
        logits = -dist * sharpness
        w = torch.softmax(logits, dim=1)
        entropy = -(w * torch.log(w + eps)).sum(dim=1).mean()

        src = torch.arange(n, device=self.device, dtype=torch.long).repeat_interleave(idx.shape[1])
        dst = idx.reshape(-1)
        weight = w.reshape(-1)
        mass_in = scatter_sum(weight * spec_energy[src], dst, self.num_carriers)
        return BindEdges(src=src, dst=dst, weight=weight, mass_in=mass_in, entropy=entropy)

    # ----------------------------
    # Learning / adaptation (no backprop)
    # ----------------------------

    def observe(
        self,
        *,
        sem_pos: torch.Tensor,
        sem_energy: Optional[torch.Tensor] = None,
        spec_pos: torch.Tensor,
        spec_energy: Optional[torch.Tensor] = None,
    ) -> BridgeObserveOutput:
        """Provide concurrent semantic + spectral evidence.

        This is the only "training" interface: the bridge updates its carriers
        based on co-activation, using purely local statistics.
        """

        eps = self.eps
        dt = self.dt

        if sem_pos.ndim == 1:
            sem_pos = sem_pos.view(1, -1)
        if sem_energy is None:
            sem_energy = torch.ones(int(sem_pos.shape[0]), device=self.device, dtype=torch.float32)
        else:
            sem_energy = sem_energy.to(device=self.device, dtype=torch.float32).flatten()

        spec_pos = spec_pos.to(device=self.device, dtype=torch.float32).flatten()
        if spec_energy is None:
            spec_energy = torch.ones(int(spec_pos.shape[0]), device=self.device, dtype=torch.float32)
        else:
            spec_energy = spec_energy.to(device=self.device, dtype=torch.float32).flatten()

        # Normalize input energies so update magnitudes are scale-free.
        sem_energy = sem_energy.clamp(min=0.0)
        sem_energy = sem_energy / (sem_energy.sum() + eps)
        spec_energy = spec_energy.clamp(min=0.0)
        spec_energy = spec_energy / (spec_energy.sum() + eps)

        sem_bind = self._semantic_bind(sem_pos, sem_energy)
        spec_bind = self._spectral_bind(spec_pos, spec_energy)
        sem_mass = sem_bind.mass_in
        spec_mass = spec_bind.mass_in

        # Carrier targets in semantic space.
        if sem_bind.src.numel() > 0:
            sem_src = sem_pos[sem_bind.src]
            sem_w = (sem_energy[sem_bind.src] * sem_bind.weight).unsqueeze(1)
            sem_weighted = scatter_sum(sem_src * sem_w, sem_bind.dst, self.num_carriers)
            sem_target = sem_weighted / (sem_mass.unsqueeze(1) + eps)
        else:
            sem_target = self.sem_pos

        # Carrier targets in spectral space.
        if spec_bind.src.numel() > 0:
            spec_src = spec_pos[spec_bind.src]
            spec_w = spec_energy[spec_bind.src] * spec_bind.weight
            spec_weighted = scatter_sum(spec_src * spec_w, spec_bind.dst, self.num_carriers)
            spec_target = spec_weighted / (spec_mass + eps)
        else:
            spec_target = self.spec_pos

        # Co-activation signal (Hebbian, but at carrier level).
        sem_scale = sem_mass.mean() + eps
        spec_scale = spec_mass.mean() + eps
        sem_n = sem_mass / sem_scale
        spec_n = spec_mass / spec_scale
        co = sem_n * spec_n

        # Incoherence generates heat.
        mismatch = (sem_n - spec_n).abs()

        total = sem_energy.sum() + spec_energy.sum() + self.energy.abs().sum()
        ratio = self._ratio(total)

        # Position updates: relax toward current evidence.
        self.sem_pos = self.sem_pos + dt * (sem_target - self.sem_pos)
        self.sem_pos = self.sem_pos / (self.sem_pos.norm(dim=1, keepdim=True) + eps)

        self.spec_pos = self.spec_pos + dt * (spec_target - self.spec_pos)

        # Heat-driven diffusion (noise), without blurring the binding kernel.
        heat_level = self.heat.abs().mean()
        if bool(heat_level > 0):
            h_scale = heat_level / (heat_level + 1.0 + eps)
            self.sem_pos = self.sem_pos + dt * torch.randn_like(self.sem_pos) * h_scale
            self.spec_pos = self.spec_pos + dt * torch.randn_like(self.spec_pos) * h_scale

        # Energy + heat: homeostatic metabolism.
        e_scale = self.energy.abs().mean() + eps
        intake = co
        cost = ratio * self.energy / e_scale
        self.energy = (self.energy + dt * (intake - cost)).clamp(min=0.0)

        h_scale = self.heat.abs().mean() + eps
        self.heat = (self.heat + dt * (mismatch - ratio * self.heat / h_scale)).clamp(min=0.0)

        out = BridgeObserveOutput(
            mismatch=mismatch.detach(),
            mismatch_mean=float(mismatch.mean().item()),
            mismatch_min=float(mismatch.min().item()) if mismatch.numel() > 0 else 0.0,
            mismatch_max=float(mismatch.max().item()) if mismatch.numel() > 0 else 0.0,
            sem_entropy=float(sem_bind.entropy.item()),
            spec_entropy=float(spec_bind.entropy.item()),
            ratio=float(ratio.detach().item()),
            heat_mean=float(self.heat.mean().item()),
            energy_mean=float(self.energy.mean().item()),
        )
        if self._diagnostics is not None:
            self._diagnostics.log(step=self._observe_step, out=out)
        self._observe_step += 1
        return out

    def idle_think(self, steps: int = 1) -> None:
        """Self-observation loop to keep energy circulating without external input."""
        steps = int(steps)
        if steps <= 0 or self.num_carriers == 0:
            return
        eps = self.eps
        for _ in range(steps):
            sem_pos = self.sem_pos.detach()
            spec_pos = self.spec_pos.detach()
            sem_energy = self.energy.clamp(min=0.0)
            spec_energy = self.energy.clamp(min=0.0)
            h = self.heat.abs().mean()
            if bool(h > 0):
                noise_scale = h / (h + 1.0 + eps)
                sem_pos = sem_pos + noise_scale * torch.randn_like(sem_pos)
                spec_pos = spec_pos + noise_scale * torch.randn_like(spec_pos)
            self.observe(
                sem_pos=sem_pos,
                sem_energy=sem_energy,
                spec_pos=spec_pos,
                spec_energy=spec_energy,
            )

    def idle_think_from_semantic(self, sem_vec: torch.Tensor, steps: int = 1) -> None:
        """Idle bridge pondering driven by a semantic state vector (no new external data)."""
        steps = int(steps)
        if steps <= 0:
            return
        eps = self.eps
        sem_vec = sem_vec.to(device=self.device, dtype=torch.float32).view(1, -1)
        sem_energy = torch.ones(1, device=self.device, dtype=torch.float32)
        for _ in range(steps):
            # Use current bridge spectral state as concurrent evidence.
            spec_pos = self.spec_pos.detach()
            spec_energy = self.energy.clamp(min=0.0)
            if spec_energy.numel() > 0:
                spec_energy = spec_energy / (spec_energy.sum() + eps)
            self.observe(sem_pos=sem_vec, sem_energy=sem_energy, spec_pos=spec_pos, spec_energy=spec_energy)

    # ----------------------------
    # Readout
    # ----------------------------

    def forward(self, sem_pos: torch.Tensor, sem_energy: Optional[torch.Tensor] = None) -> BridgeOutput:
        """Project semantic particle(s) into a spectral distribution over spec_bins."""

        eps = self.eps

        if sem_pos.ndim == 1:
            sem_pos = sem_pos.view(1, -1)
        sem_pos = sem_pos.to(device=self.device, dtype=torch.float32)
        if sem_energy is None:
            sem_energy = torch.ones(int(sem_pos.shape[0]), device=self.device, dtype=torch.float32)
        else:
            sem_energy = sem_energy.to(device=self.device, dtype=torch.float32).flatten()
        sem_energy = sem_energy.clamp(min=0.0)
        sem_energy = sem_energy / (sem_energy.sum() + eps)

        # Carrier activations from semantic input.
        sem_bind = self._semantic_bind(sem_pos, sem_energy)
        carrier_act = sem_bind.mass_in * (self.energy / (self.energy.mean() + eps))
        carrier_act = carrier_act.clamp(min=0.0)

        if carrier_act.numel() == 0 or float(carrier_act.sum().item()) <= float(eps):
            logits = torch.zeros(self.num_bins, device=self.device, dtype=torch.float32)
            probs = logits
            meta = {"carriers": int(self.num_carriers), "active": 0}
            return BridgeOutput(spec_logits=logits, spec_probs=probs, meta=meta)

        # Event-horizon projection: each carrier distributes mass to its left/right bin neighbors.
        bins = self.spec_bins
        m = self.num_bins
        a_sorted = bins
        p = self.spec_pos
        ins = torch.searchsorted(a_sorted, p)
        left = (ins - 1).clamp(min=0, max=m - 1)
        right = ins.clamp(min=0, max=m - 1)
        src = torch.arange(self.num_carriers, device=self.device, dtype=torch.long)
        src2 = torch.cat([src, src], dim=0)
        dst2 = torch.cat([left, right], dim=0)

        # Remove duplicate edges where left==right.
        keep = torch.ones(src2.numel(), device=self.device, dtype=torch.bool)
        dup = left == right
        keep[self.num_carriers :][dup] = False
        src_e = src2[keep]
        dst_e = dst2[keep]

        # Distances on the spectral axis.
        d = (p[src_e] - a_sorted[dst_e]).abs()
        d_scale = d.mean() + eps
        sharpness = 1.0 / d_scale
        logits_e = -d * sharpness

        # Softmax within each carrier's outgoing neighborhood.
        w_e = segment_softmax(logits_e, src_e, self.num_carriers, eps=eps)

        # Scatter to bins.
        contrib = carrier_act[src_e] * w_e
        logits = scatter_sum(contrib, dst_e, m)
        probs = logits / (logits.sum() + eps)

        meta = {
            "carriers": int(self.num_carriers),
            "active": int(torch.count_nonzero(carrier_act).item()),
            "energy_mean": float(self.energy.mean().item()),
            "heat_mean": float(self.heat.mean().item()),
        }
        return BridgeOutput(spec_logits=logits, spec_probs=probs, meta=meta)



---
File: /thermo_manifold/core/__init__.py
---

"""Core utilities for thermodynamic manifolds.

This package is intentionally lightweight at import-time.

Some modules (e.g. `state`, `scatter`) depend on PyTorch; importing them eagerly
would make `import thermo_manifold` fail in environments where torch is not
installed (even if the caller only needs config/dataclasses).
"""

from __future__ import annotations

from .config import PhysicsConfig, PhysicsMedium
from .diagnostics import SemanticDiagnosticsLogger

__all__ = [
    "PhysicsConfig",
    "PhysicsMedium",
    "SemanticDiagnosticsLogger",
    # Lazily resolved (torch-backed):
    "BatchState",
    "scatter_sum",
    "scatter_max",
    "segment_softmax",
]


def __getattr__(name: str):  # pragma: no cover
    # Lazy imports to avoid importing torch unless needed.
    if name == "BatchState":
        from .state import BatchState as _BatchState

        return _BatchState
    if name in {"scatter_sum", "scatter_max", "segment_softmax"}:
        from .scatter import scatter_max as _scatter_max
        from .scatter import scatter_sum as _scatter_sum
        from .scatter import segment_softmax as _segment_softmax

        return {
            "scatter_sum": _scatter_sum,
            "scatter_max": _scatter_max,
            "segment_softmax": _segment_softmax,
        }[name]
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")



---
File: /thermo_manifold/core/config.py
---

from __future__ import annotations

from dataclasses import dataclass
from dataclasses import field


@dataclass
class PhysicsMedium:
    """Medium/constant registry for the physics engine.

    This is intentionally simple: it exposes the stabilizing constants that were
    previously implicit inside inner loops (ad-hoc normalization / re-scaling).
    """

    # Controls heat retention/cooling (higher -> slower cooling).
    thermal_resistance: float = 1.0
    # Controls drift damping (higher -> slower motion).
    viscosity: float = 1.0
    # Initial/default scale for energetic quantities before EMAs settle.
    baseline_energy_scale: float = 1.0

    # Time constant for slow-moving, global EMA scales (distance/motion/heat/etc).
    scale_tau: float = 5.0
    # Floor to prevent degenerate (near-zero) scales.
    min_scale: float = 1e-6


@dataclass
class PhysicsConfig:
    """Simulation configuration.

    Notes:
    - `dt` is the integration step (a physical simulation timescale, not a tuned ML hyperparameter).
    - `eps` is numerical safety for division/log.
    """

    dt: float = 1e-2
    eps: float = 1e-8
    # Homeostasis time constant (base value; can be modulated by plasticity).
    tau: float = 1.0

    # Exposed physics medium constants.
    medium: PhysicsMedium = field(default_factory=PhysicsMedium)

    # ----------------------------
    # Plastic homeostasis controls
    # ----------------------------
    # If provided with a gate in [0,1], homeostasis becomes slower during mismatch
    # and applies weaker damping (so energetic spikes persist longer).
    homeostasis_tau_gain: float = 0.0
    homeostasis_strength_gain: float = 0.0

    # ----------------------------
    # Dreaming controls (semantic manifolds)
    # ----------------------------
    # Sampling temperature for exploration (higher -> flatter sampling).
    dream_sampling_temperature: float = 1.0
    # Total dream compute/energy budget per idle_think step.
    dream_energy_budget: float = 32.0
    # How strongly global "stress" (homeostasis ratio above 1) increases budget.
    dream_budget_stress_gain: float = 0.0
    # Stop dreaming early when predictive entropy becomes low (confident/settled).
    dream_entropy_stop: float = 0.0

    # ----------------------------
    # Per-carrier homeostasis (semantic manifolds)
    # ----------------------------
    carrier_tau: float = 5.0



---
File: /thermo_manifold/core/diagnostics.py
---

from __future__ import annotations

import csv
import json
import os
from typing import Any, Optional


class BridgeDiagnosticsLogger:
    """Write BridgeObserveOutput metrics to CSV and/or JSONL."""

    def __init__(self, *, csv_path: Optional[str] = None, jsonl_path: Optional[str] = None):
        self.csv_path = csv_path
        self.jsonl_path = jsonl_path

    def log(self, *, step: int, out: Any) -> None:
        record = {
            "step": int(step),
            "mismatch_mean": float(out.mismatch_mean),
            "mismatch_min": float(out.mismatch_min),
            "mismatch_max": float(out.mismatch_max),
            "sem_entropy": float(out.sem_entropy),
            "spec_entropy": float(out.spec_entropy),
            "ratio": float(out.ratio),
            "heat_mean": float(out.heat_mean),
            "energy_mean": float(out.energy_mean),
        }

        if self.jsonl_path:
            os.makedirs(os.path.dirname(self.jsonl_path), exist_ok=True)
            with open(self.jsonl_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(record) + "\n")

        if self.csv_path:
            os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)
            file_exists = os.path.exists(self.csv_path)
            with open(self.csv_path, "a", encoding="utf-8", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=list(record.keys()))
                if not file_exists:
                    writer.writeheader()
                writer.writerow(record)


class SemanticDiagnosticsLogger:
    """Write semantic pondering metrics/events to CSV and/or JSONL."""

    def __init__(self, *, csv_path: Optional[str] = None, jsonl_path: Optional[str] = None):
        self.csv_path = csv_path
        self.jsonl_path = jsonl_path

    def log(self, record: dict[str, Any]) -> None:
        if self.jsonl_path:
            os.makedirs(os.path.dirname(self.jsonl_path), exist_ok=True)
            with open(self.jsonl_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(record) + "\n")

        if self.csv_path:
            os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)
            file_exists = os.path.exists(self.csv_path)
            with open(self.csv_path, "a", encoding="utf-8", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=list(record.keys()))
                if not file_exists:
                    writer.writeheader()
                writer.writerow(record)



---
File: /thermo_manifold/core/scatter.py
---

from __future__ import annotations

from typing import Tuple

try:
    import torch
except ModuleNotFoundError as e:  # pragma: no cover
    raise ModuleNotFoundError(
        "Missing dependency: PyTorch (`torch`).\n\n"
        "This module provides torch-backed scatter helpers.\n"
        "Install it with one of:\n"
        "- `pip install torch`\n"
        "- `uv pip install torch`\n"
    ) from e

try:  # Optional fast path if torch_scatter is installed.
    import torch_scatter  # type: ignore

    _HAS_TORCH_SCATTER = True
except Exception:
    torch_scatter = None  # type: ignore
    _HAS_TORCH_SCATTER = False


def scatter_sum(values: torch.Tensor, index: torch.Tensor, dim_size: int) -> torch.Tensor:
    """Sum `values` grouped by `index` along dim 0."""
    if values.numel() == 0:
        # Preserve trailing dims.
        return torch.zeros((dim_size,) + tuple(values.shape[1:]), device=values.device, dtype=values.dtype)
    out = torch.zeros((dim_size,) + tuple(values.shape[1:]), device=values.device, dtype=values.dtype)
    out.index_add_(0, index, values)
    return out


def scatter_max(values: torch.Tensor, index: torch.Tensor, dim_size: int) -> torch.Tensor:
    """Max-reduce `values` grouped by `index` along dim 0."""
    if values.numel() == 0:
        return torch.full((dim_size,), float("-inf"), device=values.device, dtype=values.dtype)
    out = torch.full((dim_size,), float("-inf"), device=values.device, dtype=values.dtype)
    if hasattr(out, "scatter_reduce_"):
        out.scatter_reduce_(0, index, values, reduce="amax", include_self=True)
        return out
    # Fallback (slower): sort by index then reduce.
    order = torch.argsort(index)
    idx_sorted = index[order]
    val_sorted = values[order]
    out = out.clone()
    # Iterate runs (CPU-friendly fallback).
    start = 0
    while start < idx_sorted.numel():
        j = int(idx_sorted[start].item())
        end = start + 1
        while end < idx_sorted.numel() and int(idx_sorted[end].item()) == j:
            end += 1
        out[j] = torch.max(val_sorted[start:end])
        start = end
    return out


def segment_softmax(logits: torch.Tensor, segment: torch.Tensor, num_segments: int, eps: float) -> torch.Tensor:
    """Softmax within each segment."""
    if logits.numel() == 0:
        return logits
    if _HAS_TORCH_SCATTER:
        max_per, _ = torch_scatter.scatter_max(logits, segment, dim=0, dim_size=num_segments)
        stabilized = logits - max_per[segment]
        ex = torch.exp(stabilized)
        denom = torch_scatter.scatter_add(ex, segment, dim=0, dim_size=num_segments)
        return ex / (denom[segment] + eps)
    max_per = scatter_max(logits, segment, num_segments)
    stabilized = logits - max_per[segment]
    ex = torch.exp(stabilized)
    denom = scatter_sum(ex, segment, num_segments)
    return ex / (denom[segment] + eps)



---
File: /thermo_manifold/core/state.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Iterable, Mapping, Optional

try:
    import torch
except ModuleNotFoundError as e:  # pragma: no cover
    raise ModuleNotFoundError(
        "Missing dependency: PyTorch (`torch`).\n\n"
        "Install it with one of:\n"
        "- `pip install torch`\n"
        "- `uv pip install torch`\n\n"
        "If you're running from a checkout, also ensure the project deps are installed:\n"
        "- `pip install -e .`\n"
        "- `uv pip install -e .`\n"
    ) from e


@dataclass
class BatchState:
    """A lightweight (TensorDict-free) batched container.

    All tensors are expected to have the same leading dimension `n`.
    """

    data: Dict[str, torch.Tensor]

    @staticmethod
    def empty() -> "BatchState":
        return BatchState({})

    @property
    def n(self) -> int:
        if not self.data:
            return 0
        for v in self.data.values():
            if isinstance(v, torch.Tensor) and v.ndim >= 1:
                return int(v.shape[0])
        return 0

    def keys(self) -> Iterable[str]:
        return self.data.keys()

    def has(self, key: str) -> bool:
        return key in self.data

    def get(self, key: str, default: Optional[torch.Tensor] = None) -> Optional[torch.Tensor]:
        return self.data.get(key, default)

    def set(self, key: str, value: torch.Tensor) -> None:
        self.data[key] = value

    def ensure(self, key: str, shape0: int, *, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        if key not in self.data:
            self.data[key] = torch.zeros(shape0, device=device, dtype=dtype)
        return self.data[key]

    def select(self, idx: torch.Tensor) -> "BatchState":
        if idx.numel() == 0:
            return BatchState.empty()
        out: Dict[str, torch.Tensor] = {}
        for k, v in self.data.items():
            if isinstance(v, torch.Tensor) and v.ndim >= 1 and v.shape[0] == self.n:
                out[k] = v[idx]
            else:
                out[k] = v
        return BatchState(out)

    def writeback(self, idx: torch.Tensor, subset: "BatchState") -> None:
        for k, v in subset.data.items():
            if k in self.data and isinstance(self.data[k], torch.Tensor) and self.data[k].ndim >= 1 and self.data[k].shape[0] == self.n:
                self.data[k][idx] = v



---
File: /thermo_manifold/core/viz.py
---

from __future__ import annotations

import json
from pathlib import Path
from typing import Any


def load_jsonl(path: Path) -> list[dict[str, Any]]:
    if not path.exists():
        return []
    rows: list[dict[str, Any]] = []
    for line in path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line:
            continue
        rows.append(json.loads(line))
    return rows


def plot_pondering_jsonl(jsonl_path: Path, out_png: Path) -> Path:
    """Plot pondering diagnostics time series to a PNG."""
    rows = load_jsonl(jsonl_path)
    if not rows:
        return out_png

    try:
        import matplotlib.pyplot as plt
    except Exception:
        return out_png

    x = [int(r.get("step", i)) for i, r in enumerate(rows)]
    shortcuts = [float(r.get("shortcuts", 0.0)) for r in rows]
    dead_ends = [float(r.get("dead_ends", 0.0)) for r in rows]
    hunger = [float(r.get("hunger_mean", 0.0)) for r in rows]
    heat = [float(r.get("heat_mean", 0.0)) for r in rows]
    exc = [float(r.get("exc_mean", 0.0)) for r in rows]
    active = [float(r.get("active", 0.0)) for r in rows]

    cum_short = []
    s = 0.0
    for v in shortcuts:
        s += v
        cum_short.append(s)

    cum_dead = []
    d = 0.0
    for v in dead_ends:
        d += v
        cum_dead.append(d)

    fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)

    ax[0].plot(x, shortcuts, label="shortcuts per step")
    ax[0].plot(x, dead_ends, label="dead_ends per step")
    ax[0].plot(x, active, label="active sources")
    ax[0].set_ylabel("events / locality")
    ax[0].legend(loc="upper left")

    ax[1].plot(x, hunger, label="hunger_mean")
    ax[1].plot(x, heat, label="heat_mean")
    ax[1].plot(x, exc, label="exc_mean")
    ax[1].plot(x, cum_short, label="cumulative shortcuts")
    ax[1].plot(x, cum_dead, label="cumulative dead_ends")
    ax[1].set_ylabel("state / cumulative")
    ax[1].set_xlabel("time step")
    ax[1].legend(loc="upper left")

    out_png.parent.mkdir(parents=True, exist_ok=True)
    fig.tight_layout()
    fig.savefig(out_png)
    plt.close(fig)
    return out_png




---
File: /thermo_manifold/demos/__init__.py
---

"""Demonstration scripts for thermodynamic manifolds."""



---
File: /thermo_manifold/demos/cross_modal_demo.py
---

"""
Cross-Modal Demo

Demonstrates text and image particles living in the same unified manifold,
with thermodynamic dynamics operating on both simultaneously.

This proves the core claim: native multimodality where modality is emergent
from position in the space, not bolted on as separate modules.
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import List

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality


def create_stripe_image(size: int = 32, orientation: str = "horizontal") -> torch.Tensor:
    """Create a simple stripe pattern."""
    coords = torch.linspace(0, 2 * torch.pi * 4, size)
    rows, cols = torch.meshgrid(coords, coords, indexing='ij')
    # rows varies along vertical axis (row index)
    # cols varies along horizontal axis (column index)
    
    if orientation == "horizontal":
        # Horizontal stripes = bands that run left-right = vary with row (vertical position)
        image = torch.sin(rows * 4)
    elif orientation == "vertical":
        # Vertical stripes = bands that run up-down = vary with column (horizontal position)
        image = torch.sin(cols * 4)
    elif orientation == "diagonal":
        image = torch.sin(rows * 4 + cols * 4)
    else:
        # Checkerboard
        image = torch.sin(rows * 4) * torch.sin(cols * 4)
    
    # Normalize to [0, 1]
    image = (image - image.min()) / (image.max() - image.min() + 1e-8)
    return image


def create_simple_embeddings(vocab: List[str], embed_dim: int, device: torch.device) -> torch.Tensor:
    """Create simple word embeddings.
    
    In a real system, these would come from a pretrained model.
    Here we create structured embeddings where semantically related
    words are closer together.
    """
    embeddings = torch.zeros(len(vocab), embed_dim, device=device, dtype=torch.float32)
    
    # Semantic clusters (hand-designed for demo)
    # Pattern words cluster together
    pattern_words = {"stripes", "lines", "pattern", "bars", "waves"}
    # Direction words cluster together  
    direction_words = {"horizontal", "vertical", "diagonal"}
    # Shape words
    shape_words = {"grid", "checkerboard", "cross"}
    
    for i, word in enumerate(vocab):
        # Base: random direction
        torch.manual_seed(hash(word) % (2**32))
        base = torch.randn(embed_dim, device=device)
        base = base / (base.norm() + 1e-8)
        
        # Add cluster bias
        if word in pattern_words:
            bias = torch.zeros(embed_dim, device=device)
            bias[0:10] = 1.0  # Pattern words have high values in dims 0-10
            base = base + 0.5 * bias
        elif word in direction_words:
            bias = torch.zeros(embed_dim, device=device)
            bias[10:20] = 1.0  # Direction words in dims 10-20
            base = base + 0.5 * bias
        elif word in shape_words:
            bias = torch.zeros(embed_dim, device=device)
            bias[20:30] = 1.0  # Shape words in dims 20-30
            base = base + 0.5 * bias
        
        embeddings[i] = base / (base.norm() + 1e-8)
    
    return embeddings


def run_demo(
    *,
    image_size: int = 32,
    top_k_freq: int = 50,
    steps: int = 20,
    dt: float = 0.02,
    embed_dim: int = 64,
    device: torch.device,
    out_dir: Path,
) -> None:
    """Run the cross-modal demo."""
    out_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("CROSS-MODAL MANIFOLD DEMO")
    print("=" * 60)
    
    # Create manifold
    cfg = PhysicsConfig(dt=dt, eps=1e-8)
    manifold = UnifiedManifold(cfg, device, embed_dim=embed_dim)
    
    # =========================================================================
    # 1. Create vocabulary and embeddings
    # =========================================================================
    print("\n1. Setting up vocabulary and embeddings...")
    vocab = [
        "stripes", "lines", "pattern", "bars", "waves",
        "horizontal", "vertical", "diagonal",
        "grid", "checkerboard", "cross",
        "image", "picture", "visual",
    ]
    word_to_id = {w: i for i, w in enumerate(vocab)}
    embeddings = create_simple_embeddings(vocab, embed_dim, device)
    print(f"   Vocabulary size: {len(vocab)}")
    print(f"   Embedding dim: {embed_dim}")
    
    # =========================================================================
    # 2. Encode text: "horizontal stripes"
    # =========================================================================
    print("\n2. Encoding text: 'horizontal stripes'...")
    text_tokens = ["horizontal", "stripes"]
    text_ids = [word_to_id[w] for w in text_tokens]
    text_embeddings = embeddings[text_ids]
    
    text_indices = manifold.encode_text(text_embeddings, token_ids=text_ids)
    print(f"   Created {len(text_indices)} TEXT particles")
    
    # =========================================================================
    # 3. Encode image: horizontal stripe pattern
    # =========================================================================
    print("\n3. Encoding image: horizontal stripe pattern...")
    image = create_stripe_image(image_size, orientation="horizontal").to(device)
    
    image_indices = manifold.encode_image(image, top_k=top_k_freq)
    print(f"   Created {len(image_indices)} IMAGE particles")
    
    # =========================================================================
    # 4. Show initial state
    # =========================================================================
    state = manifold.output_state()
    print(f"\n4. Manifold state (before dynamics):")
    print(f"   Total particles: {state.meta['num_particles']}")
    print(f"   By modality: {state.meta['modality_counts']}")
    
    # =========================================================================
    # 5. Run thermodynamic dynamics
    # =========================================================================
    print(f"\n5. Running {steps} steps of thermodynamic dynamics...")
    
    energy_history = []
    heat_history = []
    
    for t in range(steps):
        manifold.step()
        
        # Track metrics
        state = manifold.output_state()
        total_energy = sum(p.energy.item() for p in state.particles)
        total_heat = sum(p.heat.item() for p in state.particles)
        energy_history.append(total_energy)
        heat_history.append(total_heat)
        
        if (t + 1) % 5 == 0:
            print(f"   Step {t+1}: energy={total_energy:.4f}, heat={total_heat:.4f}")
    
    # =========================================================================
    # 6. Analyze cross-modal relationships
    # =========================================================================
    print("\n6. Analyzing cross-modal relationships...")
    
    # Get positions in common space for all particles
    text_positions = []
    image_positions = []
    
    for i, p in enumerate(manifold._particles):
        common_pos = manifold._to_common_space(p.position)
        if p.modality == Modality.TEXT:
            text_positions.append((i, common_pos))
        elif p.modality == Modality.IMAGE:
            image_positions.append((i, common_pos))
    
    # Compute distances between text and image particles
    if text_positions and image_positions:
        print(f"\n   Cross-modal distances (text <-> image):")
        for ti, (text_idx, text_pos) in enumerate(text_positions):
            token_id = manifold._particles[text_idx].token_id
            word = vocab[token_id] if token_id is not None else "?"
            
            # Find closest image particles
            distances = []
            for img_idx, img_pos in image_positions:
                dist = torch.linalg.norm(text_pos - img_pos).item()
                distances.append((img_idx, dist))
            
            distances.sort(key=lambda x: x[1])
            closest_dist = distances[0][1]
            mean_dist = sum(d for _, d in distances) / len(distances)
            
            print(f"   '{word}': closest_img_dist={closest_dist:.4f}, mean_img_dist={mean_dist:.4f}")
    
    # =========================================================================
    # 7. Decode back
    # =========================================================================
    print("\n7. Decoding outputs...")
    
    # Decode image
    reconstructed = manifold.decode_image((image_size, image_size))
    mse = ((image - reconstructed) ** 2).mean().item()
    print(f"   Image reconstruction MSE: {mse:.6f}")
    
    # Decode text
    decoded_text = manifold.decode_text(vocab, top_k=5)
    print(f"   Top decoded tokens: {decoded_text}")
    
    # =========================================================================
    # 8. Visualization
    # =========================================================================
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d import Axes3D
        
        print("\n8. Generating visualizations...")
        
        # Figure 1: Image comparison
        fig1, axes = plt.subplots(1, 3, figsize=(12, 4))
        
        axes[0].imshow(image.cpu().numpy(), cmap='viridis')
        axes[0].set_title('Original (horizontal stripes)')
        axes[0].axis('off')
        
        axes[1].imshow(reconstructed.cpu().numpy(), cmap='viridis')
        axes[1].set_title(f'Reconstructed (MSE={mse:.4f})')
        axes[1].axis('off')
        
        diff = (image - reconstructed).abs().cpu().numpy()
        axes[2].imshow(diff, cmap='hot')
        axes[2].set_title('Absolute Difference')
        axes[2].axis('off')
        
        fig1.tight_layout()
        fig1.savefig(out_dir / "cross_modal_images.png", dpi=150)
        plt.close(fig1)
        print(f"   Saved: cross_modal_images.png")
        
        # Figure 2: Particle positions in common space (first 3 dims)
        fig2 = plt.figure(figsize=(10, 8))
        ax = fig2.add_subplot(111, projection='3d')
        
        text_coords = []
        text_labels = []
        image_coords = []
        image_energies = []
        
        for p in manifold._particles:
            common = manifold._to_common_space(p.position).cpu().numpy()
            if p.modality == Modality.TEXT:
                text_coords.append(common[:3])
                token_id = p.token_id
                text_labels.append(vocab[token_id] if token_id is not None else "?")
            elif p.modality == Modality.IMAGE:
                image_coords.append(common[:3])
                image_energies.append(p.energy.item())
        
        if image_coords:
            image_coords = torch.tensor(image_coords)
            ax.scatter(
                image_coords[:, 0], image_coords[:, 1], image_coords[:, 2],
                c=image_energies, cmap='Blues', alpha=0.3, s=20, label='Image frequencies'
            )
        
        if text_coords:
            text_coords = torch.tensor(text_coords)
            ax.scatter(
                text_coords[:, 0], text_coords[:, 1], text_coords[:, 2],
                c='red', s=200, marker='*', label='Text tokens'
            )
            for i, label in enumerate(text_labels):
                ax.text(text_coords[i, 0], text_coords[i, 1], text_coords[i, 2], 
                       f'  {label}', fontsize=12, color='red')
        
        ax.set_xlabel('Dim 0')
        ax.set_ylabel('Dim 1')
        ax.set_zlabel('Dim 2')
        ax.set_title('Particles in Common Embedding Space (first 3 dims)')
        ax.legend()
        
        fig2.savefig(out_dir / "cross_modal_space.png", dpi=150)
        plt.close(fig2)
        print(f"   Saved: cross_modal_space.png")
        
        # Figure 3: Energy dynamics
        fig3, ax = plt.subplots(figsize=(8, 4))
        ax.plot(energy_history, label='Total Energy')
        ax.plot(heat_history, label='Total Heat')
        ax.set_xlabel('Step')
        ax.set_ylabel('Value')
        ax.set_title('Thermodynamic Dynamics')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        fig3.savefig(out_dir / "cross_modal_dynamics.png", dpi=150)
        plt.close(fig3)
        print(f"   Saved: cross_modal_dynamics.png")
        
    except ImportError:
        print("\n   (matplotlib not available, skipping visualization)")
    
    print("\n" + "=" * 60)
    print("DEMO COMPLETE")
    print("=" * 60)
    print("""
KEY INSIGHTS:

1. Text particles ("horizontal", "stripes") and image particles
   (2D frequency components) coexist in the SAME manifold.

2. The thermodynamic dynamics operate on BOTH simultaneously,
   with no special handling for either modality.

3. Modality is just a tag for the decoder—the manifold itself
   is modality-agnostic.

4. Cross-modal relationships can emerge from proximity in the
   shared embedding space (with proper training/alignment).

This is NATIVE multimodality, not adapters bolted together.
""")


def main() -> None:
    parser = argparse.ArgumentParser(description="Cross-Modal Manifold Demo")
    parser.add_argument("--image-size", type=int, default=32)
    parser.add_argument("--top-k-freq", type=int, default=50)
    parser.add_argument("--steps", type=int, default=20)
    parser.add_argument("--dt", type=float, default=0.02)
    parser.add_argument("--embed-dim", type=int, default=64)
    parser.add_argument("--out-dir", type=str, default="./artifacts/cross_modal")
    
    args = parser.parse_args()
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    run_demo(
        image_size=args.image_size,
        top_k_freq=args.top_k_freq,
        steps=args.steps,
        dt=args.dt,
        embed_dim=args.embed_dim,
        device=device,
        out_dir=Path(args.out_dir),
    )


if __name__ == "__main__":
    main()



---
File: /thermo_manifold/demos/rule_shift_demo.py
---

from __future__ import annotations

import argparse
from dataclasses import asdict
from pathlib import Path
from typing import Dict, List, Tuple

import torch

from ..core.config import PhysicsConfig
from ..core.diagnostics import SemanticDiagnosticsLogger
from ..core.viz import plot_pondering_jsonl
from ..semantic.hierarchical import HierarchicalSemanticManifold


def _topological_entropy(src: torch.Tensor, w: torch.Tensor, eps: float) -> float:
    """Mean per-src entropy of outgoing normalized weights."""

    if src.numel() == 0:
        return 0.0

    w = w.clamp(min=0.0)
    if float(w.sum().item()) <= eps:
        return 0.0

    src_u, inv = torch.unique(src, return_inverse=True)
    out_sum = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    out_sum.index_add_(0, inv, w)

    p = w / (out_sum[inv] + eps)
    edge_ent = -p * torch.log(p + eps)

    ent_src = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    ent_src.index_add_(0, inv, edge_ent)

    return float(ent_src.mean().item())


def _make_stream(vocab: List[str]) -> Tuple[Dict[str, int], List[int], List[int]]:
    tid = {t: i for i, t in enumerate(vocab)}

    # "The cat sat on the mat" with repeated 'the' to force >1-step memory.
    fwd = [
        tid["<bos>"],
        tid["the"],
        tid["cat"],
        tid["sat"],
        tid["on"],
        tid["the"],
        tid["mat"],
        tid["<eos>"],
    ]

    rev = [
        tid["<bos>"],
        tid["mat"],
        tid["the"],
        tid["on"],
        tid["sat"],
        tid["cat"],
        tid["the"],
        tid["<eos>"],
    ]

    return tid, fwd, rev


def run_rule_shift(
    *,
    steps: int,
    shift_at: int,
    context_len: int,
    dt: float,
    device: torch.device,
    out_dir: Path,
) -> Path:
    out_dir.mkdir(parents=True, exist_ok=True)

    vocab = ["<bos>", "the", "cat", "sat", "on", "mat", "<eos>"]
    tid, fwd, rev = _make_stream(vocab)

    # Pre-generate the full token stream (deterministic).
    stream: List[int] = []
    pos = 0
    seq = fwd
    for t in range(steps + 1):
        if t == shift_at:
            seq = rev
            pos = 0
        stream.append(seq[pos])
        pos = (pos + 1) % len(seq)

    cfg = PhysicsConfig(dt=dt, eps=1e-8)
    brain = HierarchicalSemanticManifold(
        cfg,
        device,
        vocab=vocab,
        embed_dim=min(16, len(vocab)),
        chunk_min_len=2,
        chunk_max_len=4,
    )

    # Pondering diagnostics (JSONL + optional CSV)
    ponder_jsonl = out_dir / "pondering.jsonl"
    ponder_csv = out_dir / "pondering.csv"
    brain.set_diagnostics(SemanticDiagnosticsLogger(csv_path=str(ponder_csv), jsonl_path=str(ponder_jsonl)))

    history: List[int] = []

    acc = torch.zeros(steps, dtype=torch.float32)
    energy = torch.zeros(steps, dtype=torch.float32)
    topo = torch.zeros(steps, dtype=torch.float32)
    chunks = torch.zeros(steps, dtype=torch.float32)
    ponder_shortcuts = torch.zeros(steps, dtype=torch.float32)
    ponder_dead_ends = torch.zeros(steps, dtype=torch.float32)
    ponder_hunger = torch.zeros(steps, dtype=torch.float32)

    for t in range(steps):
        cur = int(stream[t])
        nxt = int(stream[t + 1])

        history.append(cur)
        if len(history) > context_len:
            history = history[-context_len:]

        ctx = torch.tensor(history, device=device, dtype=torch.long)
        brain.ingest_ids(ctx)

        brain.step_grammar()
        out = brain.output_state()

        pred = int(out.token_index)
        acc[t] = 1.0 if pred == nxt else 0.0

        # Metrics
        # Dynamic system energy (exclude long-term structural mass)
        _exc = brain.attractors.get('excitation').abs().sum()
        _heat = brain.attractors.get('heat').abs().sum()
        _cexc = brain.chunks.excitation.abs().sum()
        _cheat = brain.chunks.heat.abs().sum()
        energy[t] = (_exc + _heat + _cexc + _cheat).detach().to(torch.float32).cpu()
        topo[t] = torch.tensor(
            _topological_entropy(brain.graph.src.detach(), brain.graph.w.detach(), eps=cfg.eps),
            dtype=torch.float32,
        )
        chunks[t] = float(brain.chunks.num_chunks)

        # Online structural update (metabolic shock).
        brain.observe_next_token(nxt, probs=out.probs)

        # Idle pondering: discover relations between what it already knows.
        p = brain.idle_think(steps=1, dream_steps=context_len)
        ponder_shortcuts[t] = float(p.get("shortcuts", 0.0))
        ponder_dead_ends[t] = float(p.get("dead_ends", 0.0))
        ponder_hunger[t] = float(brain.hunger.mean().detach().cpu().item())

    # Rolling accuracy for readability
    win = max(1, int(len(fwd)))
    kern = torch.ones(win, dtype=torch.float32) / float(win)
    acc_smooth = torch.nn.functional.conv1d(
        acc.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2
    ).view(-1)
    acc_smooth = acc_smooth[:steps]

    # Save raw metrics
    data = {
        "cfg": asdict(cfg),
        "steps": steps,
        "shift_at": shift_at,
        "context_len": context_len,
        "vocab": vocab,
        "tid": tid,
        "acc": acc.cpu().tolist(),
        "acc_smooth": acc_smooth.cpu().tolist(),
        "energy": energy.cpu().tolist(),
        "topo_entropy": topo.cpu().tolist(),
        "chunks": chunks.cpu().tolist(),
        "ponder_shortcuts": ponder_shortcuts.cpu().tolist(),
        "ponder_dead_ends": ponder_dead_ends.cpu().tolist(),
        "ponder_hunger_mean": ponder_hunger.cpu().tolist(),
    }
    json_path = out_dir / "rule_shift_metrics.json"
    json_path.write_text(__import__("json").dumps(data, indent=2))

    # Plot rule-shift + pondering
    try:
        import matplotlib.pyplot as plt

        x = list(range(steps))

        fig, (ax1, ax3) = plt.subplots(2, 1, figsize=(12, 7), sharex=True)
        ax2 = ax1.twinx()

        ax1.plot(x, acc_smooth.cpu().numpy(), label="accuracy (rolling)")
        ax1.axvline(shift_at, linestyle="--")
        ax1.set_ylim(0.0, 1.05)
        ax1.set_ylabel("accuracy")

        ax2.plot(x, energy.cpu().numpy(), label="system energy")
        ax2.plot(x, topo.cpu().numpy(), label="topology entropy")
        ax2.plot(x, chunks.cpu().numpy(), label="#chunks")
        ax2.set_ylabel("energy / entropy / count")

        ax1.legend(loc="upper left")
        ax2.legend(loc="upper right")

        ax3.plot(x, ponder_shortcuts.cpu().numpy(), label="shortcuts/step")
        ax3.plot(x, ponder_dead_ends.cpu().numpy(), label="dead_ends/step")
        ax3.plot(x, ponder_hunger.cpu().numpy(), label="hunger_mean")
        ax3.set_xlabel("time step")
        ax3.set_ylabel("pondering")
        ax3.legend(loc="upper left")

        fig.tight_layout()
        fig_path = out_dir / "rule_shift.png"
        fig.savefig(fig_path)
        plt.close(fig)

        # Also generate a dedicated pondering plot from JSONL (easy to read standalone).
        plot_pondering_jsonl(ponder_jsonl, out_dir / "pondering.png")
        return fig_path
    except Exception:
        # matplotlib not available or headless issues: return json path.
        return json_path


def main() -> None:
    p = argparse.ArgumentParser(description="Thermodynamic Manifold Rule-Shift benchmark")
    p.add_argument("--steps", type=int, default=2000)
    p.add_argument("--shift-at", type=int, default=1000)
    p.add_argument("--context-len", type=int, default=6)
    p.add_argument("--dt", type=float, default=0.02)
    p.add_argument("--out-dir", type=str, default="./artifacts")

    args = p.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    out_dir = Path(args.out_dir)

    path = run_rule_shift(
        steps=args.steps,
        shift_at=args.shift_at,
        context_len=args.context_len,
        dt=args.dt,
        device=device,
        out_dir=out_dir,
    )
    print(f"saved: {path}")


if __name__ == "__main__":
    main()



---
File: /thermo_manifold/demos/unified_demo.py
---

from __future__ import annotations

import math
from typing import List, Tuple

import torch

from thermo_manifold import BridgeManifold, PhysicsConfig, SemanticManifold, SpectralManifold


def make_vocab() -> List[str]:
    return ["the", "cat", "sat", "on", "mat", ".", "dog", "ran"]


def token_frequencies(vocab_size: int, *, device: torch.device) -> torch.Tensor:
    """Environment mapping: assign each token a distinct carrier frequency.

    This is not used by the learning rules directly; it only generates sensory co-occurrence
    (text token + audio frequency) to let the bridge bonds emerge.
    """
    # Frequencies span a range implied by the population statistics (no hand-tuned per-token values).
    idx = torch.arange(vocab_size, device=device, dtype=torch.float32)
    frac = idx / (vocab_size - 1 + 1e-8)
    # Use a log-scale spread so low and high are both represented.
    f_min = torch.tensor(110.0, device=device)  # A2 as a conventional audible anchor
    f_max = torch.tensor(1760.0, device=device)  # A6
    freqs = f_min * (f_max / f_min) ** frac
    return freqs


def train_ring_grammar(brain: SemanticManifold, seq: List[int], steps_per_context: int) -> None:
    """Train simple ring transitions by repeatedly stepping on short contexts."""
    device = brain.device
    seq_t = torch.tensor(seq, device=device, dtype=torch.long)

    for i in range(len(seq)):
        ctx = seq_t[i : i + 2]
        if ctx.numel() < 2:
            continue
        brain.ingest_ids(ctx)
        for _ in range(steps_per_context):
            brain.step_grammar()


def main() -> None:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    cfg = PhysicsConfig(dt=1e-2)

    vocab = make_vocab()
    brain = SemanticManifold(cfg, device, vocab=vocab, embed_dim=min(16, len(vocab)))

    # Train a ring: a->b->c->...
    ring = list(range(len(vocab)))
    steps_per_context = int(1.0 / cfg.dt)  # simulate ~1 unit time per observation
    train_ring_grammar(brain, ring + [ring[0]], steps_per_context=steps_per_context)

    # Bridge: semantic vector space -> spectral bins.
    freqs = token_frequencies(len(vocab), device=device)
    bridge = BridgeManifold(sem_dim=brain.embed_dim, spec_bins=freqs, dt=cfg.dt, device=device)

    # Co-activation training (no hard-coded mapping inside the bridge):
    # present each token's semantic embedding concurrently with its sensory frequency.
    emb = brain.attractors.get("position")
    for tid in range(len(vocab)):
        bridge.observe(
            sem_pos=emb[tid],
            spec_pos=freqs[tid : tid + 1],
        )

    # Inference: given a short context, predict next token and synthesize audio.
    context = torch.tensor([0, 1], device=device)  # "the cat"
    brain.ingest_ids(context)
    while not brain.thinking_complete():
        brain.step_grammar()
    out = brain.output_state()
    print("Predicted next token:", out.token, "(index", out.token_index, ")")
    print("Meta:", {k: round(v, 4) for k, v in out.meta.items() if isinstance(v, (int, float))})

    # Bridge the semantic state into spectral energy.
    # Use a continuous "thought" vector: E[pos] under the semantic distribution.
    sem_vec = out.probs @ brain.attractors.get("position")
    b_out = bridge.forward(sem_vec)
    spec_energy = b_out.spec_probs

    voice = SpectralManifold(cfg, device)
    voice.set_targets(freqs, energy=spec_energy)
    voice.seed_particles(n=int(1.0 / cfg.dt))  # particle budget proportional to simulated time

    # Diffuse for ~1 simulated time unit.
    steps = int(1.0 / cfg.dt)
    for _ in range(steps):
        voice.step_physics()

    audio = voice.output_state(topk=5)
    print("Top synthesized frequencies (Hz):", [round(float(f), 2) for f in audio.frequencies.tolist()])
    print("Amplitudes:", [round(float(a), 4) for a in audio.amplitudes.tolist()])
    print("Bridge meta:", b_out.meta)


if __name__ == "__main__":
    main()



---
File: /thermo_manifold/demos/unified_multimodal_demo.py
---

"""
Unified Multimodal Demo

Demonstrates the unified manifold processing particles from multiple modalities:
1. Encode an image to frequency-space particles
2. Run thermodynamic dynamics
3. Decode back to image

This proves that the spectral manifold is truly modality-agnostic.
"""

from __future__ import annotations

import argparse
from pathlib import Path

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality


def create_test_image(size: int = 64) -> torch.Tensor:
    """Create a simple test image with clear frequency structure."""
    x = torch.linspace(0, 2 * torch.pi * 4, size)
    y = torch.linspace(0, 2 * torch.pi * 4, size)
    xx, yy = torch.meshgrid(x, y, indexing='ij')
    
    # Combination of sine waves at different frequencies
    image = (
        torch.sin(xx * 2) * 0.3 +           # Low freq horizontal
        torch.sin(yy * 4) * 0.3 +           # Mid freq vertical  
        torch.sin(xx * 8 + yy * 8) * 0.2 +  # High freq diagonal
        torch.sin(xx * 1 + yy * 1) * 0.2    # Very low freq diagonal
    )
    
    # Normalize to [0, 1]
    image = (image - image.min()) / (image.max() - image.min() + 1e-8)
    
    return image


def run_demo(
    *,
    image_size: int = 64,
    top_k: int = 100,
    steps: int = 10,
    dt: float = 0.02,
    device: torch.device,
    out_dir: Path,
) -> None:
    """Run the unified multimodal demo."""
    out_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("UNIFIED MULTIMODAL MANIFOLD DEMO")
    print("=" * 60)
    
    # Create manifold
    cfg = PhysicsConfig(dt=dt, eps=1e-8)
    manifold = UnifiedManifold(cfg, device, embed_dim=256)
    
    # Create test image
    print(f"\n1. Creating test image ({image_size}x{image_size})...")
    original = create_test_image(image_size).to(device)
    
    # Encode image to particles
    print(f"2. Encoding image to {top_k} frequency particles...")
    particle_indices = manifold.encode_image(original, top_k=top_k)
    print(f"   Created {len(particle_indices)} IMAGE particles")
    
    # Show modality distribution
    state = manifold.output_state()
    print(f"   Modality counts: {state.meta['modality_counts']}")
    
    # Run thermodynamic dynamics
    print(f"\n3. Running {steps} steps of thermodynamic dynamics...")
    for t in range(steps):
        manifold.step()
        if (t + 1) % 5 == 0:
            state = manifold.output_state()
            total_energy = sum(p.energy.item() for p in state.particles)
            total_heat = sum(p.heat.item() for p in state.particles)
            print(f"   Step {t+1}: energy={total_energy:.4f}, heat={total_heat:.4f}")
    
    # Decode back to image
    print(f"\n4. Decoding particles back to image...")
    reconstructed = manifold.decode_image((image_size, image_size))
    
    # Compute reconstruction error
    mse = ((original - reconstructed) ** 2).mean().item()
    print(f"   Reconstruction MSE: {mse:.6f}")
    
    # Save results
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(1, 3, figsize=(12, 4))
        
        axes[0].imshow(original.cpu().numpy(), cmap='viridis')
        axes[0].set_title('Original')
        axes[0].axis('off')
        
        axes[1].imshow(reconstructed.cpu().numpy(), cmap='viridis')
        axes[1].set_title(f'Reconstructed (MSE={mse:.4f})')
        axes[1].axis('off')
        
        diff = (original - reconstructed).abs().cpu().numpy()
        axes[2].imshow(diff, cmap='hot')
        axes[2].set_title('Absolute Difference')
        axes[2].axis('off')
        
        fig.tight_layout()
        fig_path = out_dir / "unified_multimodal.png"
        fig.savefig(fig_path, dpi=150)
        plt.close(fig)
        print(f"\n5. Saved visualization to: {fig_path}")
        
        # Also save particle distribution
        fig2, ax = plt.subplots(figsize=(8, 8))
        
        # Extract 2D positions of image particles
        u_coords = []
        v_coords = []
        energies = []
        for p in manifold._particles:
            if p.modality == Modality.IMAGE and p.position.numel() == 2:
                u_coords.append(p.position[0].item())
                v_coords.append(p.position[1].item())
                energies.append(p.energy.item())
        
        scatter = ax.scatter(
            v_coords, u_coords, 
            c=energies, 
            s=[e * 1000 for e in energies],
            cmap='plasma',
            alpha=0.6,
        )
        ax.set_xlabel('v (horizontal frequency)')
        ax.set_ylabel('u (vertical frequency)')
        ax.set_title('Particle Distribution in 2D Frequency Space')
        ax.set_aspect('equal')
        plt.colorbar(scatter, label='Energy')
        
        fig2_path = out_dir / "frequency_particles.png"
        fig2.savefig(fig2_path, dpi=150)
        plt.close(fig2)
        print(f"   Saved particle distribution to: {fig2_path}")
        
    except ImportError:
        print("\n   (matplotlib not available, skipping visualization)")
    
    print("\n" + "=" * 60)
    print("DEMO COMPLETE")
    print("=" * 60)
    print(f"\nKey insight: The manifold processed IMAGE particles using")
    print(f"the same thermodynamic dynamics that work for TEXT and AUDIO.")
    print(f"Modality is not special—it's just a tag for the decoder.")


def main() -> None:
    parser = argparse.ArgumentParser(description="Unified Multimodal Manifold Demo")
    parser.add_argument("--image-size", type=int, default=64)
    parser.add_argument("--top-k", type=int, default=100)
    parser.add_argument("--steps", type=int, default=10)
    parser.add_argument("--dt", type=float, default=0.02)
    parser.add_argument("--out-dir", type=str, default="./artifacts/unified")
    
    args = parser.parse_args()
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    run_demo(
        image_size=args.image_size,
        top_k=args.top_k,
        steps=args.steps,
        dt=args.dt,
        device=device,
        out_dir=Path(args.out_dir),
    )


if __name__ == "__main__":
    main()



---
File: /thermo_manifold/experiments/__init__.py
---

"""Experiment suite for Thermodynamic Manifolds.

All experiments use HuggingFace datasets for real-world benchmarks.
Each experiment runs at three scales: toy, medium, full.
"""

from .base import BaseExperiment, Scale, ScaleConfig, ExperimentResult, SCALE_CONFIGS
from .timeseries import TimeSeriesExperiment, run_timeseries_experiment
from .next_token import NextTokenExperiment, run_next_token_experiment
from .image_gen import ImageGenerationExperiment, run_image_gen_experiment
from .audio_gen import AudioGenerationExperiment, run_audio_gen_experiment
from .text_diffusion import TextDiffusionExperiment, run_text_diffusion_experiment

__all__ = [
    # Base
    "BaseExperiment",
    "Scale",
    "ScaleConfig", 
    "ExperimentResult",
    "SCALE_CONFIGS",
    # Experiments
    "TimeSeriesExperiment",
    "NextTokenExperiment",
    "ImageGenerationExperiment",
    "AudioGenerationExperiment",
    "TextDiffusionExperiment",
    # Runners
    "run_timeseries_experiment",
    "run_next_token_experiment",
    "run_image_gen_experiment",
    "run_audio_gen_experiment",
    "run_text_diffusion_experiment",
]



---
File: /thermo_manifold/experiments/ablations.py
---

"""
Ablation Study

Tests the contribution of individual components by disabling them.
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List, Optional

import torch

from ..core.config import PhysicsConfig
from ..semantic.hierarchical import HierarchicalSemanticManifold
from ..semantic.manifold import SemanticManifold


def run_single_condition(
    *,
    condition_name: str,
    steps: int,
    shift_at: int,
    context_len: int,
    dt: float,
    device: torch.device,
    use_hierarchy: bool = True,
    use_pondering: bool = True,
    use_homeostasis: bool = True,
) -> Dict[str, Any]:
    """Run a single ablation condition."""
    
    vocab = ["<bos>", "the", "cat", "sat", "on", "mat", "<eos>"]
    tid = {t: i for i, t in enumerate(vocab)}
    
    fwd = [tid["<bos>"], tid["the"], tid["cat"], tid["sat"], tid["on"], tid["the"], tid["mat"], tid["<eos>"]]
    rev = [tid["<bos>"], tid["mat"], tid["the"], tid["on"], tid["sat"], tid["cat"], tid["the"], tid["<eos>"]]
    
    # Pre-generate stream
    stream: List[int] = []
    pos = 0
    seq = fwd
    for t in range(steps + 1):
        if t == shift_at:
            seq = rev
            pos = 0
        stream.append(seq[pos])
        pos = (pos + 1) % len(seq)
    
    # Configure based on ablation
    cfg = PhysicsConfig(
        dt=dt,
        eps=1e-8,
        tau=1.0 if use_homeostasis else 1000.0,  # Very slow homeostasis = effectively off
    )
    
    if use_hierarchy:
        brain = HierarchicalSemanticManifold(
            cfg, device,
            vocab=vocab,
            embed_dim=min(16, len(vocab)),
            chunk_min_len=2,
            chunk_max_len=4,
        )
    else:
        brain = SemanticManifold(
            config=cfg,
            device=device,
            vocab=vocab,
            embed_dim=min(16, len(vocab)),
        )
    
    history: List[int] = []
    acc = torch.zeros(steps, dtype=torch.float32)
    
    for t in range(steps):
        cur = int(stream[t])
        nxt = int(stream[t + 1])
        
        history.append(cur)
        if len(history) > context_len:
            history = history[-context_len:]
        
        ctx = torch.tensor(history, device=device, dtype=torch.long)
        brain.ingest_ids(ctx)
        brain.step_grammar()
        out = brain.output_state()
        
        pred = int(out.token_index)
        acc[t] = 1.0 if pred == nxt else 0.0
        
        brain.observe_next_token(nxt, probs=out.probs)
        
        if use_pondering:
            brain.idle_think(steps=1, dream_steps=context_len)
    
    # Rolling accuracy
    win = max(1, len(fwd))
    kern = torch.ones(win, dtype=torch.float32) / float(win)
    acc_smooth = torch.nn.functional.conv1d(
        acc.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2
    ).view(-1)[:steps]
    
    pre_shift_acc = float(acc_smooth[shift_at - 100:shift_at].mean().item())
    post_shift_acc_recovered = float(acc_smooth[-100:].mean().item())
    
    # Find recovery
    threshold = pre_shift_acc * 0.8
    recovery_step = None
    for t in range(shift_at, min(shift_at + 500, steps)):
        if float(acc_smooth[t].item()) >= threshold:
            recovery_step = t - shift_at
            break
    
    return {
        "condition": condition_name,
        "pre_shift_accuracy": pre_shift_acc,
        "post_shift_accuracy": post_shift_acc_recovered,
        "recovery_steps": recovery_step,
    }


def generate_ablation_table(results: List[Dict[str, Any]]) -> str:
    """Generate LaTeX table for ablation results."""
    rows = []
    for r in results:
        recovery = str(r['recovery_steps']) if r['recovery_steps'] else "$>$500"
        rows.append(
            f"    {r['condition']} & {r['pre_shift_accuracy']:.1%} & {r['post_shift_accuracy']:.1%} & {recovery} \\\\"
        )
    
    return r"""\begin{table}[t]
\centering
\caption{Ablation study. Each row disables one component from the full system.}
\label{tab:ablation}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Pre-shift Acc.} & \textbf{Post-shift Acc.} & \textbf{Recovery Steps} \\
\midrule
""" + "\n".join(rows) + r"""
\bottomrule
\end{tabular}
\end{table}
"""


def run_ablation_study(
    device: torch.device,
    tables_dir: Path,
    figures_dir: Path,
    steps: int = 2000,
    shift_at: int = 1000,
    context_len: int = 6,
    dt: float = 0.02,
):
    """Run all ablation conditions and generate table."""
    from .harness import ExperimentResult
    
    conditions = [
        ("Full system", True, True, True),
        ("No hierarchy", False, True, True),
        ("No pondering", True, False, True),
        ("No homeostasis", True, True, False),
    ]
    
    results = []
    for name, hier, pond, homeo in conditions:
        print(f"  Running: {name}...")
        result = run_single_condition(
            condition_name=name,
            steps=steps,
            shift_at=shift_at,
            context_len=context_len,
            dt=dt,
            device=device,
            use_hierarchy=hier,
            use_pondering=pond,
            use_homeostasis=homeo,
        )
        results.append(result)
        print(f"    Pre: {result['pre_shift_accuracy']:.1%}, "
              f"Post: {result['post_shift_accuracy']:.1%}, "
              f"Recovery: {result['recovery_steps']}")
    
    # Generate table
    table_content = generate_ablation_table(results)
    table_path = tables_dir / "ablation.tex"
    table_path.write_text(table_content)
    print(f"  [TABLE] ablation.tex")
    
    # Combine metrics
    metrics = {
        "conditions": results,
        "full_pre": results[0]["pre_shift_accuracy"],
        "full_post": results[0]["post_shift_accuracy"],
        "full_recovery": results[0]["recovery_steps"],
    }
    
    return ExperimentResult(
        name="Ablation Study",
        metrics=metrics,
        tables={"ablation": table_content},
        figures={},
    )



---
File: /thermo_manifold/experiments/audio_gen.py
---

"""Audio/Music Generation Experiment

Uses NSynth or similar audio datasets from HuggingFace.
Tests spectral manifold's audio synthesis capabilities.

Goal: Generate audio via thermodynamic diffusion in frequency space.
Metrics: Reconstruction MSE, Spectral distance
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale


class AudioGenerationExperiment(BaseExperiment):
    """Audio generation using thermodynamic dynamics in frequency space.
    
    The approach:
    1. Encode audio samples to frequency-space particles via FFT
    2. Build attractors from frequency distributions
    3. For generation: seed with noise, let particles diffuse
    4. Decode via inverse FFT
    """
    
    name = "audio_gen"
    goal = "Generate audio via thermodynamic diffusion in frequency space"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.sample_rate = 16000
            self.audio_length = 8000  # 0.5 seconds
            self.top_k_freq = 50
            self.max_samples = 100
        elif scale == Scale.MEDIUM:
            self.sample_rate = 16000
            self.audio_length = 16000  # 1 second
            self.top_k_freq = 200
            self.max_samples = 1000
        else:
            self.sample_rate = 22050
            self.audio_length = 44100  # 2 seconds
            self.top_k_freq = 500
            self.max_samples = 10000
        
        # Frequency statistics (learned from training data)
        self._freq_attractors: Dict[int, List[Tuple[float, float]]] = {}
    
    def setup(self) -> None:
        """Load audio dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading audio dataset (speech_commands)...")
        
        # Use Google Speech Commands as a simple audio dataset
        # It's smaller and easier to work with than NSynth
        try:
            dataset = load_dataset(
                "google/speech_commands",
                "v0.02",
                streaming=True,
            )
            self.audio_key = "audio"
            self.has_real_data = True
        except Exception as e:
            print(f"    Could not load speech_commands: {e}")
            print(f"    Falling back to synthetic audio")
            self.has_real_data = False
            dataset = None
        
        if self.has_real_data and dataset is not None:
            self.train_stream = dataset["train"]
            self.eval_stream = dataset["validation"]
            
            # Prefetch audio samples
            self._train_audio: List[torch.Tensor] = []
            self._eval_audio: List[torch.Tensor] = []
            
            self._load_audio(
                self.train_stream,
                self._train_audio,
                min(self.scale_config.max_train_samples or 1000, self.max_samples),
            )
            self._load_audio(
                self.eval_stream,
                self._eval_audio,
                min(self.scale_config.max_eval_samples or 200, self.max_samples // 5),
            )
        else:
            # Generate synthetic audio for testing
            self._train_audio = [self._generate_synthetic() for _ in range(100)]
            self._eval_audio = [self._generate_synthetic() for _ in range(20)]
        
        print(f"    Train samples: {len(self._train_audio)}")
        print(f"    Eval samples: {len(self._eval_audio)}")
        print(f"    Sample rate: {self.sample_rate}")
        print(f"    Audio length: {self.audio_length} samples ({self.audio_length/self.sample_rate:.2f}s)")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _generate_synthetic(self) -> torch.Tensor:
        """Generate synthetic audio for testing when real data unavailable."""
        t = torch.linspace(0, self.audio_length / self.sample_rate, self.audio_length)
        
        # Random combination of sine waves
        freq1 = 220 + torch.randint(0, 440, (1,)).item()  # A3-A4 range
        freq2 = freq1 * 2  # Octave
        freq3 = freq1 * 1.5  # Fifth
        
        audio = (
            0.5 * torch.sin(2 * torch.pi * freq1 * t) +
            0.3 * torch.sin(2 * torch.pi * freq2 * t) +
            0.2 * torch.sin(2 * torch.pi * freq3 * t)
        )
        
        # Add envelope
        envelope = torch.exp(-3 * t / (self.audio_length / self.sample_rate))
        audio = audio * envelope
        
        return audio
    
    def _load_audio(
        self,
        stream,
        output: List[torch.Tensor],
        max_samples: int,
    ) -> None:
        """Load audio from stream."""
        for sample in stream:
            audio_data = sample[self.audio_key]
            
            # Extract array from audio dict
            if isinstance(audio_data, dict):
                arr = audio_data.get("array", [])
                sr = audio_data.get("sampling_rate", self.sample_rate)
            else:
                arr = audio_data
                sr = self.sample_rate
            
            # Convert to tensor
            audio = torch.tensor(arr, dtype=torch.float32)
            
            # Resample if needed
            if sr != self.sample_rate:
                # Simple resampling (not ideal but works for demo)
                ratio = self.sample_rate / sr
                new_len = int(len(audio) * ratio)
                audio = torch.nn.functional.interpolate(
                    audio.unsqueeze(0).unsqueeze(0),
                    size=new_len,
                    mode='linear',
                    align_corners=False,
                ).squeeze()
            
            # Pad or truncate to fixed length
            if len(audio) < self.audio_length:
                audio = torch.nn.functional.pad(audio, (0, self.audio_length - len(audio)))
            else:
                audio = audio[:self.audio_length]
            
            # Normalize
            max_val = audio.abs().max()
            if max_val > 0:
                audio = audio / max_val
            
            output.append(audio)
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[torch.Tensor]:
        """Iterate over training audio."""
        for audio in self._train_audio:
            yield audio
    
    def train_step(self, batch: torch.Tensor) -> Dict[str, float]:
        """One step of thermodynamic audio learning."""
        audio = batch.to(self.device)
        
        # Clear and encode audio
        self.manifold.clear()
        self.manifold.encode_audio(audio, sample_rate=self.sample_rate, top_k=self.top_k_freq)
        
        # Run dynamics
        for _ in range(5):
            self.manifold.step()
        
        # Store frequency attractors
        for p in self.manifold._particles:
            if p.modality == Modality.AUDIO and p.position.numel() == 1:
                freq_bin = int(p.position[0].item())
                
                if freq_bin not in self._freq_attractors:
                    self._freq_attractors[freq_bin] = []
                
                phase = p.phase[0].item() if p.phase is not None else 0.0
                self._freq_attractors[freq_bin].append((p.energy.item(), phase))
        
        # Decode and compute reconstruction error
        reconstructed = self.manifold.decode_audio(self.audio_length, self.sample_rate)
        mse = ((audio - reconstructed) ** 2).mean().item()
        
        return {"mse": mse}
    
    def _generate_audio(self) -> torch.Tensor:
        """Generate new audio using learned attractors."""
        self.manifold.clear()
        
        if not self._freq_attractors:
            return torch.randn(self.audio_length, device=self.device)
        
        # Create particles from attractor statistics
        for freq_bin, stats in self._freq_attractors.items():
            if not stats:
                continue
            
            mean_energy = sum(e for e, _ in stats) / len(stats)
            mean_phase = sum(p for _, p in stats) / len(stats)
            
            noise = torch.randn(1, device=self.device).item() * 0.1
            
            position = torch.tensor([float(freq_bin)], device=self.device)
            phase = torch.tensor([mean_phase + noise], device=self.device)
            
            self.manifold.add_particle(
                position=position,
                energy=max(0.001, mean_energy + noise * 0.1),
                modality=Modality.AUDIO,
                phase=phase,
            )
        
        # Run dynamics
        for _ in range(10):
            self.manifold.step()
        
        return self.manifold.decode_audio(self.audio_length, self.sample_rate)
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate reconstruction and generation quality."""
        mse_total = 0.0
        spectral_dist_total = 0.0
        count = 0
        
        for audio in self._eval_audio[:20]:
            audio = audio.to(self.device)
            
            self.manifold.clear()
            self.manifold.encode_audio(audio, sample_rate=self.sample_rate, top_k=self.top_k_freq)
            
            for _ in range(5):
                self.manifold.step()
            
            reconstructed = self.manifold.decode_audio(self.audio_length, self.sample_rate)
            
            # Time-domain MSE
            mse_total += ((audio - reconstructed) ** 2).mean().item()
            
            # Spectral distance
            orig_spec = torch.fft.rfft(audio).abs()
            recon_spec = torch.fft.rfft(reconstructed).abs()
            spectral_dist_total += ((orig_spec - recon_spec) ** 2).mean().item()
            
            count += 1
        
        recon_mse = mse_total / max(count, 1)
        spectral_dist = spectral_dist_total / max(count, 1)
        
        # Generate some samples
        gen_audio = [self._generate_audio() for _ in range(5)]
        
        # Basic generation metrics
        gen_energy = torch.stack(gen_audio).abs().mean().item()
        
        return {
            "reconstruction_mse": recon_mse,
            "spectral_distance": spectral_dist,
            "gen_energy": gen_energy,
            "num_freq_attractors": len(self._freq_attractors),
            "eval_samples": count,
        }
    
    def save_samples(self, out_dir: str, num_samples: int = 4) -> None:
        """Save generated audio samples."""
        try:
            import scipy.io.wavfile as wav
            from pathlib import Path
            import numpy as np
            
            out_path = Path(out_dir)
            out_path.mkdir(parents=True, exist_ok=True)
            
            for i in range(num_samples):
                audio = self._generate_audio().cpu().numpy()
                audio = np.clip(audio, -1, 1)
                audio = (audio * 32767).astype(np.int16)
                
                wav.write(
                    str(out_path / f"generated_{i}.wav"),
                    self.sample_rate,
                    audio,
                )
            
            print(f"    Saved {num_samples} audio samples to {out_path}")
            
        except ImportError:
            print("    (scipy not available, skipping audio saving)")


def run_audio_gen_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = AudioGenerationExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Save samples
    exp.save_samples("./artifacts/audio_gen")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /thermo_manifold/experiments/base.py
---

"""Base experiment class for all experiments.

This provides the common infrastructure for:
- Scale management (toy, medium, full)
- HuggingFace dataset streaming
- Training loops (thermodynamic style)
- Metric collection
- Result formatting
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig


class Scale(Enum):
    """Experiment scale levels."""
    TOY = "toy"
    MEDIUM = "medium"
    FULL = "full"


@dataclass
class ScaleConfig:
    """Configuration for a specific scale."""
    name: str
    # Data limits
    max_train_samples: Optional[int]
    max_eval_samples: Optional[int]
    # Model size (if applicable)
    embed_dim: int
    # Training
    train_steps: int
    eval_every: int
    # Physics
    dt: float = 0.02
    
    
# Default scale configurations
SCALE_CONFIGS = {
    Scale.TOY: ScaleConfig(
        name="toy",
        max_train_samples=1000,
        max_eval_samples=100,
        embed_dim=64,
        train_steps=500,
        eval_every=100,
    ),
    Scale.MEDIUM: ScaleConfig(
        name="medium",
        max_train_samples=10000,
        max_eval_samples=1000,
        embed_dim=256,
        train_steps=5000,
        eval_every=500,
    ),
    Scale.FULL: ScaleConfig(
        name="full",
        max_train_samples=None,  # Use full dataset
        max_eval_samples=5000,
        embed_dim=512,
        train_steps=50000,
        eval_every=1000,
    ),
}


@dataclass
class TrainingState:
    """Tracks training progress."""
    step: int = 0
    epoch: int = 0
    samples_seen: int = 0
    metrics_history: Dict[str, List[float]] = field(default_factory=dict)
    
    def record(self, name: str, value: float) -> None:
        if name not in self.metrics_history:
            self.metrics_history[name] = []
        self.metrics_history[name].append(value)
    
    def get_latest(self, name: str, default: float = 0.0) -> float:
        if name in self.metrics_history and self.metrics_history[name]:
            return self.metrics_history[name][-1]
        return default
    
    def get_mean(self, name: str, window: int = 100) -> float:
        if name not in self.metrics_history:
            return 0.0
        values = self.metrics_history[name][-window:]
        return sum(values) / len(values) if values else 0.0


@dataclass 
class ExperimentResult:
    """Container for experiment outputs."""
    name: str
    scale: str
    goal: str
    success: bool
    metrics: Dict[str, Any]
    failure_reason: Optional[str] = None
    tables: Dict[str, str] = field(default_factory=dict)
    figures: Dict[str, Path] = field(default_factory=dict)
    
    def summary(self) -> str:
        status = "SUCCESS" if self.success else f"FAILED: {self.failure_reason}"
        lines = [
            f"Experiment: {self.name} ({self.scale})",
            f"Goal: {self.goal}",
            f"Status: {status}",
            "Metrics:",
        ]
        for k, v in self.metrics.items():
            if not isinstance(v, (list, dict)):
                lines.append(f"  {k}: {v}")
        return "\n".join(lines)


class BaseExperiment(ABC):
    """Base class for all experiments.
    
    Subclasses should implement:
    - setup(): Initialize model, load data
    - train_step(): One step of thermodynamic training
    - evaluate(): Compute metrics on eval set
    - cleanup(): Optional cleanup
    """
    
    name: str = "base"
    goal: str = "Base experiment"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        self.scale = scale
        self.scale_config = SCALE_CONFIGS[scale]
        self.device = device or self._get_device()
        self.seed = seed
        
        # Set seeds
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        
        # Training state
        self.state = TrainingState()
        
        # Physics config
        self.physics_config = PhysicsConfig(
            dt=self.scale_config.dt,
            eps=1e-8,
        )
        
        # Will be set by subclasses
        self.model = None
        self.train_data = None
        self.eval_data = None
    
    def _get_device(self) -> torch.device:
        if torch.cuda.is_available():
            return torch.device("cuda")
        # Prefer MPS on Apple Silicon when torch_scatter isn't installed.
        if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            try:
                import torch_scatter  # type: ignore  # noqa: F401

                has_torch_scatter = True
            except Exception:
                has_torch_scatter = False
            if not has_torch_scatter:
                return torch.device("mps")
        return torch.device("cpu")
    
    @abstractmethod
    def setup(self) -> None:
        """Initialize model and load data."""
        pass
    
    @abstractmethod
    def train_step(self, batch: Any) -> Dict[str, float]:
        """Execute one training step.
        
        In thermodynamic training, this typically means:
        1. Ingest context
        2. Run grammar step / physics
        3. Observe next token / target
        4. Optionally run idle pondering
        
        Returns dict of metrics for this step.
        """
        pass
    
    @abstractmethod
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on the eval set.
        
        Returns dict of evaluation metrics.
        """
        pass
    
    def cleanup(self) -> None:
        """Optional cleanup after experiment."""
        pass
    
    def train_iterator(self) -> Iterator[Any]:
        """Iterate over training data.
        
        Override if you need custom batching.
        """
        if self.train_data is None:
            return iter([])
        return iter(self.train_data)
    
    def _format_metrics(self, metrics: Dict[str, float], max_items: int = 4) -> str:
        """Format metrics for display."""
        items = []
        for k, v in list(metrics.items())[:max_items]:
            if isinstance(v, float):
                if abs(v) < 0.01 or abs(v) > 1000:
                    items.append(f"{k}={v:.2e}")
                else:
                    items.append(f"{k}={v:.4f}")
            else:
                items.append(f"{k}={v}")
        return ", ".join(items)
    
    def run(self) -> ExperimentResult:
        """Run the full experiment."""
        try:
            from tqdm import tqdm
        except ImportError:
            tqdm = None
        
        print(f"\n{'='*60}")
        print(f"EXPERIMENT: {self.name} ({self.scale.value})")
        print(f"Goal: {self.goal}")
        print(f"Device: {self.device}")
        print(f"{'='*60}")
        
        try:
            # Setup
            print("\n[1] Setup...")
            self.setup()
            print(f"    Model initialized")
            print(f"    Train samples: {self.scale_config.max_train_samples or 'all'}")
            print(f"    Eval samples: {self.scale_config.max_eval_samples or 'all'}")
            
            # Training loop
            print(f"\n[2] Training ({self.scale_config.train_steps} steps)...")
            
            data_iter = self.train_iterator()
            
            # Create progress bar
            if tqdm is not None:
                pbar = tqdm(
                    range(self.scale_config.train_steps),
                    desc="Training",
                    unit="step",
                    ncols=100,
                    leave=True,
                )
            else:
                pbar = range(self.scale_config.train_steps)
            
            last_metrics: Dict[str, float] = {}
            
            for step in pbar:
                self.state.step = step
                
                # Get next batch (cycle if needed)
                try:
                    batch = next(data_iter)
                except StopIteration:
                    self.state.epoch += 1
                    data_iter = self.train_iterator()
                    try:
                        batch = next(data_iter)
                    except StopIteration:
                        print("    Warning: No training data available")
                        break
                
                # Train step
                step_metrics = self.train_step(batch)
                for k, v in step_metrics.items():
                    self.state.record(k, v)
                
                self.state.samples_seen += 1
                
                # Update progress bar with metrics
                if tqdm is not None:
                    # Show rolling averages
                    display_metrics = {
                        k: self.state.get_mean(k, window=50)
                        for k in list(step_metrics.keys())[:3]
                    }
                    display_metrics["epoch"] = self.state.epoch
                    pbar.set_postfix(display_metrics)
                
                # Periodic evaluation
                if (step + 1) % self.scale_config.eval_every == 0:
                    eval_metrics = self.evaluate()
                    last_metrics = eval_metrics
                    
                    if tqdm is None:
                        # Fallback text output
                        train_summary = self._format_metrics(
                            {k: self.state.get_mean(k) for k in step_metrics.keys()}
                        )
                        eval_summary = self._format_metrics(eval_metrics)
                        print(f"    Step {step+1}: train=[{train_summary}]")
                        print(f"              eval=[{eval_summary}]")
                    else:
                        # Brief eval summary in tqdm
                        tqdm.write(f"  [Eval @ {step+1}] {self._format_metrics(eval_metrics)}")
            
            if tqdm is not None and hasattr(pbar, 'close'):
                pbar.close()
            
            # Final evaluation
            print(f"\n[3] Final evaluation...")
            final_metrics = self.evaluate()
            
            print(f"\n    {'─'*40}")
            for k, v in final_metrics.items():
                if isinstance(v, float):
                    if abs(v) < 0.01 or abs(v) > 1000:
                        print(f"    {k:.<30} {v:.4e}")
                    else:
                        print(f"    {k:.<30} {v:.4f}")
                else:
                    print(f"    {k:.<30} {v}")
            print(f"    {'─'*40}")
            
            # Cleanup
            self.cleanup()
            
            # Success
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=True,
                metrics={
                    "final": final_metrics,
                    "training_history": self.state.metrics_history,
                    "steps": self.state.step,
                    "epochs": self.state.epoch,
                    "samples_seen": self.state.samples_seen,
                },
            )
            
        except Exception as e:
            import traceback
            tb = traceback.format_exc()
            print(f"\n[FAILED] {e}")
            print(tb)
            
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=False,
                metrics={"training_history": self.state.metrics_history},
                failure_reason=str(e),
            )



---
File: /thermo_manifold/experiments/harness.py
---

"""
Experiment Harness

Runs all experiments at specified scales and generates paper artifacts.

Usage:
    # Run all experiments at toy scale
    python -m thermo_manifold.experiments.harness --scale toy
    
    # Run specific experiment
    python -m thermo_manifold.experiments.harness --experiment next_token --scale medium
    
    # Run all at all scales (warning: slow!)
    python -m thermo_manifold.experiments.harness --scale all
"""

from __future__ import annotations

import argparse
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import torch

from .base import Scale, ExperimentResult
from .timeseries import TimeSeriesExperiment
from .next_token import NextTokenExperiment
from .image_gen import ImageGenerationExperiment
from .audio_gen import AudioGenerationExperiment
from .text_diffusion import TextDiffusionExperiment


# Experiment registry
EXPERIMENTS = {
    "timeseries": TimeSeriesExperiment,
    "next_token": NextTokenExperiment,
    "image_gen": ImageGenerationExperiment,
    "audio_gen": AudioGenerationExperiment,
    "text_diffusion": TextDiffusionExperiment,
}


def get_device() -> torch.device:
    """Get the best available device.
    
    Note: torch_scatter doesn't support MPS, so we fall back to CPU
    on Apple Silicon until scatter operations are reimplemented.
    """
    if torch.cuda.is_available():
        return torch.device("cuda")
    # MPS is fine as long as we aren't using torch_scatter.
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        try:
            import torch_scatter  # type: ignore  # noqa: F401

            has_torch_scatter = True
        except Exception:
            has_torch_scatter = False
        if not has_torch_scatter:
            return torch.device("mps")
    return torch.device("cpu")


def run_single_experiment(
    name: str,
    scale: Scale,
    device: torch.device,
    *,
    profile_dir: Optional[Path] = None,
) -> ExperimentResult:
    """Run a single experiment."""
    if name not in EXPERIMENTS:
        raise ValueError(f"Unknown experiment: {name}. Available: {list(EXPERIMENTS.keys())}")
    
    exp_class = EXPERIMENTS[name]
    experiment = exp_class(scale=scale, device=device)

    if profile_dir is None:
        return experiment.run()

    # Profile even if the experiment fails; always write stats in a finally.
    import cProfile
    import pstats
    import io

    profile_dir.mkdir(parents=True, exist_ok=True)
    stem = f"{name}_{scale.value}"
    prof_path = profile_dir / f"{stem}.prof"
    txt_path = profile_dir / f"{stem}.txt"

    pr = cProfile.Profile()
    pr.enable()
    try:
        return experiment.run()
    finally:
        pr.disable()
        pr.dump_stats(str(prof_path))
        # Also write a readable summary for quick inspection.
        s = io.StringIO()
        pstats.Stats(pr, stream=s).strip_dirs().sort_stats("cumtime").print_stats(40)
        txt_path.write_text(s.getvalue(), encoding="utf-8")


def generate_latex_table(results: List[ExperimentResult]) -> str:
    """Generate LaTeX summary table from results."""
    lines = [
        r"\begin{table}[t]",
        r"\centering",
        r"\caption{Experiment results across scales. Success indicates the experiment completed without errors.}",
        r"\label{tab:experiments}",
        r"\begin{tabular}{llccc}",
        r"\toprule",
        r"\textbf{Experiment} & \textbf{Scale} & \textbf{Success} & \textbf{Key Metric} & \textbf{Value} \\",
        r"\midrule",
    ]
    
    for result in results:
        status = r"\checkmark" if result.success else r"$\times$"
        
        # Get the most relevant metric
        if "final" in result.metrics:
            final = result.metrics["final"]
            if "accuracy" in final:
                key_metric = "Accuracy"
                value = f"{final['accuracy']:.2%}"
            elif "mse" in final:
                key_metric = "MSE"
                value = f"{final['mse']:.4f}"
            elif "reconstruction_mse" in final:
                key_metric = "Recon. MSE"
                value = f"{final['reconstruction_mse']:.4f}"
            elif "perplexity" in final:
                key_metric = "Perplexity"
                value = f"{final['perplexity']:.2f}"
            else:
                key_metric = "--"
                value = "--"
        else:
            key_metric = "--"
            value = "--"
        
        lines.append(
            f"{result.name} & {result.scale} & {status} & {key_metric} & {value} \\\\"
        )
    
    lines.extend([
        r"\bottomrule",
        r"\end{tabular}",
        r"\end{table}",
    ])
    
    return "\n".join(lines)


def generate_report(results: List[ExperimentResult], output_dir: Path) -> None:
    """Generate full experiment report."""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Summary JSON
    summary = {
        "timestamp": datetime.now().isoformat(),
        "experiments": [
            {
                "name": r.name,
                "scale": r.scale,
                "success": r.success,
                "failure_reason": r.failure_reason,
                "metrics": {
                    k: v for k, v in r.metrics.items() 
                    if k == "final" or not isinstance(v, (list, dict))
                },
            }
            for r in results
        ],
    }
    
    with open(output_dir / "experiment_results.json", "w") as f:
        json.dump(summary, f, indent=2, default=str)
    
    # LaTeX table
    latex_table = generate_latex_table(results)
    with open(output_dir / "experiment_results.tex", "w") as f:
        f.write(latex_table)
    
    # Markdown summary
    md_lines = [
        "# Experiment Results",
        "",
        f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## Summary",
        "",
        "| Experiment | Scale | Success | Key Metric |",
        "|------------|-------|---------|------------|",
    ]
    
    for r in results:
        status = "✓" if r.success else f"✗ ({r.failure_reason})"
        
        if "final" in r.metrics:
            final = r.metrics["final"]
            if "accuracy" in final:
                metric = f"Acc: {final['accuracy']:.2%}"
            elif "mse" in final:
                metric = f"MSE: {final['mse']:.4f}"
            elif "reconstruction_mse" in final:
                metric = f"MSE: {final['reconstruction_mse']:.4f}"
            else:
                metric = "--"
        else:
            metric = "--"
        
        md_lines.append(f"| {r.name} | {r.scale} | {status} | {metric} |")
    
    md_lines.extend([
        "",
        "## Detailed Results",
        "",
    ])
    
    for r in results:
        md_lines.append(f"### {r.name} ({r.scale})")
        md_lines.append("")
        if r.success and "final" in r.metrics:
            for k, v in r.metrics["final"].items():
                md_lines.append(f"- **{k}**: {v}")
        elif r.failure_reason:
            md_lines.append(f"**Failed**: {r.failure_reason}")
        md_lines.append("")
    
    with open(output_dir / "experiment_results.md", "w") as f:
        f.write("\n".join(md_lines))
    
    print(f"\nReports saved to {output_dir}")


def run_all_experiments(
    scales: List[Scale],
    experiments: Optional[List[str]] = None,
    output_dir: Path = Path("./artifacts/experiments"),
    *,
    profile: bool = False,
) -> List[ExperimentResult]:
    """Run all (or selected) experiments at specified scales."""
    
    device = get_device()
    print(f"Device: {device}")
    print(f"Scales: {[s.value for s in scales]}")
    print(f"Experiments: {experiments or 'all'}")
    print("=" * 60)
    
    if experiments is None:
        experiments = list(EXPERIMENTS.keys())
    
    results: List[ExperimentResult] = []
    profile_dir = (output_dir / "profiles") if profile else None
    
    total = len(experiments) * len(scales)
    current = 0
    
    for exp_name in experiments:
        for scale in scales:
            current += 1
            print(f"\n[{current}/{total}] Running {exp_name} at {scale.value} scale...")
            
            try:
                result = run_single_experiment(exp_name, scale, device, profile_dir=profile_dir)
                results.append(result)
                
                if result.success:
                    print(f"    ✓ Success")
                else:
                    print(f"    ✗ Failed: {result.failure_reason}")
                    
            except Exception as e:
                print(f"    ✗ Exception: {e}")
                results.append(ExperimentResult(
                    name=exp_name,
                    scale=scale.value,
                    goal="",
                    success=False,
                    metrics={},
                    failure_reason=str(e),
                ))
    
    # Generate reports
    generate_report(results, output_dir)
    
    # Print summary
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    
    successes = sum(1 for r in results if r.success)
    failures = len(results) - successes
    
    print(f"Total: {len(results)}")
    print(f"Successes: {successes}")
    print(f"Failures: {failures}")
    
    if failures > 0:
        print("\nFailed experiments:")
        for r in results:
            if not r.success:
                print(f"  - {r.name} ({r.scale}): {r.failure_reason}")
    
    return results


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Run thermodynamic manifold experiments"
    )
    parser.add_argument(
        "--scale",
        choices=["toy", "medium", "full", "all"],
        default="toy",
        help="Scale to run experiments at (default: toy)",
    )
    parser.add_argument(
        "--experiment",
        choices=list(EXPERIMENTS.keys()) + ["all"],
        default="all",
        help="Which experiment to run (default: all)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./artifacts/experiments",
        help="Output directory for results",
    )
    parser.add_argument(
        "--profile",
        action="store_true",
        help="Write cProfile stats per experiment to <output-dir>/profiles/",
    )
    
    args = parser.parse_args()
    
    # Parse scales
    if args.scale == "all":
        scales = [Scale.TOY, Scale.MEDIUM, Scale.FULL]
    else:
        scales = [Scale(args.scale)]
    
    # Parse experiments
    if args.experiment == "all":
        experiments = None  # Will run all
    else:
        experiments = [args.experiment]
    
    print("=" * 60)
    print("THERMODYNAMIC MANIFOLD - EXPERIMENT HARNESS")
    print("=" * 60)
    
    run_all_experiments(
        scales=scales,
        experiments=experiments,
        output_dir=Path(args.output_dir),
        profile=bool(args.profile),
    )


if __name__ == "__main__":
    main()



---
File: /thermo_manifold/experiments/image_gen.py
---

"""Image Generation Experiment

Uses MNIST / CIFAR-10 from HuggingFace.
Standard image benchmarks.

Goal: Generate images via thermodynamic diffusion in frequency space.
Metrics: Reconstruction MSE, FID (if we can compute it)
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale


class ImageGenerationExperiment(BaseExperiment):
    """Image generation using thermodynamic dynamics in frequency space.
    
    The approach:
    1. Encode training images to frequency-space particles
    2. Build attractors from the frequency distributions
    3. For generation: seed with noise, let particles diffuse toward attractors
    4. Decode via inverse FFT
    """
    
    name = "image_gen"
    goal = "Generate images via thermodynamic diffusion in frequency space"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.dataset_name = "mnist"
            self.image_size = 28
            self.top_k_freq = 50
        elif scale == Scale.MEDIUM:
            self.dataset_name = "mnist"
            self.image_size = 28
            self.top_k_freq = 200
        else:
            self.dataset_name = "cifar10"
            self.image_size = 32
            self.top_k_freq = 500
        
        # Frequency statistics (learned from training data)
        self._freq_attractors: Dict[Tuple[int, int], List[Tuple[float, float]]] = {}
    
    def setup(self) -> None:
        """Load image dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading {self.dataset_name}...")
        
        if self.dataset_name == "mnist":
            dataset = load_dataset(
                "ylecun/mnist",
                streaming=True,
                trust_remote_code=True,
            )
            self.image_key = "image"
        else:  # cifar10
            dataset = load_dataset(
                "uoft-cs/cifar10",
                streaming=True,
                trust_remote_code=True,
            )
            self.image_key = "img"
        
        # Store iterators
        self.train_stream = dataset["train"]
        self.eval_stream = dataset["test"]
        
        # Prefetch images
        self._train_images: List[torch.Tensor] = []
        self._eval_images: List[torch.Tensor] = []
        self._train_labels: List[int] = []
        self._eval_labels: List[int] = []
        
        self._load_images(
            self.train_stream,
            self._train_images,
            self._train_labels,
            self.scale_config.max_train_samples or 1000,
        )
        self._load_images(
            self.eval_stream,
            self._eval_images,
            self._eval_labels,
            self.scale_config.max_eval_samples or 200,
        )
        
        print(f"    Train images: {len(self._train_images)}")
        print(f"    Eval images: {len(self._eval_images)}")
        print(f"    Image size: {self.image_size}x{self.image_size}")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _load_images(
        self,
        stream,
        images: List[torch.Tensor],
        labels: List[int],
        max_samples: int,
    ) -> None:
        """Load images from stream."""
        for sample in stream:
            img = sample[self.image_key]
            
            # Convert PIL to tensor if needed
            if hasattr(img, "convert"):
                img = img.convert("L")  # Grayscale
                import numpy as np
                img = np.array(img, dtype=np.float32) / 255.0
                img = torch.from_numpy(img)
            else:
                img = torch.tensor(img, dtype=torch.float32)
                if img.max() > 1.0:
                    img = img / 255.0
                if img.ndim == 3:
                    img = img.mean(dim=-1)  # Grayscale
            
            # Resize if needed
            if img.shape[0] != self.image_size or img.shape[1] != self.image_size:
                img = torch.nn.functional.interpolate(
                    img.unsqueeze(0).unsqueeze(0),
                    size=(self.image_size, self.image_size),
                    mode="bilinear",
                    align_corners=False,
                ).squeeze()
            
            images.append(img)
            labels.append(sample.get("label", 0))
            
            if len(images) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[torch.Tensor, int]]:
        """Iterate over training images."""
        for img, label in zip(self._train_images, self._train_labels):
            yield img, label
    
    def train_step(self, batch: Tuple[torch.Tensor, int]) -> Dict[str, float]:
        """One step of thermodynamic image learning.
        
        Training = building attractor statistics from images.
        """
        image, label = batch
        image = image.to(self.device)
        
        # Clear and encode image
        self.manifold.clear()
        self.manifold.encode_image(image, top_k=self.top_k_freq)
        
        # Run dynamics to let structure emerge
        for _ in range(5):
            self.manifold.step()
        
        # Store frequency attractors (building a generative model)
        for p in self.manifold._particles:
            if p.modality == Modality.IMAGE and p.position.numel() == 2:
                u = int(p.position[0].item())
                v = int(p.position[1].item())
                key = (u, v)
                
                if key not in self._freq_attractors:
                    self._freq_attractors[key] = []
                
                # Store (energy, phase) for this frequency
                phase = p.phase[0].item() if p.phase is not None else 0.0
                self._freq_attractors[key].append((p.energy.item(), phase))
        
        # Decode and compute reconstruction error
        reconstructed = self.manifold.decode_image((self.image_size, self.image_size))
        mse = ((image - reconstructed) ** 2).mean().item()
        
        return {"mse": mse}
    
    def _generate_image(self) -> torch.Tensor:
        """Generate a new image using learned attractors."""
        self.manifold.clear()
        
        if not self._freq_attractors:
            # No attractors learned yet, return noise
            return torch.randn(self.image_size, self.image_size, device=self.device)
        
        # Create particles from attractor statistics
        for (u, v), stats in self._freq_attractors.items():
            if not stats:
                continue
            
            # Use mean energy and phase
            mean_energy = sum(e for e, _ in stats) / len(stats)
            mean_phase = sum(p for _, p in stats) / len(stats)
            
            # Add some noise for generation diversity
            noise = torch.randn(1, device=self.device).item() * 0.1
            
            position = torch.tensor([float(u), float(v)], device=self.device)
            phase = torch.tensor([mean_phase + noise], device=self.device)
            
            self.manifold.add_particle(
                position=position,
                energy=max(0.001, mean_energy + noise * 0.1),
                modality=Modality.IMAGE,
                phase=phase,
            )
        
        # Run dynamics
        for _ in range(10):
            self.manifold.step()
        
        # Decode
        return self.manifold.decode_image((self.image_size, self.image_size))
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate reconstruction and generation quality."""
        # Reconstruction quality on eval set
        mse_total = 0.0
        count = 0
        
        for image in self._eval_images[:50]:
            image = image.to(self.device)
            
            self.manifold.clear()
            self.manifold.encode_image(image, top_k=self.top_k_freq)
            
            for _ in range(5):
                self.manifold.step()
            
            reconstructed = self.manifold.decode_image((self.image_size, self.image_size))
            mse_total += ((image - reconstructed) ** 2).mean().item()
            count += 1
        
        recon_mse = mse_total / max(count, 1)
        
        # Generate some samples and compute metrics
        gen_images = [self._generate_image() for _ in range(10)]
        
        # Basic generation metrics
        gen_mean = torch.stack(gen_images).mean().item()
        gen_std = torch.stack(gen_images).std().item()
        
        # Compare to training distribution
        train_mean = torch.stack(self._train_images[:100]).mean().item()
        train_std = torch.stack(self._train_images[:100]).std().item()
        
        mean_diff = abs(gen_mean - train_mean)
        std_diff = abs(gen_std - train_std)
        
        return {
            "reconstruction_mse": recon_mse,
            "gen_mean": gen_mean,
            "gen_std": gen_std,
            "mean_diff": mean_diff,
            "std_diff": std_diff,
            "num_attractors": len(self._freq_attractors),
            "eval_images": count,
        }
    
    def save_samples(self, out_dir: str, num_samples: int = 16) -> None:
        """Save generated samples for visual inspection."""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            from pathlib import Path
            
            out_path = Path(out_dir)
            out_path.mkdir(parents=True, exist_ok=True)
            
            # Generate samples
            samples = [self._generate_image().cpu().numpy() for _ in range(num_samples)]
            
            # Plot grid
            rows = int(num_samples ** 0.5)
            cols = (num_samples + rows - 1) // rows
            
            fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
            axes = axes.flatten() if num_samples > 1 else [axes]
            
            for ax, sample in zip(axes, samples):
                ax.imshow(sample, cmap='gray')
                ax.axis('off')
            
            for ax in axes[len(samples):]:
                ax.axis('off')
            
            fig.tight_layout()
            fig.savefig(out_path / "generated_samples.png", dpi=150)
            plt.close(fig)
            
            print(f"    Saved samples to {out_path / 'generated_samples.png'}")
            
        except ImportError:
            print("    (matplotlib not available, skipping sample saving)")


def run_image_gen_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = ImageGenerationExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Save samples
    exp.save_samples("./artifacts/image_gen")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /thermo_manifold/experiments/next_token.py
---

"""Next Token Prediction Experiment

Uses WikiText-2 / WikiText-103 from HuggingFace.
Standard language modeling benchmark.

Goal: Predict next token from context.
Metrics: Accuracy, Perplexity (where applicable)
"""

from __future__ import annotations

import json
from collections import Counter
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.diagnostics import SemanticDiagnosticsLogger
from thermo_manifold.core.viz import plot_pondering_jsonl
from thermo_manifold.semantic.hierarchical import HierarchicalSemanticManifold

from .base import BaseExperiment, Scale

DEFAULT_OUT_DIR = Path("./artifacts/next_token")


class NextTokenExperiment(BaseExperiment):
    """Next token prediction using the semantic manifold.
    
    This is the core capability of the system.
    """
    
    name = "next_token"
    goal = "Predict next token from context (language modeling)"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.dataset_name = "wikitext-2-raw-v1"
            self.context_length = 32
            self.vocab_size = 1000  # Limit vocab
        elif scale == Scale.MEDIUM:
            self.dataset_name = "wikitext-2-raw-v1"
            self.context_length = 64
            self.vocab_size = 10000
        else:
            self.dataset_name = "wikitext-103-raw-v1"
            self.context_length = 128
            self.vocab_size = 50000
        
        self.vocab: List[str] = []
        self.token_to_id: Dict[str, int] = {}
        self._train_steps: int = int(self.scale_config.train_steps)
    
    def setup(self) -> None:
        """Load WikiText and build vocabulary."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading {self.dataset_name}...")
        
        dataset = load_dataset(
            "wikitext",
            self.dataset_name,
            streaming=True
        )
        
        # Build vocabulary from training data
        print(f"    Building vocabulary (max {self.vocab_size} tokens)...")
        
        word_counts: Counter = Counter()
        sample_count = 0
        max_vocab_samples = self.scale_config.max_train_samples or 10000
        
        for sample in dataset["train"]:
            text = sample["text"]
            if not text.strip():
                continue
            
            # Simple whitespace tokenization
            tokens = text.split()
            word_counts.update(tokens)
            sample_count += 1
            
            if sample_count >= max_vocab_samples:
                break
        
        # Build vocab from most common tokens
        special_tokens = ["<pad>", "<unk>", "<bos>", "<eos>"]
        self.vocab = special_tokens + [
            word for word, _ in word_counts.most_common(self.vocab_size - len(special_tokens))
        ]
        self.token_to_id = {token: i for i, token in enumerate(self.vocab)}
        
        print(f"    Vocabulary size: {len(self.vocab)}")
        print(f"    Sample tokens: {self.vocab[4:14]}")
        
        # Store dataset iterators
        self.train_stream = dataset["train"]
        self.eval_stream = dataset["validation"]
        
        # Prefetch and tokenize data
        self._train_sequences: List[List[int]] = []
        self._eval_sequences: List[List[int]] = []
        
        self._tokenize_stream(
            self.train_stream,
            self._train_sequences,
            self.scale_config.max_train_samples or 10000,
        )
        self._tokenize_stream(
            self.eval_stream,
            self._eval_sequences,
            self.scale_config.max_eval_samples or 1000,
        )
        
        print(f"    Train sequences: {len(self._train_sequences)}")
        print(f"    Eval sequences: {len(self._eval_sequences)}")
        
        # Initialize semantic manifold
        self.manifold = HierarchicalSemanticManifold(
            self.physics_config,
            self.device,
            vocab=self.vocab,
            embed_dim=min(self.scale_config.embed_dim, len(self.vocab)),
            chunk_min_len=2,
            chunk_max_len=4,
        )

    def _reset_artifacts(self, out_dir: Path) -> None:
        """Ensure deterministic artifact outputs (overwrite vs append)."""
        out_dir.mkdir(parents=True, exist_ok=True)
        for p in [
            out_dir / "pondering.jsonl",
            out_dir / "pondering.csv",
            out_dir / "next_token_metrics.json",
            out_dir / "next_token_data.json",
            out_dir / "next_token.png",
            out_dir / "pondering.png",
            out_dir / "tables" / "next_token_summary.tex",
        ]:
            try:
                if p.exists():
                    p.unlink()
            except Exception:
                # Best-effort cleanup; we still want the experiment to run.
                pass

    @staticmethod
    def _topological_entropy(src: torch.Tensor, w: torch.Tensor, eps: float) -> float:
        """Mean per-src entropy of outgoing normalized weights."""
        if src.numel() == 0:
            return 0.0
        w = w.clamp(min=0.0)
        if float(w.sum().item()) <= eps:
            return 0.0
        src_u, inv = torch.unique(src, return_inverse=True)
        out_sum = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
        out_sum.index_add_(0, inv, w)
        p = w / (out_sum[inv] + eps)
        edge_ent = -p * torch.log(p + eps)
        ent_src = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
        ent_src.index_add_(0, inv, edge_ent)
        return float(ent_src.mean().item())

    @staticmethod
    def _rolling_mean(x: torch.Tensor, win: int) -> torch.Tensor:
        win = max(1, int(win))
        if x.numel() == 0:
            return x
        kern = torch.ones(win, dtype=torch.float32, device=x.device) / float(win)
        y = torch.nn.functional.conv1d(x.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2).view(-1)
        return y[: x.numel()]

    def _generate_artifacts(self, *, out_dir: Path, metrics: Dict[str, Any]) -> Dict[str, Path]:
        """Write figures/tables for paper artifacts."""
        figures: Dict[str, Path] = {}
        tables_dir = out_dir / "tables"
        tables_dir.mkdir(parents=True, exist_ok=True)

        # LaTeX table (summary)
        final = metrics.get("final_eval", {}) if isinstance(metrics, dict) else {}
        acc = float(final.get("accuracy", 0.0))
        ppl = float(final.get("perplexity", float("inf")))
        edges = int(final.get("graph_edges", 0))
        chunks = int(final.get("chunks", 0))
        table = (
            r"""\begin{table}[t]
\centering
\caption{Next-token prediction after a single online training pass (no gradient optimization).}
\label{tab:next_token}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Validation accuracy & """
            + f"{acc:.1%}"
            + r""" \\
Validation perplexity & """
            + (f"{ppl:.2f}" if ppl != float("inf") else r"$\infty$")
            + r""" \\
Graph edges & """
            + f"{edges}"
            + r""" \\
Chunks & """
            + f"{chunks}"
            + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""
        )
        table_path = tables_dir / "next_token_summary.tex"
        table_path.write_text(table, encoding="utf-8")

        # Figures
        try:
            import matplotlib

            matplotlib.use("Agg")
            import matplotlib.pyplot as plt

            steps = int(metrics["steps"])
            x = list(range(steps))

            fig, ax = plt.subplots(3, 1, figsize=(10, 7), sharex=True)
            ax[0].plot(x, metrics["acc_smooth"], label="accuracy (rolling)", linewidth=1.5)
            ax[0].set_ylabel("accuracy")
            ax[0].set_ylim(0.0, 1.05)
            ax[0].legend(loc="upper right", fontsize=8)

            ax[1].plot(x, metrics["nll_smooth"], label="NLL (rolling)", linewidth=1.2)
            ax[1].set_ylabel("NLL")
            ax[1].legend(loc="upper right", fontsize=8)

            ax[2].plot(x, metrics["energy"], label="system energy", alpha=0.7)
            ax[2].plot(x, metrics["topo_entropy"], label="topology entropy", alpha=0.7)
            ax[2].plot(x, metrics["chunks_ts"], label="#chunks", alpha=0.7)
            ax[2].set_ylabel("energy / entropy / count")
            ax[2].set_xlabel("train step")
            ax[2].legend(loc="upper right", fontsize=8)

            fig.tight_layout()
            fig_path = out_dir / "next_token.png"
            fig.savefig(fig_path, dpi=150)
            plt.close(fig)
            figures["next_token"] = fig_path
        except Exception:
            pass

        # Pondering plot from JSONL (if any)
        try:
            ponder_png = plot_pondering_jsonl(out_dir / "pondering.jsonl", out_dir / "pondering.png")
            if ponder_png.exists():
                figures["pondering"] = ponder_png
        except Exception:
            pass

        return figures

    def run(self):  # type: ignore[override]
        """Run experiment and generate paper artifacts.

        Key property: this system does *not* optimize a loss; we do not run evaluation
        during training. We pump tokens (online structural updates), then evaluate once.
        """
        print(f"\n{'='*60}")
        print(f"EXPERIMENT: {self.name} ({self.scale.value})")
        print(f"Goal: {self.goal}")
        print(f"Device: {self.device}")
        print(f"{'='*60}")

        from .base import ExperimentResult

        try:
            print("\n[1] Setup...")
            self.setup()

            out_dir = DEFAULT_OUT_DIR / self.scale.value
            self._reset_artifacts(out_dir)

            # Attach diagnostics for pondering traces (written only when idle_think is called).
            ponder_jsonl = out_dir / "pondering.jsonl"
            ponder_csv = out_dir / "pondering.csv"
            self.manifold.set_diagnostics(
                SemanticDiagnosticsLogger(csv_path=str(ponder_csv), jsonl_path=str(ponder_jsonl))
            )

            steps = int(self._train_steps)
            print(f"\n[2] Training ({steps} steps; no in-loop eval)...")

            # Per-step metrics
            acc = torch.zeros(steps, dtype=torch.float32)
            nll = torch.zeros(steps, dtype=torch.float32)
            entropy = torch.zeros(steps, dtype=torch.float32)
            energy = torch.zeros(steps, dtype=torch.float32)
            topo = torch.zeros(steps, dtype=torch.float32)
            chunks_ts = torch.zeros(steps, dtype=torch.float32)

            data_iter = self.train_iterator()
            for t in range(steps):
                try:
                    context, target = next(data_iter)
                except StopIteration:
                    # Restart streaming iterator if it ended early.
                    data_iter = self.train_iterator()
                    context, target = next(data_iter)

                context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(context_tensor)

                # Fixed steps for speed (dt-calibrated heuristic)
                num_steps = 3 if self.scale == Scale.TOY else 5
                for _ in range(num_steps):
                    self.manifold.step_grammar()

                out = self.manifold.output_state()
                pred = int(out.token_index)
                acc[t] = 1.0 if pred == int(target) else 0.0

                p = float(out.probs[int(target)].clamp(min=1e-10).item())
                nll[t] = float((-torch.log(torch.tensor(p, dtype=torch.float32))).item())
                entropy[t] = float(out.meta.get("entropy", 0.0))

                # System metrics (exclude long-term structural mass where possible)
                _exc = self.manifold.attractors.get("excitation").abs().sum()
                _heat = self.manifold.attractors.get("heat").abs().sum()
                _cexc = self.manifold.chunks.excitation.abs().sum()
                _cheat = self.manifold.chunks.heat.abs().sum()
                energy[t] = (_exc + _heat + _cexc + _cheat).detach().to(torch.float32).cpu()
                topo[t] = torch.tensor(
                    self._topological_entropy(self.manifold.graph.src.detach(), self.manifold.graph.w.detach(), eps=self.physics_config.eps),
                    dtype=torch.float32,
                )
                chunks_ts[t] = float(self.manifold.chunks.num_chunks)

                # Online structural update ("learning")
                self.manifold.observe_next_token(int(target), probs=out.probs)

                # Idle pondering cadence (deterministic; writes diagnostics via logger)
                if t > 0 and (t % 50 == 0):
                    self.manifold.idle_think(steps=1, dream_steps=2)

            # Smooth curves for readability
            acc_smooth = self._rolling_mean(acc, win=200).cpu().tolist()
            nll_smooth = self._rolling_mean(nll, win=200).cpu().tolist()

            # Save training time series + config
            metrics: Dict[str, Any] = {
                "config": asdict(self.physics_config),
                "scale": self.scale.value,
                "dataset": self.dataset_name,
                "context_length": int(self.context_length),
                "vocab_size": int(len(self.vocab)),
                "steps": steps,
                "acc": acc.cpu().tolist(),
                "acc_smooth": acc_smooth,
                "nll": nll.cpu().tolist(),
                "nll_smooth": nll_smooth,
                "entropy": entropy.cpu().tolist(),
                "energy": energy.cpu().tolist(),
                "topo_entropy": topo.cpu().tolist(),
                "chunks_ts": chunks_ts.cpu().tolist(),
            }

            (out_dir / "next_token_metrics.json").write_text(json.dumps(metrics, indent=2), encoding="utf-8")

            print("\n[3] Final evaluation...")
            final_eval = self.evaluate()
            metrics["final_eval"] = final_eval

            # Save a compact summary JSON (avoids duplicating full time series)
            summary = {k: v for k, v in metrics.items() if not isinstance(v, list)}
            (out_dir / "next_token_data.json").write_text(json.dumps(summary, indent=2, default=str), encoding="utf-8")

            figures = self._generate_artifacts(out_dir=out_dir, metrics=metrics)

            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=True,
                metrics={"final": final_eval, "artifacts_dir": str(out_dir)},
                tables={"next_token_summary": (out_dir / "tables" / "next_token_summary.tex").read_text(encoding="utf-8")},
                figures=figures,
            )
        except Exception as e:
            import traceback

            tb = traceback.format_exc()
            print(f"\n[FAILED] {e}")
            print(tb)
            return ExperimentResult(
                name=self.name,
                scale=self.scale.value,
                goal=self.goal,
                success=False,
                metrics={},
                failure_reason=str(e),
            )
    
    def _tokenize_stream(
        self,
        stream,
        output: List[List[int]],
        max_samples: int,
    ) -> None:
        """Tokenize a stream into sequences."""
        unk_id = self.token_to_id.get("<unk>", 1)
        
        for sample in stream:
            text = sample["text"]
            if not text.strip():
                continue
            
            tokens = text.split()
            if len(tokens) < 2:
                continue
            
            # Convert to IDs
            ids = [self.token_to_id.get(t, unk_id) for t in tokens]
            output.append(ids)
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[List[int], int]]:
        """Iterate over training (context, next_token) pairs."""
        for sequence in self._train_sequences:
            # Sliding window
            for i in range(len(sequence) - 1):
                start = max(0, i - self.context_length + 1)
                context = sequence[start:i+1]
                target = sequence[i + 1]
                yield context, target
    
    def _run_grammar_steps(self, num_steps: int = 5) -> None:
        """Run a fixed number of grammar steps.
        
        Note: thinking_complete() can be slow to converge, so for experiments
        we use a fixed number of steps calibrated to dt.
        """
        for _ in range(num_steps):
            self.manifold.step_grammar()
    
    def train_step(self, batch: Tuple[List[int], int]) -> Dict[str, float]:
        """One step of thermodynamic language modeling."""
        context, target = batch
        
        # Convert to tensor
        context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
        
        # Ingest context
        self.manifold.ingest_ids(context_tensor)
        
        # Run grammar dynamics (fixed steps for speed)
        # Toy scale benefits from fewer steps on CPU.
        num_steps = 3 if self.scale == Scale.TOY else 5
        self._run_grammar_steps(num_steps=num_steps)
        
        # Get prediction
        output = self.manifold.output_state()
        predicted = output.token_index
        
        # Observe actual next token (this is the learning!)
        probs = output.probs
        self.manifold.observe_next_token(target, probs=probs)
        
        # Optionally do some pondering
        # NOTE: idle_think/dreaming is comparatively expensive; avoid doing it on
        # step 0 (it makes the progress bar look "stuck") and run it less often.
        if self.state.step > 0 and self.state.step % 50 == 0:
            self.manifold.idle_think(steps=1, dream_steps=2)
        
        # Metrics
        correct = 1.0 if predicted == target else 0.0
        
        # Compute approximate perplexity contribution
        prob = probs[target].item()
        log_prob = -torch.log(torch.tensor(prob + 1e-10)).item()
        
        return {
            "accuracy": correct,
            "log_prob": log_prob,
            "entropy": output.meta.get("entropy", 0.0),
        }
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on validation set."""
        correct = 0
        total = 0
        total_log_prob = 0.0
        
        # Note: evaluation is run once after the online training pass.
        # `_eval_sequences` is already bounded during prefetch/tokenization by scale.
        for sequence in self._eval_sequences:
            for i in range(len(sequence) - 1):
                start = max(0, i - self.context_length + 1)
                context = sequence[start:i+1]
                target = sequence[i + 1]
                
                context_tensor = torch.tensor(context, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(context_tensor)
                num_steps = 3 if self.scale == Scale.TOY else 5
                self._run_grammar_steps(num_steps=num_steps)
                
                output = self.manifold.output_state()
                predicted = output.token_index
                
                if predicted == target:
                    correct += 1
                
                prob = output.probs[target].item()
                total_log_prob += -torch.log(torch.tensor(prob + 1e-10)).item()
                
                total += 1
                
                # Don't learn during eval
        
        if total == 0:
            return {"accuracy": 0.0, "perplexity": float("inf")}
        
        avg_log_prob = total_log_prob / total
        perplexity = torch.exp(torch.tensor(avg_log_prob)).item()
        
        return {
            "accuracy": correct / total,
            "perplexity": perplexity,
            "eval_tokens": total,
            "graph_edges": self.manifold.graph.num_edges,
            "chunks": self.manifold.chunks.num_chunks,
        }


def run_next_token_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = NextTokenExperiment(scale=scale, device=device)
    result = exp.run()
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /thermo_manifold/experiments/result.py
---

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List


@dataclass
class LaTeXTable:
    """Container for LaTeX table outputs."""
    name: str
    header: List[str]
    rows: List[List[str|int|float]]


    def to_latex(self) -> str:
        """Convert the table to LaTeX format."""
        return f"\\begin{{table}}[h]\n\\centering\n\\caption{{{self.name}}}\n\\label{{tab:{self.name}}}\n\\begin{{tabular}}{{{'l' * len(self.header)}}}\n\\toprule\n{' & '.join(self.header)}\n\\midrule\n{'\n'.join([' & '.join(map(str, row)) for row in self.rows])}n\\bottomrule\n\\end{{tabular}}\n\\end{{table}}"

    def to_markdown(self) -> str:
        """Convert the table to Markdown format."""
        return f"| {self.name} |\n| {' | '.join(self.header)} |\n| {' | '.join([' | '.join(map(str, row)) for row in self.rows])} |\n"


@dataclass
class ExperimentResult:
    """Container for experiment outputs."""
    name: str
    goal: str
    metrics: Dict[str, float|int|str|List[float|int|str]]
    tables: Dict[str, str]  # name -> LaTeX content
    figures: Dict[str, Path]  # name -> path to generated figure


---
File: /thermo_manifold/experiments/rule_shift.py
---

"""
Rule Shift Experiment

Tests the system's ability to adapt when the underlying sequential pattern
reverses mid-stream.
"""

from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Any, Dict, List, Tuple

import torch

from ..core.config import PhysicsConfig
from ..semantic.hierarchical import HierarchicalSemanticManifold


def _topological_entropy(src: torch.Tensor, w: torch.Tensor, eps: float) -> float:
    """Mean per-src entropy of outgoing normalized weights."""
    if src.numel() == 0:
        return 0.0
    w = w.clamp(min=0.0)
    if float(w.sum().item()) <= eps:
        return 0.0
    src_u, inv = torch.unique(src, return_inverse=True)
    out_sum = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    out_sum.index_add_(0, inv, w)
    p = w / (out_sum[inv] + eps)
    edge_ent = -p * torch.log(p + eps)
    ent_src = torch.zeros(int(src_u.numel()), device=w.device, dtype=w.dtype)
    ent_src.index_add_(0, inv, edge_ent)
    return float(ent_src.mean().item())


def _make_stream(vocab: List[str]) -> Tuple[Dict[str, int], List[int], List[int]]:
    """Create forward and reverse token streams."""
    tid = {t: i for i, t in enumerate(vocab)}
    fwd = [
        tid["<bos>"], tid["the"], tid["cat"], tid["sat"],
        tid["on"], tid["the"], tid["mat"], tid["<eos>"],
    ]
    rev = [
        tid["<bos>"], tid["mat"], tid["the"], tid["on"],
        tid["sat"], tid["cat"], tid["the"], tid["<eos>"],
    ]
    return tid, fwd, rev


def run_rule_shift(
    *,
    steps: int,
    shift_at: int,
    context_len: int,
    dt: float,
    device: torch.device,
) -> Dict[str, Any]:
    """
    Run the rule shift experiment.
    
    Returns:
        Dictionary with all metrics and raw data
    """
    vocab = ["<bos>", "the", "cat", "sat", "on", "mat", "<eos>"]
    tid, fwd, rev = _make_stream(vocab)
    
    # Pre-generate the full token stream
    stream: List[int] = []
    pos = 0
    seq = fwd
    for t in range(steps + 1):
        if t == shift_at:
            seq = rev
            pos = 0
        stream.append(seq[pos])
        pos = (pos + 1) % len(seq)
    
    cfg = PhysicsConfig(dt=dt, eps=1e-8)
    brain = HierarchicalSemanticManifold(
        cfg, device,
        vocab=vocab,
        embed_dim=min(16, len(vocab)),
        chunk_min_len=2,
        chunk_max_len=4,
    )
    
    history: List[int] = []
    
    # Metrics tensors
    acc = torch.zeros(steps, dtype=torch.float32)
    energy = torch.zeros(steps, dtype=torch.float32)
    topo = torch.zeros(steps, dtype=torch.float32)
    chunks = torch.zeros(steps, dtype=torch.float32)
    ponder_shortcuts = torch.zeros(steps, dtype=torch.float32)
    ponder_dead_ends = torch.zeros(steps, dtype=torch.float32)
    ponder_hunger = torch.zeros(steps, dtype=torch.float32)
    
    for t in range(steps):
        cur = int(stream[t])
        nxt = int(stream[t + 1])
        
        history.append(cur)
        if len(history) > context_len:
            history = history[-context_len:]
        
        ctx = torch.tensor(history, device=device, dtype=torch.long)
        brain.ingest_ids(ctx)
        brain.step_grammar()
        out = brain.output_state()
        
        pred = int(out.token_index)
        acc[t] = 1.0 if pred == nxt else 0.0
        
        # Dynamic system energy
        _exc = brain.attractors.get('excitation').abs().sum()
        _heat = brain.attractors.get('heat').abs().sum()
        _cexc = brain.chunks.excitation.abs().sum()
        _cheat = brain.chunks.heat.abs().sum()
        energy[t] = (_exc + _heat + _cexc + _cheat).detach().to(torch.float32).cpu()
        
        topo[t] = torch.tensor(
            _topological_entropy(brain.graph.src.detach(), brain.graph.w.detach(), eps=cfg.eps),
            dtype=torch.float32,
        )
        chunks[t] = float(brain.chunks.num_chunks)
        
        # Online learning
        brain.observe_next_token(nxt, probs=out.probs)
        
        # Idle pondering
        p = brain.idle_think(steps=1, dream_steps=context_len)
        ponder_shortcuts[t] = float(p.get("shortcuts", 0.0))
        ponder_dead_ends[t] = float(p.get("dead_ends", 0.0))
        ponder_hunger[t] = float(brain.hunger.mean().detach().cpu().item())
    
    # Rolling accuracy
    win = max(1, len(fwd))
    kern = torch.ones(win, dtype=torch.float32) / float(win)
    acc_smooth = torch.nn.functional.conv1d(
        acc.view(1, 1, -1), kern.view(1, 1, -1), padding=win // 2
    ).view(-1)[:steps]
    
    # Compute summary statistics
    pre_shift_acc = float(acc_smooth[shift_at - 100:shift_at].mean().item())
    post_shift_acc_immediate = float(acc_smooth[shift_at:shift_at + 50].mean().item())
    post_shift_acc_recovered = float(acc_smooth[shift_at + 200:shift_at + 300].mean().item()) if shift_at + 300 <= steps else float(acc_smooth[-100:].mean().item())
    
    # Find recovery point (first time accuracy returns to 80% of pre-shift)
    threshold = pre_shift_acc * 0.8
    recovery_step = None
    for t in range(shift_at, min(shift_at + 500, steps)):
        if float(acc_smooth[t].item()) >= threshold:
            recovery_step = t - shift_at
            break
    
    return {
        "config": asdict(cfg),
        "steps": steps,
        "shift_at": shift_at,
        "context_len": context_len,
        "vocab": vocab,
        "pre_shift_accuracy": pre_shift_acc,
        "post_shift_accuracy_immediate": post_shift_acc_immediate,
        "post_shift_accuracy_recovered": post_shift_acc_recovered,
        "recovery_steps": recovery_step,
        "final_chunks": int(chunks[-1].item()),
        "acc": acc.cpu().tolist(),
        "acc_smooth": acc_smooth.cpu().tolist(),
        "energy": energy.cpu().tolist(),
        "topo_entropy": topo.cpu().tolist(),
        "chunks": chunks.cpu().tolist(),
        "ponder_shortcuts": ponder_shortcuts.cpu().tolist(),
        "ponder_dead_ends": ponder_dead_ends.cpu().tolist(),
        "ponder_hunger_mean": ponder_hunger.cpu().tolist(),
    }


def generate_rule_shift_table(metrics: Dict[str, Any]) -> str:
    """Generate LaTeX table for rule shift results."""
    return r"""\begin{table}[t]
\centering
\caption{Rule-shift experiment results. The system adapts to a complete reversal of sequential structure at step """ + str(metrics.get('shift_at', 1000)) + r""".}
\label{tab:rule_shift}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Pre-shift accuracy & """ + f"{metrics.get('pre_shift_accuracy', 0):.1%}" + r""" \\
Post-shift accuracy (immediate) & """ + f"{metrics.get('post_shift_accuracy_immediate', 0):.1%}" + r""" \\
Post-shift accuracy (recovered) & """ + f"{metrics.get('post_shift_accuracy_recovered', 0):.1%}" + r""" \\
Steps to 80\% recovery & """ + f"{metrics.get('recovery_steps', 'N/A')}" + r""" \\
Final chunk count & """ + f"{metrics.get('final_chunks', 0)}" + r""" \\
\bottomrule
\end{tabular}
\end{table}
"""


def generate_rule_shift_figures(
    metrics: Dict[str, Any],
    figures_dir: Path,
) -> Dict[str, Path]:
    """Generate figures for rule shift experiment."""
    try:
        import matplotlib
        matplotlib.use('Agg')  # Non-interactive backend
        import matplotlib.pyplot as plt
        from matplotlib.backends.backend_pdf import PdfPages
    except ImportError:
        print("  [WARN] matplotlib not available, skipping figures")
        return {}
    
    figures = {}
    steps = metrics["steps"]
    shift_at = metrics["shift_at"]
    x = list(range(steps))
    
    # Figure 1: Main rule shift dynamics
    fig, (ax1, ax3) = plt.subplots(2, 1, figsize=(10, 6), sharex=True)
    ax2 = ax1.twinx()
    
    # Top panel: accuracy and system metrics
    ax1.plot(x, metrics["acc_smooth"], 'b-', label="Accuracy (rolling)", linewidth=1.5)
    ax1.axvline(shift_at, color='r', linestyle='--', alpha=0.7, label="Rule shift")
    ax1.set_ylim(0.0, 1.05)
    ax1.set_ylabel("Accuracy", color='b')
    ax1.tick_params(axis='y', labelcolor='b')
    
    ax2.plot(x, metrics["energy"], 'g-', alpha=0.6, label="System energy", linewidth=1)
    ax2.plot(x, metrics["topo_entropy"], 'm-', alpha=0.6, label="Topo. entropy", linewidth=1)
    ax2.set_ylabel("Energy / Entropy", color='g')
    ax2.tick_params(axis='y', labelcolor='g')
    
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=8)
    
    # Bottom panel: pondering metrics
    ax3.plot(x, metrics["ponder_shortcuts"], 'c-', label="Shortcuts/step", linewidth=1)
    ax3.plot(x, metrics["ponder_dead_ends"], 'orange', label="Dead ends/step", linewidth=1)
    ax3.plot(x, metrics["ponder_hunger_mean"], 'purple', label="Hunger (mean)", linewidth=1)
    ax3.axvline(shift_at, color='r', linestyle='--', alpha=0.7)
    ax3.set_xlabel("Time step")
    ax3.set_ylabel("Pondering metrics")
    ax3.legend(loc='upper right', fontsize=8)
    
    fig.tight_layout()
    
    # Save as PDF
    fig_path = figures_dir / "rule_shift.pdf"
    fig.savefig(fig_path, format='pdf', bbox_inches='tight', dpi=150)
    plt.close(fig)
    figures["rule_shift"] = fig_path
    print(f"  [FIGURE] rule_shift.pdf")
    
    # Figure 2: Pondering detail
    fig2, ax = plt.subplots(figsize=(8, 4))
    ax.fill_between(x, 0, metrics["ponder_shortcuts"], alpha=0.3, label="Shortcuts")
    ax.fill_between(x, 0, metrics["ponder_dead_ends"], alpha=0.3, label="Dead ends")
    ax.plot(x, metrics["ponder_hunger_mean"], 'k-', linewidth=1.5, label="Hunger")
    ax.axvline(shift_at, color='r', linestyle='--', alpha=0.7, label="Rule shift")
    ax.set_xlabel("Time step")
    ax.set_ylabel("Count / Mean")
    ax.set_title("Idle Pondering Behavior")
    ax.legend(loc='upper right')
    fig2.tight_layout()
    
    fig_path2 = figures_dir / "pondering.pdf"
    fig2.savefig(fig_path2, format='pdf', bbox_inches='tight', dpi=150)
    plt.close(fig2)
    figures["pondering"] = fig_path2
    print(f"  [FIGURE] pondering.pdf")
    
    return figures


def run_rule_shift_experiment(
    device: torch.device,
    tables_dir: Path,
    figures_dir: Path,
    steps: int = 2000,
    shift_at: int = 1000,
    context_len: int = 6,
    dt: float = 0.02,
):
    """
    Run the complete rule shift experiment and generate artifacts.
    """
    from .harness import ExperimentResult
    
    print("  Running rule shift simulation...")
    metrics = run_rule_shift(
        steps=steps,
        shift_at=shift_at,
        context_len=context_len,
        dt=dt,
        device=device,
    )
    
    print(f"  Pre-shift accuracy: {metrics['pre_shift_accuracy']:.1%}")
    print(f"  Post-shift (immediate): {metrics['post_shift_accuracy_immediate']:.1%}")
    print(f"  Post-shift (recovered): {metrics['post_shift_accuracy_recovered']:.1%}")
    if metrics['recovery_steps']:
        print(f"  Recovery steps: {metrics['recovery_steps']}")
    
    # Generate table
    table_content = generate_rule_shift_table(metrics)
    table_path = tables_dir / "rule_shift_summary.tex"
    table_path.write_text(table_content)
    print(f"  [TABLE] rule_shift_summary.tex")
    
    # Generate figures
    figures = generate_rule_shift_figures(metrics, figures_dir)
    
    # Save raw data as JSON
    json_path = figures_dir.parent / "rule_shift_data.json"
    # Only save summary, not full time series (too large)
    summary = {k: v for k, v in metrics.items() if not isinstance(v, list)}
    json_path.write_text(json.dumps(summary, indent=2))
    
    return ExperimentResult(
        name="Rule Shift",
        metrics=metrics,
        tables={"rule_shift_summary": table_content},
        figures=figures,
    )



---
File: /thermo_manifold/experiments/text_diffusion.py
---

"""Text Generation by Thermodynamic Annealing

This is an experimental, novel approach to text generation.
Instead of autoregressive next-token prediction, we:

1. Initialize with a noisy/random distribution of token particles
2. Let thermodynamic dynamics pull them toward attractors
3. The attractors are shaped by the prompt/context
4. Read out the final token sequence

This is NOT diffusion in the DDPM sense. It's thermodynamic annealing.
The text "crystallizes" from noise via energy minimization.

Goal: Generate coherent text from prompt via thermodynamic annealing.
Metrics: Perplexity of generated text, coherence (measured by continuation)
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.semantic.hierarchical import HierarchicalSemanticManifold

from .base import BaseExperiment, Scale


class TextDiffusionExperiment(BaseExperiment):
    """Text generation via thermodynamic annealing.
    
    EXPERIMENTAL: This is a novel approach, expect failures!
    """
    
    name = "text_diffusion"
    goal = "Generate text via thermodynamic annealing (experimental)"
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
    ):
        super().__init__(scale, device, seed)
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.vocab_size = 500
            self.context_length = 16
            self.gen_length = 8
            self.annealing_steps = 50
        elif scale == Scale.MEDIUM:
            self.vocab_size = 5000
            self.context_length = 32
            self.gen_length = 16
            self.annealing_steps = 100
        else:
            self.vocab_size = 20000
            self.context_length = 64
            self.gen_length = 32
            self.annealing_steps = 200
        
        self.vocab: List[str] = []
        self.token_to_id: Dict[str, int] = {}
    
    def setup(self) -> None:
        """Load dataset and build vocabulary."""
        try:
            from datasets import load_dataset
            from collections import Counter
        except ImportError:
            raise ImportError("Please install datasets: pip install datasets")
        
        print(f"    Loading wikitext-2-raw-v1...")
        
        # `trust_remote_code` is no longer supported by `datasets` for security reasons.
        dataset = load_dataset("wikitext", "wikitext-2-raw-v1", streaming=True)
        
        # Build vocabulary
        print(f"    Building vocabulary...")
        word_counts: Counter = Counter()
        sample_count = 0
        
        for sample in dataset["train"]:
            text = sample["text"]
            if not text.strip():
                continue
            tokens = text.split()
            word_counts.update(tokens)
            sample_count += 1
            if sample_count >= 5000:
                break
        
        special_tokens = ["<pad>", "<unk>", "<bos>", "<eos>", "<mask>"]
        self.vocab = special_tokens + [
            word for word, _ in word_counts.most_common(self.vocab_size - len(special_tokens))
        ]
        self.token_to_id = {token: i for i, token in enumerate(self.vocab)}
        
        print(f"    Vocabulary size: {len(self.vocab)}")
        
        # Prefetch and tokenize data
        self._train_sequences: List[List[int]] = []
        self._eval_sequences: List[List[int]] = []
        
        self._tokenize_stream(dataset["train"], self._train_sequences, 2000)
        self._tokenize_stream(dataset["validation"], self._eval_sequences, 500)
        
        print(f"    Train sequences: {len(self._train_sequences)}")
        print(f"    Eval sequences: {len(self._eval_sequences)}")
        
        # Initialize manifold
        self.manifold = HierarchicalSemanticManifold(
            self.physics_config,
            self.device,
            vocab=self.vocab,
            embed_dim=min(self.scale_config.embed_dim, len(self.vocab)),
            chunk_min_len=2,
            chunk_max_len=4,
        )

    def _think_until_complete(self, *, max_steps: int = 20) -> None:
        """Run grammar steps until confidence-based halting or max_steps.

        Note: `thinking_complete()` can be slow to converge in general, so we cap
        the number of steps for experiments.
        """
        max_steps = int(max_steps)
        if max_steps <= 0:
            return
        for _ in range(max_steps):
            self.manifold.step_grammar()
            try:
                if self.manifold.thinking_complete():
                    break
            except Exception:
                # If a subclass doesn't support the halting test, fall back to fixed steps.
                break
    
    def _tokenize_stream(
        self,
        stream,
        output: List[List[int]],
        max_samples: int,
    ) -> None:
        """Tokenize stream into sequences."""
        unk_id = self.token_to_id.get("<unk>", 1)
        
        for sample in stream:
            text = sample["text"]
            if not text.strip():
                continue
            
            tokens = text.split()
            if len(tokens) < self.context_length + self.gen_length:
                continue
            
            ids = [self.token_to_id.get(t, unk_id) for t in tokens]
            output.append(ids)
            
            if len(output) >= max_samples:
                break
    
    def train_iterator(self) -> Iterator[Tuple[List[int], List[int]]]:
        """Iterate over (context, target) pairs for annealing training."""
        for sequence in self._train_sequences:
            # Random starting point
            max_start = len(sequence) - self.context_length - self.gen_length
            if max_start <= 0:
                continue
            
            start = torch.randint(0, max_start, (1,)).item()
            context = sequence[start:start + self.context_length]
            target = sequence[start + self.context_length:start + self.context_length + self.gen_length]
            
            yield context, target
    
    def _run_grammar_steps(self, num_steps: int = 5) -> None:
        """Run a fixed number of grammar steps."""
        for _ in range(num_steps):
            self.manifold.step_grammar()
    
    def train_step(self, batch: Tuple[List[int], List[int]]) -> Dict[str, float]:
        """Training step for thermodynamic text annealing.
        
        The key insight: we train by showing the manifold complete sequences,
        so it learns the structure. Then at generation time, we use that
        structure to "anneal" from noise.
        """
        context, target = batch
        full_sequence = context + target
        
        # Process the full sequence through the manifold
        seq_tensor = torch.tensor(full_sequence, device=self.device, dtype=torch.long)
        self.manifold.ingest_ids(seq_tensor)
        self._run_grammar_steps(5)
        
        # Observe each transition (this builds the bond structure)
        for i in range(len(full_sequence) - 1):
            current = full_sequence[i]
            next_token = full_sequence[i + 1]
            
            # Get current prediction
            ctx = torch.tensor(full_sequence[:i+1], device=self.device, dtype=torch.long)
            self.manifold.ingest_ids(ctx)
            self._run_grammar_steps(5)
            output = self.manifold.output_state()
            
            # Observe (learn)
            self.manifold.observe_next_token(next_token, probs=output.probs)
        
        # Compute how well we can reconstruct
        correct = 0
        for i in range(len(target)):
            ctx_len = self.context_length + i
            ctx = torch.tensor(full_sequence[:ctx_len], device=self.device, dtype=torch.long)
            self.manifold.ingest_ids(ctx)
            self._run_grammar_steps(5)
            output = self.manifold.output_state()
            
            if output.token_index == target[i]:
                correct += 1
        
        accuracy = correct / len(target)
        
        # Occasionally ponder
        if self.state.step % 20 == 0:
            self.manifold.idle_think(steps=2, dream_steps=8)
        
        return {"accuracy": accuracy}
    
    def _generate_by_annealing(
        self, 
        context: List[int],
        temperature_schedule: Optional[List[float]] = None,
    ) -> List[int]:
        """Generate text by thermodynamic annealing.
        
        1. Start with random token candidates for each position
        2. Iteratively refine using manifold dynamics
        3. Lower "temperature" over time to crystallize the sequence
        """
        if temperature_schedule is None:
            # Exponential cooling schedule
            temperature_schedule = [
                1.0 * (0.9 ** i) for i in range(self.annealing_steps)
            ]
        
        # Initialize: random tokens for generation positions
        generated = [
            torch.randint(0, len(self.vocab), (1,)).item()
            for _ in range(self.gen_length)
        ]
        
        for step, temp in enumerate(temperature_schedule):
            # For each position, consider alternatives
            for pos in range(self.gen_length):
                # Build context for this position
                prefix = context + generated[:pos]
                
                ctx_tensor = torch.tensor(prefix, device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(ctx_tensor)
                
                # Run dynamics
                self._run_grammar_steps(5)
                
                output = self.manifold.output_state()
                probs = output.probs
                
                # Temperature-scaled sampling
                if temp > 0.01:
                    # Sample with temperature
                    scaled_logits = output.logits / temp
                    scaled_probs = torch.softmax(scaled_logits, dim=0)
                    
                    # Mix with current token (momentum)
                    current_prob = torch.zeros_like(scaled_probs)
                    current_prob[generated[pos]] = 0.5
                    mixed_probs = 0.5 * scaled_probs + current_prob
                    mixed_probs = mixed_probs / mixed_probs.sum()
                    
                    new_token = torch.multinomial(mixed_probs, 1).item()
                else:
                    # Greedy at low temperature
                    new_token = output.token_index
                
                generated[pos] = new_token
        
        return generated
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate generation quality."""
        total_accuracy = 0.0
        total_perplexity = 0.0
        count = 0
        
        for sequence in self._eval_sequences[:20]:
            if len(sequence) < self.context_length + self.gen_length:
                continue
            
            context = sequence[:self.context_length]
            target = sequence[self.context_length:self.context_length + self.gen_length]
            
            # Generate by annealing
            generated = self._generate_by_annealing(context)
            
            # Compare to target
            correct = sum(1 for g, t in zip(generated, target) if g == t)
            accuracy = correct / len(target)
            total_accuracy += accuracy
            
            # Compute perplexity of generated sequence
            log_prob_sum = 0.0
            full_gen = context + generated
            for i in range(len(context), len(full_gen) - 1):
                ctx = torch.tensor(full_gen[:i+1], device=self.device, dtype=torch.long)
                self.manifold.ingest_ids(ctx)
                self._think_until_complete(max_steps=20)
                output = self.manifold.output_state()
                
                next_token = full_gen[i + 1] if i + 1 < len(full_gen) else generated[-1]
                prob = output.probs[next_token].item()
                log_prob_sum += -torch.log(torch.tensor(prob + 1e-10)).item()
            
            if len(generated) > 1:
                avg_log_prob = log_prob_sum / (len(generated) - 1)
                perplexity = torch.exp(torch.tensor(avg_log_prob)).item()
                total_perplexity += perplexity
            
            count += 1
        
        if count == 0:
            return {"accuracy": 0.0, "perplexity": float("inf")}
        
        return {
            "accuracy": total_accuracy / count,
            "perplexity": total_perplexity / count,
            "samples_evaluated": count,
            "graph_edges": self.manifold.graph.num_edges,
            "chunks": self.manifold.chunks.num_chunks,
        }
    
    def generate_samples(self, num_samples: int = 5) -> List[str]:
        """Generate text samples for inspection."""
        samples = []
        
        for sequence in self._eval_sequences[:num_samples]:
            if len(sequence) < self.context_length + self.gen_length:
                continue
            
            context = sequence[:self.context_length]
            generated = self._generate_by_annealing(context)
            
            # Convert to text
            context_text = " ".join(self.vocab[i] for i in context)
            gen_text = " ".join(self.vocab[i] for i in generated)
            
            samples.append({
                "context": context_text,
                "generated": gen_text,
            })
        
        return samples


def run_text_diffusion_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = TextDiffusionExperiment(scale=scale, device=device)
    result = exp.run()
    
    # Generate some samples for inspection
    samples = exp.generate_samples(3)
    for i, sample in enumerate(samples):
        print(f"\n  Sample {i+1}:")
        print(f"    Context: ...{sample['context'][-50:]}")
        print(f"    Generated: {sample['generated']}")
    
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
        "samples": samples,
    }



---
File: /thermo_manifold/experiments/timeseries.py
---

"""Time Series Prediction Experiment

Uses the ETT (Electricity Transformer Temperature) dataset from HuggingFace.
This is a standard benchmark for time series forecasting.

Goal: Predict future values from context window.
Metrics: MSE, MAE
"""

from __future__ import annotations

from typing import Any, Dict, Iterator, List, Optional, Tuple

import torch
from torch.nn import functional as F

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.spectral.unified import UnifiedManifold, Modality

from .base import BaseExperiment, Scale, ScaleConfig


class TimeSeriesExperiment(BaseExperiment):
    """Time series prediction using thermodynamic dynamics.
    
    The approach:
    1. Treat each time step as a particle in 1D "value space"
    2. Context window creates attractors
    3. Predict by letting a query particle diffuse toward attractors
    4. Read out the final position as the predicted value
    """
    
    name = "timeseries"
    goal = "Predict future values from historical context"
    
    # Dataset config
    dataset_name = "ettm1"  # ETT-small dataset
    context_length = 96     # ~4 days at 15-min intervals
    prediction_length = 24  # ~1 day ahead
    
    def __init__(
        self,
        scale: Scale = Scale.TOY,
        device: Optional[torch.device] = None,
        seed: int = 42,
        feature: str = "OT",  # Oil Temperature (main target)
    ):
        super().__init__(scale, device, seed)
        self.feature = feature
        
        # Scale-specific configs
        if scale == Scale.TOY:
            self.context_length = 24
            self.prediction_length = 6
        elif scale == Scale.MEDIUM:
            self.context_length = 48
            self.prediction_length = 12
        else:
            self.context_length = 96
            self.prediction_length = 24
    
    def setup(self) -> None:
        """Load ETT dataset and initialize model."""
        try:
            from datasets import load_dataset
        except ImportError:
            raise ImportError(
                "Please install datasets: pip install datasets"
            )
        
        print(f"    Loading electricity dataset (streaming)...")
        
        # Use chronos_datasets which has proper parquet format
        # The 'monash_electricity_hourly' subset has hourly electricity consumption
        try:
            dataset = load_dataset(
                "autogluon/chronos_datasets",
                "monash_electricity_hourly",
                streaming=True,
            )
            self._use_real_data = True
            
            # Prepare data iterators
            self.train_stream = dataset["train"]
            
            # Buffer for streaming
            self._train_buffer: List[Dict] = []
            self._eval_buffer: List[Dict] = []
            self._train_iter = iter(self.train_stream)
            
            # Prefetch some data - each row is a full time series
            self._prefetch_buffer(self._train_buffer, self._train_iter, 100)
            
            # Extract values from the first time series
            if self._train_buffer and "target" in self._train_buffer[0]:
                # chronos format has 'target' as list of values
                all_values = []
                for row in self._train_buffer:
                    target = row.get("target", [])
                    if isinstance(target, list):
                        all_values.extend(target)
                    elif hasattr(target, "tolist"):
                        all_values.extend(target.tolist())
                
                if all_values:
                    self._mean = sum(all_values) / len(all_values)
                    self._std = (sum((v - self._mean)**2 for v in all_values) / len(all_values)) ** 0.5
                else:
                    self._mean, self._std = 0.0, 1.0
            else:
                self._mean, self._std = 0.0, 1.0
                
        except Exception as e:
            print(f"    Could not load real data: {e}")
            print(f"    Falling back to synthetic data")
            self._use_real_data = False
            self._train_buffer = []
            self._eval_buffer = []
            self._mean, self._std = 0.0, 1.0
        
        self._std = max(self._std, 1e-8)
        
        # Flatten time series data into single array
        self._train_values: List[float] = []
        self._eval_values: List[float] = []
        
        if self._use_real_data and self._train_buffer:
            for row in self._train_buffer:
                target = row.get("target", [])
                if isinstance(target, list):
                    self._train_values.extend(target)
                elif hasattr(target, "tolist"):
                    self._train_values.extend(target.tolist())
            
            # Use last 20% as eval
            split_idx = int(len(self._train_values) * 0.8)
            self._eval_values = self._train_values[split_idx:]
            self._train_values = self._train_values[:split_idx]
        else:
            # Generate synthetic data
            self._train_values = self._generate_synthetic_series(5000)
            self._eval_values = self._generate_synthetic_series(1000)
        
        print(f"    Using real data: {self._use_real_data}")
        print(f"    Train values: {len(self._train_values)}")
        print(f"    Eval values: {len(self._eval_values)}")
        print(f"    Mean: {self._mean:.4f}, Std: {self._std:.4f}")
        print(f"    Context: {self.context_length}, Prediction: {self.prediction_length}")
        
        # Initialize manifold
        self.manifold = UnifiedManifold(
            self.physics_config,
            self.device,
            embed_dim=self.scale_config.embed_dim,
        )
    
    def _prefetch_buffer(
        self, 
        buffer: List[Dict], 
        iterator: Iterator,
        count: int,
    ) -> None:
        """Prefetch data into buffer."""
        for _ in range(count):
            try:
                buffer.append(next(iterator))
            except StopIteration:
                break
    
    def _generate_synthetic_series(self, length: int) -> List[float]:
        """Generate synthetic time series for testing."""
        import math
        values = []
        for t in range(length):
            # Mix of trends, seasonality, and noise
            trend = 0.001 * t
            daily = math.sin(2 * math.pi * t / 24) * 0.5
            weekly = math.sin(2 * math.pi * t / (24 * 7)) * 0.3
            noise = (torch.randn(1).item()) * 0.1
            values.append(trend + daily + weekly + noise)
        return values
    
    def _normalize(self, value: float) -> float:
        return (value - self._mean) / self._std
    
    def _denormalize(self, value: float) -> float:
        return value * self._std + self._mean
    
    def _get_window(self, values: List[float], start: int) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:
        """Extract context and target windows from flat value list."""
        total_len = self.context_length + self.prediction_length
        
        if start + total_len > len(values):
            return None
        
        context = torch.tensor([
            self._normalize(values[start + i])
            for i in range(self.context_length)
        ], dtype=torch.float32, device=self.device)
        
        target = torch.tensor([
            self._normalize(values[start + self.context_length + i])
            for i in range(self.prediction_length)
        ], dtype=torch.float32, device=self.device)
        
        return context, target
    
    def train_iterator(self) -> Iterator[Tuple[torch.Tensor, torch.Tensor]]:
        """Iterate over training windows."""
        max_samples = self.scale_config.max_train_samples or len(self._train_values)
        total_len = self.context_length + self.prediction_length
        
        # Sliding windows over the flat value array
        for start in range(0, min(max_samples, len(self._train_values) - total_len)):
            window = self._get_window(self._train_values, start)
            if window is not None:
                yield window
    
    def train_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -> Dict[str, float]:
        """One step of thermodynamic time series learning."""
        context, target = batch
        
        # Clear manifold
        self.manifold.clear()
        
        # Encode context as particles
        # Position = (time_index, value)
        for t, value in enumerate(context):
            position = torch.tensor([float(t), value.item()], device=self.device)
            self.manifold.add_particle(
                position=position,
                energy=1.0 / len(context),
                modality=Modality.UNKNOWN,
            )
        
        # Add attractors at context positions (for diffusion)
        for t, value in enumerate(context):
            position = torch.tensor([float(t), value.item()], device=self.device)
            self.manifold.add_attractor(
                position=position,
                energy=1.0 / len(context),
            )
        
        # Run thermodynamic dynamics
        for _ in range(5):
            self.manifold.step()
        
        # Predict: add query particles at future time indices
        predictions = []
        for t in range(self.prediction_length):
            query_time = self.context_length + t
            
            # Initialize query at extrapolated position
            if len(context) >= 2:
                # Simple linear extrapolation for initial position
                slope = (context[-1] - context[-2]).item()
                init_value = context[-1].item() + slope * (t + 1)
            else:
                init_value = context[-1].item()
            
            query_pos = torch.tensor([float(query_time), init_value], device=self.device)
            self.manifold.add_particle(
                position=query_pos,
                energy=1.0,
                modality=Modality.UNKNOWN,
            )
        
        # Let queries diffuse
        for _ in range(10):
            self.manifold.step()
        
        # Read out predictions (from last prediction_length particles)
        for i in range(self.prediction_length):
            idx = len(context) + i
            if idx < len(self.manifold._particles):
                pred_value = self.manifold._particles[idx].position[1].item()
                predictions.append(pred_value)
            else:
                predictions.append(0.0)
        
        predictions = torch.tensor(predictions, device=self.device)
        
        # Compute loss (for monitoring, not for gradients!)
        mse = F.mse_loss(predictions, target).item()
        mae = F.l1_loss(predictions, target).item()
        
        return {"mse": mse, "mae": mae}
    
    def evaluate(self) -> Dict[str, float]:
        """Evaluate on eval set."""
        mse_total = 0.0
        mae_total = 0.0
        count = 0
        
        total_len = self.context_length + self.prediction_length
        max_samples = self.scale_config.max_eval_samples or len(self._eval_values)
        
        # Step by total_len to get non-overlapping windows
        for start in range(0, min(max_samples, len(self._eval_values) - total_len), total_len):
            window = self._get_window(self._eval_values, start)
            if window is None:
                break
            
            context, target = window
            
            # Same as train_step but without recording history
            self.manifold.clear()
            
            for t, value in enumerate(context):
                position = torch.tensor([float(t), value.item()], device=self.device)
                self.manifold.add_particle(position=position, energy=1.0/len(context))
                self.manifold.add_attractor(position=position, energy=1.0/len(context))
            
            for _ in range(5):
                self.manifold.step()
            
            predictions = []
            for t in range(self.prediction_length):
                query_time = self.context_length + t
                if len(context) >= 2:
                    slope = (context[-1] - context[-2]).item()
                    init_value = context[-1].item() + slope * (t + 1)
                else:
                    init_value = context[-1].item()
                
                query_pos = torch.tensor([float(query_time), init_value], device=self.device)
                self.manifold.add_particle(position=query_pos, energy=1.0)
            
            for _ in range(10):
                self.manifold.step()
            
            for i in range(self.prediction_length):
                idx = len(context) + i
                if idx < len(self.manifold._particles):
                    predictions.append(self.manifold._particles[idx].position[1].item())
                else:
                    predictions.append(0.0)
            
            predictions = torch.tensor(predictions, device=self.device)
            
            mse_total += F.mse_loss(predictions, target).item()
            mae_total += F.l1_loss(predictions, target).item()
            count += 1
        
        if count == 0:
            return {"mse": float("nan"), "mae": float("nan")}
        
        return {
            "mse": mse_total / count,
            "mae": mae_total / count,
            "rmse": (mse_total / count) ** 0.5,
            "eval_samples": count,
        }


def run_timeseries_experiment(
    scale: Scale = Scale.TOY,
    device: Optional[torch.device] = None,
) -> Dict[str, Any]:
    """Convenience function to run the experiment."""
    exp = TimeSeriesExperiment(scale=scale, device=device)
    result = exp.run()
    return {
        "result": result,
        "success": result.success,
        "metrics": result.metrics,
    }



---
File: /thermo_manifold/physics/__init__.py
---

"""Physics engine for thermodynamic dynamics."""

from .engine import ThermodynamicEngine, PhysicsStepStats

__all__ = ["ThermodynamicEngine", "PhysicsStepStats"]



---
File: /thermo_manifold/physics/engine.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Tuple

import torch

from ..core.config import PhysicsConfig
from ..core.state import BatchState
from ..core.scatter import scatter_sum, segment_softmax


@dataclass
class PhysicsStepStats:
    edges: int
    heat_level: float
    sharpness: float
    energy_ratio: float


class ThermodynamicEngine:
    """Domain-agnostic thermodynamic engine with sparse interactions.

    Core design:
    - Interactions are expressed as an edge list (particle -> attractor).
    - The engine never materializes an NxM distance matrix unless a subclass chooses to.
    """

    def __init__(self, config: PhysicsConfig, device: torch.device):
        self.cfg = config
        self.device = device
        self.t = 0.0

        self.particles = BatchState.empty()
        self.attractors = BatchState.empty()

        # Homeostasis baseline (scalar)
        self._energy_baseline: Optional[torch.Tensor] = None

        # Slow-moving, global scales (EMA) to avoid per-step renormalization.
        self._dist_scale: Optional[torch.Tensor] = None
        self._pos_disp_scale: Optional[torch.Tensor] = None
        self._motion_scale: Optional[torch.Tensor] = None
        self._heat_abs_scale: Optional[torch.Tensor] = None
        self._energy_abs_scale: Optional[torch.Tensor] = None

        self.last_stats: Optional[PhysicsStepStats] = None

    def _ema_update(self, prev: Optional[torch.Tensor], cur: torch.Tensor, *, tau: float) -> torch.Tensor:
        dt = float(self.cfg.dt)
        if prev is None:
            return cur.detach().clone()
        alpha = dt / (float(tau) + dt)
        return (1.0 - alpha) * prev.to(cur.dtype) + alpha * cur.detach()

    def _update_global_scales(self, *, dists: Optional[torch.Tensor] = None, drift: Optional[torch.Tensor] = None) -> None:
        """Update slow global scales used inside inner loops.

        This decouples stabilizing normalization from per-step instantaneous means.
        """
        eps = self.cfg.eps
        med = self.cfg.medium
        tau = float(med.scale_tau)
        min_scale = float(med.min_scale)

        if dists is not None and dists.numel() > 0:
            cur = torch.std(dists.to(torch.float32)).clamp(min=min_scale) + eps
            self._dist_scale = self._ema_update(self._dist_scale, cur, tau=tau)

        # Position dispersion scale (for diffusion noise amplitude).
        if self.particles.has("position") and self.particles.get("position").numel() > 0:
            pos = self.particles.get("position").to(torch.float32)
            cur = torch.std(pos).clamp(min=min_scale) + eps
            self._pos_disp_scale = self._ema_update(self._pos_disp_scale, cur, tau=tau)

        # Motion scale (for motion->heat conversion).
        if drift is not None and drift.numel() > 0:
            if drift.ndim == 1:
                motion = drift.abs()
            else:
                motion = torch.linalg.norm(drift, dim=1)
            cur = motion.abs().mean().clamp(min=min_scale) + eps
            self._motion_scale = self._ema_update(self._motion_scale, cur, tau=tau)

        # Heat absolute scale (for cooling / diffusion normalization).
        heat_terms: list[torch.Tensor] = []
        if self.particles.has("heat") and self.particles.get("heat").numel() > 0:
            heat_terms.append(self.particles.get("heat").abs().mean().to(torch.float32))
        if self.attractors.has("heat") and self.attractors.get("heat").numel() > 0:
            heat_terms.append(self.attractors.get("heat").abs().mean().to(torch.float32))
        if heat_terms:
            cur = (torch.stack(heat_terms).mean()).clamp(min=min_scale) + eps
        else:
            cur = torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32).clamp(min=min_scale) + eps
        self._heat_abs_scale = self._ema_update(self._heat_abs_scale, cur, tau=tau)

        # Energy absolute scale (for energy damping normalization).
        energy_terms: list[torch.Tensor] = []
        if self.particles.has("energy") and self.particles.get("energy").numel() > 0:
            energy_terms.append(self.particles.get("energy").abs().mean().to(torch.float32))
        if self.attractors.has("energy") and self.attractors.get("energy").numel() > 0:
            energy_terms.append(self.attractors.get("energy").abs().mean().to(torch.float32))
        if energy_terms:
            cur_e = (torch.stack(energy_terms).mean()).clamp(min=min_scale) + eps
        else:
            cur_e = torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32).clamp(min=min_scale) + eps
        self._energy_abs_scale = self._ema_update(self._energy_abs_scale, cur_e, tau=tau)

    def _effective_homeostasis_tau(self, *, plasticity_gate: Optional[torch.Tensor]) -> float:
        """Return homeostasis baseline update time constant with optional plasticity."""
        tau = float(self.cfg.tau)
        if plasticity_gate is None:
            return tau
        g = float(plasticity_gate.detach().to(torch.float32).clamp(0.0, 1.0).item())
        return tau * (1.0 + float(self.cfg.homeostasis_tau_gain) * g)

    def _homeostasis_strength(self, *, plasticity_gate: Optional[torch.Tensor]) -> torch.Tensor:
        """Return multiplicative factor applied to damping strength (<= 1)."""
        if plasticity_gate is None:
            return torch.tensor(1.0, device=self.device, dtype=torch.float32)
        g = plasticity_gate.to(device=self.device, dtype=torch.float32).clamp(0.0, 1.0)
        return 1.0 / (1.0 + float(self.cfg.homeostasis_strength_gain) * g)

    # ----------------------------
    # Hooks for subclasses
    # ----------------------------

    def candidate_edges(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """Return (src_idx, dst_idx) edge list for particle-attractor interactions.

        Default: all-to-all (only appropriate for small systems).
        """
        n = self.particles.n
        m = self.attractors.n
        if n == 0 or m == 0:
            return (
                torch.empty(0, dtype=torch.long, device=self.device),
                torch.empty(0, dtype=torch.long, device=self.device),
            )
        src = torch.arange(n, device=self.device, dtype=torch.long).repeat_interleave(m)
        dst = torch.arange(m, device=self.device, dtype=torch.long).repeat(n)
        return src, dst

    def distance(self, p_pos: torch.Tensor, a_pos: torch.Tensor) -> torch.Tensor:
        """Per-edge distance metric. Subclasses should override."""
        d = p_pos - a_pos
        if d.ndim == 1:
            return d.abs()
        return torch.linalg.norm(d, dim=1)

    def post_step(self) -> None:
        """Optional cleanup after physics step (e.g., TTL)."""
        return

    # ----------------------------
    # Homeostasis
    # ----------------------------

    def total_energy(self) -> torch.Tensor:
        """Total energy proxy used for homeostasis."""
        total = torch.tensor(0.0, device=self.device, dtype=torch.float32)
        if self.particles.has("energy"):
            total = total + self.particles.get("energy").sum().to(torch.float32)
        if self.attractors.has("energy"):
            total = total + self.attractors.get("energy").sum().to(torch.float32)
        return total

    def _homeostasis_ratio(self, *, plasticity_gate: Optional[torch.Tensor] = None) -> torch.Tensor:
        """Update baseline once and return E / baseline.

        Uses a fixed time constant to avoid runaway feedback loops.
        """
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        e = self.total_energy().to(torch.float32)
        if self._energy_baseline is None:
            self._energy_baseline = e.detach().clone()
            return torch.tensor(1.0, device=self.device, dtype=torch.float32)
        base = self._energy_baseline.to(torch.float32)
        ratio = torch.log1p(e) / (torch.log1p(base) + eps)
        tau_eff = self._effective_homeostasis_tau(plasticity_gate=plasticity_gate)
        alpha = dt / (tau_eff + dt)
        self._energy_baseline = (1 - alpha) * base + alpha * e.detach()
        strength = self._homeostasis_strength(plasticity_gate=plasticity_gate)
        return (ratio * strength).clamp(min=eps)

    def step_physics(self) -> None:
        """Advance one thermodynamic step."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        med = self.cfg.medium

        n = self.particles.n
        m = self.attractors.n
        if n == 0 or m == 0:
            self.t += dt
            self.last_stats = PhysicsStepStats(edges=0, heat_level=0.0, sharpness=0.0, energy_ratio=1.0)
            return

        # Compute ratio once per step (thermostat).
        ratio = self._homeostasis_ratio().to(torch.float32)

        src, dst = self.candidate_edges()
        if src.numel() == 0:
            self.t += dt
            self.last_stats = PhysicsStepStats(edges=0, heat_level=0.0, sharpness=0.0, energy_ratio=float(ratio.item()))
            return

        p_pos = self.particles.get("position")[src]
        a_pos = self.attractors.get("position")[dst]

        dists = self.distance(p_pos, a_pos)  # [E]
        # Update slow-moving scales before using them.
        self._update_global_scales(dists=dists.to(torch.float32))

        d_scale = (self._dist_scale if self._dist_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
        sharpness = 1.0 / d_scale

        logits = -dists * sharpness
        w = segment_softmax(logits, src, n, eps=eps)  # [E], sum per particle = 1

        # Targets: weighted average of attractor positions per particle.
        a_pos_full = self.attractors.get("position")
        a_gather = a_pos_full[dst]
        if a_gather.ndim == 1:
            contrib = a_gather * w
        else:
            contrib = a_gather * w.unsqueeze(1)
        targets = scatter_sum(contrib, src, n)  # [N, ...]

        cur = self.particles.get("position")
        drift = targets - cur

        # Brownian diffusion scale emerges from current dispersion and heat.
        self._update_global_scales(drift=drift.to(torch.float32))
        disp = (self._pos_disp_scale if self._pos_disp_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
        noise = torch.randn_like(cur) * disp
        heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
        # Dimensionless temperature proxy: current heat relative to slow heat scale.
        heat_mean = torch.tensor(0.0, device=self.device, dtype=torch.float32)
        if self.particles.has("heat") and self.particles.get("heat").numel() > 0:
            heat_mean = self.particles.get("heat").abs().mean().to(torch.float32)
        elif self.attractors.has("heat") and self.attractors.get("heat").numel() > 0:
            heat_mean = self.attractors.get("heat").abs().mean().to(torch.float32)
        temperature = (heat_mean / heat_scale).clamp(min=0.0)
        noise = noise * (1.0 + temperature)

        visc = float(med.viscosity) if float(med.viscosity) > 0 else 1.0
        self.particles.set("position", cur + (dt / visc) * drift + dt * noise)

        # Particle heat update: motion -> heat; heat diffuses via binding.
        if self.particles.has("heat"):
            p_heat = self.particles.get("heat")
            motion = drift.abs() if drift.ndim == 1 else torch.linalg.norm(drift, dim=1)
            motion_scale = (self._motion_scale if self._motion_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
            p_heat = p_heat + dt * (motion / motion_scale)

            if self.attractors.has("heat"):
                a_heat = self.attractors.get("heat")
                # Project attractor heat onto particles via binding.
                h_in = scatter_sum((a_heat[dst] * w), src, n)
                heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
                p_heat = p_heat + (dt / float(med.thermal_resistance if float(med.thermal_resistance) > 0 else 1.0)) * (h_in - p_heat) / heat_scale

            # Homeostatic cooling.
            heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
            cool_tau = float(med.thermal_resistance if float(med.thermal_resistance) > 0 else 1.0) * heat_scale
            p_heat = p_heat * torch.exp(-dt * ratio.to(p_heat.dtype) / (cool_tau.to(p_heat.dtype) + eps))
            self.particles.set("heat", p_heat)

        # Attractor energy and heat receive weighted inflow.
        self.update_thermodynamics(src, dst, w, ratio=ratio.to(w.dtype))

        self.post_step()
        self.t += dt

        self.last_stats = PhysicsStepStats(
            edges=int(src.numel()),
            heat_level=float(temperature.detach().cpu().item()),
            sharpness=float(sharpness.detach().cpu().item()),
            energy_ratio=float(ratio.detach().cpu().item()),
        )

    def update_thermodynamics(self, src: torch.Tensor, dst: torch.Tensor, w: torch.Tensor, *, ratio: torch.Tensor) -> None:
        """Energy/heat flow between particles and attractors (edge-based)."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        med = self.cfg.medium

        m = self.attractors.n
        if m == 0:
            return

        # Energy inflow: weighted by particle energy if present; otherwise by binding mass.
        if self.particles.has("energy"):
            p_e = self.particles.get("energy")
            flow = w * p_e[src]
        else:
            flow = w

        e_in = scatter_sum(flow, dst, m)  # [M]

        a_e = self.attractors.ensure("energy", m, device=self.device, dtype=e_in.dtype)
        self._update_global_scales()
        e_scale = (self._energy_abs_scale if self._energy_abs_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
        a_e = (a_e + dt * e_in) * torch.exp(-dt * ratio / (e_scale.to(ratio.dtype) + eps))
        self.attractors.set("energy", a_e)

        if self.attractors.has("heat"):
            a_h = self.attractors.get("heat")
            if self.particles.has("heat"):
                p_h = self.particles.get("heat")
                h_flow = w * p_h[src]
            else:
                h_flow = w
            h_in = scatter_sum(h_flow, dst, m)
            h_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else torch.tensor(float(med.baseline_energy_scale), device=self.device, dtype=torch.float32)).clamp(min=float(med.min_scale)) + eps
            a_h = (a_h + dt * h_in) * torch.exp(-dt * ratio / (h_scale.to(ratio.dtype) + eps))
            self.attractors.set("heat", a_h)



---
File: /thermo_manifold/semantic/__init__.py
---

"""Semantic manifolds for token-level thermodynamics."""

from .manifold import SemanticManifold, SemanticOutput
from .hierarchical import HierarchicalSemanticManifold
from .bond_graph import SparseBondGraph
from .bipartite_graph import SparseBipartiteBondGraph
from .chunk_store import ChunkStore

__all__ = [
    "SemanticManifold",
    "SemanticOutput",
    "HierarchicalSemanticManifold",
    "SparseBondGraph",
    "SparseBipartiteBondGraph",
    "ChunkStore",
]



---
File: /thermo_manifold/semantic/bipartite_graph.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional

import torch


def _isin_sorted(query: torch.Tensor, sorted_set: torch.Tensor) -> torch.Tensor:
    """Vectorized membership test: query in sorted_set.

    Both tensors must be 1D on the same device.
    """

    if query.numel() == 0:
        return torch.zeros(0, device=query.device, dtype=torch.bool)
    if sorted_set.numel() == 0:
        return torch.zeros_like(query, dtype=torch.bool)

    idx = torch.searchsorted(sorted_set, query)
    in_range = idx < sorted_set.numel()
    idx_safe = idx.clamp(max=max(int(sorted_set.numel()) - 1, 0))
    hit = sorted_set[idx_safe] == query
    return in_range & hit


@dataclass
class BipartiteBatch:
    eidx: torch.Tensor
    src: torch.Tensor
    dst: torch.Tensor
    w: torch.Tensor
    trace: torch.Tensor


class SparseBipartiteBondGraph:
    """GPU-friendly sparse directed bipartite bond graph.

    src nodes: 0..num_src-1
    dst nodes: 0..num_dst-1

    Edge key is encoded as: key = src*num_dst + dst (fits in int64 for realistic sizes
    when src is a compact index).

    This is used for hierarchical chunks: chunk_index -> token_id.
    """

    def __init__(self, *, num_src: int, num_dst: int, device: torch.device, dtype: torch.dtype, eps: float):
        self.num_src = int(num_src)
        self.num_dst = int(num_dst)
        self.device = device
        self.dtype = dtype
        self.eps = float(eps)

        self.key = torch.empty(0, device=device, dtype=torch.long)
        self.src = torch.empty(0, device=device, dtype=torch.long)
        self.dst = torch.empty(0, device=device, dtype=torch.long)
        self.w = torch.empty(0, device=device, dtype=dtype)
        self.trace = torch.empty(0, device=device, dtype=dtype)

    @property
    def num_edges(self) -> int:
        return int(self.key.numel())

    def set_num_src(self, num_src: int) -> None:
        self.num_src = int(num_src)

    # ----------------------------
    # Insertion (vectorized)
    # ----------------------------

    def add_edges(self, src: torch.Tensor, dst: torch.Tensor, mass: torch.Tensor) -> None:
        """Add or reinforce edges.

        src, dst: [E]
        mass: scalar or [E]
        """

        src = src.to(device=self.device, dtype=torch.long).flatten()
        dst = dst.to(device=self.device, dtype=torch.long).flatten()
        if src.numel() == 0:
            return
        if src.shape != dst.shape:
            raise ValueError("src and dst must have the same shape")

        mass = mass.to(device=self.device, dtype=self.dtype)
        if mass.numel() == 1:
            mass = mass.expand_as(src).contiguous()
        else:
            mass = mass.flatten()
            if mass.shape != src.shape:
                raise ValueError("mass must be scalar or have the same shape as src/dst")

        if self.num_src <= 0:
            return

        src = src.clamp(min=0, max=self.num_src - 1)
        dst = dst.clamp(min=0, max=self.num_dst - 1)

        key_new = src * self.num_dst + dst

        # Coalesce duplicates in the new batch.
        order = torch.argsort(key_new)
        key_new = key_new[order]
        src = src[order]
        dst = dst[order]
        mass = mass[order]

        key_u, inv = torch.unique_consecutive(key_new, return_inverse=True)
        if key_u.numel() != key_new.numel():
            mass_u = torch.zeros(int(key_u.numel()), device=self.device, dtype=self.dtype)
            mass_u.index_add_(0, inv, mass)
            src_u = (key_u // self.num_dst).to(torch.long)
            dst_u = (key_u % self.num_dst).to(torch.long)
        else:
            mass_u = mass
            src_u = src
            dst_u = dst

        # Observation gives immediate eligibility.
        trace_u = mass_u.clone()

        if self.num_edges == 0:
            self.key = key_u
            self.src = src_u
            self.dst = dst_u
            self.w = mass_u
            self.trace = trace_u
            return

        # Locate keys in existing sorted key vector.
        pos = torch.searchsorted(self.key, key_u)
        exists = (pos < self.key.numel()) & (self.key[pos.clamp(max=self.key.numel() - 1)] == key_u)

        if exists.any():
            p = pos[exists]
            self.w[p] = self.w[p] + mass_u[exists]
            self.trace[p] = self.trace[p] + mass_u[exists]

        add_mask = ~exists
        if not add_mask.any():
            return

        key_add = key_u[add_mask]
        src_add = src_u[add_mask]
        dst_add = dst_u[add_mask]
        w_add = mass_u[add_mask]
        tr_add = trace_u[add_mask]
        pos_add = pos[add_mask]

        old_n = int(self.num_edges)
        add_n = int(key_add.numel())
        merged_n = old_n + add_n

        new_pos = pos_add + torch.arange(add_n, device=self.device, dtype=torch.long)
        old_i = torch.arange(old_n, device=self.device, dtype=torch.long)
        shift = torch.searchsorted(pos_add, old_i, right=True)
        old_pos = old_i + shift

        key_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        src_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        dst_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        w_m = torch.empty(merged_n, device=self.device, dtype=self.dtype)
        tr_m = torch.empty(merged_n, device=self.device, dtype=self.dtype)

        key_m[old_pos] = self.key
        src_m[old_pos] = self.src
        dst_m[old_pos] = self.dst
        w_m[old_pos] = self.w
        tr_m[old_pos] = self.trace

        key_m[new_pos] = key_add
        src_m[new_pos] = src_add
        dst_m[new_pos] = dst_add
        w_m[new_pos] = w_add
        tr_m[new_pos] = tr_add

        self.key, self.src, self.dst, self.w, self.trace = key_m, src_m, dst_m, w_m, tr_m

    # ----------------------------
    # Query
    # ----------------------------

    def batch_edges(self, src_ids: torch.Tensor) -> Optional[BipartiteBatch]:
        """Collect all outgoing edges for provided sources."""
        if src_ids.numel() == 0 or self.num_edges == 0:
            return None
        src_ids = torch.unique(src_ids.to(device=self.device, dtype=torch.long).flatten())
        src_sorted, _ = torch.sort(src_ids)
        mask = _isin_sorted(self.src, src_sorted)
        if not bool(mask.any()):
            return None
        eidx = torch.nonzero(mask, as_tuple=False).flatten()
        return BipartiteBatch(eidx=eidx, src=self.src[eidx], dst=self.dst[eidx], w=self.w[eidx], trace=self.trace[eidx])

    # ----------------------------
    # Updates
    # ----------------------------

    def update_edges(self, eidx: torch.Tensor, w_new: torch.Tensor, trace_new: torch.Tensor) -> None:
        self.w[eidx] = w_new
        self.trace[eidx] = trace_new

    def prune_by_src_mean(self, src_ids: torch.Tensor) -> None:
        """Prune weak edges using per-source adaptive threshold (no fixed constants).

        Keeps edges with w >= mean(w_out(src)) - std(w_out(src)).
        """
        batch = self.batch_edges(src_ids)
        if batch is None:
            return

        eps = self.eps
        s = batch.src
        w = batch.w

        s_u, inv = torch.unique(s, return_inverse=True)
        out_sum = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sum.index_add_(0, inv, w)
        count = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        count.index_add_(0, inv, torch.ones_like(w))
        mean = out_sum / (count + eps)

        out_sq = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sq.index_add_(0, inv, w * w)
        ex2 = out_sq / (count + eps)
        var = (ex2 - mean * mean).clamp(min=0.0)
        std = torch.sqrt(var + eps)
        # Numerical slack so the minimum edge in a 2-edge fanout isn't dropped by roundoff.
        thresh = (mean - std) - eps
        keep = w >= thresh[inv]
        if bool(keep.all()):
            return

        pruned = batch.eidx[~keep]
        if pruned.numel() == 0:
            return
        self.w[pruned] = torch.zeros_like(self.w[pruned])
        self.trace[pruned] = torch.zeros_like(self.trace[pruned])

    def compact(self) -> None:
        """Physically remove zeroed edges."""
        if self.num_edges == 0:
            return
        keep = (self.w > 0) | (self.trace != 0)
        if bool(keep.all()):
            return
        self.key = self.key[keep]
        self.src = self.src[keep]
        self.dst = self.dst[keep]
        self.w = self.w[keep]
        self.trace = self.trace[keep]

    # ----------------------------
    # Flow
    # ----------------------------

    def flow_from_distribution(self, dist: torch.Tensor) -> torch.Tensor:
        """One-step flow from a distribution over src into dst mass."""

        out = torch.zeros(self.num_dst, device=self.device, dtype=self.dtype)

        dist = dist.to(device=self.device, dtype=self.dtype).flatten()
        if self.num_edges == 0 or dist.numel() == 0:
            return out

        # Restrict to sources with nonzero mass.
        src_ids = torch.nonzero(dist > 0, as_tuple=False).flatten()
        batch = self.batch_edges(src_ids)
        if batch is None:
            return out

        eps = self.eps
        s = batch.src
        d = batch.dst
        w = batch.w

        s_u, inv = torch.unique(s, return_inverse=True)
        out_sum = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sum.index_add_(0, inv, w)
        w_norm = w / (out_sum[inv] + eps)

        contrib = dist[s] * w_norm
        out.index_add_(0, d, contrib)
        return out



---
File: /thermo_manifold/semantic/bond_graph.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Tuple

import torch


def _isin_sorted(query: torch.Tensor, sorted_set: torch.Tensor) -> torch.Tensor:
    """Vectorized membership test: query in sorted_set.

    Both tensors must be 1D on the same device.
    """

    if query.numel() == 0:
        return torch.zeros(0, device=query.device, dtype=torch.bool)
    if sorted_set.numel() == 0:
        return torch.zeros_like(query, dtype=torch.bool)

    idx = torch.searchsorted(sorted_set, query)
    in_range = idx < sorted_set.numel()
    idx_safe = idx.clamp(max=max(int(sorted_set.numel()) - 1, 0))
    hit = sorted_set[idx_safe] == query
    return in_range & hit


@dataclass
class BondBatch:
    eidx: torch.Tensor
    src: torch.Tensor
    dst: torch.Tensor
    w: torch.Tensor
    trace: torch.Tensor


class SparseBondGraph:
    """GPU-friendly sparse directed bond graph.

    Goals:
    - No Python dicts or per-edge loops.
    - Dynamic insertion via sorted-key merge (no full re-sort of the whole graph).
    - Edge-local state: mass (w) and eligibility trace.
    """

    def __init__(self, num_nodes: int, *, device: torch.device, dtype: torch.dtype, eps: float):
        self.num_nodes = int(num_nodes)
        self.device = device
        self.dtype = dtype
        self.eps = float(eps)

        # Sorted by key = src*num_nodes + dst.
        self.key = torch.empty(0, device=device, dtype=torch.long)
        self.src = torch.empty(0, device=device, dtype=torch.long)
        self.dst = torch.empty(0, device=device, dtype=torch.long)
        self.w = torch.empty(0, device=device, dtype=dtype)
        self.trace = torch.empty(0, device=device, dtype=dtype)

    @property
    def num_edges(self) -> int:
        return int(self.key.numel())

    # ----------------------------
    # Insertion (vectorized)
    # ----------------------------

    def add_edges(self, src: torch.Tensor, dst: torch.Tensor, mass: torch.Tensor) -> None:
        """Add or reinforce edges.

        src, dst: [E]
        mass: scalar or [E]
        """

        src = src.to(device=self.device, dtype=torch.long).flatten()
        dst = dst.to(device=self.device, dtype=torch.long).flatten()
        if src.numel() == 0:
            return

        if src.shape != dst.shape:
            raise ValueError("src and dst must have the same shape")

        mass = mass.to(device=self.device, dtype=self.dtype)
        if mass.numel() == 1:
            mass = mass.expand_as(src).contiguous()
        else:
            mass = mass.flatten()
            if mass.shape != src.shape:
                raise ValueError("mass must be scalar or have the same shape as src/dst")

        # Clamp node IDs into range.
        src = src.clamp(min=0, max=self.num_nodes - 1)
        dst = dst.clamp(min=0, max=self.num_nodes - 1)

        key_new = src * self.num_nodes + dst

        # Coalesce duplicates in the *new* batch (typically small).
        order = torch.argsort(key_new)
        key_new = key_new[order]
        src = src[order]
        dst = dst[order]
        mass = mass[order]

        key_u, inv = torch.unique_consecutive(key_new, return_inverse=True)
        if key_u.numel() != key_new.numel():
            mass_u = torch.zeros(int(key_u.numel()), device=self.device, dtype=self.dtype)
            mass_u.index_add_(0, inv, mass)
            # src/dst can be reconstructed from key_u.
            src_u = (key_u // self.num_nodes).to(torch.long)
            dst_u = (key_u % self.num_nodes).to(torch.long)
        else:
            mass_u = mass
            src_u = src
            dst_u = dst

        # New edges start with trace equal to their injected mass (eligibility from observation).
        trace_u = mass_u.clone()

        if self.num_edges == 0:
            self.key = key_u
            self.src = src_u
            self.dst = dst_u
            self.w = mass_u
            self.trace = trace_u
            return

        # Locate keys in existing sorted key vector.
        pos = torch.searchsorted(self.key, key_u)
        exists = (pos < self.key.numel()) & (self.key[pos.clamp(max=self.key.numel() - 1)] == key_u)

        # Reinforce existing.
        if exists.any():
            p = pos[exists]
            self.w[p] = self.w[p] + mass_u[exists]
            self.trace[p] = self.trace[p] + mass_u[exists]

        # Insert novel edges.
        add_mask = ~exists
        if not add_mask.any():
            return

        key_add = key_u[add_mask]
        src_add = src_u[add_mask]
        dst_add = dst_u[add_mask]
        w_add = mass_u[add_mask]
        tr_add = trace_u[add_mask]
        pos_add = pos[add_mask]

        # Merge two sorted arrays without a full sort.
        old_n = int(self.num_edges)
        add_n = int(key_add.numel())
        merged_n = old_n + add_n

        new_pos = pos_add + torch.arange(add_n, device=self.device, dtype=torch.long)
        old_i = torch.arange(old_n, device=self.device, dtype=torch.long)
        shift = torch.searchsorted(pos_add, old_i, right=True)
        old_pos = old_i + shift

        key_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        src_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        dst_m = torch.empty(merged_n, device=self.device, dtype=torch.long)
        w_m = torch.empty(merged_n, device=self.device, dtype=self.dtype)
        tr_m = torch.empty(merged_n, device=self.device, dtype=self.dtype)

        key_m[old_pos] = self.key
        src_m[old_pos] = self.src
        dst_m[old_pos] = self.dst
        w_m[old_pos] = self.w
        tr_m[old_pos] = self.trace

        key_m[new_pos] = key_add
        src_m[new_pos] = src_add
        dst_m[new_pos] = dst_add
        w_m[new_pos] = w_add
        tr_m[new_pos] = tr_add

        self.key, self.src, self.dst, self.w, self.trace = key_m, src_m, dst_m, w_m, tr_m

    def add_path(self, ids: torch.Tensor, mass: torch.Tensor) -> None:
        """Add edges ids[t] -> ids[t+1] for a token path."""
        ids = ids.to(device=self.device, dtype=torch.long).flatten()
        if ids.numel() < 2:
            return
        self.add_edges(ids[:-1], ids[1:], mass)

    def get_edges(self, src: torch.Tensor, dst: torch.Tensor):
        """Vectorized lookup of edges.

        Returns (w, trace, exists) aligned with the input pairs.
        """

        src = src.to(device=self.device, dtype=torch.long).flatten()
        dst = dst.to(device=self.device, dtype=torch.long).flatten()
        if src.shape != dst.shape:
            raise ValueError('src and dst must have the same shape')

        if src.numel() == 0 or self.num_edges == 0:
            w0 = torch.zeros(src.numel(), device=self.device, dtype=self.dtype)
            t0 = torch.zeros(src.numel(), device=self.device, dtype=self.dtype)
            e0 = torch.zeros(src.numel(), device=self.device, dtype=torch.bool)
            return w0, t0, e0

        src = src.clamp(min=0, max=self.num_nodes - 1)
        dst = dst.clamp(min=0, max=self.num_nodes - 1)
        key_q = src * self.num_nodes + dst

        pos = torch.searchsorted(self.key, key_q)
        in_range = pos < self.key.numel()
        pos_safe = pos.clamp(max=max(int(self.key.numel()) - 1, 0))
        hit = self.key[pos_safe] == key_q
        exists = in_range & hit

        w = torch.zeros_like(key_q, dtype=self.dtype)
        t = torch.zeros_like(key_q, dtype=self.dtype)
        if bool(exists.any()):
            p = pos_safe[exists]
            w[exists] = self.w[p]
            t[exists] = self.trace[p]
        return w, t, exists


    # ----------------------------
    # Query
    # ----------------------------

    def batch_edges(self, src_ids: torch.Tensor) -> Optional[BondBatch]:
        """Collect all outgoing edges for provided sources."""
        if src_ids.numel() == 0 or self.num_edges == 0:
            return None
        src_ids = torch.unique(src_ids.to(device=self.device, dtype=torch.long).flatten())
        src_sorted, _ = torch.sort(src_ids)
        mask = _isin_sorted(self.src, src_sorted)
        if not bool(mask.any()):
            return None
        eidx = torch.nonzero(mask, as_tuple=False).flatten()
        return BondBatch(eidx=eidx, src=self.src[eidx], dst=self.dst[eidx], w=self.w[eidx], trace=self.trace[eidx])

    # ----------------------------
    # Updates
    # ----------------------------

    def update_edges(self, eidx: torch.Tensor, w_new: torch.Tensor, trace_new: torch.Tensor) -> None:
        self.w[eidx] = w_new
        self.trace[eidx] = trace_new

    def prune_by_src_mean(self, src_ids: torch.Tensor) -> None:
        """Prune weak edges using per-source adaptive threshold (no fixed constants).

        For each source, keep edges with w >= mean(w_out(src)) - std(w_out(src)).
        Pruning is implemented by zeroing edge state; call compact() to drop zeros.
        """

        batch = self.batch_edges(src_ids)
        if batch is None:
            return

        eps = self.eps
        s = batch.src
        w = batch.w

        # Per-source mean/std over the active subset.
        s_u, inv = torch.unique(s, return_inverse=True)
        out_sum = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sum.index_add_(0, inv, w)
        count = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        count.index_add_(0, inv, torch.ones_like(w))
        mean = out_sum / (count + eps)

        out_sq = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sq.index_add_(0, inv, w * w)
        ex2 = out_sq / (count + eps)
        var = (ex2 - mean * mean).clamp(min=0.0)
        std = torch.sqrt(var + eps)
        # Numerical slack so the minimum edge in a 2-edge fanout isn't dropped by roundoff.
        thresh = (mean - std) - eps
        keep = w >= thresh[inv]
        if bool(keep.all()):
            return

        pruned = batch.eidx[~keep]
        if pruned.numel() == 0:
            return
        self.w[pruned] = torch.zeros_like(self.w[pruned])
        self.trace[pruned] = torch.zeros_like(self.trace[pruned])

    def compact(self) -> None:
        """Physically remove zeroed edges."""
        if self.num_edges == 0:
            return
        keep = (self.w > 0) | (self.trace != 0)
        if bool(keep.all()):
            return
        self.key = self.key[keep]
        self.src = self.src[keep]
        self.dst = self.dst[keep]
        self.w = self.w[keep]
        self.trace = self.trace[keep]

    # ----------------------------
    # Flow
    # ----------------------------

    def flow_from_distribution(self, dist: torch.Tensor) -> torch.Tensor:
        """One-step flow of a distribution through the graph.

        dist: [V] nonnegative mass over sources
        returns: [V] mass over destinations
        """

        dist = dist.to(device=self.device, dtype=self.dtype).flatten()
        if self.num_edges == 0:
            return torch.zeros_like(dist)

        # Restrict to sources with nonzero mass.
        src_ids = torch.nonzero(dist > 0, as_tuple=False).flatten()
        batch = self.batch_edges(src_ids)
        if batch is None:
            return torch.zeros_like(dist)

        eps = self.eps

        s = batch.src
        d = batch.dst
        w = batch.w

        # Normalize outgoing weights per source (within the active subset).
        s_u, inv = torch.unique(s, return_inverse=True)
        out_sum = torch.zeros(int(s_u.numel()), device=self.device, dtype=self.dtype)
        out_sum.index_add_(0, inv, w)
        w_norm = w / (out_sum[inv] + eps)

        contrib = dist[s] * w_norm
        out = torch.zeros_like(dist)
        out.index_add_(0, d, contrib)
        return out



---
File: /thermo_manifold/semantic/chunk_store.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple

import torch

from .radix_trie import RadixTrie


@dataclass
class LookupResult:
    idx: torch.Tensor
    exists: torch.Tensor
    key: torch.Tensor  # retained for compatibility; 0 for variable-length mode


class ChunkStore:
    """Dynamic store of higher-order "slow" particles (chunks).

    Key design constraint: chunk indices must remain stable once assigned, because
    other structures (e.g., chunk->token bond graphs) reference them.

    We therefore maintain:
    - An append-only set of chunk state tensors indexed by chunk_id (0..C-1)
    - A separate sorted key->chunk_id mapping for fast GPU lookups.

    Chunk sequences are variable-length; we maintain a radix trie for lookup.
    """

    def __init__(
        self,
        *,
        order: int,
        vocab_size: int,
        sem_dim: int,
        device: torch.device,
        eps: float,
    ):
        if order < 2:
            raise ValueError('order must be >= 2')
        # `order` is treated as a maximum expected order (used only for validation of inputs
        # if callers still pass fixed-length sequences). Actual stored chunks can vary in length.
        self.order = int(order)
        self.vocab_size = int(vocab_size)
        self.sem_dim = int(sem_dim)
        self.device = device
        self.eps = float(eps)

        # Stable chunk state (append-only)
        # Variable-length sequences are stored in a flat buffer with offsets.
        self.seq_flat = torch.empty(0, device=device, dtype=torch.long)
        self.seq_offsets = torch.zeros(1, device=device, dtype=torch.long)  # len = num_chunks+1
        self.seq_len = torch.empty(0, device=device, dtype=torch.long)
        self.position = torch.empty(0, self.sem_dim, device=device, dtype=torch.float32)
        self.energy = torch.empty(0, device=device, dtype=torch.float32)
        self.excitation = torch.empty(0, device=device, dtype=torch.float32)
        self.heat = torch.empty(0, device=device, dtype=torch.float32)

        # Radix trie mapping sequence tuples -> chunk_id.
        self._trie = RadixTrie()

        # Baseline for binding energies (homeostatic scale), tracked per sequence length.
        self._binding_baseline_by_len: Dict[int, torch.Tensor] = {}

    @property
    def num_chunks(self) -> int:
        return int(self.energy.numel())

    # ----------------------------
    # Lookup
    # ----------------------------

    def lookup(self, seq: torch.Tensor) -> LookupResult:
        """Lookup chunk_id(s) for a batch of sequences."""
        seq = seq.to(device=self.device, dtype=torch.long)
        if seq.ndim == 1:
            seq = seq.view(1, -1)
        if seq.ndim != 2 or seq.shape[1] < 2:
            raise ValueError("seq must have shape [N,L] with L>=2")

        n = int(seq.shape[0])
        idx = torch.full((n,), -1, dtype=torch.long, device=self.device)
        exists = torch.zeros((n,), dtype=torch.bool, device=self.device)

        # Trie operates on CPU tuples; overhead is small because lookups are locality-bound.
        seq_cpu = seq.detach().to("cpu")
        for i in range(n):
            key_t = tuple(int(x) for x in seq_cpu[i].tolist())
            hit = self._trie.get(key_t)
            if hit is not None:
                idx[i] = int(hit)
                exists[i] = True

        key = torch.zeros((n,), device=self.device, dtype=torch.long)
        return LookupResult(idx=idx, exists=exists, key=key)

    # ----------------------------
    # Homeostatic baseline
    # ----------------------------

    def update_binding_baseline(self, binding: torch.Tensor, *, length: int, dt: float) -> torch.Tensor:
        """Update and return the binding baseline for a given length (scalar tensor)."""

        eps = self.eps
        b = binding.to(device=self.device, dtype=torch.float32).mean()
        ln = int(length)
        base = self._binding_baseline_by_len.get(ln)
        if base is None:
            base = b.detach().clone()
            self._binding_baseline_by_len[ln] = base
            return base
        alpha = float(dt) / (float(dt) + float(base.abs().item()) + eps)
        base_new = base * (1.0 - alpha) + b.detach() * alpha
        self._binding_baseline_by_len[ln] = base_new
        return base_new

    def binding_baseline(self, length: int) -> torch.Tensor:
        base = self._binding_baseline_by_len.get(int(length))
        if base is None:
            return torch.tensor(0.0, device=self.device, dtype=torch.float32)
        return base

    # ----------------------------
    # Insertion / reinforcement
    # ----------------------------

    def add_or_reinforce(self, seq: torch.Tensor, mass: torch.Tensor, *, word_pos: torch.Tensor) -> LookupResult:
        """Add new chunks or reinforce existing ones.

        seq: [N,L] where L>=2 (variable-length supported)
        mass: scalar or [N]
        word_pos: [V,D] token embeddings (used to place new chunks)

        Returns a LookupResult aligned with the input seq rows.
        """

        eps = self.eps

        seq = seq.to(device=self.device, dtype=torch.long)
        if seq.ndim == 1:
            seq = seq.view(1, -1)
        if seq.ndim != 2 or seq.shape[1] < 2:
            raise ValueError("seq must have shape [N,L] with L>=2")

        mass = mass.to(device=self.device, dtype=torch.float32)
        if mass.numel() == 1:
            mass = mass.expand(int(seq.shape[0]))
        else:
            mass = mass.flatten()
            if mass.shape[0] != seq.shape[0]:
                raise ValueError('mass must be scalar or have shape [N]')

        # Filter: only positive mass contributes to structural reinforcement.
        pos_mask = mass > 0
        if not bool(pos_mask.any()):
            return self.lookup(seq)

        seq_p = seq[pos_mask]
        mass_p = mass[pos_mask]

        # Coalesce duplicates on CPU (locality-bound).
        seq_cpu = seq_p.detach().to("cpu")
        mass_cpu = mass_p.detach().to("cpu")
        accum: Dict[Tuple[int, ...], float] = {}
        reps: Dict[Tuple[int, ...], torch.Tensor] = {}
        for i in range(int(seq_cpu.shape[0])):
            key_t = tuple(int(x) for x in seq_cpu[i].tolist())
            accum[key_t] = accum.get(key_t, 0.0) + float(mass_cpu[i].item())
            if key_t not in reps:
                reps[key_t] = seq_p[i]

        keys = list(accum.keys())
        seq_u = torch.stack([reps[k] for k in keys], dim=0)
        mass_u = torch.tensor([accum[k] for k in keys], device=self.device, dtype=torch.float32)

        idx_existing = torch.full((int(seq_u.shape[0]),), -1, device=self.device, dtype=torch.long)
        exists = torch.zeros((int(seq_u.shape[0]),), device=self.device, dtype=torch.bool)
        for i, k in enumerate(keys):
            hit = self._trie.get(k)
            if hit is not None:
                idx_existing[i] = int(hit)
                exists[i] = True

        # Reinforce existing chunks.
        if bool(exists.any()):
            idx_e = idx_existing[exists]
            m_e = mass_u[exists]
            self.energy[idx_e] = self.energy[idx_e] + m_e
            self.excitation[idx_e] = self.excitation[idx_e] + m_e

        # Insert new chunks.
        add_mask = ~exists
        if bool(add_mask.any()):
            seq_add = seq_u[add_mask]
            mass_add = mass_u[add_mask]

            # Append stable chunk state.
            start = self.num_chunks
            add_n = int(seq_add.shape[0])
            idx_add = torch.arange(start, start + add_n, device=self.device, dtype=torch.long)

            # Place new chunks at the normalized sum of constituent token embeddings.
            wp = word_pos.to(device=self.device, dtype=torch.float32)
            pos_add = wp[seq_add].sum(dim=1)
            pos_add = pos_add / (pos_add.norm(dim=1, keepdim=True) + eps)

            self.position = torch.cat([self.position, pos_add], dim=0)
            self.energy = torch.cat([self.energy, mass_add], dim=0)
            self.excitation = torch.cat([self.excitation, mass_add], dim=0)
            self.heat = torch.cat([self.heat, torch.zeros(add_n, device=self.device, dtype=torch.float32)], dim=0)

            # Append sequences to flat buffer + offsets.
            flat_add = seq_add.reshape(-1)
            self.seq_flat = torch.cat([self.seq_flat, flat_add], dim=0)
            lens_add = torch.full((add_n,), int(seq_add.shape[1]), device=self.device, dtype=torch.long)
            self.seq_len = torch.cat([self.seq_len, lens_add], dim=0)
            last = int(self.seq_offsets[-1].item())
            new_offsets = last + torch.cumsum(lens_add, dim=0)
            self.seq_offsets = torch.cat([self.seq_offsets, new_offsets.to(self.seq_offsets.dtype)], dim=0)

            # Update trie
            seq_add_cpu = seq_add.detach().to("cpu")
            for i in range(add_n):
                key_t = tuple(int(x) for x in seq_add_cpu[i].tolist())
                self._trie.insert(key_t, int(idx_add[i].item()))

        return self.lookup(seq)

    # ----------------------------
    # Dynamics
    # ----------------------------

    def decay(self, *, ratio: torch.Tensor, dt: float) -> None:
        """Homeostatic decay for chunk reservoirs (no reinforcement)."""

        if self.num_chunks == 0:
            return

        eps = self.eps
        dt = float(dt)
        ratio = ratio.to(device=self.device, dtype=torch.float32)

        e = self.energy
        x = self.excitation
        h = self.heat

        e_scale = e.abs().mean() + eps
        x_scale = x.abs().mean() + eps
        h_scale = h.abs().mean() + eps

        e_decay = torch.exp(-dt * ratio / e_scale)
        x_decay = torch.exp(-dt * ratio / x_scale)
        h_decay = torch.exp(-dt * ratio / h_scale)

        self.energy = (e * e_decay).clamp(min=0.0)
        self.excitation = (x * x_decay).clamp(min=0.0)
        self.heat = (h * h_decay).clamp(min=0.0)

    def distribution(self) -> torch.Tensor:
        """Return a normalized distribution over chunks based on excitation."""

        if self.num_chunks == 0:
            return torch.zeros(0, device=self.device, dtype=torch.float32)

        eps = self.eps
        x = self.excitation.clamp(min=0.0)
        s = x.sum()
        if float(s.item()) <= eps:
            return torch.zeros_like(x)
        return x / (s + eps)



---
File: /thermo_manifold/semantic/hierarchical.py
---

from __future__ import annotations

from typing import Dict, Optional, Union

import torch

from .manifold import SemanticManifold, SemanticOutput
from .chunk_store import ChunkStore
from .bipartite_graph import SparseBipartiteBondGraph


class HierarchicalSemanticManifold(SemanticManifold):
    """Semantic manifold with hierarchical nucleation (slow "chunk" particles).

    Design goals:
    - No backprop.
    - Online structural re-alignment: bonds and chunks update from ongoing observation.
    - Context is represented by persistent energetic objects (chunks) rather than a fixed
      attention window.

    The hierarchy implemented here is minimal but functional:
    - Token layer: token->token sparse bond graph (inherits from SemanticManifold)
    - Chunk layer: trigram chunks (order=3) with chunk->token sparse bipartite bonds

    The chunk layer is created and reinforced via:
    - Coherence (binding energy) of token bonds (condensation)
    - Metabolic shock from prediction surprise (error-driven nucleation)
    """

    def __init__(
        self,
        config,
        device: torch.device,
        *,
        vocab: list[str],
        embed_dim: Optional[int] = None,
        chunk_min_len: int = 2,
        chunk_max_len: int = 4,
    ):
        super().__init__(config=config, device=device, vocab=vocab, embed_dim=embed_dim)

        self.chunk_min_len = int(chunk_min_len)
        self.chunk_max_len = int(chunk_max_len)
        if self.chunk_min_len < 2:
            self.chunk_min_len = 2
        if self.chunk_max_len < self.chunk_min_len:
            self.chunk_max_len = self.chunk_min_len

        self.chunks = ChunkStore(
            order=self.chunk_max_len,
            vocab_size=self.vocab_size,
            sem_dim=self.embed_dim,
            device=device,
            eps=self.cfg.eps,
        )
        self.chunk_graph = SparseBipartiteBondGraph(
            num_src=0,
            num_dst=self.vocab_size,
            device=device,
            dtype=torch.float32,
            eps=self.cfg.eps,
        )

        # Surprise baseline for error-driven nucleation.
        self._surprise_baseline: Optional[torch.Tensor] = None

        # Cache last probs for convenience.
        self._last_probs: Optional[torch.Tensor] = None

    # ----------------------------
    # Homeostasis energy
    # ----------------------------

    def total_energy(self) -> torch.Tensor:
        total = super().total_energy()

        if self.chunks.num_chunks > 0:
            total = total + self.chunks.energy.abs().sum().to(torch.float32)
            total = total + self.chunks.excitation.abs().sum().to(torch.float32)

        if self.chunk_graph.num_edges > 0:
            total = total + self.chunk_graph.w.abs().sum().to(torch.float32)

        return total

    # ----------------------------
    # Chunk helpers
    # ----------------------------

    def _recent_seqs(self) -> list[torch.Tensor]:
        """Return recent sequence candidates of multiple lengths."""
        ids = self.particles.get("id")
        n = int(ids.numel())
        out: list[torch.Tensor] = []
        for L in range(self.chunk_min_len, self.chunk_max_len + 1):
            if n >= L:
                out.append(ids[-L:].view(1, -1))
        return out

    def _binding(self, seq: torch.Tensor) -> torch.Tensor:
        """Binding energy density proxy for a variable-length seq."""

        eps = self.cfg.eps
        if self.graph.num_edges == 0:
            return torch.tensor(0.0, device=self.device, dtype=torch.float32)

        seq = seq.to(device=self.device, dtype=torch.long)
        if seq.ndim != 2 or int(seq.shape[0]) != 1 or int(seq.shape[1]) < 2:
            raise ValueError("seq must be [1,L] with L>=2")
        s = seq[0]
        src = s[:-1].contiguous()
        dst = s[1:].contiguous()

        w, tr, _ = self.graph.get_edges(src, dst)

        w_scale = self.graph.w.abs().mean() + eps
        t_scale = self.graph.trace.abs().mean() + eps

        w_n = w.to(torch.float32) / w_scale
        t_n = tr.to(torch.float32) / t_scale

        bond = torch.sqrt((w_n * t_n).clamp(min=0.0) + eps)
        # Energy density: geometric mean across edges (length-normalized).
        return torch.exp(torch.log(bond + eps).mean())

    def _best_candidate(self) -> Optional[torch.Tensor]:
        """Select the best recent sequence candidate by thermodynamic bidding."""
        eps = self.cfg.eps
        dt = float(self.cfg.dt)

        best_seq: Optional[torch.Tensor] = None
        best_score = torch.tensor(0.0, device=self.device, dtype=torch.float32)

        for seq in self._recent_seqs():
            L = int(seq.shape[1])
            binding = self._binding(seq)
            base = self.chunks.update_binding_baseline(binding, length=L, dt=dt)
            pressure = (binding - base).clamp(min=0.0) / (binding + base + eps)
            score = pressure * binding
            if bool(score > best_score):
                best_score = score
                best_seq = seq
        return best_seq

    def _chunk_condensation(self, *, ratio: torch.Tensor) -> None:
        """Condense and activate a chunk from the current context (multi-resolution)."""

        seq = self._best_candidate()
        if seq is None:
            return

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        binding = self._binding(seq)
        base = self.chunks.update_binding_baseline(binding, length=int(seq.shape[1]), dt=dt)

        # Condensation pressure: supersaturation (binding above baseline).
        pressure = (binding - base).clamp(min=0.0) / (binding + base + eps)
        mass = torch.tensor(dt, device=self.device, dtype=torch.float32) * pressure

        # Ensure chunk exists when there is condensation mass.
        res = self.chunks.add_or_reinforce(seq, mass, word_pos=self.attractors.get('position'))
        if self.chunks.num_chunks != self.chunk_graph.num_src:
            self.chunk_graph.set_num_src(self.chunks.num_chunks)

        # Always activate existing chunk when observed (even if no condensation).
        act = torch.tensor(dt, device=self.device, dtype=torch.float32) * (binding / (binding + base + eps))
        if bool(res.exists.any()):
            idx = res.idx[res.exists]
            self.chunks.excitation[idx] = self.chunks.excitation[idx] + act

        self.last_debug.update(
            {
                "chunk_binding": float(binding.item()),
                "chunk_baseline": float(base.item()),
                "chunks": float(self.chunks.num_chunks),
            }
        )

    def _chunk_metabolism(self, *, ratio: torch.Tensor) -> None:
        """Decay chunk reservoirs and chunk->token bonds."""

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        # Chunk reservoirs
        self.chunks.decay(ratio=ratio, dt=dt)

        # Chunk bonds
        if self.chunk_graph.num_edges == 0 or self.chunks.num_chunks == 0:
            return

        active = torch.nonzero(self.chunks.excitation > 0, as_tuple=False).flatten()
        if active.numel() == 0:
            return

        batch = self.chunk_graph.batch_edges(active)
        if batch is None:
            return

        w = batch.w
        tr = batch.trace

        # Heat modulates decay: hotter => faster forgetting.
        h = self.chunks.heat
        heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else (h.abs().mean() + eps)).to(torch.float32)
        heat_level = (h.abs().mean().to(torch.float32) / (heat_scale + eps)).clamp(min=0.0)
        heat_factor = 1.0 + heat_level

        decay = torch.exp(-dt * ratio.to(w.dtype) * heat_factor.to(w.dtype))
        w_new = w * decay
        tr_new = tr * decay.to(tr.dtype)

        self.chunk_graph.update_edges(batch.eidx, w_new, tr_new)
        self.chunk_graph.compact()

    def _chunk_to_tokens(self) -> None:
        """Project the most-recent chunk into token excitation.

        Using only the *current* chunk avoids global mixing of old narratives.
        """

        if self.chunks.num_chunks == 0 or self.chunk_graph.num_edges == 0:
            return

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        best_idx: Optional[int] = None
        best_x = torch.tensor(0.0, device=self.device, dtype=torch.float32)
        for seq in self._recent_seqs():
            lr = self.chunks.lookup(seq)
            if not bool(lr.exists.any()):
                continue
            cidx = int(lr.idx[lr.exists][0].item())
            x = self.chunks.excitation[cidx]
            if bool(x > best_x):
                best_x = x
                best_idx = cidx
        if best_idx is None:
            return

        dist = torch.zeros(self.chunks.num_chunks, device=self.device, dtype=torch.float32)
        dist[best_idx] = 1.0

        flow = self.chunk_graph.flow_from_distribution(dist)
        if float(flow.abs().sum().item()) <= eps:
            return

        exc = self.attractors.get("excitation")
        exc = exc + torch.tensor(dt, device=self.device, dtype=exc.dtype) * flow.to(exc.dtype)
        self.attractors.set("excitation", exc)

        self.last_debug.update({"chunk_flow_sum": float(flow.sum().item())})

    # ----------------------------
    # Grammar step
    # ----------------------------

    def run_metabolism(self, active_src: torch.Tensor, ratio: torch.Tensor) -> None:
        """Homeostatic decay for word-level bonds.

        Reinforcement comes from observation (update_topology/observe_next_token).
        This metabolism step applies thermostatic decay only to prevent
        self-reinforcement loops from dominating adaptation.
        """

        if active_src.numel() == 0:
            return

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        batch = self.graph.batch_edges(active_src)
        if batch is None:
            return

        heat = self.attractors.get("heat")
        # Per-carrier ratio (local baselines) + per-edge heat modulation.
        if self._excitation_baseline is not None:
            exc = self.attractors.get("excitation")
            base_src = self._excitation_baseline[batch.src].to(torch.float32)
            local = (torch.log1p(exc[batch.src].to(torch.float32).clamp(min=0.0)) / (torch.log1p(base_src) + eps)).clamp(min=eps)
            ratio_src = ratio.to(torch.float32) * local
        else:
            ratio_src = ratio.to(torch.float32)

        heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else (heat.abs().mean() + eps)).to(torch.float32)
        heat_factor = 1.0 + (heat[batch.src].to(torch.float32).clamp(min=0.0) / (heat_scale + eps))

        w = batch.w
        tr = batch.trace

        w_decay = torch.exp(-dt * ratio_src.to(w.dtype) * heat_factor.to(w.dtype))
        t_decay = torch.exp(-dt * ratio_src.to(tr.dtype) * heat_factor.to(tr.dtype))

        w_new = w * w_decay
        tr_new = tr * t_decay

        self.graph.update_edges(batch.eidx, w_new, tr_new)
        self.graph.compact()


    def propagate_flow(self, active_src: torch.Tensor, ratio: torch.Tensor) -> None:
        """Propagate grammatical flow and update attractor excitation/heat.

        This override uses *direct* scale-dependent decay (large excitation => faster decay),
        which improves energetic homeostasis during continuous streaming.
        """

        if active_src.numel() == 0:
            return

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        ctx = self._context_distribution()
        flow = self.graph.flow_from_distribution(ctx)
        f_scale = flow.abs().mean() + eps
        flow = flow / f_scale

        exc = self.attractors.get("excitation")
        exc_scale = exc.abs().mean() + eps
        if self._excitation_baseline is not None:
            base = self._excitation_baseline.to(torch.float32)
            local = (torch.log1p(exc.to(torch.float32).clamp(min=0.0)) / (torch.log1p(base) + eps)).clamp(min=eps)
            ratio_vec = ratio.to(torch.float32) * local
        else:
            ratio_vec = ratio.to(torch.float32)

        exc_decay = torch.exp(-dt * ratio_vec.to(exc.dtype) * exc_scale)
        exc_new = exc * exc_decay + flow
        self.attractors.set("excitation", exc_new)

        heat = self.attractors.get("heat")
        heat_scale = heat.abs().mean() + eps
        heat_decay = torch.exp(-dt * ratio_vec.to(heat.dtype) * heat_scale)
        heat_utility = 1.0 / (1.0 + heat_scale + eps)
        heat_new = heat * heat_decay + dt * flow.abs() * heat_utility
        self.attractors.set("heat", heat_new)

    def step_grammar(self) -> None:
        if self.particles.n == 0:
            return

        self._update_carrier_baselines()
        ratio = self._homeostasis_ratio(plasticity_gate=self._plasticity_gate).to(torch.float32)

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        ids = self.particles.get('id')

        # Observation injection: after an ingestion event, don't immediately double-inject.
        if self._fresh_observation:
            self._fresh_observation = False
        else:
            exc = self.attractors.get('excitation')
            e = self.particles.get('energy').clamp(min=0.0)
            exc.index_add_(0, ids, torch.tensor(dt, device=self.device) * (e / (e.sum() + eps)))
            self.attractors.set('excitation', exc)

        # Phase 1: token topology
        self.update_topology()

        # Phase 1b: chunk condensation (hierarchy)
        self._chunk_condensation(ratio=ratio)

        active_src = torch.unique(ids)

        # Phase 2: token metabolism
        self.run_metabolism(active_src, ratio=ratio)

        # Phase 3: token propagation
        self.propagate_flow(active_src, ratio=ratio)

        # Chunk phases: decay + top-down bias
        self._chunk_metabolism(ratio=ratio)
        self._chunk_to_tokens()

        ent = float(self.entropy().item())
        if self.last_entropy is None:
            self.last_entropy = ent
        self.last_debug['entropy'] = ent
        self.last_confidence = self.thinking_confidence()

    # ----------------------------
    # Readout
    # ----------------------------

    def predict_next(self) -> torch.Tensor:
        eps = self.cfg.eps
        ids = self.particles.get("id")
        if ids.numel() == 0:
            return torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)

        # --- Word-level (bigram) proposal: condition primarily on the current token.
        cur = ids[-1].to(torch.long)
        dist_word = torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)
        dist_word[cur] = 1.0
        word_flow = self.graph.flow_from_distribution(dist_word)
        if word_flow.abs().sum() <= eps:
            # Cold start fallback: use the full context distribution.
            ctx = self._context_distribution()
            word_flow = self.graph.flow_from_distribution(ctx)

        # --- Chunk-level proposal: condition on the most excited recent chunk candidate.
        chunk_flow = torch.zeros_like(word_flow)
        if self.chunks.num_chunks > 0 and self.chunk_graph.num_edges > 0:
            best_idx: Optional[int] = None
            best_x = torch.tensor(0.0, device=self.device, dtype=torch.float32)
            for seq in self._recent_seqs():
                lr = self.chunks.lookup(seq)
                if not bool(lr.exists.any()):
                    continue
                cidx = int(lr.idx[lr.exists][0].item())
                x = self.chunks.excitation[cidx]
                if bool(x > best_x):
                    best_x = x
                    best_idx = cidx
            if best_idx is not None:
                dist_chunk = torch.zeros(self.chunks.num_chunks, device=self.device, dtype=torch.float32)
                dist_chunk[best_idx] = 1.0
                chunk_flow = self.chunk_graph.flow_from_distribution(dist_chunk)

        # --- Mixture (no tuned constants): gate by relative mass of the proposals.
        w_mass = word_flow.abs().sum()
        c_mass = chunk_flow.abs().sum()
        gate = c_mass / (c_mass + w_mass + eps)
        combined = (1.0 - gate) * word_flow + gate * chunk_flow
        g_scale = combined.abs().sum()
        if g_scale > eps:
            return combined / (g_scale + eps)
        return dist_word

    def output_state(self) -> SemanticOutput:
        logits = self.predict_next()
        probs = torch.softmax(logits, dim=0)
        self._last_probs = probs.detach()

        idx = int(torch.argmax(probs).item())
        tok = self.vocab[idx] if 0 <= idx < len(self.vocab) else None

        meta = {
            "entropy": float(self.entropy().item()),
            "confidence": float(self.last_confidence),
            **self.last_debug,
        }
        return SemanticOutput(logits=logits, probs=probs, token_index=idx, token=tok, meta=meta)

    # ----------------------------
    # Online learning hook
    # ----------------------------

    def observe_next_token(
        self,
        next_id: Union[int, torch.Tensor],
        *,
        probs: Optional[torch.Tensor] = None,
        cur_id: Optional[int] = None,
        mass_scale: Optional[torch.Tensor] = None,
    ) -> Dict[str, float]:
        """Observation hook to apply metabolic shock and create new structure.

        This is intentionally local:
        - Compute surprise on the observed next token.
        - Inject mass into the specific transition (token->token) and (chunk->token).

        No gradients, no backprop.
        """

        # Run base token-level reinforcement (also works during dreaming).
        if probs is None:
            probs = self._last_probs
        if probs is None:
            probs = torch.softmax(self.predict_next(), dim=0)
        # Determine the current source token for chunk coupling.
        if cur_id is None:
            if self.particles.n == 0:
                return {"surprise": 0.0, "pressure": 0.0}
            cur = int(self.particles.get("id")[-1].item())
        else:
            cur = int(cur_id)
        out = super().observe_next_token(int(next_id), probs=probs, cur_id=cur, mass_scale=mass_scale)
        # Carry plasticity gate upward so homeostasis can relax during surprise.
        self._plasticity_gate = torch.tensor(float(out.get("pressure", 0.0)), device=self.device, dtype=torch.float32).clamp(0.0, 1.0)

        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        # Mirror token-level plasticity for chunk coupling.
        h = self.hunger[cur].clamp(min=0.0)
        h_scale = self.hunger.abs().mean() + eps
        hunger_factor = h / (h + h_scale + eps)
        mass = torch.tensor(dt, device=self.device, dtype=torch.float32) * torch.tensor(out["pressure"], device=self.device) * (1.0 + hunger_factor)
        if mass_scale is not None:
            mass = mass * mass_scale.to(device=self.device, dtype=mass.dtype).clamp(min=0.0)

        # Chunk->token reinforcement using the best multi-resolution candidate.
        seq = self._best_candidate()
        if seq is not None:
            res = self.chunks.add_or_reinforce(seq, mass, word_pos=self.attractors.get('position'))
            if self.chunks.num_chunks != self.chunk_graph.num_src:
                self.chunk_graph.set_num_src(self.chunks.num_chunks)
            if bool(res.exists.any()):
                cidx = res.idx[res.exists]
                dst_c = torch.full_like(cidx, int(next_id), dtype=torch.long)
                m_c = mass.expand_as(cidx)
                self.chunk_graph.add_edges(cidx, dst_c, m_c)

        return out

    def idle_think(self, *, steps: int = 1, dream_steps: int = 8) -> Dict[str, float]:
        """Idle pondering with hierarchy (chunks participate)."""
        out = super().idle_think(steps=steps, dream_steps=dream_steps)
        ratio = self._homeostasis_ratio().to(torch.float32)
        # Let the chunk layer metabolize and bias tokens during idle time.
        self._chunk_metabolism(ratio=ratio)
        self._chunk_to_tokens()
        return out



---
File: /thermo_manifold/semantic/manifold.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import torch

from ..core.config import PhysicsConfig
from ..core.diagnostics import SemanticDiagnosticsLogger
from ..core.state import BatchState
from ..physics.engine import ThermodynamicEngine
from .bond_graph import SparseBondGraph


@dataclass
class SemanticOutput:
    logits: torch.Tensor
    probs: torch.Tensor
    token_index: int
    token: Optional[str]
    meta: Dict[str, Any]


class SemanticManifold(ThermodynamicEngine):
    """Thermodynamic grammar on a sparse bond graph (no dense V×V matrices)."""

    def __init__(self, config: PhysicsConfig, device: torch.device, *, vocab: List[str], embed_dim: Optional[int] = None):
        super().__init__(config, device)
        self.vocab = list(vocab)
        self.vocab_size = len(self.vocab)
        self.embed_dim = int(embed_dim if embed_dim is not None else self.vocab_size)

        pos = self._init_embeddings(self.vocab_size, self.embed_dim, eps=self.cfg.eps, device=device)
        self.attractors = BatchState(
            {
                "id": torch.arange(self.vocab_size, device=device, dtype=torch.long),
                "position": pos,
                "energy": torch.zeros(self.vocab_size, device=device, dtype=torch.float32),
                "excitation": torch.zeros(self.vocab_size, device=device, dtype=torch.float32),
                "heat": torch.zeros(self.vocab_size, device=device, dtype=torch.float32),
            }
        )

        self.graph = SparseBondGraph(self.vocab_size, device=device, dtype=torch.float32, eps=self.cfg.eps)

        # Pondering state (idle discovery)
        self.hunger = torch.zeros(self.vocab_size, device=device, dtype=torch.float32)
        self._surprise_baseline: Optional[torch.Tensor] = None
        self._ponder_step = 0
        self._diagnostics: Optional[SemanticDiagnosticsLogger] = None
        self._fresh_observation = False

        # Thinking / halting state
        self.halt_mass = 0.0
        self.last_entropy: Optional[float] = None
        self.last_confidence: float = 0.0
        self.last_debug: Dict[str, float] = {}

        # Per-carrier (token) baselines for local homeostasis.
        self._excitation_baseline: Optional[torch.Tensor] = None
        self._heat_baseline: Optional[torch.Tensor] = None

        # Plasticity gate (e.g. surprise/mismatch) used to modulate homeostasis.
        self._plasticity_gate: Optional[torch.Tensor] = None

    def total_energy(self) -> torch.Tensor:
        """Homeostasis energy for semantic dynamics.

        Excitation is treated as the dominant energetic quantity for the grammar.
        """
        total = super().total_energy()
        exc = self.attractors.get("excitation")
        return total + exc.abs().sum().to(torch.float32)

    @staticmethod
    def _init_embeddings(vocab_size: int, embed_dim: int, *, eps: float, device: torch.device) -> torch.Tensor:
        if embed_dim >= vocab_size:
            emb = torch.eye(vocab_size, embed_dim, device=device, dtype=torch.float32)
        else:
            emb = torch.randn(vocab_size, embed_dim, device=device, dtype=torch.float32)
            emb = emb / (emb.norm(dim=1, keepdim=True) + eps)
        return emb

    # ----------------------------
    # Ingest
    # ----------------------------

    def ingest_ids(self, ids: torch.Tensor) -> None:
        """Ingest a token-id context as particles."""
        ids = ids.to(device=self.device, dtype=torch.long).flatten()
        n = int(ids.numel())
        if n == 0:
            self.particles = BatchState.empty()
            return

        idx = torch.arange(1, n + 1, device=self.device, dtype=torch.float32)
        energy = idx / (idx.max() + self.cfg.eps)

        pos = self.attractors.get("position")[ids]
        self.particles = BatchState(
            {
                "id": ids,
                "position": pos,
                "energy": energy,
                "heat": torch.zeros(n, device=self.device, dtype=torch.float32),
            }
        )

        # Energy enters the semantic manifold via observation (context excitation).
        exc = self.attractors.get("excitation")
        e_norm = energy / (energy.sum() + self.cfg.eps)
        exc.index_add_(0, ids, e_norm)
        self.attractors.set("excitation", exc)
        self._fresh_observation = True

        # Reset thinking state for the new observation.
        self.halt_mass = 0.0
        self.last_entropy = None
        self.last_confidence = 0.0
        self.last_debug = {}

    def set_diagnostics(self, diagnostics: Optional[SemanticDiagnosticsLogger]) -> None:
        self._diagnostics = diagnostics

    # ----------------------------
    # Idle pondering
    # ----------------------------

    def _active_sources_from_excitation(self) -> torch.Tensor:
        """Select active sources stochastically (Boltzmann-style), no deterministic top-k."""
        exc = self.attractors.get("excitation").clamp(min=0.0)
        heat = self.attractors.get("heat").clamp(min=0.0)

        ids_exc = torch.nonzero(exc > 0, as_tuple=False).flatten()
        ids_heat = torch.nonzero(heat > 0, as_tuple=False).flatten()
        if ids_exc.numel() == 0 and ids_heat.numel() == 0:
            return torch.empty(0, device=self.device, dtype=torch.long)

        eps = self.cfg.eps
        temp = float(self.cfg.dream_sampling_temperature)
        if temp <= 0:
            temp = 1.0

        active: list[torch.Tensor] = []
        if ids_exc.numel() > 0:
            k_exc = max(1, int(round(float(ids_exc.numel()) ** 0.5)))
            k_exc = min(k_exc, int(ids_exc.numel()))
            w = exc[ids_exc].to(torch.float32)
            w = torch.exp(torch.log(w + eps) / temp)
            w = w / (w.sum() + eps)
            pick = torch.multinomial(w, k_exc, replacement=False)
            active.append(ids_exc[pick])
        if ids_heat.numel() > 0:
            k_heat = max(1, int(round(float(ids_heat.numel()) ** 0.5)))
            k_heat = min(k_heat, int(ids_heat.numel()))
            w = heat[ids_heat].to(torch.float32)
            w = torch.exp(torch.log(w + eps) / temp)
            w = w / (w.sum() + eps)
            pick = torch.multinomial(w, k_heat, replacement=False)
            active.append(ids_heat[pick])

        if not active:
            return torch.empty(0, device=self.device, dtype=torch.long)
        return torch.unique(torch.cat(active, dim=0))

    def _update_carrier_baselines(self) -> None:
        """Update slow per-token baselines for excitation and heat."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        tau = float(self.cfg.carrier_tau)
        if tau <= 0:
            tau = 1.0
        alpha = dt / (tau + dt)

        exc = self.attractors.get("excitation").to(torch.float32).clamp(min=0.0)
        heat = self.attractors.get("heat").to(torch.float32).clamp(min=0.0)

        if self._excitation_baseline is None:
            self._excitation_baseline = exc.detach().clone()
        else:
            base = self._excitation_baseline.to(torch.float32)
            self._excitation_baseline = (1.0 - alpha) * base + alpha * exc.detach()

        if self._heat_baseline is None:
            self._heat_baseline = heat.detach().clone()
        else:
            base = self._heat_baseline.to(torch.float32)
            self._heat_baseline = (1.0 - alpha) * base + alpha * heat.detach()

        self._excitation_baseline = self._excitation_baseline.clamp(min=eps)
        self._heat_baseline = self._heat_baseline.clamp(min=eps)

    def predict_from_token(self, token_id: int) -> torch.Tensor:
        """Sparse next-token proposal conditioned on a single token."""
        eps = self.cfg.eps
        out = torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)
        if self.graph.num_edges == 0:
            return out
        src = torch.tensor([int(token_id)], device=self.device, dtype=torch.long)
        batch = self.graph.batch_edges(src)
        if batch is None:
            return out
        w = batch.w.clamp(min=0.0)
        s = w.sum()
        if float(s.item()) <= float(eps):
            return out
        w_norm = w / (s + eps)
        out.index_add_(0, batch.dst, w_norm.to(out.dtype))
        return out

    def observe_next_token(
        self,
        next_id: int,
        *,
        probs: Optional[torch.Tensor] = None,
        cur_id: Optional[int] = None,
        mass_scale: Optional[torch.Tensor] = None,
    ) -> Dict[str, float]:
        """Local learning hook usable both online and during dreaming."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        next_i = int(next_id)
        if cur_id is None:
            if self.particles.n == 0:
                return {"surprise": 0.0, "pressure": 0.0}
            cur = int(self.particles.get("id")[-1].item())
        else:
            cur = int(cur_id)

        if probs is None:
            probs = torch.softmax(self.predict_from_token(cur), dim=0)

        p = probs[next_i].clamp(min=eps)
        surprise = (-torch.log(p)).to(torch.float32)

        # Surprise baseline (homeostatic scale).
        if self._surprise_baseline is None:
            self._surprise_baseline = surprise.detach().clone()
        else:
            base = self._surprise_baseline
            alpha = dt / (float(self.cfg.tau) + dt)
            self._surprise_baseline = base * (1.0 - alpha) + surprise.detach() * alpha
        base = self._surprise_baseline

        pressure = surprise / (surprise + base + eps)
        # Plasticity gate: pressure in [0,1], used to relax homeostasis during surprise.
        self._plasticity_gate = pressure.detach().clone()

        # Hunger modulates plasticity without hard thresholds.
        h = self.hunger[cur].clamp(min=0.0)
        h_scale = self.hunger.abs().mean() + eps
        hunger_factor = h / (h + h_scale + eps)

        mass = torch.tensor(dt, device=self.device, dtype=torch.float32) * pressure * (1.0 + hunger_factor)
        if mass_scale is not None:
            mass = mass * mass_scale.to(device=self.device, dtype=mass.dtype).clamp(min=0.0)

        src = torch.tensor([cur], device=self.device, dtype=torch.long)
        dst = torch.tensor([next_i], device=self.device, dtype=torch.long)
        self.graph.add_edges(src, dst, mass)

        heat = self.attractors.get("heat")
        heat[cur] = heat[cur] + mass.to(heat.dtype)
        self.attractors.set("heat", heat)

        self.last_debug.update({"surprise": float(surprise.item()), "shock": float(pressure.item())})
        return {"surprise": float(surprise.item()), "pressure": float(pressure.item())}

    def _ponder_transitive_closure(self, active_src: torch.Tensor, *, ratio: torch.Tensor) -> Dict[str, float]:
        """Infer shortcut bonds A->C from A->B and B->C (sparse 2-hop closure)."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        if active_src.numel() == 0 or self.graph.num_edges == 0:
            return {"shortcuts": 0.0}

        hop1 = self.graph.batch_edges(active_src)
        if hop1 is None:
            return {"shortcuts": 0.0}

        # Normalize hop1 per source (A).
        a_u, inv1 = torch.unique(hop1.src, return_inverse=True)
        out1 = torch.zeros(int(a_u.numel()), device=self.device, dtype=torch.float32)
        out1.index_add_(0, inv1, hop1.w)
        w1 = hop1.w / (out1[inv1] + eps)

        mids = torch.unique(hop1.dst)
        hop2 = self.graph.batch_edges(mids)
        if hop2 is None:
            return {"shortcuts": 0.0}

        # Normalize hop2 per source (B).
        b_u, inv2 = torch.unique(hop2.src, return_inverse=True)
        out2 = torch.zeros(int(b_u.numel()), device=self.device, dtype=torch.float32)
        out2.index_add_(0, inv2, hop2.w)
        w2 = hop2.w / (out2[inv2] + eps)

        # Join on B with a bounded per-mid loop (mid count is locality-derived).
        order1 = torch.argsort(hop1.dst)
        dst1 = hop1.dst[order1]
        src1 = hop1.src[order1]
        w1s = w1[order1]
        u1, c1 = torch.unique_consecutive(dst1, return_counts=True)
        s1 = torch.cumsum(torch.cat([torch.zeros(1, device=self.device, dtype=torch.long), c1[:-1]]), dim=0)

        order2 = torch.argsort(hop2.src)
        src2 = hop2.src[order2]
        dst2 = hop2.dst[order2]
        w2s = w2[order2]
        u2, c2 = torch.unique_consecutive(src2, return_counts=True)
        s2 = torch.cumsum(torch.cat([torch.zeros(1, device=self.device, dtype=torch.long), c2[:-1]]), dim=0)

        # Intersection of mids present in both.
        pos = torch.searchsorted(u2, u1)
        in_range = pos < u2.numel()
        pos_safe = pos.clamp(max=max(int(u2.numel()) - 1, 0))
        hit = in_range & (u2[pos_safe] == u1)
        mids_i = u1[hit]
        if mids_i.numel() == 0:
            return {"shortcuts": 0.0}

        pos2 = pos_safe[hit]
        i1 = torch.nonzero(hit, as_tuple=False).flatten()

        src_all: list[torch.Tensor] = []
        dst_all: list[torch.Tensor] = []
        mass_all: list[torch.Tensor] = []

        emb = self.attractors.get("position")

        for j in range(int(mids_i.numel())):
            # hop1 slice for this mid
            start1 = int(s1[i1[j]].item())
            end1 = start1 + int(c1[i1[j]].item())
            a = src1[start1:end1]
            w_a = w1s[start1:end1]

            # hop2 slice for this mid
            start2 = int(s2[pos2[j]].item())
            end2 = start2 + int(c2[pos2[j]].item())
            c = dst2[start2:end2]
            w_c = w2s[start2:end2]

            if a.numel() == 0 or c.numel() == 0:
                continue

            # Cartesian product A×C for this mid.
            aa = a.repeat_interleave(int(c.numel()))
            cc = c.repeat(int(a.numel()))
            path_mass = w_a.repeat_interleave(int(c.numel())) * w_c.repeat(int(a.numel()))

            # Geometric compatibility (derived): exp(-d2 / mean(d2)).
            pa = emb[aa]
            pc = emb[cc]
            diff = pa - pc
            d2 = (diff * diff).sum(dim=1)
            d2_scale = d2.mean() + eps
            geom = torch.exp(-d2 / d2_scale)

            mass = torch.tensor(dt, device=self.device, dtype=torch.float32) * path_mass * geom

            src_all.append(aa)
            dst_all.append(cc)
            mass_all.append(mass)

        if not src_all:
            return {"shortcuts": 0.0}

        src_cat = torch.cat(src_all, dim=0)
        dst_cat = torch.cat(dst_all, dim=0)
        mass_cat = torch.cat(mass_all, dim=0)

        # Novelty: only add missing edges (no hard thresholds).
        _, _, exists = self.graph.get_edges(src_cat, dst_cat)
        add = ~exists
        if not bool(add.any()):
            return {"shortcuts": 0.0}

        self.graph.add_edges(src_cat[add], dst_cat[add], mass_cat[add])

        # Heat release on sources that formed shortcuts.
        heat = self.attractors.get("heat")
        heat.index_add_(0, src_cat[add], mass_cat[add].to(heat.dtype))
        self.attractors.set("heat", heat)

        return {"shortcuts": float(int(add.sum().item()))}

    def _ponder_conflict_resolution(self, active_src: torch.Tensor, *, ratio: torch.Tensor) -> Dict[str, float]:
        """Resolve ambiguity by focusing competition on high-entropy sources."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        if active_src.numel() == 0 or self.graph.num_edges == 0:
            return {"confused": 0.0}

        batch = self.graph.batch_edges(active_src)
        if batch is None:
            return {"confused": 0.0}

        s_u, inv = torch.unique(batch.src, return_inverse=True)
        out_sum = torch.zeros(int(s_u.numel()), device=self.device, dtype=torch.float32)
        out_sum.index_add_(0, inv, batch.w)
        w = batch.w / (out_sum[inv] + eps)

        ent_e = -(w * torch.log(w + eps))
        ent = torch.zeros(int(s_u.numel()), device=self.device, dtype=torch.float32)
        ent.index_add_(0, inv, ent_e)

        med = ent.median()
        confused = s_u[ent >= med]
        if confused.numel() == 0:
            return {"confused": 0.0}

        exc = self.attractors.get("excitation")
        ex = exc[confused]
        scale = ex.abs().mean() + eps
        ent_scale = ent[ent >= med].mean() + eps
        noise = torch.randn_like(ex) * (scale * (ent[ent >= med] / ent_scale))
        exc.index_add_(0, confused, torch.tensor(dt, device=self.device) * noise.to(exc.dtype))
        exc = exc.clamp(min=0.0)
        self.attractors.set("excitation", exc)

        # Let competition play out thermodynamically.
        self.run_metabolism(confused, ratio=ratio)
        self.propagate_flow(confused, ratio=ratio)
        return {"confused": float(int(confused.numel()))}

    def _ponder_dream_rollouts(self, active_src: torch.Tensor, *, ratio: torch.Tensor, steps: int) -> Dict[str, float]:
        """Hypothetical rollouts to find dead-ends and build hunger signals."""
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        exc = self.attractors.get("excitation").clamp(min=0.0)
        if active_src.numel() == 0:
            return {"dreams": 0.0, "dead_ends": 0.0}

        # Energy/heat budget loop (state-dependent cognitive depth).
        budget = torch.tensor(float(self.cfg.dream_energy_budget), device=self.device, dtype=torch.float32).clamp(min=0.0)
        stress = (ratio.to(torch.float32) - 1.0).clamp(min=0.0)
        budget = budget * (1.0 + float(self.cfg.dream_budget_stress_gain) * stress)

        temp = float(self.cfg.dream_sampling_temperature)
        if temp <= 0:
            temp = 1.0
        w = exc[active_src].to(torch.float32)
        w = torch.exp(torch.log(w + eps) / temp)
        w = w / (w.sum() + eps)

        dead_ends = 0
        rollouts = 0
        heat = self.attractors.get("heat").clamp(min=0.0).to(torch.float32)
        while float(budget.item()) > 0.0:
            cur = int(active_src[int(torch.multinomial(w, 1).item())].item())
            cum_prob = torch.tensor(1.0, device=self.device, dtype=torch.float32)
            for _t in range(int(steps)):
                if float(self.cfg.dream_entropy_stop) > 0.0:
                    ent = float(self.entropy().item())
                    if ent <= float(self.cfg.dream_entropy_stop):
                        budget = torch.tensor(0.0, device=self.device, dtype=torch.float32)
                        break
                dist = self.predict_from_token(cur)
                s = float(dist.abs().sum().item())
                if s <= float(eps):
                    self.hunger[cur] = self.hunger[cur] + torch.tensor(dt, device=self.device, dtype=self.hunger.dtype)
                    dead_ends += 1
                    break
                probs = dist / (dist.sum() + eps)
                nxt = int(torch.multinomial(probs, 1).item())
                cum_prob = cum_prob * probs[nxt].to(cum_prob.dtype)
                self.observe_next_token(nxt, probs=probs, cur_id=cur, mass_scale=cum_prob.detach())
                cur = nxt
                heat_scale = (self._heat_abs_scale if self._heat_abs_scale is not None else (heat.abs().mean() + eps)).to(torch.float32)
                step_cost = 1.0 + (heat[cur] / (heat_scale + eps)).clamp(min=0.0)
                budget = budget - step_cost
                if float(budget.item()) <= 0.0:
                    break
            rollouts += 1

        # Hunger decays homeostatically (no manual resets).
        h_scale = self.hunger.abs().mean() + eps
        self.hunger = self.hunger * torch.exp(-torch.tensor(dt, device=self.device) * ratio.to(self.hunger.dtype) / h_scale)
        return {"dreams": float(rollouts), "dead_ends": float(dead_ends)}

    def idle_think(self, *, steps: int = 1, dream_steps: int = 8) -> Dict[str, float]:
        """Idle pondering: discover relations from existing structure (no external data)."""
        steps = int(steps)
        dream_steps = int(dream_steps)
        if steps <= 0:
            return {}

        self._update_carrier_baselines()
        ratio = self._homeostasis_ratio(plasticity_gate=self._plasticity_gate).to(torch.float32)
        active = self._active_sources_from_excitation()

        agg: Dict[str, float] = {}
        for _ in range(steps):
            r1 = self._ponder_transitive_closure(active, ratio=ratio)
            r2 = self._ponder_conflict_resolution(active, ratio=ratio)
            r3 = self._ponder_dream_rollouts(active, ratio=ratio, steps=dream_steps)
            agg.update({k: agg.get(k, 0.0) + float(v) for k, v in {**r1, **r2, **r3}.items()})

        if self._diagnostics is not None:
            self._diagnostics.log(
                {
                    "step": int(self._ponder_step),
                    "active": int(active.numel()),
                    "shortcuts": float(agg.get("shortcuts", 0.0)),
                    "confused": float(agg.get("confused", 0.0)),
                    "dreams": float(agg.get("dreams", 0.0)),
                    "dead_ends": float(agg.get("dead_ends", 0.0)),
                    "hunger_mean": float(self.hunger.mean().item()),
                    "heat_mean": float(self.attractors.get("heat").mean().item()),
                    "exc_mean": float(self.attractors.get("excitation").mean().item()),
                }
            )
        self._ponder_step += 1
        return agg

    # ----------------------------
    # Grammar phases
    # ----------------------------

    def update_topology(self) -> None:
        """Topology update phase: nucleate/strengthen edges from observed order."""
        if self.particles.n < 2:
            return
        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        ids = self.particles.get("id")
        e = self.particles.get("energy")
        e_scale = e.abs().mean() + eps

        # Nucleation mass emerges from current context energy scale.
        mass = torch.tensor(dt, device=self.device, dtype=torch.float32) * (e.mean() / e_scale)
        self.graph.add_path(ids, mass)

    def run_metabolism(self, active_src: torch.Tensor, *, ratio: torch.Tensor) -> None:
        """Metabolism phase: update bond masses and traces for active sources."""
        if active_src.numel() == 0 or self.graph.num_edges == 0:
            return
        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        exc = self.attractors.get("excitation")
        heat = self.attractors.get("heat")
        exc_scale = exc[active_src].abs().mean() + eps

        batch = self.graph.batch_edges(active_src)
        if batch is None:
            return

        # Local homeostasis per source token (carrier baseline).
        if self._excitation_baseline is not None:
            base_src = self._excitation_baseline[batch.src].to(torch.float32)
            local = (torch.log1p(exc[batch.src].to(torch.float32).clamp(min=0.0)) / (torch.log1p(base_src) + eps)).clamp(min=eps)
            ratio_src = ratio.to(torch.float32) * local
        else:
            ratio_src = ratio.to(torch.float32)

        # Outgoing normalization per source (active subset only).
        src_u, inv = torch.unique(batch.src, return_inverse=True)
        out_sum = torch.zeros(int(src_u.numel()), device=self.device, dtype=torch.float32)
        out_sum.index_add_(0, inv, batch.w)
        w_norm = batch.w / (out_sum[inv] + eps)

        # Flow-based usage.
        use = exc[batch.src] * w_norm

        # Heat reduces usable energy (entropy).
        h_level = heat[batch.src].abs().mean()
        heat_utility = 1.0 / (1.0 + h_level + eps)
        income = use * heat_utility

        # Trace: local time-extended credit.
        trace = batch.trace
        trace_scale = trace.abs().mean() + eps
        trace_decay = torch.exp(-dt * ratio_src.to(trace.dtype) / (exc_scale + trace_scale))
        trace_new = trace * trace_decay + income

        # Cost: proportional decay (edges starve without use).
        cost = ratio_src.to(batch.w.dtype) * exc_scale * batch.w / (batch.w.abs().mean() + eps)
        w_new = (batch.w + dt * (income - cost)).clamp(min=0.0)

        # Write back.
        self.graph.update_edges(batch.eidx, w_new, trace_new)

        # Prune weak edges without fixed thresholds.
        self.graph.prune_by_src_mean(active_src)
        self.graph.compact()

        self.last_debug.update(
            {
                "exc_scale": float(exc_scale.item()),
                "heat_level": float(h_level.item()),
                "income_mean": float(income.mean().item()),
                "cost_mean": float(cost.mean().item()),
                "edges_active": float(int(batch.eidx.numel())),
            }
        )

    def propagate_flow(self, active_src: torch.Tensor, *, ratio: torch.Tensor) -> None:
        """Flow propagation phase: push excitation through bonds."""
        if active_src.numel() == 0 or self.graph.num_edges == 0:
            return
        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        exc = self.attractors.get("excitation")
        heat = self.attractors.get("heat")
        exc_scale = exc[active_src].abs().mean() + eps

        # Local homeostasis per carrier.
        if self._excitation_baseline is not None:
            base = self._excitation_baseline.to(torch.float32)
            local = (torch.log1p(exc.to(torch.float32).clamp(min=0.0)) / (torch.log1p(base) + eps)).clamp(min=eps)
            ratio_vec = ratio.to(torch.float32) * local
        else:
            ratio_vec = ratio.to(torch.float32)

        # Sparse source distribution from excitation on active sources.
        dist = torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)
        dist[active_src] = exc[active_src].clamp(min=0.0)
        dist = dist / (dist.sum() + eps)

        flow = self.graph.flow_from_distribution(dist)

        # Heat generation: using excitation produces heat.
        nnz = torch.count_nonzero(flow)
        flow_scale = flow.abs().sum() / (nnz.to(flow.dtype) + eps)
        heat = heat + dt * (flow.abs() / (flow_scale + eps))

        # Homeostatic excitation damping.
        exc = (exc + dt * flow) * torch.exp(-dt * ratio_vec.to(exc.dtype) / (exc_scale + eps))

        self.attractors.set("excitation", exc)
        self.attractors.set("heat", heat)

        self.last_debug.update(
            {
                "flow_mean": float(flow.mean().item()),
                "exc_mean": float(exc.mean().item()),
                "heat_mean": float(heat.mean().item()),
            }
        )

    def step_grammar(self) -> None:
        """One grammar step, decomposed into phases for debuggability."""
        if self.particles.n == 0:
            return

        self._update_carrier_baselines()
        ratio = self._homeostasis_ratio(plasticity_gate=self._plasticity_gate).to(torch.float32)

        dt = float(self.cfg.dt)
        eps = self.cfg.eps

        # Continuous observation: after an ingestion event, don't immediately double-inject.
        if self._fresh_observation:
            self._fresh_observation = False
        else:
            exc = self.attractors.get("excitation")
            ids = self.particles.get("id")
            e = self.particles.get("energy").clamp(min=0.0)
            exc.index_add_(0, ids, torch.tensor(dt, device=self.device) * (e / (e.sum() + eps)))
            self.attractors.set("excitation", exc)

        # Phase 1: topology
        self.update_topology()

        # Active sources: context tokens (locality without global thresholds).
        active_src = torch.unique(self.particles.get("id"))

        # Phase 2: metabolism
        self.run_metabolism(active_src, ratio=ratio)

        # Phase 3: propagation
        self.propagate_flow(active_src, ratio=ratio)

        ent = float(self.entropy().item())
        if self.last_entropy is None:
            self.last_entropy = ent
        self.last_debug["entropy"] = ent
        self.last_confidence = self.thinking_confidence()

    # ----------------------------
    # Readout
    # ----------------------------

    def _context_distribution(self) -> torch.Tensor:
        eps = self.cfg.eps
        dist = torch.zeros(self.vocab_size, device=self.device, dtype=torch.float32)
        ids = self.particles.get("id")
        e = self.particles.get("energy").clamp(min=0.0)
        dist.index_add_(0, ids, e / (e.sum() + eps))
        return dist

    def predict_next(self) -> torch.Tensor:
        eps = self.cfg.eps
        ctx = self._context_distribution()
        gram = self.graph.flow_from_distribution(ctx)

        c_scale = ctx.abs().sum() + eps
        g_scale = gram.abs().sum()

        # Readout prioritizes *forward* flow when grammar has support; otherwise fall back to context.
        if float(g_scale.item()) > float(eps):
            return gram / (g_scale + eps)
        return ctx / c_scale

    def entropy(self) -> torch.Tensor:
        logits = self.predict_next()
        probs = torch.softmax(logits, dim=0)
        return -(probs * torch.log(probs + self.cfg.eps)).sum()

    def thinking_confidence(self) -> float:
        ctx = self._context_distribution()
        gram = self.graph.flow_from_distribution(ctx)
        c = ctx.abs().sum() + self.cfg.eps
        g = gram.abs().sum()
        # Confidence is the amount of forward signal available relative to the observation mass.
        conf = (g / (c + self.cfg.eps)).clamp(min=0.0, max=1.0)
        return float(conf.item())

    def thinking_complete(self) -> bool:
        dt = float(self.cfg.dt)
        eps = self.cfg.eps
        conf = self.thinking_confidence()
        self.halt_mass = min(1.0, self.halt_mass + (conf * dt) / (conf + eps))
        return self.halt_mass >= 1.0

    def output_state(self) -> SemanticOutput:
        logits = self.predict_next()
        probs = torch.softmax(logits, dim=0)
        idx = int(torch.argmax(probs).item())
        tok = self.vocab[idx] if 0 <= idx < len(self.vocab) else None
        meta = {
            "entropy": float(self.entropy().item()),
            "confidence": float(self.last_confidence),
            **self.last_debug,
        }
        return SemanticOutput(logits=logits, probs=probs, token_index=idx, token=tok, meta=meta)



---
File: /thermo_manifold/semantic/radix_trie.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple


def _lcp(a: Tuple[int, ...], b: Tuple[int, ...]) -> int:
    """Longest common prefix length for two tuples."""
    n = min(len(a), len(b))
    i = 0
    while i < n and a[i] == b[i]:
        i += 1
    return i


@dataclass
class _Edge:
    label: Tuple[int, ...]
    child: "_Node"


class _Node:
    __slots__ = ("value", "edges")

    def __init__(self):
        self.value: Optional[int] = None
        # Keyed by first token of edge.label for fast selection.
        self.edges: Dict[int, _Edge] = {}


class RadixTrie:
    """Radix trie mapping token sequences -> stable IDs.

    This is a path-compressed trie:
    - Each edge stores a tuple label (a run of tokens).
    - Insert/lookup are O(L) in sequence length with low constant factors.
    """

    def __init__(self):
        self._root = _Node()

    def get(self, seq: Tuple[int, ...]) -> Optional[int]:
        node = self._root
        rest = seq
        while rest:
            e = node.edges.get(rest[0])
            if e is None:
                return None
            lab = e.label
            if len(rest) < len(lab) or rest[: len(lab)] != lab:
                return None
            rest = rest[len(lab) :]
            node = e.child
        return node.value

    def insert(self, seq: Tuple[int, ...], value: int) -> None:
        if not seq:
            self._root.value = int(value)
            return
        node = self._root
        rest = seq
        while rest:
            first = rest[0]
            e = node.edges.get(first)
            if e is None:
                child = _Node()
                child.value = int(value)
                node.edges[first] = _Edge(label=rest, child=child)
                return

            lab = e.label
            i = _lcp(rest, lab)

            # Full edge match, continue.
            if i == len(lab):
                node = e.child
                rest = rest[i:]
                continue

            # Need to split the existing edge at i.
            # Create intermediate node for the common prefix.
            common = lab[:i]
            old_suffix = lab[i:]
            new_suffix = rest[i:]

            mid = _Node()
            # Replace edge with common prefix -> mid
            node.edges[first] = _Edge(label=common, child=mid)

            # Reattach old edge suffix
            mid.edges[old_suffix[0]] = _Edge(label=old_suffix, child=e.child)

            if not new_suffix:
                # New sequence ends at the split.
                mid.value = int(value)
                return

            # Attach new suffix as fresh edge
            new_child = _Node()
            new_child.value = int(value)
            mid.edges[new_suffix[0]] = _Edge(label=new_suffix, child=new_child)
            return

        node.value = int(value)




---
File: /thermo_manifold/spectral/__init__.py
---

"""Spectral manifolds for frequency-domain thermodynamics."""

from .manifold import SpectralManifold, SpectralOutput
from .unified import UnifiedManifold, UnifiedParticle, UnifiedOutput, Modality

__all__ = [
    "SpectralManifold",
    "SpectralOutput", 
    "UnifiedManifold",
    "UnifiedParticle",
    "UnifiedOutput",
    "Modality",
]



---
File: /thermo_manifold/spectral/manifold.py
---

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import torch

from ..core.config import PhysicsConfig
from ..core.state import BatchState
from ..physics.engine import ThermodynamicEngine


@dataclass
class SpectralOutput:
    frequencies: torch.Tensor
    amplitudes: torch.Tensor
    meta: Dict[str, Any]


class SpectralManifold(ThermodynamicEngine):
    """1D thermodynamic diffusion over frequency attractors."""

    def __init__(self, config: PhysicsConfig, device: torch.device):
        super().__init__(config, device)

        self.particles = BatchState.empty()
        self.attractors = BatchState.empty()

    def set_targets(self, freqs: torch.Tensor, energy: Optional[torch.Tensor] = None) -> None:
        freqs = freqs.to(device=self.device, dtype=torch.float32).flatten()
        m = int(freqs.numel())
        if m == 0:
            self.attractors = BatchState.empty()
            return
        if energy is None:
            energy = torch.ones(m, device=self.device, dtype=torch.float32) / (m + self.cfg.eps)
        else:
            energy = energy.to(device=self.device, dtype=torch.float32).flatten()
            energy = energy / (energy.sum() + self.cfg.eps)

        self.attractors = BatchState(
            {
                "position": freqs.clamp(min=self.cfg.eps),
                "energy": energy,
                "heat": torch.zeros(m, device=self.device, dtype=torch.float32),
            }
        )

    def seed_particles(self, n: int) -> None:
        n = int(n)
        if n <= 0 or self.attractors.n == 0:
            self.particles = BatchState.empty()
            return
        freqs = self.attractors.get("position")
        probs = self.attractors.get("energy").clamp(min=0.0)
        probs = probs / (probs.sum() + self.cfg.eps)
        idx = torch.multinomial(probs, n, replacement=True)
        base = freqs[idx]

        # Dispersion emerges from target spread.
        spread = freqs.std() + self.cfg.eps
        noise = torch.randn(n, device=self.device) * spread
        pos = (base + noise).clamp(min=self.cfg.eps)

        self.particles = BatchState(
            {
                "position": pos,
                "energy": torch.ones(n, device=self.device, dtype=torch.float32) / (n + self.cfg.eps),
                "heat": torch.zeros(n, device=self.device, dtype=torch.float32),
            }
        )

    # ----------------------------
    # Engine overrides
    # ----------------------------

    def candidate_edges(self) -> Tuple[torch.Tensor, torch.Tensor]:
        n = self.particles.n
        m = self.attractors.n
        if n == 0 or m == 0:
            return (
                torch.empty(0, dtype=torch.long, device=self.device),
                torch.empty(0, dtype=torch.long, device=self.device),
            )

        a = self.attractors.get("position")
        a_sorted, order = torch.sort(a)
        p = self.particles.get("position")
        # insertion indices in sorted attractors
        ins = torch.searchsorted(a_sorted, p)

        left = (ins - 1).clamp(min=0, max=m - 1)
        right = ins.clamp(min=0, max=m - 1)

        # Map back to original attractor indices.
        left_idx = order[left]
        right_idx = order[right]

        src = torch.arange(n, device=self.device, dtype=torch.long)
        src2 = torch.cat([src, src], dim=0)
        dst2 = torch.cat([left_idx, right_idx], dim=0)

        # Remove duplicates (when left==right).
        keep = torch.ones(src2.numel(), device=self.device, dtype=torch.bool)
        # duplicates occur at positions i and i+n
        dup = left_idx == right_idx
        keep[n:][dup] = False

        return src2[keep], dst2[keep]

    def distance(self, p_pos: torch.Tensor, a_pos: torch.Tensor) -> torch.Tensor:
        return (p_pos - a_pos).abs()

    def post_step(self) -> None:
        # Ensure positive frequencies.
        if self.particles.n:
            self.particles.set("position", self.particles.get("position").clamp(min=self.cfg.eps))

    # ----------------------------
    # Readout
    # ----------------------------

    def output_state(self, topk: Optional[int] = None) -> SpectralOutput:
        if self.particles.n == 0:
            return SpectralOutput(
                frequencies=torch.empty(0, device=self.device),
                amplitudes=torch.empty(0, device=self.device),
                meta={"empty": True},
            )
        freqs = self.particles.get("position")
        amps = self.particles.get("energy")
        if topk is not None and freqs.numel() > int(topk):
            k = int(topk)
            idx = torch.topk(amps, k=k).indices
            freqs = freqs[idx]
            amps = amps[idx]
        meta = {
            "num_particles": int(self.particles.n),
            "num_targets": int(self.attractors.n),
        }
        return SpectralOutput(frequencies=freqs, amplitudes=amps, meta=meta)



---
File: /thermo_manifold/spectral/unified.py
---

"""
Unified Spectral Manifold

A dimensionality-agnostic thermodynamic manifold where particles from any modality
can coexist. Text tokens, audio frequencies, image frequencies, video frequencies—
all just particles with positions in a continuous space.

The manifold doesn't know or care about modality. Modality is:
1. Determined by which encoder created the particle
2. Emergent from which region of the space the particle occupies
3. Used by decoders to select which particles to render

This enables true native multimodality: not adapters glued together,
but a unified dynamics where cross-modal relationships emerge naturally.
"""

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum, auto
from typing import Any, Dict, List, Optional, Tuple, Union

import torch

from ..core.config import PhysicsConfig
from ..core.state import BatchState
from ..physics.engine import ThermodynamicEngine


class Modality(Enum):
    """Modality tags for particles. Used by decoders, not by the manifold itself."""
    TEXT = auto()
    AUDIO = auto()
    IMAGE = auto()
    VIDEO = auto()
    UNKNOWN = auto()


@dataclass
class UnifiedParticle:
    """A particle in the unified manifold.
    
    The position can be any dimensionality:
    - Text: D-dimensional embedding
    - Audio: 1D frequency
    - Image: 2D frequency (u, v)
    - Video: 3D frequency (u, v, t)
    
    The manifold doesn't care—it just computes distances and flows.
    """
    position: torch.Tensor  # Shape: [D] where D is any dimensionality
    energy: torch.Tensor    # Scalar
    heat: torch.Tensor      # Scalar
    modality: Modality = Modality.UNKNOWN
    
    # Optional: additional properties for rendering
    phase: Optional[torch.Tensor] = None  # For frequency-domain particles
    token_id: Optional[int] = None        # For text particles


@dataclass 
class UnifiedOutput:
    """Output from the unified manifold."""
    particles: List[UnifiedParticle]
    by_modality: Dict[Modality, List[int]]  # modality -> particle indices
    meta: Dict[str, Any]


class UnifiedManifold(ThermodynamicEngine):
    """
    Dimensionality-agnostic thermodynamic manifold.
    
    All particles live in a shared space. The manifold processes them
    with the same thermodynamic dynamics regardless of their origin
    or intended output modality.
    
    Key insight: particles of different dimensionalities can coexist
    if we project them into a common embedding space for distance
    computation, while preserving their native coordinates for decoding.
    """
    
    def __init__(
        self, 
        config: PhysicsConfig, 
        device: torch.device,
        embed_dim: int = 256,
    ):
        super().__init__(config, device)
        self.embed_dim = embed_dim
        
        # Storage for heterogeneous particles
        self._particles: List[UnifiedParticle] = []
        self._attractors: List[UnifiedParticle] = []
        
        # Projection matrices for different dimensionalities → common space
        # Lazily initialized as we encounter new dimensionalities
        self._projections: Dict[int, torch.Tensor] = {}
        
        # Modality region centers (learned/adapted over time)
        self._modality_centers: Dict[Modality, torch.Tensor] = {}
        
    def _get_projection(self, dim: int) -> torch.Tensor:
        """Get or create projection matrix for a given dimensionality."""
        if dim not in self._projections:
            if dim == self.embed_dim:
                # Identity projection
                self._projections[dim] = torch.eye(
                    dim, device=self.device, dtype=torch.float32
                )
            elif dim < self.embed_dim:
                # Pad with zeros (or use learned projection)
                proj = torch.zeros(dim, self.embed_dim, device=self.device, dtype=torch.float32)
                proj[:, :dim] = torch.eye(dim, device=self.device, dtype=torch.float32)
                self._projections[dim] = proj
            else:
                # Project down (random projection preserves distances approximately)
                proj = torch.randn(dim, self.embed_dim, device=self.device, dtype=torch.float32)
                proj = proj / (torch.linalg.norm(proj, dim=1, keepdim=True) + self.cfg.eps)
                self._projections[dim] = proj
        return self._projections[dim]
    
    def _to_common_space(self, position: torch.Tensor) -> torch.Tensor:
        """Project a position to the common embedding space."""
        dim = position.numel()
        proj = self._get_projection(dim)
        return position.flatten() @ proj
    
    def _update_modality_center(self, modality: Modality, position: torch.Tensor) -> None:
        """Update running average of modality region center."""
        common_pos = self._to_common_space(position)
        if modality not in self._modality_centers:
            self._modality_centers[modality] = common_pos.clone()
        else:
            # EMA update
            alpha = self.cfg.dt / (self.cfg.tau + self.cfg.dt)
            self._modality_centers[modality] = (
                (1 - alpha) * self._modality_centers[modality] + alpha * common_pos
            )
    
    # =========================================================================
    # Particle Management
    # =========================================================================
    
    def add_particle(
        self,
        position: torch.Tensor,
        energy: float = 1.0,
        heat: float = 0.0,
        modality: Modality = Modality.UNKNOWN,
        phase: Optional[torch.Tensor] = None,
        token_id: Optional[int] = None,
    ) -> int:
        """Add a particle to the manifold. Returns particle index."""
        particle = UnifiedParticle(
            position=position.to(device=self.device, dtype=torch.float32).flatten(),
            energy=torch.tensor(energy, device=self.device, dtype=torch.float32),
            heat=torch.tensor(heat, device=self.device, dtype=torch.float32),
            modality=modality,
            phase=phase.to(device=self.device, dtype=torch.float32) if phase is not None else None,
            token_id=token_id,
        )
        self._particles.append(particle)
        self._update_modality_center(modality, particle.position)
        return len(self._particles) - 1
    
    def add_attractor(
        self,
        position: torch.Tensor,
        energy: float = 1.0,
        modality: Modality = Modality.UNKNOWN,
    ) -> int:
        """Add an attractor to the manifold. Returns attractor index."""
        attractor = UnifiedParticle(
            position=position.to(device=self.device, dtype=torch.float32).flatten(),
            energy=torch.tensor(energy, device=self.device, dtype=torch.float32),
            heat=torch.tensor(0.0, device=self.device, dtype=torch.float32),
            modality=modality,
        )
        self._attractors.append(attractor)
        self._update_modality_center(modality, attractor.position)
        return len(self._attractors) - 1
    
    def clear(self) -> None:
        """Clear all particles and attractors."""
        self._particles.clear()
        self._attractors.clear()
    
    # =========================================================================
    # Batch Encoding (for use with modal encoders)
    # =========================================================================
    
    def encode_text(self, embeddings: torch.Tensor, token_ids: Optional[List[int]] = None) -> List[int]:
        """
        Add text particles from embeddings.
        
        Args:
            embeddings: [N, D] tensor of token embeddings
            token_ids: Optional list of token IDs for decoding
            
        Returns:
            List of particle indices
        """
        embeddings = embeddings.to(device=self.device, dtype=torch.float32)
        if embeddings.ndim == 1:
            embeddings = embeddings.unsqueeze(0)
        
        indices = []
        for i in range(embeddings.shape[0]):
            idx = self.add_particle(
                position=embeddings[i],
                modality=Modality.TEXT,
                token_id=token_ids[i] if token_ids else None,
            )
            indices.append(idx)
        return indices
    
    def encode_image(
        self, 
        image: torch.Tensor,
        top_k: Optional[int] = None,
    ) -> List[int]:
        """
        Add image particles from an image via 2D FFT.
        
        Args:
            image: [H, W] or [C, H, W] tensor (grayscale or color)
            top_k: Only keep top-k frequency components by magnitude
            
        Returns:
            List of particle indices
        """
        image = image.to(device=self.device, dtype=torch.float32)
        
        # Handle color images by converting to grayscale for now
        if image.ndim == 3:
            if image.shape[0] in (1, 3, 4):
                # Channel first: average channels
                image = image.mean(dim=0)
            else:
                # Assume [H, W, C]
                image = image.mean(dim=-1)
        
        # 2D FFT
        spectrum = torch.fft.fft2(image)
        spectrum_shifted = torch.fft.fftshift(spectrum)
        
        magnitudes = spectrum_shifted.abs()
        phases = spectrum_shifted.angle()
        
        H, W = image.shape
        
        # Create frequency coordinates
        u_coords = torch.arange(H, device=self.device, dtype=torch.float32) - H // 2
        v_coords = torch.arange(W, device=self.device, dtype=torch.float32) - W // 2
        uu, vv = torch.meshgrid(u_coords, v_coords, indexing='ij')
        
        # Flatten everything
        mags_flat = magnitudes.flatten()
        phases_flat = phases.flatten()
        u_flat = uu.flatten()
        v_flat = vv.flatten()
        
        # Select top-k if specified
        if top_k is not None and top_k < mags_flat.numel():
            _, top_indices = torch.topk(mags_flat, top_k)
            mags_flat = mags_flat[top_indices]
            phases_flat = phases_flat[top_indices]
            u_flat = u_flat[top_indices]
            v_flat = v_flat[top_indices]
        
        # Normalize magnitudes to energy
        total_mag = mags_flat.sum() + self.cfg.eps
        energies = mags_flat / total_mag
        
        # Add particles
        indices = []
        for i in range(mags_flat.numel()):
            # Position is 2D frequency coordinate
            position = torch.stack([u_flat[i], v_flat[i]])
            phase = phases_flat[i].unsqueeze(0)
            
            idx = self.add_particle(
                position=position,
                energy=float(energies[i].item()),
                modality=Modality.IMAGE,
                phase=phase,
            )
            indices.append(idx)
        
        return indices
    
    def encode_audio(
        self,
        waveform: torch.Tensor,
        sample_rate: int = 44100,
        top_k: Optional[int] = None,
    ) -> List[int]:
        """
        Add audio particles from a waveform via 1D FFT.
        
        Args:
            waveform: [N] tensor of audio samples
            sample_rate: Sample rate in Hz
            top_k: Only keep top-k frequency components
            
        Returns:
            List of particle indices
        """
        waveform = waveform.to(device=self.device, dtype=torch.float32).flatten()
        
        # 1D FFT
        spectrum = torch.fft.rfft(waveform)
        magnitudes = spectrum.abs()
        phases = spectrum.angle()
        
        # Frequency bins
        n = waveform.numel()
        freqs = torch.fft.rfftfreq(n, d=1.0/sample_rate).to(device=self.device)
        
        # Select top-k if specified
        if top_k is not None and top_k < magnitudes.numel():
            _, top_indices = torch.topk(magnitudes, top_k)
            magnitudes = magnitudes[top_indices]
            phases = phases[top_indices]
            freqs = freqs[top_indices]
        
        # Normalize to energy
        total_mag = magnitudes.sum() + self.cfg.eps
        energies = magnitudes / total_mag
        
        # Add particles
        indices = []
        for i in range(magnitudes.numel()):
            position = freqs[i].unsqueeze(0)  # 1D position
            phase = phases[i].unsqueeze(0)
            
            idx = self.add_particle(
                position=position,
                energy=float(energies[i].item()),
                modality=Modality.AUDIO,
                phase=phase,
            )
            indices.append(idx)
        
        return indices
    
    # =========================================================================
    # Decoding (Attractor-based modality selection)
    # =========================================================================
    
    def decode_image(self, output_shape: Tuple[int, int]) -> torch.Tensor:
        """
        Decode image-modality particles back to an image.
        
        Uses attractor dynamics: particles near the image modality center
        are selected and their frequencies reconstructed via iFFT2D.
        """
        H, W = output_shape
        
        # Initialize spectrum
        spectrum = torch.zeros(H, W, dtype=torch.complex64, device=self.device)
        
        # Collect image particles
        for p in self._particles:
            if p.modality != Modality.IMAGE:
                continue
            if p.position.numel() != 2:
                continue  # Not a 2D frequency
            
            u, v = p.position[0], p.position[1]
            
            # Convert back to spectrum indices
            u_idx = int(u.item() + H // 2)
            v_idx = int(v.item() + W // 2)
            
            if 0 <= u_idx < H and 0 <= v_idx < W:
                magnitude = p.energy.item()
                phase = p.phase[0].item() if p.phase is not None else 0.0
                spectrum[u_idx, v_idx] = magnitude * torch.exp(
                    torch.tensor(1j * phase, device=self.device)
                )
        
        # Inverse shift and FFT
        spectrum_unshifted = torch.fft.ifftshift(spectrum)
        image = torch.fft.ifft2(spectrum_unshifted).real
        
        return image
    
    def decode_audio(self, num_samples: int, sample_rate: int = 44100) -> torch.Tensor:
        """
        Decode audio-modality particles back to a waveform.
        """
        # Number of frequency bins for rfft
        n_freqs = num_samples // 2 + 1
        spectrum = torch.zeros(n_freqs, dtype=torch.complex64, device=self.device)
        
        # Frequency resolution
        freq_resolution = sample_rate / num_samples
        
        for p in self._particles:
            if p.modality != Modality.AUDIO:
                continue
            if p.position.numel() != 1:
                continue
            
            freq = p.position[0].item()
            freq_idx = int(freq / freq_resolution)
            
            if 0 <= freq_idx < n_freqs:
                magnitude = p.energy.item()
                phase = p.phase[0].item() if p.phase is not None else 0.0
                spectrum[freq_idx] = magnitude * torch.exp(
                    torch.tensor(1j * phase, device=self.device)
                )
        
        # Inverse FFT
        waveform = torch.fft.irfft(spectrum, n=num_samples)
        
        return waveform
    
    def decode_text(self, vocab: List[str], top_k: int = 1) -> List[Tuple[str, float]]:
        """
        Decode text-modality particles to tokens.
        
        Returns tokens with highest energy.
        """
        text_particles = [
            (p.token_id, p.energy.item()) 
            for p in self._particles 
            if p.modality == Modality.TEXT and p.token_id is not None
        ]
        
        if not text_particles:
            return []
        
        # Sort by energy
        text_particles.sort(key=lambda x: x[1], reverse=True)
        
        results = []
        for token_id, energy in text_particles[:top_k]:
            if 0 <= token_id < len(vocab):
                results.append((vocab[token_id], energy))
        
        return results
    
    # =========================================================================
    # Thermodynamic Step (Override to handle heterogeneous particles)
    # =========================================================================
    
    def _build_batch_state(self) -> None:
        """Convert particle list to BatchState for engine."""
        if not self._particles:
            self.particles = BatchState.empty()
        else:
            # Project all to common space for dynamics
            positions = torch.stack([
                self._to_common_space(p.position) for p in self._particles
            ])
            energies = torch.stack([p.energy for p in self._particles])
            heats = torch.stack([p.heat for p in self._particles])
            
            self.particles = BatchState({
                "position": positions,
                "energy": energies,
                "heat": heats,
            })
        
        if not self._attractors:
            self.attractors = BatchState.empty()
        else:
            positions = torch.stack([
                self._to_common_space(a.position) for a in self._attractors
            ])
            energies = torch.stack([a.energy for a in self._attractors])
            heats = torch.stack([a.heat for a in self._attractors])
            
            self.attractors = BatchState({
                "position": positions,
                "energy": energies,
                "heat": heats,
            })
    
    def _sync_from_batch_state(self) -> None:
        """Sync updates back to particle list."""
        if self.particles.n == 0:
            return
        
        positions = self.particles.get("position")
        energies = self.particles.get("energy")
        heats = self.particles.get("heat")
        
        for i, p in enumerate(self._particles):
            # Update energy and heat (position in common space doesn't 
            # directly map back to native space trivially, so we skip that)
            p.energy = energies[i]
            p.heat = heats[i]
    
    def step(self) -> None:
        """One step of unified thermodynamic dynamics."""
        self._build_batch_state()
        self.step_physics()
        self._sync_from_batch_state()
    
    # =========================================================================
    # Output
    # =========================================================================
    
    def output_state(self) -> UnifiedOutput:
        """Get current state organized by modality."""
        by_modality: Dict[Modality, List[int]] = {m: [] for m in Modality}
        
        for i, p in enumerate(self._particles):
            by_modality[p.modality].append(i)
        
        return UnifiedOutput(
            particles=self._particles.copy(),
            by_modality=by_modality,
            meta={
                "num_particles": len(self._particles),
                "num_attractors": len(self._attractors),
                "modality_counts": {m.name: len(v) for m, v in by_modality.items()},
            },
        )



---
File: /thermo_manifold/tests/__init__.py
---

"""Tests for thermodynamic manifolds."""



---
File: /thermo_manifold/tests/test_bridge_heat.py
---

from __future__ import annotations

import torch

from thermo_manifold.bridge.manifold import BridgeManifold


def test_bridge_heat_increases_on_mismatch() -> None:
    device = torch.device("cpu")
    sem_dim = 4
    bins = torch.linspace(0.0, 1.0, steps=8, device=device)
    bridge = BridgeManifold(sem_dim=sem_dim, spec_bins=bins, dt=1e-2, device=device, num_carriers=4)

    # Contradictory evidence: fixed semantic inputs with alternating spectral positions.
    sem_pos = torch.randn(6, sem_dim, device=device)
    spec_pos = torch.tensor([0.0, 1.0, 0.0, 1.0, 0.0, 1.0], device=device)

    heat_means = []
    for _ in range(6):
        out = bridge.observe(sem_pos=sem_pos, spec_pos=spec_pos)
        heat_means.append(out.heat_mean)

    assert heat_means[-1] > heat_means[0]



---
File: /thermo_manifold/tests/test_hunger.py
---

from __future__ import annotations

import sys
from pathlib import Path

import torch

ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.semantic.manifold import SemanticManifold


def test_hunger_increases_on_dead_end_dreams() -> None:
    device = torch.device("cpu")
    cfg = PhysicsConfig(dt=1e-2, tau=1.0)
    vocab = ["A", "B", "C"]
    brain = SemanticManifold(cfg, device, vocab=vocab, embed_dim=3)

    # No edges => immediate dead end.
    a = 0
    exc = brain.attractors.get("excitation")
    exc[a] = 1.0
    brain.attractors.set("excitation", exc)

    h0 = float(brain.hunger[a].item())
    brain.idle_think(steps=2, dream_steps=4)
    h1 = float(brain.hunger[a].item())
    assert h1 > h0



---
File: /thermo_manifold/tests/test_multi_resolution_chunks.py
---

from __future__ import annotations

import sys
from pathlib import Path

import torch

ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.semantic.hierarchical import HierarchicalSemanticManifold


def test_multi_resolution_nucleation_creates_variable_length_chunks() -> None:
    device = torch.device("cpu")
    cfg = PhysicsConfig(dt=1e-2, tau=1.0)
    vocab = ["<bos>", "a", "b", "c", "<eos>"]
    brain = HierarchicalSemanticManifold(cfg, device, vocab=vocab, embed_dim=5, chunk_min_len=2, chunk_max_len=4)

    # Build a context long enough for 2/3/4 candidates.
    ids = torch.tensor([0, 1, 2, 3], device=device, dtype=torch.long)
    brain.ingest_ids(ids)

    # Seed strong bigram bonds for the last 4-tokens: a->b, b->c, c-><eos> missing so 4-gram should not win.
    a, b, c = 1, 2, 3
    brain.graph.add_edges(torch.tensor([a, b], device=device), torch.tensor([b, c], device=device), torch.tensor(5.0, device=device))

    # Force baselines low so condensation can occur on first call.
    brain.chunks._binding_baseline_by_len[2] = torch.tensor(0.0, device=device)
    brain.chunks._binding_baseline_by_len[3] = torch.tensor(0.0, device=device)
    brain.chunks._binding_baseline_by_len[4] = torch.tensor(0.0, device=device)

    ratio = brain._homeostasis_ratio().to(torch.float32)
    brain._chunk_condensation(ratio=ratio)

    assert brain.chunks.num_chunks >= 1
    # Stored sequences are variable-length, tracked by seq_len.
    assert brain.chunks.seq_len.numel() == brain.chunks.num_chunks



---
File: /thermo_manifold/tests/test_transitive_closure.py
---

from __future__ import annotations

import sys
from pathlib import Path

import torch

ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from thermo_manifold.core.config import PhysicsConfig
from thermo_manifold.semantic.manifold import SemanticManifold


def test_transitive_closure_adds_shortcut_edge() -> None:
    device = torch.device("cpu")
    cfg = PhysicsConfig(dt=1e-2, tau=1.0)
    vocab = ["A", "B", "C"]
    brain = SemanticManifold(cfg, device, vocab=vocab, embed_dim=3)

    # Seed A->B and B->C edges.
    a, b, c = 0, 1, 2
    brain.graph.add_edges(torch.tensor([a], device=device), torch.tensor([b], device=device), torch.tensor(1.0, device=device))
    brain.graph.add_edges(torch.tensor([b], device=device), torch.tensor([c], device=device), torch.tensor(1.0, device=device))

    # Make A active so closure considers it.
    exc = brain.attractors.get("excitation")
    exc[a] = 1.0
    brain.attractors.set("excitation", exc)

    brain.idle_think(steps=3, dream_steps=2)

    w, _, exists = brain.graph.get_edges(torch.tensor([a], device=device), torch.tensor([c], device=device))
    assert bool(exists.item())
    assert float(w.item()) > 0.0



---
File: /thermo_manifold/__init__.py
---

"""Thermo Manifold: emergent thermodynamic AI primitives."""

from __future__ import annotations

from .core.config import PhysicsConfig

__all__ = [
    "PhysicsConfig",
    # Lazily resolved (torch-backed):
    "SemanticManifold",
    "HierarchicalSemanticManifold",
    "SpectralManifold",
    "BridgeManifold",
]


def __getattr__(name: str):  # pragma: no cover
    # Avoid importing torch unless a torch-backed API is actually accessed.
    if name == "SemanticManifold":
        from .semantic.manifold import SemanticManifold as _SemanticManifold

        return _SemanticManifold
    if name == "HierarchicalSemanticManifold":
        from .semantic.hierarchical import (
            HierarchicalSemanticManifold as _HierarchicalSemanticManifold,
        )

        return _HierarchicalSemanticManifold
    if name == "SpectralManifold":
        from .spectral.manifold import SpectralManifold as _SpectralManifold

        return _SpectralManifold
    if name == "BridgeManifold":
        from .bridge.manifold import BridgeManifold as _BridgeManifold

        return _BridgeManifold
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")



---
File: /README.md
---

# Thermo Manifold

**Thermodynamic Primitives for Neural Computation Without Backpropagation**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

---

## Overview

Thermo Manifold is a reference implementation exploring an alternative paradigm for machine learning: **thermodynamic computation**. Instead of relying on backpropagation and gradient descent, this framework models learning and inference as physical processes—energy flow, heat diffusion, and homeostatic regulation—operating on sparse graph structures.

The core insight is that learning can emerge from local, Hebbian-style dynamics governed by thermodynamic principles, enabling:

- **Online, continuous learning** from streaming data
- **Emergent structure formation** without explicit supervision
- **Multi-modal transduction** between semantic and spectral domains
- **Self-organization** through energy minimization and homeostasis

This repository accompanies our paper and serves as the canonical implementation for reproducing experimental results.

---

## Key Concepts

### Thermodynamic Learning

Traditional neural networks compute gradients through the entire network via backpropagation. Thermo Manifold takes a different approach: each component operates as a thermodynamic system where:

- **Energy** represents activation strength and information salience
- **Heat** captures uncertainty and exploratory noise
- **Homeostasis** maintains stable operating regimes through adaptive baselines
- **Surprise** modulates plasticity, enabling rapid adaptation to novel patterns

### Sparse Bond Graphs

Rather than dense weight matrices, relationships are encoded in sparse directed graphs:

```
Token A ──[bond strength]──▶ Token B
```

Bonds strengthen through co-activation and weaken through disuse, implementing a form of Hebbian learning. This representation scales efficiently and naturally captures the sparsity of real-world sequential patterns.

### Hierarchical Abstraction

The system discovers compositional structure through **chunk formation**:

1. Frequently co-occurring token sequences condense into chunks
2. Chunks participate in higher-level bond graphs
3. Top-down biases from chunks guide token-level predictions

This emerges from binding energy dynamics rather than explicit segmentation algorithms.

---

## Architecture

Thermo Manifold consists of four interconnected manifolds:

```
┌─────────────────────────────────────────────────────────────────┐
│                        INPUT (Tokens)                           │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    SEMANTIC MANIFOLD                            │
│  • Sparse bond graphs (token → token)                           │
│  • Thermodynamic flow propagation                               │
│  • Surprise-driven plasticity                                   │
│  • Idle pondering (transitive closure, dream rollouts)          │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│               HIERARCHICAL SEMANTIC MANIFOLD                    │
│  • Variable-length chunks (2-4 tokens)                          │
│  • Chunk ↔ token bipartite bonds                                │
│  • Binding energy condensation                                  │
│  • Multi-resolution representation                              │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                     BRIDGE MANIFOLD                             │
│  • Semantic vectors ↔ spectral frequencies                      │
│  • Carrier population (not lookup tables)                       │
│  • Co-activation learning                                       │
│  • Event-horizon locality                                       │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    SPECTRAL MANIFOLD                            │
│  • 1D thermodynamic diffusion                                   │
│  • Frequency attractor dynamics                                 │
│  • Audio synthesis from spectral energy                         │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                       OUTPUT (Audio)                            │
└─────────────────────────────────────────────────────────────────┘
```

### Component Details

| Manifold | Purpose | Key Innovation |
|----------|---------|----------------|
| **SemanticManifold** | Token-level sequential grammar | Sparse bond graphs with thermodynamic flow |
| **HierarchicalSemanticManifold** | Multi-scale abstraction | Emergent chunk formation via binding energy |
| **BridgeManifold** | Cross-modal transduction | Carrier-based coupling without lookup tables |
| **SpectralManifold** | Audio generation | Particle diffusion toward frequency attractors |

---

## Installation

### Requirements

- Python 3.10+ (3.12 recommended)
- PyTorch 2.0+
- [uv](https://github.com/astral-sh/uv) package manager
- CUDA-capable GPU (recommended)

### Quick Setup

```bash
# Clone the repository
git clone https://github.com/theapemachine/thermo_manifold.git
cd thermo_manifold

# Install using make (creates venv and syncs dependencies)
make install
```

### Installation Options

```bash
make install          # Base dependencies only
make install-dev      # Include development tools (pytest, black, mypy, etc.)
make install-viz      # Include visualization (matplotlib)
make install-all      # Install everything
```

### Manual Setup

If you prefer not to use `make`:

```bash
python3.12 -m venv .venv
. .venv/bin/activate && uv sync

# With optional dependencies
. .venv/bin/activate && uv sync --extra dev --extra viz
```

---

## Quick Start

### Basic Usage

```python
from thermo_manifold import SemanticManifold, PhysicsConfig

# Initialize configuration
config = PhysicsConfig(
    dt=0.02,                        # Integration timestep
    tau=0.95,                       # Homeostasis time constant
    dream_sampling_temperature=1.0, # Exploration temperature
    dream_energy_budget=100,        # Pondering compute budget
)

# Create semantic manifold
manifold = SemanticManifold(
    vocab_size=10000,
    embed_dim=256,
    config=config,
)

# Training: observe token sequences
for sequence in training_data:
    manifold.observe(sequence)

# Inference: predict next token
context = [token_a, token_b, token_c]
prediction = manifold.predict(context)
```

### End-to-End Demo

```bash
python -m thermo_manifold.demos.unified_demo
```

This demonstrates the complete pipeline: text tokens → semantic manifold → bridge → spectral manifold → audio synthesis.

### Rule-Shift Benchmark

```bash
python -m thermo_manifold.demos.rule_shift_demo
```

Evaluates adaptation to distributional shifts, with diagnostic output for analysis.

---

## Project Structure

```
thermo_manifold/
├── __init__.py                 # Package exports
├── core/
│   ├── config.py              # PhysicsConfig, PhysicsMedium
│   ├── state.py               # BatchState container
│   ├── scatter.py             # Scatter operations (sum, max, softmax)
│   ├── diagnostics.py         # Logging (CSV/JSONL)
│   └── viz.py                 # Visualization utilities
├── physics/
│   └── engine.py              # ThermodynamicEngine base class
├── semantic/
│   ├── manifold.py            # SemanticManifold (token-level)
│   ├── hierarchical.py        # HierarchicalSemanticManifold
│   ├── bond_graph.py          # SparseBondGraph
│   ├── bipartite_graph.py     # SparseBipartiteBondGraph
│   ├── chunk_store.py         # ChunkStore (variable-length sequences)
│   └── radix_trie.py          # RadixTrie for efficient chunk lookup
├── bridge/
│   └── manifold.py            # BridgeManifold (semantic ↔ spectral)
├── spectral/
│   └── manifold.py            # SpectralManifold (audio synthesis)
├── demos/
│   ├── unified_demo.py        # End-to-end demonstration
│   └── rule_shift_demo.py     # Benchmark with diagnostics
└── tests/
    ├── test_bridge_heat.py
    ├── test_hunger.py
    ├── test_multi_resolution_chunks.py
    └── test_transitive_closure.py
```

---

## Configuration

The `PhysicsConfig` class controls all thermodynamic parameters:

```python
from thermo_manifold import PhysicsConfig, PhysicsMedium

config = PhysicsConfig(
    # Core dynamics
    dt=0.02,                # Integration timestep
    tau=0.95,               # Homeostasis decay (higher = slower adaptation)
    eps=1e-8,               # Numerical stability
    
    # Idle pondering
    dream_sampling_temperature=1.0,  # Exploration randomness
    dream_energy_budget=100,         # Compute budget for pondering
    
    # Carrier dynamics (for BridgeManifold)
    carrier_tau=0.9,        # Per-carrier homeostasis
    
    # Physical medium properties
    medium=PhysicsMedium(
        thermal_resistance=0.1,
        viscosity=0.05,
        diffusion_rate=0.01,
    ),
)
```

---

## Design Principles

1. **No Backpropagation**: All updates are local and Hebbian-style
2. **Sparse Structures**: Avoid dense V×V matrices; use directed graphs
3. **Emergent Behavior**: Structure forms from dynamics, not design
4. **Online Learning**: Continuous adaptation to streaming data
5. **Homeostatic Regulation**: Adaptive baselines prevent runaway activation
6. **Event-Horizon Locality**: Efficient neighbor search for scalability
7. **Scale-Free Operation**: Adaptive normalization, no hard thresholds

---

## Idle Pondering

A distinctive feature of Thermo Manifold is **idle pondering**—computation that occurs between observations to consolidate knowledge:

| Mechanism | Description | Benefit |
|-----------|-------------|---------|
| **Transitive Closure** | Infers shortcuts (A→C from A→B, B→C) | Accelerates future traversals |
| **Conflict Resolution** | Resolves ambiguous predictions | Improves consistency |
| **Dream Rollouts** | Explores hypothetical sequences | Discovers dead-ends, builds hunger signals |

This enables the system to improve without additional training data, similar to memory consolidation during sleep.

---

## Benchmarks

### Rule-Shift Adaptation

The `rule_shift_demo.py` evaluates how quickly the system adapts when underlying patterns change:

```
Step 1000: Pre-shift accuracy: 94.2%
Step 1001: Rule shift applied
Step 1010: Post-shift accuracy: 67.3%
Step 1050: Recovered accuracy: 89.1%
Step 1100: Recovered accuracy: 93.8%
```

Diagnostic metrics are logged to CSV/JSONL for analysis.

---

## Diagnostics

Enable comprehensive logging:

```python
from thermo_manifold.core.diagnostics import DiagnosticsLogger

logger = DiagnosticsLogger(
    output_dir="./logs",
    format="jsonl",  # or "csv"
)

manifold.attach_diagnostics(logger)
```

Captured metrics include:
- Bond graph statistics (edges, mean strength, pruning rate)
- Energy and heat distributions
- Chunk formation events
- Pondering outcomes (shortcuts found, dead-ends explored)

---

## Citation

If you use Thermo Manifold in your research, please cite:

```bibtex
@article{thermomanifold2026,
  title={Thermodynamic Primitives for Neural Computation Without Backpropagation},
  author={[Authors]},
  journal={[Journal/Conference]},
  year={2026},
  url={https://github.com/theapemachine/thermo_manifold}
}
```

---

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Install with development dependencies
make install-dev

# Run tests
make test

# Run tests with coverage
make test-cov

# Format code
make format

# Run linter
make lint

# Type checking
make typecheck

# Run all checks
make check
```

Run `make help` to see all available commands.

---

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## Acknowledgments

This work builds on insights from thermodynamic computing, Hebbian learning theory, and sparse representation research. We thank [acknowledgments] for valuable discussions and feedback.

---

<p align="center">
  <i>Learning as physics, not optimization.</i>
</p>

